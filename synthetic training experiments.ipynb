{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Generator import Generator\n",
    "from src.Discriminator import Discriminator\n",
    "from src.utils.tools import * \n",
    "from src.data.GenLoaders import *\n",
    "from src.training.trainer import *\n",
    "import torch\n",
    "torch.manual_seed(0); # Set for testing purposes, please do not change!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14542,  1396, 14523,  9599, 10534])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,val_loader=get_training_loaders(batch_size=32,file_name=\"stamp_dataset_only_images_63.pkl\",label_as_strings=True)\n",
    "labels = train_loader.dataset.labels.to(torch.int)\n",
    "torch.bincount(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Batch 0/1582 - Train loss: 1.5968174934387207, Train acc: 0.1875\n",
      "Iteration 100 - Batch 100/1582 - Train loss: 1.441270144859163, Train acc: 0.5392945544554455\n",
      "Iteration 200 - Batch 200/1582 - Train loss: 1.3890344426406556, Train acc: 0.5679415422885572\n",
      "Iteration 300 - Batch 300/1582 - Train loss: 1.35323227521193, Train acc: 0.5911544850498339\n",
      "Iteration 400 - Batch 400/1582 - Train loss: 1.3214685381796591, Train acc: 0.6160380299251871\n",
      "Iteration 500 - Batch 500/1582 - Train loss: 1.2994070226798753, Train acc: 0.6327345309381237\n",
      "Iteration 600 - Batch 600/1582 - Train loss: 1.283815517401735, Train acc: 0.644134775374376\n",
      "Iteration 700 - Batch 700/1582 - Train loss: 1.2685577053146253, Train acc: 0.6565174750356634\n",
      "Iteration 800 - Batch 800/1582 - Train loss: 1.2540841552797477, Train acc: 0.669085518102372\n",
      "Iteration 900 - Batch 900/1582 - Train loss: 1.2427103934224517, Train acc: 0.6785516093229744\n",
      "Iteration 1000 - Batch 1000/1582 - Train loss: 1.2320576567392607, Train acc: 0.6877809690309691\n",
      "Iteration 1100 - Batch 1100/1582 - Train loss: 1.2235670821651559, Train acc: 0.6950499545867393\n",
      "Iteration 1200 - Batch 1200/1582 - Train loss: 1.2158886580344144, Train acc: 0.701706910907577\n",
      "Iteration 1300 - Batch 1300/1582 - Train loss: 1.2091757141563362, Train acc: 0.707532667179093\n",
      "Iteration 1400 - Batch 1400/1582 - Train loss: 1.203376758064567, Train acc: 0.7125267665952891\n",
      "Iteration 1500 - Batch 1500/1582 - Train loss: 1.1974446439171218, Train acc: 0.717584110592938\n",
      "[3, 4, 4, 1, 3, 3, 4, 3, 1, 1, 2, 2, 1, 3, 3, 2, 4, 2, 2, 2, 4, 2, 2, 0, 0, 1, 1, 3, 4, 0, 1, 1, 3, 2, 4, 3, 3, 3, 2, 2, 2, 1, 4, 4, 3, 1, 1, 1, 0, 4, 1, 2, 4, 1, 3, 2, 4, 1, 3, 4, 0, 4, 3, 3, 3, 3, 4, 1, 1, 2, 4, 1, 4, 1, 3, 2, 0, 0, 1, 0, 3, 2, 0, 0, 1, 0, 1, 4, 2, 4, 4, 2, 2, 2, 1, 1, 1, 3, 0, 3, 1, 1, 1, 3, 0, 4, 4, 2, 4, 3, 0, 4, 0, 3, 0, 3, 0, 3, 4, 2, 0, 2, 1, 3, 3, 3, 1, 1, 0, 4, 3, 0, 0, 2, 0, 0, 1, 1, 3, 2, 1, 4, 2, 2, 3, 0, 2, 0, 4, 4, 1, 2, 1, 1, 2, 2, 3, 4, 0, 2, 0, 2, 0, 3, 1, 2, 4, 1, 3, 2, 1, 1, 0, 1, 2, 4, 4, 2, 2, 4, 3, 0, 0, 2, 2, 2, 3, 1, 4, 2, 0, 0, 1, 2, 4, 4, 4, 1, 3, 0, 4, 1, 0, 0, 4, 2, 4, 0, 1, 4, 4, 3, 2, 1, 0, 0, 1, 3, 3, 1, 1, 3, 2, 3, 3, 0, 3, 4, 3, 0, 0, 2, 4, 3, 1, 3, 1, 4, 0, 3, 1, 2, 0, 0, 0, 3, 4, 3, 3, 0, 2, 0, 4, 3, 0, 4, 4, 2, 2, 1, 3, 0, 1, 1, 3, 3, 0, 3, 2, 1, 4, 4, 1, 0, 3, 1, 3, 0, 1, 1, 0, 4, 0, 3, 4, 2, 4, 3, 2, 2, 1, 1, 0, 0, 1, 2, 2, 4, 4, 4, 2, 1, 4, 4, 3, 1, 3, 2, 1, 2, 4, 0, 4, 3, 0, 1, 0, 1, 1, 3, 1, 1, 0, 2, 2, 2, 2, 4, 1, 4, 4, 3, 3, 2, 0, 0, 4, 4, 0, 1, 4, 1, 0, 3, 3, 0, 0, 0, 0, 1, 2, 0, 3, 1, 1, 1, 2, 1, 2, 4, 4, 1, 3, 1, 4, 2, 3, 4, 4, 4, 0, 0, 3, 2, 0, 3, 2, 3, 0, 3, 1, 0, 2, 0, 0, 0, 3, 2, 4, 3, 0, 1, 4, 2, 2, 4, 2, 4, 1, 4, 3, 2, 2, 3, 3, 1, 4, 0, 1, 1, 1, 1, 0, 2, 2, 0, 0, 1, 3, 2, 0, 4, 2, 4, 2, 2, 1, 4, 4, 0, 0, 2, 4, 0, 0, 2, 1, 1, 2, 3, 4, 2, 3, 0, 3, 0, 3, 3, 2, 3, 1, 3, 4, 2, 4, 0, 1, 2, 3, 3, 0, 4, 1, 3, 3, 2, 4, 3, 0, 2, 4, 2, 0, 4, 0, 0, 0, 2, 3, 4, 4, 2, 3, 4, 3, 2, 0, 4, 3, 4, 4, 2, 0, 4, 0, 3, 2, 1, 4, 1]\n",
      "[3, 4, 4, 3, 3, 3, 4, 3, 3, 2, 0, 2, 4, 3, 4, 4, 4, 2, 2, 2, 4, 4, 0, 0, 0, 4, 0, 3, 4, 0, 4, 4, 2, 2, 4, 3, 3, 0, 2, 2, 0, 2, 4, 4, 3, 4, 0, 3, 0, 4, 3, 2, 4, 3, 4, 0, 4, 4, 3, 4, 0, 4, 3, 3, 3, 3, 4, 4, 4, 2, 2, 4, 4, 4, 3, 2, 0, 0, 4, 0, 4, 2, 0, 0, 4, 0, 2, 4, 2, 4, 4, 2, 0, 2, 4, 4, 4, 4, 2, 3, 2, 0, 3, 4, 0, 4, 4, 2, 4, 4, 0, 4, 0, 3, 4, 3, 0, 3, 4, 2, 0, 4, 0, 3, 3, 3, 4, 0, 0, 4, 4, 0, 2, 2, 0, 0, 3, 2, 3, 2, 4, 4, 2, 2, 3, 4, 2, 0, 4, 4, 3, 0, 4, 4, 2, 2, 3, 4, 0, 2, 2, 3, 0, 3, 0, 2, 4, 0, 3, 2, 2, 4, 0, 2, 2, 4, 4, 0, 2, 4, 3, 0, 2, 2, 2, 2, 3, 2, 4, 2, 0, 0, 4, 2, 4, 4, 4, 4, 3, 0, 4, 3, 2, 0, 4, 2, 4, 0, 4, 4, 4, 3, 2, 3, 0, 0, 0, 3, 3, 4, 4, 3, 2, 3, 3, 0, 3, 4, 3, 0, 0, 2, 4, 3, 3, 3, 4, 4, 0, 3, 3, 0, 0, 0, 0, 3, 4, 3, 3, 0, 0, 0, 4, 3, 4, 4, 4, 2, 2, 0, 3, 0, 0, 4, 3, 3, 0, 3, 2, 4, 4, 4, 4, 0, 3, 4, 3, 4, 3, 4, 0, 2, 0, 4, 4, 3, 4, 3, 0, 2, 4, 4, 0, 0, 0, 0, 2, 2, 4, 2, 2, 2, 4, 4, 3, 4, 4, 2, 4, 2, 3, 0, 4, 3, 0, 4, 0, 4, 4, 3, 4, 0, 4, 0, 2, 2, 2, 4, 4, 4, 4, 3, 4, 2, 0, 0, 4, 4, 0, 4, 4, 4, 0, 4, 3, 0, 0, 0, 0, 3, 2, 0, 3, 4, 4, 3, 2, 0, 2, 4, 4, 4, 4, 0, 4, 2, 3, 4, 4, 4, 0, 0, 4, 0, 0, 3, 0, 3, 2, 3, 0, 0, 2, 0, 0, 0, 3, 2, 4, 3, 0, 3, 4, 2, 2, 4, 2, 4, 0, 4, 3, 0, 2, 3, 4, 4, 4, 0, 4, 2, 4, 4, 0, 2, 2, 0, 0, 0, 4, 0, 2, 4, 0, 4, 2, 2, 0, 4, 3, 0, 0, 2, 4, 2, 0, 3, 0, 4, 2, 4, 2, 2, 3, 4, 4, 0, 3, 3, 2, 3, 0, 3, 4, 2, 4, 0, 4, 2, 3, 3, 2, 4, 0, 0, 3, 2, 4, 3, 0, 2, 4, 0, 0, 4, 0, 0, 0, 2, 3, 4, 4, 2, 3, 4, 4, 0, 0, 4, 3, 4, 4, 2, 0, 4, 4, 3, 2, 0, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.84      0.74       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.75      0.75      0.75       100\n",
      "           3       0.79      0.79      0.79       100\n",
      "           4       0.54      0.93      0.68       100\n",
      "\n",
      "    accuracy                           0.66       500\n",
      "   macro avg       0.55      0.66      0.59       500\n",
      "weighted avg       0.55      0.66      0.59       500\n",
      "\n",
      "Val loss: 1.2382597848773003, Val acc: 0.662\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1600 - Batch 18/1582 - Train loss: 1.1329693355058368, Train acc: 0.774671052631579\n",
      "Iteration 1700 - Batch 118/1582 - Train loss: 1.1273655535794105, Train acc: 0.7762605042016807\n",
      "Iteration 1800 - Batch 218/1582 - Train loss: 1.1210041797324404, Train acc: 0.7833904109589042\n",
      "Iteration 1900 - Batch 318/1582 - Train loss: 1.1123830042662666, Train acc: 0.7922217868338558\n",
      "Iteration 2000 - Batch 418/1582 - Train loss: 1.1109156810582965, Train acc: 0.7937798329355609\n",
      "Iteration 2100 - Batch 518/1582 - Train loss: 1.1094842109836365, Train acc: 0.7950987475915221\n",
      "Iteration 2200 - Batch 618/1582 - Train loss: 1.1088490596880627, Train acc: 0.795890549273021\n",
      "Iteration 2300 - Batch 718/1582 - Train loss: 1.1079034451317555, Train acc: 0.7968532684283728\n",
      "Iteration 2400 - Batch 818/1582 - Train loss: 1.1061371107823392, Train acc: 0.7984203296703297\n",
      "Iteration 2500 - Batch 918/1582 - Train loss: 1.1066813249063958, Train acc: 0.7980141458106638\n",
      "Iteration 2600 - Batch 1018/1582 - Train loss: 1.1064360237683117, Train acc: 0.7981783611383709\n",
      "Iteration 2700 - Batch 1118/1582 - Train loss: 1.105942033783893, Train acc: 0.7984249329758714\n",
      "Iteration 2800 - Batch 1218/1582 - Train loss: 1.1055803213381592, Train acc: 0.7987079573420837\n",
      "Iteration 2900 - Batch 1318/1582 - Train loss: 1.1057934601529247, Train acc: 0.7986400682335102\n",
      "Iteration 3000 - Batch 1418/1582 - Train loss: 1.1059524185057674, Train acc: 0.7983615221987315\n",
      "Iteration 3100 - Batch 1518/1582 - Train loss: 1.1052589529120977, Train acc: 0.7990248518762344\n",
      "[0, 2, 1, 4, 2, 0, 4, 2, 3, 0, 0, 1, 4, 0, 1, 0, 0, 3, 0, 1, 0, 2, 3, 3, 3, 2, 3, 1, 2, 4, 4, 3, 3, 2, 0, 2, 0, 2, 1, 1, 3, 4, 2, 1, 4, 4, 0, 2, 2, 1, 4, 1, 2, 3, 3, 3, 3, 0, 0, 0, 0, 4, 3, 0, 2, 1, 1, 2, 2, 2, 4, 0, 1, 2, 1, 1, 0, 3, 2, 0, 1, 1, 0, 0, 1, 0, 0, 1, 3, 3, 4, 0, 4, 0, 2, 2, 3, 2, 4, 4, 4, 4, 4, 4, 3, 1, 3, 2, 0, 2, 0, 0, 0, 4, 2, 0, 2, 4, 0, 2, 2, 1, 2, 2, 3, 2, 2, 1, 1, 1, 2, 2, 0, 0, 1, 0, 2, 0, 1, 2, 4, 1, 4, 4, 0, 1, 4, 0, 0, 3, 3, 1, 3, 1, 4, 4, 1, 4, 2, 1, 4, 0, 2, 3, 3, 1, 1, 0, 1, 4, 0, 1, 2, 0, 0, 4, 3, 3, 1, 4, 0, 4, 3, 4, 2, 1, 1, 0, 4, 1, 0, 4, 4, 0, 2, 1, 2, 4, 4, 3, 0, 1, 3, 1, 2, 0, 1, 3, 4, 2, 4, 3, 1, 3, 3, 1, 4, 3, 4, 1, 3, 4, 0, 4, 0, 0, 4, 1, 0, 2, 2, 0, 4, 2, 2, 2, 0, 0, 2, 3, 1, 0, 3, 3, 1, 2, 1, 3, 2, 3, 3, 4, 1, 1, 0, 4, 0, 2, 3, 4, 4, 1, 0, 4, 3, 0, 0, 4, 3, 4, 1, 2, 1, 4, 2, 0, 4, 1, 1, 4, 3, 3, 0, 3, 2, 2, 1, 3, 3, 1, 2, 0, 3, 3, 1, 2, 2, 3, 4, 2, 4, 3, 0, 1, 0, 4, 2, 3, 2, 1, 1, 0, 4, 3, 0, 3, 2, 3, 4, 1, 0, 0, 4, 2, 1, 0, 3, 3, 2, 1, 4, 2, 3, 3, 3, 3, 1, 4, 1, 4, 2, 1, 0, 1, 1, 2, 2, 2, 4, 1, 0, 1, 2, 1, 0, 4, 0, 0, 2, 3, 2, 3, 3, 2, 4, 3, 1, 1, 4, 2, 4, 3, 1, 2, 3, 0, 3, 0, 3, 4, 0, 2, 2, 4, 3, 1, 2, 1, 4, 3, 2, 4, 3, 2, 4, 3, 3, 1, 4, 0, 4, 3, 3, 4, 2, 4, 2, 2, 0, 4, 0, 2, 1, 2, 1, 3, 3, 1, 4, 2, 2, 1, 0, 4, 1, 4, 1, 0, 2, 4, 3, 1, 2, 4, 4, 3, 3, 1, 3, 2, 0, 0, 1, 4, 4, 1, 3, 0, 0, 3, 3, 3, 4, 0, 3, 2, 3, 1, 3, 1, 3, 4, 0, 1, 4, 1, 2, 4, 4, 0, 4, 2, 0, 4, 3, 4, 1, 0, 2, 3, 0, 2, 3, 3, 1, 1, 3, 4, 4, 0, 0, 2, 4, 2, 0, 1, 3, 0, 1, 2]\n",
      "[0, 2, 0, 4, 2, 0, 4, 2, 2, 0, 4, 4, 4, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 3, 4, 0, 3, 4, 2, 4, 4, 3, 3, 2, 4, 2, 0, 2, 3, 3, 4, 4, 0, 0, 4, 4, 0, 0, 2, 4, 4, 4, 2, 4, 3, 3, 4, 0, 0, 0, 0, 4, 2, 0, 2, 0, 4, 2, 2, 0, 4, 0, 4, 2, 4, 4, 0, 4, 0, 0, 0, 4, 0, 0, 4, 0, 0, 4, 3, 3, 4, 0, 4, 0, 2, 2, 3, 2, 4, 4, 4, 2, 4, 4, 4, 3, 4, 2, 0, 2, 0, 4, 0, 4, 2, 0, 2, 4, 0, 3, 0, 4, 3, 2, 3, 0, 2, 4, 0, 4, 2, 2, 0, 0, 3, 0, 4, 0, 3, 2, 4, 0, 4, 4, 0, 4, 3, 0, 0, 4, 3, 4, 3, 0, 4, 4, 4, 4, 2, 4, 4, 0, 0, 3, 4, 4, 4, 0, 4, 4, 0, 4, 2, 2, 0, 4, 4, 3, 2, 4, 0, 4, 3, 4, 2, 3, 0, 0, 4, 4, 2, 4, 4, 0, 2, 3, 4, 4, 4, 3, 2, 4, 3, 4, 2, 0, 4, 3, 4, 2, 4, 3, 4, 3, 4, 4, 4, 2, 4, 4, 3, 4, 0, 4, 0, 0, 4, 4, 0, 2, 2, 4, 4, 2, 0, 2, 0, 0, 2, 3, 0, 0, 3, 3, 2, 2, 3, 3, 4, 2, 3, 4, 0, 4, 4, 4, 0, 2, 4, 4, 4, 2, 2, 4, 3, 0, 4, 4, 3, 4, 3, 2, 0, 4, 0, 0, 4, 4, 4, 4, 4, 3, 0, 3, 2, 2, 0, 3, 3, 0, 2, 0, 3, 4, 4, 3, 2, 3, 4, 2, 4, 3, 0, 4, 0, 4, 0, 3, 0, 4, 4, 0, 4, 4, 0, 3, 2, 3, 2, 2, 0, 0, 4, 2, 4, 4, 3, 3, 0, 0, 4, 2, 3, 3, 3, 3, 0, 4, 0, 4, 2, 2, 0, 4, 4, 0, 0, 2, 4, 3, 0, 4, 2, 4, 0, 4, 0, 0, 2, 2, 2, 3, 4, 2, 4, 4, 2, 4, 4, 2, 4, 3, 4, 2, 3, 4, 3, 0, 3, 4, 0, 2, 2, 4, 3, 4, 2, 4, 4, 4, 2, 4, 3, 2, 4, 3, 3, 4, 4, 0, 4, 4, 3, 4, 2, 4, 2, 2, 0, 4, 0, 2, 4, 2, 0, 3, 4, 0, 4, 2, 2, 0, 0, 4, 3, 4, 3, 0, 0, 4, 3, 4, 2, 4, 2, 3, 3, 4, 4, 2, 0, 0, 4, 4, 4, 4, 4, 0, 0, 3, 3, 3, 4, 0, 3, 2, 3, 4, 3, 4, 3, 4, 0, 4, 4, 0, 2, 4, 4, 0, 4, 0, 0, 4, 4, 4, 4, 0, 2, 3, 0, 2, 0, 2, 0, 0, 3, 0, 4, 0, 0, 0, 4, 2, 0, 3, 3, 0, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.77      0.75      0.76       100\n",
      "           3       0.80      0.68      0.74       100\n",
      "           4       0.51      0.95      0.66       100\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.55      0.65      0.58       500\n",
      "weighted avg       0.55      0.65      0.58       500\n",
      "\n",
      "Val loss: 1.2489440739154816, Val acc: 0.652\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3200 - Batch 36/1582 - Train loss: 1.1716940741281252, Train acc: 0.731418918918919\n",
      "Iteration 3300 - Batch 136/1582 - Train loss: 1.144682712798571, Train acc: 0.7577554744525548\n",
      "Iteration 3400 - Batch 236/1582 - Train loss: 1.1312167413124052, Train acc: 0.771756329113924\n",
      "Iteration 3500 - Batch 336/1582 - Train loss: 1.1247166083899025, Train acc: 0.778746290801187\n",
      "Iteration 3600 - Batch 436/1582 - Train loss: 1.1205037144828989, Train acc: 0.7828232265446224\n",
      "Iteration 3700 - Batch 536/1582 - Train loss: 1.118980462324686, Train acc: 0.7838687150837989\n",
      "Iteration 3800 - Batch 636/1582 - Train loss: 1.1141968615575337, Train acc: 0.7886087127158555\n",
      "Iteration 3900 - Batch 736/1582 - Train loss: 1.112172823343704, Train acc: 0.7906631614654003\n",
      "Iteration 4000 - Batch 836/1582 - Train loss: 1.1103418534232155, Train acc: 0.7924507168458781\n",
      "Iteration 4100 - Batch 936/1582 - Train loss: 1.1080849376152266, Train acc: 0.7948906083244397\n",
      "Iteration 4200 - Batch 1036/1582 - Train loss: 1.1055447071819433, Train acc: 0.7974626325940212\n",
      "Iteration 4300 - Batch 1136/1582 - Train loss: 1.1050782106692265, Train acc: 0.7980430958663148\n",
      "Iteration 4400 - Batch 1236/1582 - Train loss: 1.1045543374606652, Train acc: 0.7986307599029911\n",
      "Iteration 4500 - Batch 1336/1582 - Train loss: 1.1031872390274156, Train acc: 0.800018698578908\n",
      "Iteration 4600 - Batch 1436/1582 - Train loss: 1.1018483819195024, Train acc: 0.8014309324982603\n",
      "Iteration 4700 - Batch 1536/1582 - Train loss: 1.101129012714366, Train acc: 0.8021917696811971\n",
      "[4, 4, 4, 0, 1, 3, 3, 4, 1, 3, 2, 0, 0, 0, 0, 3, 0, 4, 1, 3, 1, 4, 4, 1, 3, 1, 4, 0, 0, 3, 0, 2, 3, 1, 1, 0, 3, 0, 4, 0, 2, 0, 0, 0, 3, 2, 2, 4, 0, 4, 2, 4, 0, 1, 0, 3, 2, 0, 1, 1, 1, 3, 4, 0, 0, 3, 3, 1, 4, 2, 3, 4, 3, 2, 3, 1, 0, 2, 2, 4, 2, 1, 1, 0, 3, 3, 0, 3, 4, 2, 1, 4, 4, 2, 0, 4, 2, 1, 0, 0, 4, 4, 4, 1, 1, 2, 2, 3, 1, 1, 2, 2, 2, 3, 2, 2, 4, 2, 3, 3, 1, 0, 1, 2, 2, 1, 3, 1, 2, 4, 1, 1, 2, 2, 4, 1, 2, 3, 1, 4, 0, 4, 3, 3, 2, 3, 1, 4, 1, 1, 3, 3, 2, 2, 2, 2, 2, 3, 1, 1, 4, 4, 3, 0, 0, 0, 2, 1, 1, 1, 1, 0, 1, 3, 1, 2, 4, 0, 4, 3, 1, 2, 3, 4, 1, 4, 0, 0, 2, 1, 1, 3, 2, 3, 3, 2, 2, 3, 4, 1, 1, 1, 0, 2, 0, 2, 2, 0, 4, 0, 4, 0, 2, 1, 2, 0, 2, 2, 3, 1, 4, 1, 4, 2, 2, 4, 3, 3, 3, 4, 4, 0, 1, 3, 1, 3, 4, 2, 3, 4, 2, 1, 4, 1, 3, 1, 3, 3, 4, 2, 0, 1, 4, 1, 3, 1, 3, 3, 4, 3, 2, 2, 4, 4, 4, 3, 4, 1, 4, 3, 2, 0, 1, 0, 2, 4, 2, 4, 0, 1, 2, 4, 2, 2, 4, 1, 2, 3, 4, 1, 1, 3, 2, 2, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 1, 0, 0, 1, 2, 1, 4, 2, 4, 1, 4, 3, 4, 2, 3, 3, 0, 0, 3, 0, 1, 3, 4, 0, 0, 0, 4, 3, 3, 0, 2, 3, 1, 1, 3, 1, 3, 3, 1, 4, 0, 1, 0, 4, 2, 1, 2, 0, 0, 4, 4, 0, 0, 2, 1, 1, 1, 0, 0, 2, 3, 2, 2, 0, 0, 1, 4, 2, 0, 3, 4, 4, 3, 0, 3, 3, 3, 0, 0, 1, 2, 3, 2, 3, 4, 3, 4, 2, 1, 3, 1, 4, 4, 3, 3, 0, 2, 0, 1, 0, 2, 1, 4, 2, 0, 4, 4, 3, 4, 4, 4, 2, 0, 0, 2, 0, 3, 4, 2, 4, 4, 3, 2, 4, 3, 4, 2, 0, 0, 2, 0, 3, 0, 0, 2, 0, 0, 1, 3, 3, 0, 3, 4, 4, 0, 1, 4, 2, 1, 1, 3, 1, 2, 2, 2, 1, 2, 2, 4, 3, 4, 3, 4, 0, 4, 0, 0, 1, 4, 3, 0, 0, 3, 3, 4, 2, 4, 2, 1, 0, 1, 0, 3, 4, 3, 3, 1, 1, 1, 3, 4, 3, 4, 2, 1, 1]\n",
      "[4, 3, 4, 0, 4, 3, 3, 4, 0, 3, 2, 0, 0, 2, 4, 3, 0, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 2, 0, 3, 0, 2, 4, 2, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 3, 0, 2, 4, 0, 4, 2, 4, 0, 0, 0, 3, 2, 0, 4, 4, 3, 3, 4, 0, 0, 3, 3, 4, 4, 0, 4, 4, 3, 0, 3, 4, 0, 2, 2, 4, 2, 0, 4, 0, 3, 3, 4, 3, 4, 2, 3, 4, 4, 2, 0, 4, 2, 4, 0, 0, 4, 4, 4, 0, 4, 2, 2, 3, 4, 0, 2, 2, 2, 3, 2, 2, 4, 2, 3, 3, 3, 0, 4, 2, 2, 0, 4, 0, 0, 4, 4, 4, 2, 2, 4, 0, 2, 3, 4, 4, 0, 4, 3, 3, 2, 0, 3, 4, 3, 4, 3, 3, 2, 2, 4, 0, 2, 3, 4, 4, 4, 4, 3, 0, 0, 0, 0, 4, 3, 4, 4, 0, 4, 4, 4, 2, 4, 4, 2, 3, 4, 2, 4, 3, 4, 4, 0, 0, 0, 4, 0, 4, 2, 3, 3, 0, 2, 3, 4, 3, 4, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 2, 4, 2, 0, 2, 0, 3, 4, 4, 3, 4, 2, 0, 4, 3, 3, 3, 4, 4, 0, 4, 4, 4, 3, 4, 2, 3, 4, 0, 2, 0, 2, 3, 0, 3, 4, 4, 2, 0, 3, 4, 4, 3, 4, 3, 3, 4, 4, 2, 2, 4, 4, 4, 3, 3, 0, 4, 4, 2, 0, 3, 0, 2, 4, 2, 4, 0, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 0, 0, 0, 4, 4, 0, 0, 2, 0, 0, 4, 0, 0, 4, 2, 4, 4, 2, 4, 4, 4, 3, 4, 2, 3, 3, 2, 0, 3, 4, 4, 3, 4, 0, 0, 0, 4, 3, 3, 0, 2, 3, 4, 4, 3, 3, 3, 3, 4, 4, 0, 4, 0, 4, 2, 4, 2, 0, 0, 4, 4, 2, 0, 2, 4, 0, 4, 0, 0, 2, 3, 3, 2, 0, 0, 4, 4, 2, 4, 3, 4, 4, 3, 0, 3, 3, 3, 0, 0, 3, 2, 3, 3, 4, 4, 3, 4, 2, 0, 4, 4, 4, 4, 4, 3, 0, 0, 0, 4, 2, 3, 3, 4, 0, 0, 4, 4, 3, 4, 4, 4, 2, 0, 0, 2, 0, 4, 4, 2, 2, 4, 3, 2, 4, 3, 4, 0, 0, 0, 2, 0, 3, 0, 0, 2, 0, 0, 0, 4, 3, 0, 2, 4, 4, 0, 3, 4, 2, 3, 2, 3, 3, 3, 0, 2, 4, 2, 2, 4, 3, 4, 3, 4, 0, 4, 0, 4, 2, 4, 3, 0, 0, 3, 4, 4, 0, 4, 2, 4, 0, 4, 0, 3, 4, 4, 3, 4, 2, 4, 3, 4, 3, 4, 2, 2, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.82      0.75      0.79       100\n",
      "           3       0.77      0.79      0.78       100\n",
      "           4       0.52      0.93      0.66       100\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.56      0.67      0.60       500\n",
      "weighted avg       0.56      0.67      0.60       500\n",
      "\n",
      "Val loss: 1.2401662096381187, Val acc: 0.668\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4800 - Batch 54/1582 - Train loss: 1.0836442058736628, Train acc: 0.8198863636363637\n",
      "Iteration 4900 - Batch 154/1582 - Train loss: 1.0902079793714707, Train acc: 0.8125\n",
      "Iteration 5000 - Batch 254/1582 - Train loss: 1.085375024290646, Train acc: 0.8182598039215686\n",
      "Iteration 5100 - Batch 354/1582 - Train loss: 1.0813638299283848, Train acc: 0.8225352112676056\n",
      "Iteration 5200 - Batch 454/1582 - Train loss: 1.0839881951992327, Train acc: 0.8195054945054945\n",
      "Iteration 5300 - Batch 554/1582 - Train loss: 1.0833999561833905, Train acc: 0.820045045045045\n",
      "Iteration 5400 - Batch 654/1582 - Train loss: 1.083195567222042, Train acc: 0.8200858778625955\n",
      "Iteration 5500 - Batch 754/1582 - Train loss: 1.0825880514075426, Train acc: 0.8207781456953642\n",
      "Iteration 5600 - Batch 854/1582 - Train loss: 1.080583889860856, Train acc: 0.822953216374269\n",
      "Iteration 5700 - Batch 954/1582 - Train loss: 1.0811817103031418, Train acc: 0.8225458115183246\n",
      "Iteration 5800 - Batch 1054/1582 - Train loss: 1.0812865554438948, Train acc: 0.8223933649289099\n",
      "Iteration 5900 - Batch 1154/1582 - Train loss: 1.0812360984422427, Train acc: 0.8225108225108225\n",
      "Iteration 6000 - Batch 1254/1582 - Train loss: 1.0814021020771498, Train acc: 0.8224352589641434\n",
      "Iteration 6100 - Batch 1354/1582 - Train loss: 1.0813342114656175, Train acc: 0.8224630996309963\n",
      "Iteration 6200 - Batch 1454/1582 - Train loss: 1.0813666616518474, Train acc: 0.8224012027491409\n",
      "Iteration 6300 - Batch 1554/1582 - Train loss: 1.0812668542003325, Train acc: 0.822508038585209\n",
      "[3, 2, 1, 3, 3, 3, 3, 4, 4, 3, 2, 0, 0, 1, 3, 0, 3, 3, 3, 3, 0, 1, 1, 4, 2, 4, 1, 0, 1, 3, 0, 4, 3, 3, 2, 0, 2, 1, 4, 1, 2, 2, 4, 1, 0, 4, 3, 1, 0, 0, 0, 2, 1, 2, 1, 2, 3, 2, 0, 0, 1, 0, 1, 0, 2, 0, 4, 4, 2, 1, 0, 1, 0, 2, 1, 4, 4, 4, 0, 4, 2, 2, 2, 4, 3, 3, 3, 4, 1, 4, 3, 1, 2, 0, 1, 0, 3, 0, 3, 4, 1, 1, 0, 4, 1, 3, 4, 0, 2, 1, 4, 4, 2, 3, 4, 1, 4, 3, 1, 0, 1, 1, 4, 2, 4, 3, 3, 0, 0, 1, 0, 4, 1, 1, 0, 4, 2, 1, 2, 1, 2, 2, 4, 3, 0, 1, 1, 3, 0, 3, 4, 3, 2, 2, 0, 4, 3, 1, 2, 4, 4, 3, 4, 1, 4, 2, 2, 2, 0, 2, 1, 2, 2, 2, 0, 3, 4, 3, 4, 4, 1, 3, 2, 0, 3, 0, 0, 4, 3, 4, 4, 0, 2, 4, 2, 0, 0, 0, 0, 1, 4, 3, 2, 2, 3, 0, 1, 2, 0, 3, 4, 3, 4, 1, 3, 2, 1, 0, 2, 0, 0, 2, 2, 0, 1, 1, 4, 2, 3, 0, 2, 0, 2, 3, 0, 3, 4, 2, 1, 2, 2, 2, 2, 2, 3, 4, 2, 3, 1, 0, 4, 2, 1, 1, 0, 3, 3, 3, 3, 4, 2, 3, 3, 4, 1, 4, 4, 1, 2, 1, 2, 0, 2, 4, 0, 2, 0, 1, 2, 4, 4, 2, 1, 2, 1, 3, 2, 4, 4, 3, 3, 0, 2, 3, 3, 1, 0, 3, 0, 1, 0, 1, 3, 2, 0, 3, 4, 0, 1, 4, 2, 4, 4, 1, 1, 1, 2, 1, 4, 0, 3, 2, 4, 2, 4, 2, 3, 3, 3, 4, 4, 4, 0, 3, 3, 4, 3, 0, 1, 1, 4, 3, 0, 3, 1, 4, 1, 0, 0, 3, 1, 3, 3, 4, 3, 2, 0, 2, 3, 4, 2, 1, 0, 2, 3, 1, 1, 0, 4, 4, 1, 3, 4, 4, 3, 4, 0, 0, 0, 0, 0, 1, 0, 1, 2, 3, 3, 1, 1, 1, 1, 4, 1, 0, 2, 4, 3, 4, 3, 2, 3, 3, 1, 0, 4, 4, 2, 1, 2, 2, 0, 2, 2, 3, 0, 2, 4, 4, 3, 0, 1, 1, 2, 2, 4, 2, 0, 3, 0, 3, 1, 3, 4, 0, 0, 4, 0, 4, 2, 4, 2, 3, 4, 1, 4, 1, 3, 0, 4, 1, 2, 4, 4, 2, 2, 1, 0, 2, 0, 0, 0, 1, 0, 3, 3, 3, 0, 1, 0, 4, 3, 4, 2, 2, 1, 3, 3, 1, 2, 0, 4, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 2, 4, 1, 2, 3, 4, 1, 1, 3]\n",
      "[3, 2, 4, 3, 3, 3, 3, 4, 4, 3, 2, 0, 0, 4, 3, 0, 3, 3, 3, 3, 0, 3, 4, 4, 2, 4, 0, 0, 4, 3, 3, 4, 3, 3, 2, 4, 2, 3, 4, 4, 2, 0, 4, 0, 0, 4, 3, 4, 0, 4, 0, 2, 3, 2, 3, 2, 3, 0, 0, 0, 4, 2, 3, 4, 2, 4, 4, 4, 2, 4, 0, 2, 0, 2, 3, 4, 4, 4, 0, 4, 2, 2, 2, 4, 3, 3, 3, 4, 3, 4, 3, 4, 2, 0, 4, 0, 4, 0, 3, 4, 4, 4, 0, 4, 0, 3, 4, 0, 2, 4, 4, 4, 2, 3, 4, 4, 4, 3, 3, 0, 4, 4, 4, 2, 4, 3, 3, 0, 0, 0, 0, 4, 3, 4, 0, 4, 2, 3, 0, 3, 2, 0, 4, 3, 0, 3, 4, 3, 0, 3, 4, 3, 2, 2, 0, 4, 3, 3, 2, 4, 4, 3, 4, 3, 2, 0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 3, 3, 0, 4, 4, 4, 3, 2, 0, 3, 0, 0, 4, 3, 4, 4, 0, 2, 4, 0, 0, 0, 0, 0, 3, 4, 3, 2, 2, 3, 0, 3, 2, 0, 3, 4, 3, 4, 4, 3, 2, 0, 4, 3, 2, 0, 2, 2, 0, 0, 4, 4, 2, 3, 0, 2, 0, 2, 3, 0, 3, 4, 2, 3, 2, 2, 2, 0, 2, 3, 4, 2, 3, 4, 0, 3, 2, 3, 4, 0, 3, 3, 3, 3, 4, 2, 3, 3, 4, 4, 4, 4, 4, 0, 0, 3, 4, 2, 4, 0, 0, 0, 4, 2, 4, 3, 2, 4, 0, 0, 3, 2, 4, 4, 3, 3, 0, 2, 3, 3, 4, 0, 4, 0, 4, 0, 3, 3, 2, 0, 3, 4, 0, 4, 4, 0, 4, 4, 4, 3, 4, 2, 4, 4, 0, 3, 0, 2, 0, 4, 2, 3, 4, 3, 4, 4, 4, 0, 3, 3, 4, 3, 0, 3, 3, 4, 3, 0, 3, 4, 4, 3, 0, 0, 3, 3, 3, 3, 4, 3, 2, 0, 2, 3, 4, 2, 4, 0, 2, 3, 4, 2, 0, 4, 4, 4, 4, 4, 4, 3, 4, 0, 0, 0, 4, 0, 4, 0, 4, 2, 3, 3, 0, 3, 0, 4, 4, 4, 0, 2, 4, 3, 3, 3, 2, 3, 4, 4, 0, 4, 4, 2, 0, 2, 0, 0, 0, 2, 3, 0, 2, 4, 4, 3, 0, 4, 0, 2, 2, 4, 2, 0, 4, 0, 3, 0, 3, 4, 0, 0, 4, 0, 4, 2, 4, 2, 3, 4, 4, 4, 4, 3, 0, 4, 4, 2, 3, 4, 2, 4, 4, 0, 2, 0, 0, 0, 3, 0, 3, 4, 3, 0, 3, 0, 4, 3, 4, 0, 2, 3, 3, 3, 3, 0, 0, 4, 3, 0, 2, 0, 4, 4, 0, 0, 4, 0, 2, 0, 4, 0, 3, 4, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.93      0.78      0.85       100\n",
      "           3       0.70      0.92      0.79       100\n",
      "           4       0.58      0.92      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.207314483821392, Val acc: 0.704\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6400 - Batch 72/1582 - Train loss: 1.0756052944758168, Train acc: 0.8287671232876712\n",
      "Iteration 6500 - Batch 172/1582 - Train loss: 1.0670375296835266, Train acc: 0.8372471098265896\n",
      "Iteration 6600 - Batch 272/1582 - Train loss: 1.0762449585911118, Train acc: 0.8284111721611722\n",
      "Iteration 6700 - Batch 372/1582 - Train loss: 1.0823098197379637, Train acc: 0.8223860589812333\n",
      "Iteration 6800 - Batch 472/1582 - Train loss: 1.0781220227920985, Train acc: 0.8265063424947146\n",
      "Iteration 6900 - Batch 572/1582 - Train loss: 1.079517474973389, Train acc: 0.824825479930192\n",
      "Iteration 7000 - Batch 672/1582 - Train loss: 1.0777908862079943, Train acc: 0.8265230312035661\n",
      "Iteration 7100 - Batch 772/1582 - Train loss: 1.0775545572556007, Train acc: 0.826851552393273\n",
      "Iteration 7200 - Batch 872/1582 - Train loss: 1.076594284309964, Train acc: 0.8276417525773195\n",
      "Iteration 7300 - Batch 972/1582 - Train loss: 1.0757589432710488, Train acc: 0.8285264645426516\n",
      "Iteration 7400 - Batch 1072/1582 - Train loss: 1.0758557630718477, Train acc: 0.8284599254426841\n",
      "Iteration 7500 - Batch 1172/1582 - Train loss: 1.0754525157903263, Train acc: 0.8288576300085252\n",
      "Iteration 7600 - Batch 1272/1582 - Train loss: 1.0752623825211836, Train acc: 0.8288982717989002\n",
      "Iteration 7700 - Batch 1372/1582 - Train loss: 1.0750716052086615, Train acc: 0.8292743991260014\n",
      "Iteration 7800 - Batch 1472/1582 - Train loss: 1.0748323924025143, Train acc: 0.8294509504412763\n",
      "Iteration 7900 - Batch 1572/1582 - Train loss: 1.0747646369224737, Train acc: 0.8295255880483153\n",
      "[1, 3, 1, 1, 0, 3, 2, 1, 0, 1, 2, 3, 3, 1, 2, 0, 0, 1, 4, 4, 4, 3, 4, 1, 3, 4, 2, 2, 4, 0, 4, 4, 2, 0, 2, 2, 0, 3, 0, 3, 1, 0, 3, 3, 2, 2, 2, 2, 3, 0, 4, 0, 2, 0, 4, 3, 1, 4, 4, 1, 2, 2, 4, 1, 0, 1, 4, 3, 0, 4, 1, 1, 0, 4, 4, 3, 1, 4, 3, 0, 2, 3, 1, 0, 2, 2, 3, 1, 2, 1, 1, 2, 0, 1, 2, 4, 1, 1, 3, 4, 3, 2, 2, 4, 0, 2, 1, 2, 3, 2, 0, 3, 3, 4, 4, 4, 0, 4, 3, 1, 4, 0, 4, 4, 2, 1, 4, 4, 0, 2, 2, 0, 3, 3, 0, 0, 0, 0, 0, 2, 4, 3, 1, 1, 1, 2, 0, 4, 0, 3, 0, 0, 3, 0, 2, 3, 1, 4, 1, 1, 4, 0, 4, 1, 1, 3, 0, 1, 3, 1, 0, 1, 0, 4, 4, 1, 3, 1, 3, 4, 4, 1, 3, 0, 0, 2, 1, 1, 1, 1, 4, 1, 2, 2, 1, 3, 0, 0, 3, 3, 3, 1, 2, 0, 4, 2, 3, 2, 2, 2, 4, 3, 3, 4, 0, 3, 1, 2, 1, 0, 2, 1, 0, 2, 3, 1, 4, 1, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 4, 2, 2, 2, 0, 3, 3, 1, 4, 2, 4, 1, 2, 1, 0, 4, 3, 3, 0, 1, 1, 1, 2, 4, 4, 0, 2, 4, 2, 3, 4, 2, 0, 1, 0, 1, 4, 3, 3, 4, 1, 2, 0, 2, 2, 3, 2, 0, 2, 0, 0, 2, 4, 3, 0, 4, 2, 0, 4, 3, 3, 0, 3, 2, 4, 0, 0, 4, 4, 3, 1, 4, 0, 1, 3, 3, 2, 3, 4, 4, 2, 3, 2, 0, 4, 3, 3, 0, 1, 0, 2, 3, 0, 1, 3, 3, 1, 3, 4, 4, 0, 3, 0, 0, 0, 1, 3, 1, 2, 0, 2, 4, 0, 4, 2, 2, 0, 1, 4, 0, 2, 4, 3, 3, 3, 3, 3, 2, 2, 2, 1, 1, 0, 4, 2, 0, 4, 1, 0, 1, 4, 3, 3, 4, 3, 3, 1, 4, 1, 3, 3, 3, 0, 2, 0, 0, 4, 0, 3, 3, 3, 1, 4, 0, 4, 4, 2, 2, 1, 2, 1, 4, 4, 4, 3, 1, 3, 1, 0, 2, 2, 1, 3, 3, 2, 3, 2, 1, 4, 3, 2, 2, 1, 3, 4, 2, 2, 4, 1, 3, 2, 0, 3, 3, 1, 4, 2, 0, 3, 4, 0, 4, 0, 4, 4, 1, 3, 4, 2, 4, 2, 1, 4, 1, 0, 0, 2, 4, 2, 3, 4, 0, 1, 0, 1, 4, 0, 3, 1, 0, 4, 4, 4, 0, 4, 1, 2, 0, 2, 3, 3, 0, 1, 2, 2, 2, 0, 0, 3, 2, 2, 0]\n",
      "[4, 3, 4, 4, 0, 3, 0, 3, 0, 4, 0, 3, 4, 4, 2, 0, 0, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 2, 3, 4, 4, 4, 2, 0, 2, 2, 0, 3, 0, 3, 4, 0, 3, 3, 2, 2, 2, 2, 3, 0, 4, 0, 2, 0, 4, 3, 4, 4, 4, 4, 2, 2, 4, 4, 0, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 3, 0, 2, 3, 4, 0, 2, 0, 3, 3, 2, 3, 2, 2, 4, 4, 2, 4, 4, 3, 3, 4, 3, 2, 2, 4, 0, 2, 4, 2, 4, 2, 0, 3, 3, 4, 4, 4, 0, 4, 3, 3, 4, 0, 4, 4, 2, 3, 4, 4, 0, 2, 0, 2, 3, 3, 0, 0, 0, 0, 0, 2, 4, 3, 3, 3, 3, 2, 0, 4, 0, 3, 0, 0, 0, 0, 2, 3, 4, 4, 4, 2, 4, 0, 4, 0, 3, 3, 0, 3, 3, 4, 0, 4, 0, 4, 4, 4, 3, 3, 3, 4, 2, 3, 3, 0, 2, 0, 4, 3, 4, 4, 4, 3, 0, 2, 3, 3, 0, 0, 4, 3, 3, 4, 2, 0, 4, 2, 3, 2, 2, 3, 4, 3, 3, 4, 2, 3, 0, 2, 3, 0, 2, 4, 0, 0, 3, 4, 4, 3, 4, 4, 4, 4, 0, 0, 2, 2, 0, 4, 4, 2, 2, 0, 0, 4, 4, 4, 4, 2, 4, 3, 2, 0, 0, 4, 3, 4, 0, 4, 0, 3, 2, 4, 4, 0, 2, 4, 2, 3, 4, 2, 0, 0, 0, 4, 4, 3, 3, 4, 4, 2, 0, 2, 2, 3, 2, 0, 0, 0, 4, 0, 4, 3, 0, 4, 2, 0, 3, 3, 3, 0, 4, 2, 4, 0, 4, 4, 4, 3, 4, 4, 0, 3, 3, 3, 2, 3, 4, 4, 2, 3, 2, 0, 4, 3, 3, 0, 3, 0, 2, 3, 0, 0, 3, 3, 0, 3, 4, 4, 0, 3, 0, 0, 0, 4, 3, 0, 2, 0, 2, 4, 0, 3, 2, 2, 0, 0, 4, 3, 2, 4, 4, 3, 3, 3, 3, 0, 2, 2, 3, 4, 0, 4, 2, 0, 4, 2, 0, 0, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 0, 2, 3, 0, 4, 0, 3, 3, 3, 4, 4, 0, 4, 4, 2, 0, 4, 3, 0, 4, 4, 4, 3, 4, 3, 4, 0, 2, 2, 3, 3, 3, 2, 3, 0, 4, 4, 3, 3, 2, 3, 3, 4, 2, 0, 4, 4, 3, 2, 0, 3, 3, 0, 4, 0, 0, 3, 4, 0, 4, 0, 4, 4, 3, 3, 4, 0, 4, 2, 3, 4, 4, 2, 0, 2, 4, 3, 3, 4, 0, 4, 0, 4, 4, 4, 3, 0, 0, 4, 4, 4, 0, 4, 3, 2, 4, 0, 3, 3, 0, 3, 0, 2, 2, 0, 0, 3, 2, 2, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.76      0.82       100\n",
      "           3       0.67      0.89      0.77       100\n",
      "           4       0.58      0.95      0.72       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2088917344808578, Val acc: 0.692\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8000 - Batch 90/1582 - Train loss: 1.0679652651587686, Train acc: 0.8399725274725275\n",
      "Iteration 8100 - Batch 190/1582 - Train loss: 1.0662568292692693, Train acc: 0.8398232984293194\n",
      "Iteration 8200 - Batch 290/1582 - Train loss: 1.0674752935101486, Train acc: 0.8376288659793815\n",
      "Iteration 8300 - Batch 390/1582 - Train loss: 1.0681432525215246, Train acc: 0.8366368286445013\n",
      "Iteration 8400 - Batch 490/1582 - Train loss: 1.0701319525538053, Train acc: 0.8346486761710794\n",
      "Iteration 8500 - Batch 590/1582 - Train loss: 1.0713963713339338, Train acc: 0.8329631979695431\n",
      "Iteration 8600 - Batch 690/1582 - Train loss: 1.0717678484971893, Train acc: 0.8323082489146165\n",
      "Iteration 8700 - Batch 790/1582 - Train loss: 1.0721740330817877, Train acc: 0.831858407079646\n",
      "Iteration 8800 - Batch 890/1582 - Train loss: 1.0725883346481624, Train acc: 0.8312640291806959\n",
      "Iteration 8900 - Batch 990/1582 - Train loss: 1.0729128383363171, Train acc: 0.8309157416750756\n",
      "Iteration 9000 - Batch 1090/1582 - Train loss: 1.0716232589687589, Train acc: 0.8322353345554537\n",
      "Iteration 9100 - Batch 1190/1582 - Train loss: 1.0709193917906255, Train acc: 0.833044710327456\n",
      "Iteration 9200 - Batch 1290/1582 - Train loss: 1.071327843793504, Train acc: 0.8325910147172735\n",
      "Iteration 9300 - Batch 1390/1582 - Train loss: 1.0723386076094863, Train acc: 0.8314836448598131\n",
      "Iteration 9400 - Batch 1490/1582 - Train loss: 1.0727006097434753, Train acc: 0.8311535881958417\n",
      "[2, 4, 4, 4, 1, 4, 2, 0, 1, 0, 3, 0, 3, 0, 2, 2, 1, 1, 3, 0, 1, 0, 2, 0, 4, 1, 3, 2, 4, 0, 4, 0, 2, 3, 2, 3, 1, 4, 1, 0, 2, 2, 2, 4, 3, 3, 1, 4, 4, 3, 3, 2, 4, 4, 0, 0, 1, 2, 3, 2, 3, 3, 4, 1, 0, 1, 3, 4, 3, 3, 2, 3, 0, 4, 2, 1, 2, 3, 0, 4, 2, 1, 1, 1, 4, 0, 4, 3, 1, 4, 3, 4, 1, 3, 1, 3, 1, 0, 1, 4, 3, 3, 3, 1, 1, 2, 0, 4, 0, 3, 3, 0, 0, 4, 4, 3, 1, 0, 4, 3, 3, 1, 3, 3, 1, 3, 2, 2, 4, 1, 1, 4, 0, 4, 4, 4, 1, 2, 2, 1, 2, 1, 0, 4, 0, 3, 4, 0, 2, 3, 0, 4, 0, 4, 2, 0, 3, 2, 1, 4, 0, 4, 0, 2, 1, 2, 1, 0, 0, 3, 0, 4, 4, 4, 1, 0, 2, 0, 3, 2, 4, 2, 3, 1, 2, 0, 0, 0, 4, 0, 4, 3, 1, 0, 1, 2, 0, 2, 0, 2, 2, 2, 1, 1, 4, 0, 3, 2, 0, 3, 3, 3, 4, 1, 1, 2, 2, 3, 2, 1, 4, 0, 3, 4, 3, 3, 3, 2, 1, 4, 0, 3, 0, 2, 1, 3, 2, 2, 0, 3, 3, 0, 0, 3, 4, 4, 0, 3, 2, 2, 0, 3, 3, 0, 4, 3, 2, 1, 3, 2, 2, 3, 1, 3, 2, 4, 3, 2, 4, 1, 2, 2, 1, 2, 4, 4, 1, 3, 1, 4, 2, 3, 2, 3, 0, 1, 0, 0, 3, 3, 3, 1, 3, 4, 4, 4, 2, 1, 3, 0, 4, 2, 0, 0, 4, 2, 2, 4, 1, 0, 1, 2, 1, 2, 3, 4, 4, 1, 1, 1, 1, 3, 4, 0, 1, 0, 1, 0, 1, 4, 4, 4, 1, 1, 4, 0, 4, 4, 3, 2, 3, 0, 3, 1, 1, 0, 3, 3, 2, 2, 2, 4, 3, 2, 3, 3, 3, 4, 0, 1, 4, 1, 4, 3, 2, 2, 3, 2, 0, 0, 1, 3, 2, 1, 0, 0, 4, 1, 3, 2, 2, 4, 2, 2, 2, 4, 2, 1, 4, 2, 0, 1, 4, 4, 4, 1, 4, 4, 2, 1, 1, 1, 0, 4, 1, 3, 2, 1, 3, 2, 2, 1, 4, 1, 0, 0, 4, 2, 3, 4, 1, 0, 0, 2, 4, 0, 1, 2, 0, 3, 3, 0, 0, 0, 4, 2, 0, 0, 3, 0, 2, 1, 1, 4, 3, 3, 4, 4, 2, 1, 3, 0, 1, 1, 2, 1, 2, 1, 4, 1, 0, 0, 0, 2, 1, 1, 4, 3, 3, 2, 0, 0, 4, 0, 4, 4, 2, 0, 2, 3, 1, 4, 2, 0, 0, 0, 3, 1, 2, 1, 2, 4, 0, 3, 1, 0, 0, 2, 3, 1]\n",
      "[0, 4, 4, 4, 3, 4, 2, 0, 3, 0, 3, 0, 3, 0, 2, 0, 3, 0, 3, 0, 4, 4, 2, 0, 4, 4, 3, 3, 3, 4, 4, 0, 2, 3, 2, 3, 3, 4, 3, 0, 0, 0, 2, 4, 3, 3, 0, 4, 4, 3, 3, 2, 4, 4, 0, 2, 4, 2, 3, 2, 3, 3, 4, 4, 0, 3, 3, 4, 3, 3, 2, 3, 0, 4, 2, 3, 0, 3, 0, 4, 2, 3, 4, 3, 4, 0, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 0, 0, 4, 3, 3, 3, 3, 4, 4, 2, 0, 4, 0, 3, 3, 0, 2, 4, 4, 3, 4, 4, 4, 3, 3, 3, 3, 3, 0, 4, 2, 2, 4, 4, 4, 4, 0, 4, 4, 3, 3, 2, 0, 3, 0, 4, 0, 4, 0, 3, 4, 0, 0, 3, 0, 4, 0, 4, 2, 0, 3, 2, 3, 4, 0, 4, 0, 0, 4, 0, 3, 0, 0, 3, 0, 4, 4, 4, 4, 0, 2, 0, 3, 2, 4, 2, 4, 3, 2, 0, 0, 0, 4, 0, 4, 3, 3, 0, 4, 2, 0, 2, 4, 2, 2, 2, 3, 4, 4, 0, 3, 0, 0, 3, 3, 3, 4, 0, 4, 2, 2, 3, 0, 4, 4, 0, 3, 4, 4, 3, 3, 0, 4, 4, 0, 3, 0, 2, 0, 3, 2, 2, 0, 3, 3, 0, 0, 3, 4, 4, 0, 4, 2, 2, 0, 3, 3, 0, 3, 3, 2, 3, 3, 3, 2, 3, 4, 3, 0, 4, 3, 2, 4, 3, 2, 2, 4, 2, 4, 4, 4, 3, 3, 4, 2, 3, 2, 3, 0, 0, 0, 2, 3, 3, 3, 4, 3, 4, 4, 4, 4, 3, 3, 0, 4, 2, 0, 0, 4, 2, 2, 4, 4, 0, 4, 2, 0, 0, 3, 4, 4, 4, 4, 3, 3, 3, 4, 0, 4, 0, 4, 0, 4, 4, 2, 4, 4, 4, 4, 0, 4, 4, 3, 2, 3, 0, 3, 0, 3, 0, 3, 3, 2, 2, 2, 4, 3, 2, 3, 3, 3, 4, 0, 4, 4, 4, 4, 3, 2, 3, 0, 2, 0, 0, 4, 3, 0, 3, 0, 0, 4, 3, 3, 2, 2, 4, 3, 2, 2, 4, 2, 4, 4, 2, 0, 3, 4, 4, 4, 3, 4, 3, 2, 3, 4, 4, 2, 4, 4, 3, 2, 4, 3, 2, 0, 4, 4, 4, 0, 0, 4, 2, 3, 4, 2, 4, 0, 2, 4, 0, 4, 2, 0, 3, 3, 0, 0, 0, 4, 0, 0, 0, 4, 0, 2, 3, 4, 4, 3, 3, 4, 4, 2, 4, 4, 0, 4, 4, 0, 4, 2, 3, 4, 4, 0, 0, 0, 2, 3, 3, 0, 3, 3, 2, 0, 0, 4, 0, 4, 4, 2, 0, 2, 3, 0, 4, 0, 4, 0, 4, 3, 4, 2, 4, 2, 4, 0, 3, 0, 4, 4, 2, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.93      0.75      0.83       100\n",
      "           3       0.68      0.93      0.79       100\n",
      "           4       0.57      0.93      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.62       500\n",
      "weighted avg       0.58      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2113484218716621, Val acc: 0.696\n",
      "Epoch 7/30\n",
      "Iteration 9500 - Batch 8/1582 - Train loss: 1.0602226456006367, Train acc: 0.84375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9600 - Batch 108/1582 - Train loss: 1.0589323683616219, Train acc: 0.8448967889908257\n",
      "Iteration 9700 - Batch 208/1582 - Train loss: 1.0638053785100507, Train acc: 0.840011961722488\n",
      "Iteration 9800 - Batch 308/1582 - Train loss: 1.0661871543208372, Train acc: 0.8372775080906149\n",
      "Iteration 9900 - Batch 408/1582 - Train loss: 1.0683148794768784, Train acc: 0.8354217603911981\n",
      "Iteration 10000 - Batch 508/1582 - Train loss: 1.0681630354264864, Train acc: 0.8357072691552063\n",
      "Iteration 10100 - Batch 608/1582 - Train loss: 1.0691141160250885, Train acc: 0.8345648604269293\n",
      "Iteration 10200 - Batch 708/1582 - Train loss: 1.0698871800862515, Train acc: 0.8335684062059239\n",
      "Iteration 10300 - Batch 808/1582 - Train loss: 1.06954214363664, Train acc: 0.8338612484548825\n",
      "Iteration 10400 - Batch 908/1582 - Train loss: 1.0698929863794409, Train acc: 0.8332989548954896\n",
      "Iteration 10500 - Batch 1008/1582 - Train loss: 1.0698197121899002, Train acc: 0.8334675421209118\n",
      "Iteration 10600 - Batch 1108/1582 - Train loss: 1.0701453879247171, Train acc: 0.8333239404869252\n",
      "Iteration 10700 - Batch 1208/1582 - Train loss: 1.0696530496906504, Train acc: 0.8337727460711332\n",
      "Iteration 10800 - Batch 1308/1582 - Train loss: 1.0694603657248913, Train acc: 0.8340097402597403\n",
      "Iteration 10900 - Batch 1408/1582 - Train loss: 1.0691978921697358, Train acc: 0.8342130943931867\n",
      "Iteration 11000 - Batch 1508/1582 - Train loss: 1.0697421523970116, Train acc: 0.8338096421471173\n",
      "[4, 1, 2, 3, 1, 4, 3, 2, 3, 4, 0, 0, 3, 4, 1, 0, 3, 0, 0, 4, 3, 2, 0, 0, 4, 0, 2, 3, 2, 1, 1, 0, 1, 4, 2, 4, 2, 3, 4, 4, 2, 0, 3, 4, 4, 1, 2, 3, 1, 0, 2, 3, 1, 3, 0, 2, 0, 0, 4, 4, 4, 2, 0, 2, 1, 4, 3, 0, 0, 1, 2, 4, 0, 3, 2, 0, 3, 4, 2, 3, 2, 0, 1, 4, 4, 3, 4, 2, 2, 0, 3, 1, 4, 4, 3, 0, 0, 2, 0, 4, 1, 1, 2, 3, 2, 4, 0, 1, 0, 0, 4, 3, 4, 1, 3, 1, 2, 4, 1, 1, 1, 3, 0, 3, 4, 1, 2, 4, 3, 4, 2, 0, 4, 0, 1, 2, 3, 1, 3, 3, 2, 2, 1, 0, 1, 4, 0, 3, 3, 4, 2, 1, 1, 1, 3, 1, 2, 1, 2, 4, 3, 4, 2, 2, 4, 0, 4, 1, 1, 0, 0, 3, 0, 1, 4, 3, 2, 0, 0, 1, 0, 4, 4, 2, 3, 1, 4, 3, 0, 1, 3, 1, 1, 4, 0, 4, 3, 0, 2, 2, 0, 0, 1, 4, 1, 2, 0, 3, 2, 4, 0, 4, 3, 0, 2, 2, 1, 3, 4, 0, 2, 2, 3, 2, 3, 0, 1, 4, 4, 4, 2, 0, 0, 0, 4, 1, 4, 2, 4, 0, 2, 3, 4, 0, 2, 4, 4, 0, 0, 4, 1, 2, 1, 0, 2, 4, 2, 4, 2, 2, 1, 1, 2, 3, 2, 2, 3, 4, 1, 1, 2, 2, 4, 1, 4, 3, 0, 3, 2, 3, 3, 2, 0, 4, 0, 0, 3, 2, 3, 2, 1, 3, 2, 3, 1, 3, 3, 3, 1, 1, 1, 3, 4, 3, 0, 0, 3, 1, 0, 1, 3, 1, 2, 3, 1, 3, 0, 3, 3, 1, 1, 1, 3, 4, 2, 0, 0, 2, 1, 0, 0, 4, 4, 3, 3, 0, 2, 4, 1, 3, 1, 3, 3, 4, 4, 4, 0, 4, 3, 1, 0, 1, 1, 2, 0, 2, 2, 1, 2, 3, 0, 0, 3, 4, 3, 0, 2, 2, 1, 0, 2, 4, 1, 3, 2, 2, 4, 4, 1, 4, 0, 3, 0, 2, 3, 2, 4, 4, 4, 0, 0, 3, 2, 4, 2, 1, 1, 2, 0, 4, 0, 1, 4, 3, 3, 3, 4, 1, 1, 3, 2, 3, 4, 0, 1, 4, 1, 4, 3, 2, 3, 2, 0, 3, 0, 0, 0, 3, 3, 0, 4, 1, 4, 2, 2, 2, 4, 0, 2, 0, 3, 2, 4, 2, 1, 2, 0, 1, 3, 2, 1, 3, 1, 1, 4, 0, 0, 4, 2, 1, 4, 1, 0, 1, 1, 0, 3, 4, 2, 1, 1, 3, 0, 1, 3, 3, 1, 2, 2, 1, 3, 4, 4, 0, 1, 3, 2, 2, 4, 4, 2, 1, 1, 1, 3, 2, 3, 0, 0, 1]\n",
      "[4, 3, 2, 3, 4, 4, 3, 2, 3, 4, 0, 0, 3, 4, 3, 0, 3, 0, 0, 4, 4, 2, 0, 0, 4, 0, 0, 3, 2, 3, 0, 0, 0, 4, 0, 0, 0, 3, 4, 4, 2, 0, 3, 4, 3, 4, 2, 3, 0, 0, 2, 3, 3, 3, 0, 2, 0, 0, 3, 3, 4, 2, 0, 2, 4, 4, 3, 0, 0, 2, 2, 4, 0, 3, 0, 0, 3, 4, 2, 3, 2, 0, 0, 4, 4, 3, 4, 2, 0, 0, 3, 3, 4, 2, 3, 0, 0, 2, 0, 0, 3, 2, 2, 3, 2, 3, 0, 2, 0, 0, 4, 3, 4, 2, 3, 0, 2, 4, 0, 2, 4, 3, 0, 3, 4, 0, 2, 4, 3, 4, 2, 0, 4, 3, 4, 2, 3, 4, 3, 3, 0, 2, 4, 0, 3, 4, 0, 3, 3, 4, 2, 4, 3, 4, 3, 4, 0, 4, 2, 4, 3, 4, 2, 2, 4, 0, 4, 2, 4, 3, 0, 3, 0, 2, 4, 3, 2, 0, 0, 4, 0, 4, 4, 0, 3, 4, 4, 3, 0, 3, 3, 3, 0, 4, 0, 4, 3, 0, 0, 2, 0, 0, 4, 4, 3, 3, 0, 3, 2, 4, 0, 4, 0, 0, 2, 2, 3, 3, 4, 0, 2, 2, 3, 2, 3, 0, 3, 4, 4, 3, 2, 0, 0, 0, 4, 3, 4, 3, 4, 0, 2, 3, 4, 0, 0, 2, 4, 0, 0, 4, 4, 2, 3, 0, 2, 4, 2, 4, 2, 2, 3, 4, 0, 3, 2, 2, 3, 4, 3, 0, 2, 2, 4, 3, 4, 3, 0, 3, 2, 3, 3, 0, 0, 4, 4, 0, 3, 2, 3, 2, 0, 3, 2, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3, 0, 0, 3, 0, 0, 0, 2, 3, 2, 3, 0, 3, 0, 3, 3, 0, 0, 3, 3, 4, 2, 0, 0, 2, 0, 0, 0, 4, 4, 3, 3, 0, 2, 4, 3, 3, 2, 3, 3, 4, 4, 4, 0, 4, 4, 4, 0, 4, 3, 0, 0, 2, 3, 3, 2, 3, 0, 0, 3, 4, 3, 0, 2, 2, 4, 0, 2, 4, 0, 3, 2, 2, 3, 4, 3, 4, 0, 3, 0, 2, 3, 2, 4, 4, 4, 0, 0, 3, 2, 3, 2, 3, 0, 2, 0, 3, 0, 4, 2, 3, 3, 3, 4, 4, 2, 3, 2, 3, 4, 0, 4, 4, 0, 4, 3, 0, 3, 2, 0, 3, 0, 0, 0, 3, 3, 0, 4, 4, 4, 2, 2, 2, 4, 0, 2, 0, 3, 0, 4, 0, 3, 2, 0, 3, 4, 0, 4, 3, 4, 3, 4, 0, 0, 4, 2, 3, 4, 0, 0, 4, 4, 0, 3, 4, 2, 0, 4, 3, 0, 2, 3, 3, 3, 2, 2, 4, 4, 4, 4, 2, 0, 3, 2, 0, 4, 4, 2, 0, 0, 4, 3, 0, 3, 0, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.84      0.78      0.81       100\n",
      "           3       0.67      0.93      0.78       100\n",
      "           4       0.69      0.87      0.77       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1994672492146492, Val acc: 0.708\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11100 - Batch 26/1582 - Train loss: 1.0476500458187528, Train acc: 0.8576388888888888\n",
      "Iteration 11200 - Batch 126/1582 - Train loss: 1.0609398765826787, Train acc: 0.843011811023622\n",
      "Iteration 11300 - Batch 226/1582 - Train loss: 1.063768931159889, Train acc: 0.8411343612334802\n",
      "Iteration 11400 - Batch 326/1582 - Train loss: 1.066341135297711, Train acc: 0.8383983180428135\n",
      "Iteration 11500 - Batch 426/1582 - Train loss: 1.0680033692989752, Train acc: 0.8362119437939111\n",
      "Iteration 11600 - Batch 526/1582 - Train loss: 1.0671541556235282, Train acc: 0.8367528462998103\n",
      "Iteration 11700 - Batch 626/1582 - Train loss: 1.065759874131691, Train acc: 0.8383672248803827\n",
      "Iteration 11800 - Batch 726/1582 - Train loss: 1.065178485815266, Train acc: 0.8388067400275103\n",
      "Iteration 11900 - Batch 826/1582 - Train loss: 1.0647391294914117, Train acc: 0.8394044740024184\n",
      "Iteration 12000 - Batch 926/1582 - Train loss: 1.0656509810924015, Train acc: 0.8384236785329018\n",
      "Iteration 12100 - Batch 1026/1582 - Train loss: 1.0642654210358076, Train acc: 0.8398855890944499\n",
      "Iteration 12200 - Batch 1126/1582 - Train loss: 1.0638638327051924, Train acc: 0.8401730257320319\n",
      "Iteration 12300 - Batch 1226/1582 - Train loss: 1.0635622207382003, Train acc: 0.8405154849225754\n",
      "Iteration 12400 - Batch 1326/1582 - Train loss: 1.063495562547297, Train acc: 0.8404059909570459\n",
      "Iteration 12500 - Batch 1426/1582 - Train loss: 1.0637930212692523, Train acc: 0.8400709530483532\n",
      "Iteration 12600 - Batch 1526/1582 - Train loss: 1.0633571672142919, Train acc: 0.8404960707269156\n",
      "[3, 1, 0, 0, 0, 4, 3, 2, 4, 4, 3, 0, 4, 1, 1, 4, 0, 2, 2, 1, 0, 4, 1, 2, 0, 1, 0, 1, 1, 4, 4, 2, 2, 4, 4, 0, 0, 1, 4, 1, 1, 3, 4, 3, 3, 2, 0, 3, 3, 1, 3, 2, 4, 0, 2, 1, 1, 0, 4, 2, 3, 1, 3, 4, 0, 1, 3, 4, 0, 1, 2, 0, 2, 2, 0, 2, 4, 3, 1, 4, 1, 1, 2, 3, 2, 4, 3, 0, 4, 2, 0, 2, 0, 0, 1, 3, 4, 4, 3, 2, 1, 0, 3, 1, 3, 0, 4, 0, 4, 3, 1, 3, 2, 0, 3, 0, 4, 4, 0, 0, 4, 1, 2, 1, 3, 4, 0, 4, 3, 1, 1, 3, 2, 3, 4, 2, 0, 0, 0, 2, 3, 4, 2, 4, 3, 3, 3, 2, 2, 0, 2, 4, 3, 2, 3, 4, 3, 4, 2, 3, 0, 0, 4, 1, 1, 1, 0, 3, 1, 0, 4, 4, 1, 4, 1, 4, 1, 4, 2, 4, 2, 0, 3, 3, 3, 4, 0, 1, 3, 0, 4, 2, 4, 0, 0, 3, 4, 0, 0, 1, 1, 4, 1, 4, 3, 0, 0, 2, 3, 1, 4, 4, 0, 3, 2, 4, 2, 1, 4, 2, 2, 4, 2, 2, 1, 2, 4, 0, 4, 2, 2, 4, 3, 2, 3, 3, 3, 4, 3, 2, 3, 1, 1, 0, 1, 2, 1, 2, 2, 4, 2, 0, 4, 1, 1, 0, 0, 3, 4, 1, 1, 4, 4, 0, 0, 3, 3, 3, 3, 0, 2, 3, 3, 1, 1, 2, 3, 2, 1, 2, 2, 2, 1, 1, 3, 4, 1, 1, 0, 4, 3, 0, 3, 0, 3, 1, 1, 0, 1, 0, 0, 0, 1, 2, 3, 1, 3, 4, 3, 0, 4, 0, 4, 0, 3, 2, 2, 4, 3, 1, 0, 0, 4, 4, 3, 2, 4, 4, 2, 1, 4, 0, 2, 1, 3, 2, 3, 3, 4, 2, 0, 3, 0, 0, 2, 1, 3, 3, 1, 1, 0, 0, 2, 3, 3, 0, 0, 4, 0, 1, 0, 2, 2, 4, 3, 2, 2, 1, 4, 1, 1, 3, 1, 4, 2, 0, 3, 4, 2, 1, 2, 4, 0, 2, 3, 2, 1, 2, 0, 1, 1, 1, 4, 4, 0, 2, 2, 4, 0, 1, 1, 3, 0, 3, 3, 0, 2, 2, 1, 2, 0, 4, 1, 0, 2, 4, 3, 2, 4, 2, 1, 4, 4, 1, 3, 0, 4, 4, 2, 3, 0, 3, 1, 0, 3, 0, 3, 0, 0, 1, 1, 2, 3, 1, 2, 1, 0, 3, 3, 0, 3, 1, 2, 1, 4, 0, 4, 0, 2, 3, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 0, 2, 1, 3, 4, 2, 2, 2, 2, 0, 1, 2, 0, 1, 4, 3, 1, 3, 4, 4, 2, 2, 1, 4, 1, 2, 0, 1, 3, 2]\n",
      "[3, 0, 0, 0, 0, 4, 3, 0, 4, 3, 3, 0, 4, 4, 4, 4, 0, 0, 2, 4, 0, 4, 3, 2, 0, 3, 0, 4, 4, 4, 4, 2, 2, 4, 4, 0, 0, 0, 2, 0, 4, 3, 4, 4, 3, 0, 0, 3, 3, 0, 3, 0, 4, 0, 2, 0, 4, 0, 4, 0, 3, 0, 3, 4, 0, 0, 3, 0, 0, 4, 2, 0, 0, 0, 0, 2, 4, 3, 0, 3, 3, 0, 2, 3, 2, 3, 3, 0, 4, 0, 0, 0, 0, 0, 0, 4, 4, 0, 3, 0, 3, 0, 3, 0, 3, 0, 4, 0, 2, 3, 4, 3, 2, 0, 3, 0, 4, 3, 0, 0, 2, 2, 2, 0, 3, 0, 0, 4, 3, 3, 0, 3, 2, 3, 4, 0, 0, 0, 0, 0, 3, 4, 2, 4, 3, 3, 3, 2, 2, 0, 0, 4, 3, 2, 3, 4, 3, 4, 2, 3, 0, 0, 4, 0, 3, 3, 0, 3, 3, 0, 4, 4, 3, 3, 3, 4, 0, 4, 2, 4, 2, 0, 3, 3, 3, 4, 0, 3, 3, 0, 4, 2, 3, 0, 0, 3, 0, 0, 0, 4, 0, 3, 3, 4, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 2, 4, 2, 3, 4, 2, 0, 4, 0, 0, 2, 2, 4, 0, 0, 0, 2, 4, 3, 2, 3, 3, 3, 2, 3, 0, 3, 0, 0, 0, 3, 2, 4, 2, 2, 4, 2, 0, 4, 0, 0, 0, 0, 3, 4, 3, 0, 4, 4, 0, 0, 3, 3, 3, 3, 0, 2, 3, 3, 3, 3, 0, 3, 0, 3, 0, 2, 2, 0, 3, 3, 4, 4, 3, 0, 4, 3, 0, 3, 0, 3, 0, 3, 0, 4, 0, 0, 0, 3, 2, 3, 0, 3, 3, 3, 0, 4, 0, 4, 0, 3, 2, 2, 4, 3, 3, 0, 0, 4, 4, 3, 2, 4, 4, 2, 3, 4, 0, 2, 0, 3, 3, 3, 3, 4, 2, 0, 3, 0, 0, 2, 0, 3, 3, 0, 0, 0, 0, 2, 3, 3, 0, 0, 4, 0, 0, 0, 2, 0, 4, 0, 2, 2, 3, 4, 3, 0, 3, 4, 4, 2, 0, 3, 4, 2, 0, 2, 3, 0, 0, 3, 3, 3, 2, 0, 0, 0, 4, 4, 4, 0, 2, 2, 4, 0, 3, 3, 3, 0, 3, 3, 0, 2, 2, 3, 0, 0, 4, 0, 0, 2, 0, 3, 0, 4, 2, 3, 4, 4, 3, 3, 0, 4, 4, 0, 3, 0, 3, 3, 0, 3, 0, 3, 0, 0, 2, 0, 0, 3, 0, 2, 3, 0, 3, 4, 0, 3, 3, 2, 0, 3, 0, 4, 0, 2, 3, 2, 3, 4, 0, 2, 3, 3, 0, 3, 4, 0, 3, 0, 4, 4, 2, 2, 0, 0, 0, 0, 2, 0, 2, 4, 3, 4, 3, 4, 3, 2, 2, 4, 4, 3, 2, 0, 0, 3, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.67      0.77       100\n",
      "           3       0.65      0.95      0.77       100\n",
      "           4       0.78      0.76      0.77       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.58      0.68      0.60       500\n",
      "weighted avg       0.58      0.68      0.60       500\n",
      "\n",
      "Val loss: 1.2306276187300682, Val acc: 0.676\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12700 - Batch 44/1582 - Train loss: 1.067615897125668, Train acc: 0.8361111111111111\n",
      "Iteration 12800 - Batch 144/1582 - Train loss: 1.0587954722601791, Train acc: 0.844396551724138\n",
      "Iteration 12900 - Batch 244/1582 - Train loss: 1.0567696561618727, Train acc: 0.846811224489796\n",
      "Iteration 13000 - Batch 344/1582 - Train loss: 1.0584654630094334, Train acc: 0.8448369565217392\n",
      "Iteration 13100 - Batch 444/1582 - Train loss: 1.0572822426142316, Train acc: 0.8461376404494382\n",
      "Iteration 13200 - Batch 544/1582 - Train loss: 1.0582780874103581, Train acc: 0.8450688073394496\n",
      "Iteration 13300 - Batch 644/1582 - Train loss: 1.0579327322715937, Train acc: 0.8456395348837209\n",
      "Iteration 13400 - Batch 744/1582 - Train loss: 1.059943200197796, Train acc: 0.8436241610738255\n",
      "Iteration 13500 - Batch 844/1582 - Train loss: 1.059704894991316, Train acc: 0.8438609467455621\n",
      "Iteration 13600 - Batch 944/1582 - Train loss: 1.0597162265626212, Train acc: 0.843915343915344\n",
      "Iteration 13700 - Batch 1044/1582 - Train loss: 1.060020141453264, Train acc: 0.84375\n",
      "Iteration 13800 - Batch 1144/1582 - Train loss: 1.059544233671963, Train acc: 0.8443504366812227\n",
      "Iteration 13900 - Batch 1244/1582 - Train loss: 1.0597299435052527, Train acc: 0.8442269076305221\n",
      "Iteration 14000 - Batch 1344/1582 - Train loss: 1.0591854484994172, Train acc: 0.8447490706319702\n",
      "Iteration 14100 - Batch 1444/1582 - Train loss: 1.059444256142349, Train acc: 0.8443771626297578\n",
      "Iteration 14200 - Batch 1544/1582 - Train loss: 1.0598187420360479, Train acc: 0.843992718446602\n",
      "[3, 0, 4, 3, 0, 1, 1, 0, 4, 0, 1, 4, 3, 3, 0, 4, 1, 4, 1, 2, 2, 1, 2, 4, 4, 1, 2, 1, 0, 2, 4, 0, 4, 0, 0, 3, 4, 3, 4, 0, 4, 1, 3, 0, 2, 0, 2, 0, 4, 0, 1, 2, 3, 2, 1, 4, 3, 0, 0, 0, 3, 1, 2, 1, 4, 1, 2, 2, 2, 2, 3, 4, 2, 0, 2, 1, 0, 0, 2, 0, 0, 3, 4, 2, 2, 1, 4, 4, 1, 3, 3, 3, 3, 1, 1, 3, 0, 3, 2, 1, 1, 2, 1, 0, 1, 3, 3, 0, 4, 1, 2, 1, 0, 4, 4, 1, 3, 4, 2, 4, 3, 0, 3, 1, 4, 1, 1, 3, 2, 0, 2, 1, 0, 1, 4, 1, 2, 3, 2, 4, 1, 1, 1, 1, 0, 4, 4, 1, 3, 4, 1, 3, 0, 0, 3, 0, 2, 3, 3, 0, 0, 4, 2, 1, 3, 1, 4, 2, 3, 0, 0, 0, 4, 3, 1, 4, 4, 1, 4, 1, 4, 4, 3, 1, 4, 0, 4, 1, 3, 2, 3, 4, 1, 0, 3, 3, 4, 0, 2, 3, 4, 3, 0, 1, 3, 2, 2, 4, 3, 2, 2, 4, 2, 0, 2, 2, 4, 3, 1, 3, 0, 2, 0, 1, 2, 2, 2, 0, 1, 0, 0, 0, 4, 2, 2, 3, 0, 1, 2, 0, 2, 2, 2, 2, 4, 3, 2, 4, 3, 0, 1, 0, 4, 0, 1, 1, 2, 4, 2, 1, 1, 4, 4, 4, 2, 2, 3, 4, 2, 0, 0, 0, 3, 0, 2, 0, 2, 1, 1, 4, 3, 0, 2, 3, 0, 1, 4, 4, 4, 2, 2, 3, 4, 4, 1, 2, 1, 2, 0, 3, 0, 3, 3, 1, 1, 3, 4, 1, 1, 3, 1, 2, 3, 2, 4, 2, 3, 1, 1, 3, 0, 3, 0, 3, 4, 4, 1, 1, 0, 4, 4, 0, 1, 3, 4, 1, 3, 0, 2, 2, 0, 3, 4, 0, 3, 1, 0, 2, 2, 0, 2, 2, 0, 0, 3, 1, 0, 1, 4, 2, 3, 0, 1, 3, 4, 3, 3, 1, 2, 2, 2, 0, 1, 4, 4, 2, 4, 0, 1, 3, 0, 4, 4, 3, 2, 1, 4, 3, 3, 3, 2, 0, 2, 3, 3, 0, 0, 3, 2, 2, 4, 2, 1, 3, 2, 4, 2, 4, 0, 0, 2, 4, 3, 0, 0, 0, 1, 4, 1, 3, 2, 0, 3, 3, 4, 4, 4, 3, 1, 0, 0, 3, 3, 1, 4, 0, 0, 4, 2, 4, 0, 0, 0, 1, 3, 4, 0, 4, 1, 4, 4, 4, 3, 1, 1, 3, 2, 2, 1, 3, 3, 3, 3, 2, 1, 2, 2, 2, 1, 2, 1, 1, 0, 2, 2, 1, 4, 1, 0, 4, 3, 0, 3, 3, 4, 3, 1, 1, 2, 2, 4, 4, 3, 3, 1, 4, 1, 4, 0, 2]\n",
      "[3, 0, 4, 3, 0, 0, 4, 0, 4, 0, 0, 4, 3, 3, 0, 4, 3, 4, 0, 2, 0, 4, 2, 2, 4, 3, 2, 3, 0, 2, 4, 0, 0, 0, 0, 3, 4, 3, 4, 0, 4, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 4, 3, 0, 0, 0, 3, 0, 2, 4, 4, 0, 2, 2, 2, 2, 4, 4, 2, 0, 2, 0, 0, 0, 2, 0, 0, 3, 4, 2, 2, 0, 4, 4, 4, 3, 3, 3, 3, 3, 0, 3, 0, 3, 2, 0, 3, 2, 3, 0, 3, 3, 3, 0, 4, 0, 4, 4, 0, 4, 4, 0, 3, 4, 2, 4, 3, 0, 3, 0, 4, 0, 0, 3, 2, 0, 2, 4, 0, 0, 4, 4, 2, 3, 2, 4, 4, 0, 0, 4, 0, 4, 4, 3, 3, 4, 0, 3, 0, 0, 3, 0, 2, 3, 3, 0, 0, 4, 0, 4, 3, 3, 0, 2, 3, 0, 0, 0, 4, 3, 0, 4, 4, 0, 4, 4, 3, 4, 3, 4, 4, 0, 4, 0, 3, 2, 3, 4, 0, 0, 3, 3, 3, 0, 2, 3, 4, 3, 0, 0, 3, 2, 2, 4, 3, 2, 2, 4, 2, 0, 2, 0, 2, 3, 3, 3, 0, 2, 0, 3, 2, 2, 2, 0, 4, 0, 0, 0, 4, 2, 0, 3, 0, 4, 2, 0, 2, 2, 2, 2, 4, 4, 2, 4, 3, 0, 0, 0, 4, 0, 3, 3, 0, 4, 2, 4, 3, 4, 4, 0, 2, 0, 4, 2, 2, 0, 4, 0, 3, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 3, 0, 0, 4, 4, 4, 2, 2, 4, 4, 4, 4, 0, 3, 0, 0, 3, 0, 3, 3, 4, 3, 2, 0, 3, 4, 3, 4, 2, 3, 2, 4, 2, 3, 0, 0, 3, 0, 3, 0, 4, 4, 4, 0, 3, 0, 0, 4, 0, 0, 3, 4, 4, 3, 0, 2, 2, 0, 3, 4, 0, 4, 4, 0, 2, 2, 0, 2, 0, 0, 0, 3, 3, 0, 4, 4, 2, 3, 4, 0, 3, 4, 3, 3, 0, 2, 2, 2, 0, 0, 4, 0, 2, 4, 0, 4, 3, 0, 0, 4, 3, 0, 4, 4, 3, 4, 3, 0, 0, 2, 3, 3, 0, 0, 3, 0, 0, 4, 0, 3, 3, 0, 4, 2, 4, 0, 0, 2, 4, 3, 0, 2, 0, 3, 4, 0, 3, 0, 0, 3, 3, 4, 4, 4, 3, 0, 0, 0, 3, 3, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 0, 0, 4, 0, 4, 4, 4, 3, 3, 3, 0, 0, 3, 2, 2, 0, 3, 4, 3, 3, 2, 4, 2, 0, 0, 4, 2, 4, 0, 0, 2, 2, 4, 0, 4, 0, 4, 3, 0, 3, 3, 4, 3, 4, 0, 2, 0, 4, 4, 3, 0, 0, 4, 0, 4, 0, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.96      0.69       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.94      0.74      0.83       100\n",
      "           3       0.78      0.88      0.83       100\n",
      "           4       0.65      0.84      0.73       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.58      0.68      0.61       500\n",
      "weighted avg       0.58      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2225933596491814, Val acc: 0.684\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14300 - Batch 62/1582 - Train loss: 1.0595639461562747, Train acc: 0.8452380952380952\n",
      "Iteration 14400 - Batch 162/1582 - Train loss: 1.0485449272430747, Train acc: 0.8558282208588958\n",
      "Iteration 14500 - Batch 262/1582 - Train loss: 1.0511335619502193, Train acc: 0.8531368821292775\n",
      "Iteration 14600 - Batch 362/1582 - Train loss: 1.0521439639004795, Train acc: 0.8526170798898072\n",
      "Iteration 14700 - Batch 462/1582 - Train loss: 1.0536701532471, Train acc: 0.8512419006479481\n",
      "Iteration 14800 - Batch 562/1582 - Train loss: 1.0544937922094897, Train acc: 0.8500777087033747\n",
      "Iteration 14900 - Batch 662/1582 - Train loss: 1.0551924176884993, Train acc: 0.849406108597285\n",
      "Iteration 15000 - Batch 762/1582 - Train loss: 1.056180392539673, Train acc: 0.8483781127129751\n",
      "Iteration 15100 - Batch 862/1582 - Train loss: 1.0557242125652617, Train acc: 0.8487833140208575\n",
      "Iteration 15200 - Batch 962/1582 - Train loss: 1.0563427792902675, Train acc: 0.8480010384215991\n",
      "Iteration 15300 - Batch 1062/1582 - Train loss: 1.0559020954151817, Train acc: 0.8484536688617121\n",
      "Iteration 15400 - Batch 1162/1582 - Train loss: 1.0559769999027662, Train acc: 0.8486134995700774\n",
      "Iteration 15500 - Batch 1262/1582 - Train loss: 1.0565014722700263, Train acc: 0.8479562549485352\n",
      "Iteration 15600 - Batch 1362/1582 - Train loss: 1.0568109890685218, Train acc: 0.8476247248716068\n",
      "Iteration 15700 - Batch 1462/1582 - Train loss: 1.0571964459311693, Train acc: 0.8472957963089542\n",
      "Iteration 15800 - Batch 1562/1582 - Train loss: 1.0579291284656342, Train acc: 0.8466090850927703\n",
      "[1, 2, 4, 0, 4, 3, 0, 4, 3, 4, 3, 0, 4, 1, 2, 1, 4, 3, 2, 4, 0, 1, 0, 0, 0, 2, 0, 4, 0, 1, 4, 2, 3, 1, 2, 4, 0, 4, 2, 1, 2, 4, 3, 3, 1, 1, 2, 1, 2, 3, 2, 1, 1, 3, 4, 4, 3, 1, 2, 0, 2, 2, 1, 4, 4, 4, 0, 0, 2, 2, 4, 2, 0, 0, 1, 2, 4, 1, 2, 3, 4, 0, 0, 1, 4, 3, 2, 4, 4, 0, 1, 1, 2, 3, 2, 1, 3, 4, 2, 0, 3, 2, 1, 1, 2, 4, 1, 2, 0, 2, 2, 0, 1, 0, 3, 0, 3, 2, 1, 2, 0, 3, 1, 3, 1, 0, 3, 0, 2, 3, 3, 0, 3, 1, 4, 0, 1, 4, 1, 2, 0, 0, 0, 3, 0, 2, 3, 1, 2, 4, 0, 1, 0, 2, 3, 1, 1, 2, 0, 3, 1, 4, 3, 4, 2, 1, 2, 4, 2, 3, 4, 2, 2, 1, 1, 1, 4, 1, 3, 0, 2, 0, 1, 2, 1, 3, 4, 3, 4, 4, 4, 4, 4, 4, 2, 1, 4, 4, 3, 2, 4, 0, 1, 2, 4, 3, 1, 2, 1, 2, 1, 0, 0, 3, 0, 1, 4, 4, 0, 3, 0, 1, 0, 4, 3, 3, 4, 1, 2, 3, 2, 3, 3, 2, 2, 2, 1, 4, 2, 2, 0, 0, 0, 2, 1, 3, 0, 1, 1, 1, 1, 2, 3, 0, 1, 3, 0, 4, 4, 2, 3, 0, 2, 3, 4, 1, 0, 0, 4, 4, 3, 4, 2, 0, 3, 2, 4, 2, 0, 0, 2, 3, 2, 4, 3, 1, 0, 0, 3, 4, 0, 4, 4, 4, 0, 3, 0, 3, 0, 3, 1, 1, 1, 0, 1, 2, 4, 4, 4, 3, 0, 0, 2, 4, 2, 3, 2, 3, 4, 1, 1, 2, 0, 2, 3, 0, 4, 2, 3, 1, 4, 4, 1, 3, 3, 0, 0, 2, 3, 1, 0, 4, 2, 1, 1, 3, 2, 3, 3, 1, 4, 4, 1, 0, 4, 4, 3, 3, 2, 0, 0, 1, 4, 2, 3, 2, 1, 3, 2, 2, 3, 3, 3, 3, 3, 0, 2, 3, 3, 0, 3, 4, 1, 1, 2, 4, 3, 2, 1, 1, 4, 0, 2, 2, 4, 1, 3, 0, 4, 4, 4, 4, 3, 2, 1, 1, 1, 3, 1, 1, 1, 4, 3, 0, 2, 0, 1, 0, 0, 3, 1, 0, 1, 0, 4, 4, 2, 2, 3, 4, 3, 2, 3, 4, 3, 3, 2, 1, 4, 2, 3, 2, 1, 0, 4, 4, 4, 2, 4, 4, 3, 0, 0, 0, 1, 1, 1, 2, 2, 4, 0, 4, 0, 0, 2, 0, 2, 1, 2, 0, 3, 3, 0, 1, 0, 1, 1, 0, 3, 3, 3, 2, 4, 2, 3, 0, 3, 1, 0, 0, 0, 4, 3, 3, 3, 4, 0, 4, 1, 1]\n",
      "[4, 2, 2, 2, 4, 3, 0, 4, 3, 4, 3, 0, 4, 4, 2, 3, 3, 3, 2, 4, 0, 2, 0, 0, 0, 2, 2, 4, 0, 4, 4, 2, 3, 4, 2, 4, 0, 4, 2, 4, 2, 2, 4, 3, 4, 4, 2, 4, 2, 3, 2, 4, 4, 3, 4, 2, 3, 0, 3, 0, 2, 0, 4, 4, 4, 4, 0, 0, 2, 2, 4, 2, 2, 0, 3, 2, 4, 0, 2, 3, 4, 4, 2, 3, 4, 3, 2, 2, 4, 0, 3, 4, 2, 3, 2, 4, 3, 2, 2, 2, 3, 2, 2, 3, 0, 4, 3, 0, 0, 2, 2, 2, 4, 2, 3, 2, 3, 2, 4, 2, 0, 3, 3, 3, 2, 2, 2, 0, 2, 3, 2, 0, 3, 4, 4, 0, 2, 4, 2, 2, 0, 2, 2, 3, 0, 2, 4, 2, 2, 4, 0, 4, 2, 2, 3, 3, 0, 2, 2, 3, 3, 4, 3, 4, 2, 4, 2, 4, 2, 3, 4, 2, 2, 4, 4, 2, 4, 2, 3, 0, 2, 0, 4, 2, 4, 3, 4, 3, 2, 4, 2, 4, 4, 4, 2, 3, 4, 4, 3, 2, 4, 2, 3, 2, 4, 3, 4, 2, 4, 2, 3, 0, 0, 3, 2, 4, 4, 4, 2, 3, 0, 4, 0, 4, 4, 3, 4, 3, 0, 3, 2, 3, 4, 2, 2, 2, 3, 2, 2, 2, 0, 0, 0, 2, 3, 4, 0, 4, 4, 4, 4, 2, 3, 2, 3, 3, 2, 4, 2, 2, 3, 2, 2, 3, 4, 4, 2, 0, 4, 4, 3, 4, 2, 0, 3, 0, 4, 2, 4, 0, 2, 3, 0, 2, 2, 0, 0, 0, 3, 4, 0, 4, 4, 4, 0, 3, 2, 3, 2, 3, 2, 0, 3, 0, 2, 2, 4, 4, 2, 4, 0, 0, 0, 2, 2, 3, 2, 3, 4, 2, 2, 2, 0, 2, 3, 0, 4, 2, 3, 2, 4, 4, 3, 3, 4, 0, 4, 2, 3, 4, 0, 4, 2, 3, 0, 3, 2, 3, 3, 4, 4, 2, 2, 0, 4, 4, 3, 2, 2, 0, 0, 0, 4, 2, 3, 0, 2, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 2, 0, 3, 4, 4, 4, 2, 4, 3, 2, 4, 4, 4, 0, 2, 2, 2, 0, 3, 0, 4, 4, 4, 4, 3, 2, 4, 4, 2, 4, 4, 0, 3, 4, 3, 4, 2, 0, 0, 0, 0, 3, 4, 0, 4, 0, 2, 4, 2, 2, 2, 2, 3, 0, 3, 4, 3, 3, 2, 4, 4, 2, 3, 2, 4, 2, 2, 4, 4, 2, 4, 4, 3, 0, 0, 0, 2, 4, 4, 2, 2, 4, 0, 4, 0, 0, 2, 2, 0, 3, 2, 2, 3, 3, 0, 2, 0, 4, 2, 2, 3, 3, 3, 2, 2, 2, 3, 2, 3, 3, 0, 0, 0, 4, 3, 3, 3, 4, 0, 4, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.55      0.89      0.68       100\n",
      "           3       0.78      0.84      0.81       100\n",
      "           4       0.57      0.81      0.67       100\n",
      "\n",
      "    accuracy                           0.64       500\n",
      "   macro avg       0.53      0.64      0.58       500\n",
      "weighted avg       0.53      0.64      0.58       500\n",
      "\n",
      "Val loss: 1.2562063932418823, Val acc: 0.644\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15900 - Batch 80/1582 - Train loss: 1.0697964738916468, Train acc: 0.8341049382716049\n",
      "Iteration 16000 - Batch 180/1582 - Train loss: 1.0697948369532, Train acc: 0.8339088397790055\n",
      "Iteration 16100 - Batch 280/1582 - Train loss: 1.068950008030888, Train acc: 0.8344083629893239\n",
      "Iteration 16200 - Batch 380/1582 - Train loss: 1.0638224790728312, Train acc: 0.839730971128609\n",
      "Iteration 16300 - Batch 480/1582 - Train loss: 1.0615715218432975, Train acc: 0.8423856548856549\n",
      "Iteration 16400 - Batch 580/1582 - Train loss: 1.0598066698458437, Train acc: 0.8443954388984509\n",
      "Iteration 16500 - Batch 680/1582 - Train loss: 1.0588924234484085, Train acc: 0.8454478707782672\n",
      "Iteration 16600 - Batch 780/1582 - Train loss: 1.0588439460295263, Train acc: 0.8452704865556978\n",
      "Iteration 16700 - Batch 880/1582 - Train loss: 1.0580209913778793, Train acc: 0.8461620317820658\n",
      "Iteration 16800 - Batch 980/1582 - Train loss: 1.058962307817224, Train acc: 0.8452153414882773\n",
      "Iteration 16900 - Batch 1080/1582 - Train loss: 1.0584511254034474, Train acc: 0.8456868640148011\n",
      "Iteration 17000 - Batch 1180/1582 - Train loss: 1.059096961128419, Train acc: 0.844993649449619\n",
      "Iteration 17100 - Batch 1280/1582 - Train loss: 1.0592255055857858, Train acc: 0.8447989851678376\n",
      "Iteration 17200 - Batch 1380/1582 - Train loss: 1.0588278143756378, Train acc: 0.8452208544532948\n",
      "Iteration 17300 - Batch 1480/1582 - Train loss: 1.05893049700529, Train acc: 0.8452692437542201\n",
      "Iteration 17400 - Batch 1580/1582 - Train loss: 1.0594092583746793, Train acc: 0.844758064516129\n",
      "[4, 4, 1, 4, 0, 4, 3, 4, 2, 3, 1, 3, 0, 4, 3, 0, 1, 2, 3, 0, 4, 0, 0, 0, 2, 3, 4, 0, 4, 4, 1, 1, 4, 4, 0, 3, 3, 2, 3, 1, 3, 3, 2, 2, 4, 2, 2, 1, 1, 2, 1, 0, 0, 2, 2, 2, 2, 4, 2, 4, 1, 4, 3, 1, 2, 0, 3, 0, 3, 0, 2, 4, 3, 0, 0, 0, 2, 0, 4, 4, 3, 3, 2, 4, 0, 1, 4, 3, 1, 3, 0, 4, 0, 3, 4, 1, 0, 0, 3, 1, 4, 1, 2, 2, 3, 3, 3, 2, 4, 0, 2, 1, 0, 3, 3, 4, 4, 2, 0, 2, 3, 2, 2, 2, 0, 0, 1, 1, 4, 1, 1, 3, 0, 1, 2, 0, 0, 2, 1, 0, 1, 4, 3, 3, 0, 2, 3, 3, 2, 3, 0, 3, 0, 1, 2, 3, 4, 3, 0, 2, 1, 1, 3, 2, 1, 3, 3, 1, 1, 1, 0, 3, 2, 3, 1, 4, 2, 3, 3, 1, 4, 1, 3, 0, 0, 2, 3, 3, 2, 4, 3, 4, 4, 2, 3, 3, 2, 3, 3, 0, 1, 1, 4, 1, 3, 4, 1, 0, 0, 3, 2, 0, 0, 1, 4, 1, 4, 3, 1, 3, 2, 3, 4, 1, 2, 1, 0, 2, 4, 4, 2, 1, 1, 2, 3, 1, 4, 2, 4, 0, 2, 2, 3, 0, 1, 1, 2, 4, 3, 2, 3, 3, 0, 4, 4, 2, 3, 4, 4, 1, 1, 2, 4, 2, 2, 2, 2, 2, 3, 2, 1, 2, 1, 3, 3, 4, 2, 3, 4, 1, 3, 4, 1, 3, 4, 3, 1, 4, 3, 0, 1, 1, 4, 1, 0, 2, 1, 2, 4, 1, 0, 4, 1, 1, 0, 0, 0, 2, 1, 4, 0, 2, 4, 0, 1, 2, 0, 4, 0, 0, 4, 0, 1, 0, 1, 0, 1, 0, 3, 1, 4, 4, 2, 1, 3, 3, 1, 0, 4, 2, 2, 1, 4, 2, 1, 1, 0, 0, 4, 0, 2, 1, 0, 0, 0, 1, 0, 1, 3, 0, 4, 4, 0, 2, 0, 4, 3, 0, 2, 0, 4, 4, 0, 2, 4, 1, 1, 2, 0, 3, 3, 2, 0, 1, 4, 1, 1, 2, 2, 3, 1, 4, 3, 1, 0, 3, 0, 4, 4, 4, 3, 0, 1, 2, 0, 1, 4, 1, 3, 4, 2, 0, 2, 4, 3, 4, 0, 0, 2, 1, 0, 3, 0, 3, 1, 0, 2, 3, 4, 1, 3, 3, 2, 2, 0, 2, 4, 3, 1, 0, 2, 2, 4, 1, 2, 3, 1, 4, 4, 2, 1, 1, 3, 1, 2, 4, 3, 3, 2, 4, 2, 0, 2, 2, 2, 1, 3, 3, 0, 0, 3, 2, 0, 4, 4, 4, 1, 0, 0, 0, 4, 4, 2, 2, 0, 1, 4, 3, 4, 4, 1, 4, 4, 3, 3, 2, 4, 0, 3, 1]\n",
      "[4, 4, 0, 4, 0, 4, 3, 4, 2, 3, 4, 3, 4, 4, 3, 0, 3, 0, 3, 0, 4, 0, 0, 0, 2, 3, 4, 0, 4, 4, 2, 4, 3, 4, 4, 4, 3, 2, 3, 4, 3, 3, 0, 2, 4, 2, 0, 4, 4, 2, 4, 0, 2, 2, 2, 0, 2, 2, 2, 4, 0, 4, 3, 4, 2, 0, 3, 0, 3, 0, 0, 4, 3, 0, 0, 0, 2, 0, 4, 4, 3, 4, 2, 4, 0, 4, 4, 4, 0, 3, 0, 4, 0, 3, 4, 4, 4, 0, 3, 0, 4, 4, 0, 2, 3, 3, 3, 2, 4, 0, 2, 3, 0, 3, 3, 4, 4, 2, 4, 3, 4, 0, 2, 2, 0, 0, 3, 4, 4, 0, 3, 3, 0, 4, 2, 2, 0, 2, 4, 0, 4, 4, 3, 3, 0, 2, 3, 3, 2, 3, 0, 3, 0, 4, 2, 3, 4, 4, 0, 2, 4, 2, 3, 2, 2, 3, 3, 4, 4, 4, 4, 3, 2, 3, 4, 4, 2, 3, 3, 4, 4, 4, 0, 0, 0, 2, 3, 3, 2, 4, 3, 4, 4, 2, 3, 4, 2, 3, 3, 0, 0, 4, 4, 4, 3, 4, 4, 0, 4, 3, 0, 0, 0, 4, 4, 4, 4, 3, 4, 3, 2, 3, 4, 3, 0, 0, 0, 2, 4, 4, 0, 4, 2, 2, 3, 0, 4, 2, 4, 0, 2, 2, 3, 0, 3, 0, 3, 4, 4, 2, 3, 3, 0, 4, 4, 2, 4, 4, 4, 3, 3, 2, 4, 2, 2, 2, 2, 2, 3, 2, 4, 2, 3, 3, 3, 4, 2, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 0, 4, 4, 4, 4, 0, 2, 4, 4, 0, 0, 0, 4, 0, 3, 0, 0, 4, 0, 4, 4, 0, 0, 4, 0, 3, 2, 4, 4, 0, 0, 4, 0, 3, 0, 3, 0, 3, 0, 3, 3, 4, 4, 2, 4, 4, 4, 4, 0, 4, 0, 2, 3, 4, 2, 2, 4, 0, 0, 4, 0, 2, 3, 0, 0, 0, 4, 0, 0, 3, 0, 4, 4, 0, 2, 0, 4, 3, 0, 2, 0, 3, 4, 0, 2, 4, 4, 4, 0, 0, 3, 3, 2, 0, 3, 4, 3, 4, 2, 0, 3, 4, 4, 3, 4, 0, 3, 0, 4, 4, 4, 3, 0, 0, 2, 0, 4, 4, 3, 3, 0, 2, 0, 0, 4, 3, 4, 0, 0, 2, 4, 0, 3, 0, 3, 3, 0, 2, 3, 4, 3, 3, 3, 2, 2, 0, 2, 4, 3, 4, 0, 2, 2, 4, 4, 0, 3, 2, 4, 4, 2, 4, 0, 3, 4, 2, 4, 3, 3, 0, 4, 2, 0, 4, 2, 2, 4, 3, 3, 0, 4, 3, 2, 0, 4, 4, 3, 3, 0, 0, 0, 4, 4, 2, 2, 0, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 2, 4, 0, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.78      0.83       100\n",
      "           3       0.76      0.87      0.81       100\n",
      "           4       0.54      0.94      0.69       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.62       500\n",
      "weighted avg       0.58      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.202896624803543, Val acc: 0.696\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17500 - Batch 98/1582 - Train loss: 1.0404229718025284, Train acc: 0.8639520202020202\n",
      "Iteration 17600 - Batch 198/1582 - Train loss: 1.0486849157055418, Train acc: 0.8556846733668342\n",
      "Iteration 17700 - Batch 298/1582 - Train loss: 1.0481973766881885, Train acc: 0.8561872909698997\n",
      "Iteration 17800 - Batch 398/1582 - Train loss: 1.0488091114170868, Train acc: 0.855733082706767\n",
      "Iteration 17900 - Batch 498/1582 - Train loss: 1.052888071847583, Train acc: 0.8515155310621243\n",
      "Iteration 18000 - Batch 598/1582 - Train loss: 1.0536359669967168, Train acc: 0.8506364774624374\n",
      "Iteration 18100 - Batch 698/1582 - Train loss: 1.0533004415905016, Train acc: 0.8507242489270386\n",
      "Iteration 18200 - Batch 798/1582 - Train loss: 1.054123468780995, Train acc: 0.8496949311639549\n",
      "Iteration 18300 - Batch 898/1582 - Train loss: 1.0553344255427233, Train acc: 0.8484427141268076\n",
      "Iteration 18400 - Batch 998/1582 - Train loss: 1.0550005203849442, Train acc: 0.8488801301301301\n",
      "Iteration 18500 - Batch 1098/1582 - Train loss: 1.0544310243591815, Train acc: 0.8495507279344859\n",
      "Iteration 18600 - Batch 1198/1582 - Train loss: 1.0539724162660906, Train acc: 0.8499791492910759\n",
      "Iteration 18700 - Batch 1298/1582 - Train loss: 1.053597769111372, Train acc: 0.8502934949961509\n",
      "Iteration 18800 - Batch 1398/1582 - Train loss: 1.0538784262961878, Train acc: 0.850071479628306\n",
      "Iteration 18900 - Batch 1498/1582 - Train loss: 1.0541760958855433, Train acc: 0.849795697131421\n",
      "[1, 4, 0, 4, 1, 3, 3, 1, 3, 1, 4, 3, 2, 4, 3, 2, 4, 3, 2, 1, 3, 3, 1, 2, 4, 0, 2, 2, 4, 4, 2, 3, 3, 0, 4, 4, 0, 0, 2, 2, 3, 1, 0, 0, 0, 2, 0, 3, 2, 2, 1, 2, 1, 4, 3, 3, 2, 3, 3, 2, 2, 3, 2, 1, 1, 0, 0, 4, 0, 1, 3, 2, 4, 3, 4, 1, 1, 4, 0, 0, 0, 0, 2, 2, 1, 1, 4, 2, 2, 4, 0, 1, 3, 4, 0, 1, 4, 0, 4, 3, 0, 0, 3, 0, 2, 4, 3, 4, 1, 2, 1, 2, 3, 1, 2, 0, 4, 4, 0, 0, 2, 3, 0, 4, 2, 1, 3, 2, 1, 2, 2, 2, 1, 4, 2, 1, 4, 0, 1, 3, 1, 4, 2, 1, 2, 0, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 0, 0, 0, 4, 3, 4, 3, 1, 0, 0, 3, 0, 4, 0, 0, 4, 0, 2, 4, 2, 2, 3, 2, 3, 2, 2, 1, 2, 0, 3, 2, 4, 4, 0, 2, 4, 1, 3, 2, 0, 4, 4, 1, 1, 4, 2, 3, 1, 0, 4, 2, 3, 1, 3, 0, 3, 3, 4, 1, 1, 4, 3, 1, 1, 4, 1, 0, 3, 0, 2, 1, 0, 0, 2, 1, 2, 3, 0, 1, 3, 0, 4, 4, 2, 3, 3, 3, 0, 4, 2, 4, 3, 0, 4, 2, 4, 1, 3, 3, 3, 0, 4, 0, 0, 0, 2, 2, 4, 4, 4, 3, 4, 1, 1, 3, 4, 3, 1, 1, 1, 4, 3, 2, 1, 0, 4, 2, 4, 3, 2, 0, 2, 2, 4, 2, 4, 2, 4, 4, 1, 1, 4, 2, 0, 4, 3, 0, 1, 3, 1, 3, 4, 2, 4, 2, 0, 4, 1, 1, 3, 4, 2, 1, 3, 1, 2, 1, 2, 3, 1, 1, 0, 1, 2, 0, 0, 3, 1, 0, 2, 3, 1, 1, 3, 1, 1, 2, 1, 0, 0, 0, 0, 1, 4, 3, 3, 1, 0, 4, 2, 2, 4, 2, 4, 0, 1, 3, 3, 3, 1, 2, 4, 1, 3, 3, 3, 0, 1, 1, 0, 0, 3, 0, 1, 0, 4, 2, 0, 2, 0, 2, 3, 2, 2, 0, 2, 1, 2, 0, 1, 3, 0, 0, 1, 3, 4, 1, 0, 3, 4, 2, 1, 4, 3, 3, 4, 1, 4, 3, 4, 0, 1, 0, 1, 1, 3, 3, 1, 4, 1, 4, 3, 3, 2, 3, 0, 4, 0, 0, 2, 0, 0, 2, 3, 1, 2, 0, 4, 4, 0, 4, 1, 0, 0, 0, 3, 3, 2, 1, 1, 2, 1, 1, 2, 3, 2, 2, 2, 2, 1, 1, 0, 2, 1, 4, 3, 4, 1, 4, 0, 1, 2, 3, 0, 4, 0, 4, 3, 4, 4, 0, 2, 2, 2, 3, 2, 3, 0, 0, 3, 1, 1, 3]\n",
      "[2, 4, 0, 4, 4, 3, 3, 4, 3, 4, 4, 3, 2, 4, 4, 0, 4, 3, 2, 4, 3, 3, 2, 2, 4, 0, 2, 2, 4, 4, 2, 3, 3, 0, 4, 4, 0, 0, 2, 2, 3, 4, 2, 0, 0, 2, 0, 3, 0, 2, 4, 2, 4, 4, 4, 3, 2, 3, 3, 2, 2, 0, 2, 3, 2, 4, 0, 4, 0, 4, 3, 2, 4, 3, 4, 3, 3, 4, 0, 0, 0, 0, 2, 2, 4, 4, 4, 2, 0, 4, 0, 4, 3, 3, 0, 4, 4, 0, 4, 3, 0, 2, 3, 0, 2, 4, 3, 4, 3, 2, 4, 2, 3, 3, 2, 0, 2, 4, 0, 0, 2, 3, 0, 4, 2, 4, 3, 2, 4, 0, 2, 2, 4, 4, 2, 4, 4, 0, 4, 3, 4, 4, 2, 4, 2, 0, 4, 3, 3, 4, 3, 3, 4, 4, 4, 4, 2, 0, 0, 0, 4, 3, 4, 3, 4, 0, 0, 3, 0, 4, 0, 0, 4, 2, 2, 4, 2, 0, 3, 2, 3, 2, 2, 4, 2, 0, 3, 2, 4, 4, 0, 2, 4, 4, 4, 2, 4, 4, 2, 3, 4, 4, 0, 3, 4, 0, 3, 2, 3, 2, 3, 0, 3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 0, 3, 2, 2, 4, 0, 0, 2, 4, 2, 3, 0, 3, 3, 4, 4, 4, 2, 4, 3, 3, 4, 4, 2, 4, 3, 0, 4, 2, 4, 3, 3, 4, 4, 0, 4, 0, 4, 4, 2, 2, 4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 0, 4, 4, 3, 2, 0, 0, 4, 2, 4, 3, 2, 0, 2, 3, 4, 2, 4, 2, 4, 4, 0, 2, 4, 2, 0, 4, 3, 0, 4, 3, 4, 3, 4, 2, 4, 2, 0, 4, 3, 4, 3, 4, 2, 4, 3, 4, 2, 4, 2, 3, 3, 0, 0, 3, 2, 0, 2, 3, 3, 2, 2, 3, 0, 3, 3, 4, 4, 2, 2, 0, 0, 2, 2, 2, 3, 3, 3, 4, 2, 4, 0, 2, 4, 2, 4, 2, 0, 3, 4, 3, 2, 2, 4, 0, 3, 3, 3, 0, 4, 0, 0, 0, 3, 0, 4, 0, 4, 2, 0, 2, 0, 2, 3, 2, 4, 0, 2, 4, 2, 0, 4, 3, 0, 4, 0, 3, 4, 4, 4, 3, 4, 2, 4, 4, 3, 3, 4, 0, 4, 3, 4, 0, 4, 0, 4, 4, 4, 3, 3, 4, 3, 3, 3, 3, 2, 3, 0, 4, 2, 0, 2, 0, 0, 2, 3, 4, 2, 0, 4, 3, 0, 4, 4, 2, 0, 0, 3, 4, 2, 3, 4, 2, 4, 3, 3, 3, 2, 2, 2, 2, 4, 4, 0, 0, 3, 4, 3, 4, 4, 4, 4, 3, 2, 3, 0, 4, 0, 4, 3, 4, 4, 0, 2, 2, 2, 3, 0, 4, 0, 2, 3, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.88      0.83       100\n",
      "           3       0.76      0.89      0.82       100\n",
      "           4       0.53      0.92      0.67       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.208514578640461, Val acc: 0.694\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19000 - Batch 16/1582 - Train loss: 1.0741521575871635, Train acc: 0.8290441176470589\n",
      "Iteration 19100 - Batch 116/1582 - Train loss: 1.0506303921723976, Train acc: 0.8530982905982906\n",
      "Iteration 19200 - Batch 216/1582 - Train loss: 1.05062486169525, Train acc: 0.8532546082949308\n",
      "Iteration 19300 - Batch 316/1582 - Train loss: 1.0513175299114985, Train acc: 0.8522279179810726\n",
      "Iteration 19400 - Batch 416/1582 - Train loss: 1.0500321779891455, Train acc: 0.8536420863309353\n",
      "Iteration 19500 - Batch 516/1582 - Train loss: 1.0512504888918228, Train acc: 0.852151837524178\n",
      "Iteration 19600 - Batch 616/1582 - Train loss: 1.0485028639025202, Train acc: 0.8551965153970826\n",
      "Iteration 19700 - Batch 716/1582 - Train loss: 1.0491726155726646, Train acc: 0.8544717573221757\n",
      "Iteration 19800 - Batch 816/1582 - Train loss: 1.048409243546326, Train acc: 0.8552249082007344\n",
      "Iteration 19900 - Batch 916/1582 - Train loss: 1.0467291130494396, Train acc: 0.8569724645583424\n",
      "Iteration 20000 - Batch 1016/1582 - Train loss: 1.0472741672071384, Train acc: 0.8565941494591937\n",
      "Iteration 20100 - Batch 1116/1582 - Train loss: 1.0490895638854352, Train acc: 0.8546888988361683\n",
      "Iteration 20200 - Batch 1216/1582 - Train loss: 1.0488462981476387, Train acc: 0.8549455628594905\n",
      "Iteration 20300 - Batch 1316/1582 - Train loss: 1.0489139106116154, Train acc: 0.8548785117691724\n",
      "Iteration 20400 - Batch 1416/1582 - Train loss: 1.0487896934645902, Train acc: 0.8551076217360621\n",
      "Iteration 20500 - Batch 1516/1582 - Train loss: 1.0491282343471529, Train acc: 0.8549151285431773\n",
      "[0, 0, 4, 3, 1, 2, 1, 0, 2, 0, 2, 1, 0, 4, 4, 4, 2, 0, 3, 2, 1, 0, 3, 4, 1, 3, 0, 4, 1, 3, 3, 3, 4, 1, 3, 3, 2, 3, 0, 0, 3, 2, 3, 2, 0, 4, 1, 3, 4, 0, 4, 4, 1, 3, 4, 4, 4, 0, 4, 1, 0, 3, 3, 0, 4, 3, 2, 0, 2, 0, 0, 4, 1, 0, 0, 1, 3, 3, 1, 3, 2, 3, 3, 0, 3, 1, 0, 2, 3, 0, 3, 2, 2, 0, 1, 3, 2, 4, 1, 4, 0, 3, 2, 4, 3, 0, 2, 2, 2, 3, 4, 0, 1, 1, 0, 4, 4, 0, 4, 3, 2, 3, 4, 0, 4, 1, 4, 3, 3, 1, 2, 3, 2, 0, 4, 3, 3, 3, 2, 0, 4, 2, 3, 0, 0, 1, 4, 1, 0, 1, 2, 0, 1, 4, 2, 3, 0, 3, 2, 4, 0, 0, 1, 3, 4, 4, 4, 0, 4, 2, 2, 4, 1, 0, 4, 3, 2, 0, 0, 0, 1, 4, 4, 3, 0, 3, 2, 2, 3, 1, 2, 3, 4, 4, 4, 2, 1, 0, 3, 2, 1, 4, 1, 3, 2, 2, 0, 3, 1, 0, 2, 2, 4, 1, 3, 1, 3, 0, 2, 0, 0, 4, 1, 4, 2, 0, 1, 1, 0, 4, 1, 2, 4, 4, 1, 1, 3, 4, 3, 0, 2, 2, 1, 3, 4, 2, 1, 0, 2, 2, 0, 1, 2, 2, 1, 4, 3, 1, 4, 3, 1, 0, 0, 3, 4, 2, 4, 1, 0, 4, 1, 4, 1, 4, 2, 4, 0, 1, 4, 1, 3, 1, 3, 2, 4, 4, 4, 4, 1, 3, 0, 2, 1, 1, 2, 4, 3, 1, 4, 3, 4, 3, 2, 0, 3, 3, 0, 2, 0, 1, 2, 2, 0, 1, 4, 1, 1, 4, 2, 4, 0, 1, 2, 1, 2, 0, 4, 2, 2, 1, 0, 2, 1, 4, 4, 2, 0, 0, 1, 4, 1, 3, 3, 1, 4, 2, 0, 0, 0, 3, 1, 0, 1, 3, 2, 1, 0, 4, 3, 4, 0, 3, 1, 2, 4, 3, 2, 2, 1, 4, 3, 1, 4, 4, 2, 0, 1, 4, 4, 0, 1, 0, 2, 3, 2, 2, 1, 2, 0, 1, 2, 3, 3, 3, 0, 3, 2, 2, 1, 1, 3, 4, 0, 3, 1, 4, 1, 2, 3, 1, 1, 1, 1, 3, 1, 2, 4, 3, 2, 0, 2, 3, 1, 0, 1, 2, 1, 2, 2, 2, 1, 0, 0, 0, 0, 3, 2, 3, 4, 0, 2, 1, 3, 3, 3, 2, 2, 4, 3, 0, 1, 2, 0, 3, 3, 3, 2, 2, 2, 1, 2, 3, 3, 0, 0, 2, 2, 1, 1, 4, 4, 3, 3, 4, 4, 3, 2, 2, 1, 1, 1, 0, 3, 0, 4, 0, 4, 3, 1, 1, 0, 0, 4, 0, 4, 4, 0, 4, 4, 2]\n",
      "[0, 0, 4, 3, 0, 2, 0, 0, 2, 0, 0, 4, 0, 4, 4, 4, 2, 0, 4, 2, 4, 0, 3, 4, 4, 3, 0, 4, 4, 3, 3, 3, 4, 0, 3, 3, 2, 3, 0, 0, 3, 2, 3, 2, 0, 4, 3, 3, 4, 0, 4, 4, 4, 2, 4, 4, 4, 0, 2, 4, 0, 3, 4, 0, 4, 3, 2, 0, 2, 0, 0, 0, 4, 0, 0, 3, 3, 3, 4, 3, 0, 4, 3, 0, 3, 4, 0, 0, 3, 0, 3, 2, 2, 0, 0, 3, 2, 4, 4, 4, 0, 3, 2, 4, 4, 0, 2, 2, 2, 4, 4, 0, 4, 0, 0, 4, 4, 0, 4, 3, 2, 3, 4, 0, 4, 4, 4, 3, 3, 4, 0, 3, 0, 0, 4, 3, 3, 0, 2, 0, 4, 2, 3, 0, 0, 3, 4, 4, 4, 2, 2, 0, 4, 4, 2, 0, 0, 3, 2, 4, 0, 0, 0, 4, 4, 4, 4, 0, 4, 2, 0, 4, 4, 4, 4, 3, 0, 0, 0, 0, 4, 4, 4, 4, 0, 3, 4, 2, 3, 4, 0, 3, 4, 3, 4, 2, 3, 2, 3, 2, 4, 4, 0, 3, 2, 2, 0, 3, 4, 0, 0, 2, 4, 3, 3, 0, 3, 0, 2, 0, 0, 4, 4, 4, 2, 0, 3, 4, 0, 4, 4, 2, 4, 4, 0, 4, 3, 4, 3, 0, 2, 0, 4, 3, 4, 0, 0, 0, 0, 0, 0, 3, 2, 2, 4, 4, 4, 0, 4, 4, 0, 0, 0, 3, 4, 2, 4, 0, 0, 4, 4, 4, 0, 4, 2, 4, 0, 0, 4, 4, 3, 4, 3, 2, 4, 4, 4, 4, 4, 4, 0, 2, 4, 3, 2, 4, 3, 4, 2, 3, 4, 4, 2, 0, 3, 4, 0, 2, 0, 0, 2, 0, 0, 4, 4, 4, 0, 0, 2, 4, 0, 4, 2, 4, 2, 0, 4, 2, 0, 2, 0, 2, 4, 4, 4, 2, 0, 0, 4, 4, 3, 3, 3, 2, 4, 2, 0, 0, 0, 3, 4, 0, 3, 3, 2, 4, 0, 4, 3, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 4, 3, 0, 4, 4, 2, 0, 4, 4, 4, 4, 4, 0, 0, 3, 2, 2, 4, 2, 0, 4, 2, 3, 4, 3, 0, 3, 2, 2, 0, 4, 3, 4, 0, 2, 4, 4, 4, 2, 3, 4, 4, 0, 4, 3, 4, 0, 4, 4, 2, 0, 0, 4, 0, 4, 0, 0, 4, 2, 0, 2, 2, 0, 0, 0, 0, 3, 2, 3, 4, 0, 2, 0, 3, 3, 3, 2, 0, 4, 4, 0, 3, 0, 0, 3, 3, 3, 2, 4, 0, 3, 2, 3, 4, 0, 0, 2, 2, 0, 0, 4, 4, 3, 3, 4, 4, 3, 0, 0, 3, 4, 0, 0, 3, 0, 4, 0, 4, 3, 4, 3, 0, 0, 4, 0, 4, 4, 0, 4, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.95      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.72      0.80       100\n",
      "           3       0.84      0.79      0.81       100\n",
      "           4       0.55      0.95      0.70       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.58      0.68      0.61       500\n",
      "weighted avg       0.58      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2206701040267944, Val acc: 0.682\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20600 - Batch 34/1582 - Train loss: 1.053580859729222, Train acc: 0.8482142857142857\n",
      "Iteration 20700 - Batch 134/1582 - Train loss: 1.0463295375859296, Train acc: 0.8557870370370371\n",
      "Iteration 20800 - Batch 234/1582 - Train loss: 1.0479968382957134, Train acc: 0.8542553191489362\n",
      "Iteration 20900 - Batch 334/1582 - Train loss: 1.051368356640659, Train acc: 0.8512126865671642\n",
      "Iteration 21000 - Batch 434/1582 - Train loss: 1.0495053684574434, Train acc: 0.8530890804597702\n",
      "Iteration 21100 - Batch 534/1582 - Train loss: 1.048734184626107, Train acc: 0.854088785046729\n",
      "Iteration 21200 - Batch 634/1582 - Train loss: 1.0504773815785806, Train acc: 0.8523622047244095\n",
      "Iteration 21300 - Batch 734/1582 - Train loss: 1.0495957760583787, Train acc: 0.8534013605442177\n",
      "Iteration 21400 - Batch 834/1582 - Train loss: 1.050045626249142, Train acc: 0.8532185628742515\n",
      "Iteration 21500 - Batch 934/1582 - Train loss: 1.049504791797801, Train acc: 0.8539438502673797\n",
      "Iteration 21600 - Batch 1034/1582 - Train loss: 1.0483564698177836, Train acc: 0.8552838164251207\n",
      "Iteration 21700 - Batch 1134/1582 - Train loss: 1.0488167072707861, Train acc: 0.8547632158590308\n",
      "Iteration 21800 - Batch 1234/1582 - Train loss: 1.048852199484945, Train acc: 0.8547823886639676\n",
      "Iteration 21900 - Batch 1334/1582 - Train loss: 1.0486101652799027, Train acc: 0.8551498127340824\n",
      "Iteration 22000 - Batch 1434/1582 - Train loss: 1.0485215033388304, Train acc: 0.8552918118466899\n",
      "Iteration 22100 - Batch 1534/1582 - Train loss: 1.0483272906235064, Train acc: 0.8555374592833876\n",
      "[2, 0, 0, 2, 3, 0, 0, 2, 3, 0, 0, 2, 2, 3, 1, 1, 4, 4, 2, 1, 4, 4, 0, 0, 4, 0, 1, 0, 4, 4, 2, 0, 4, 4, 0, 3, 3, 0, 2, 1, 4, 2, 1, 4, 3, 3, 4, 1, 3, 4, 1, 3, 1, 3, 3, 4, 2, 0, 4, 0, 3, 2, 2, 3, 0, 2, 4, 2, 3, 2, 3, 1, 3, 4, 4, 1, 3, 2, 0, 4, 2, 1, 0, 1, 3, 0, 4, 4, 3, 4, 3, 3, 3, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 3, 0, 3, 0, 3, 2, 4, 4, 3, 4, 2, 0, 4, 2, 4, 1, 2, 0, 0, 2, 1, 3, 3, 1, 0, 4, 4, 0, 1, 0, 3, 3, 1, 3, 1, 2, 4, 3, 1, 0, 1, 4, 2, 4, 1, 2, 3, 2, 0, 3, 4, 1, 1, 1, 0, 0, 0, 2, 2, 1, 2, 0, 4, 0, 0, 0, 2, 0, 0, 0, 4, 4, 1, 4, 2, 0, 2, 2, 2, 0, 2, 2, 1, 2, 0, 1, 1, 1, 2, 2, 2, 3, 4, 2, 1, 0, 3, 2, 1, 4, 1, 0, 1, 1, 0, 1, 1, 1, 4, 0, 0, 1, 3, 4, 4, 2, 0, 1, 2, 1, 3, 2, 4, 2, 3, 4, 3, 0, 0, 0, 2, 3, 4, 1, 0, 1, 4, 2, 1, 4, 1, 0, 2, 0, 1, 3, 4, 3, 2, 1, 1, 4, 2, 3, 0, 1, 1, 3, 1, 4, 2, 0, 4, 1, 4, 2, 0, 4, 1, 0, 2, 2, 3, 2, 4, 2, 3, 2, 0, 2, 1, 2, 3, 4, 0, 1, 0, 3, 3, 2, 2, 2, 3, 3, 4, 1, 4, 0, 3, 4, 2, 3, 3, 4, 0, 0, 4, 4, 2, 1, 1, 3, 0, 3, 4, 2, 3, 3, 1, 3, 1, 3, 2, 3, 3, 2, 3, 2, 3, 4, 0, 4, 3, 3, 3, 0, 1, 1, 1, 1, 0, 1, 2, 4, 0, 4, 0, 3, 2, 3, 3, 4, 4, 3, 4, 1, 0, 3, 3, 0, 3, 0, 2, 3, 2, 2, 2, 0, 1, 0, 1, 1, 1, 4, 1, 4, 4, 4, 0, 0, 1, 2, 3, 1, 1, 0, 2, 1, 2, 1, 1, 3, 4, 3, 0, 1, 2, 2, 4, 1, 4, 4, 3, 4, 0, 1, 2, 0, 4, 4, 4, 1, 0, 2, 4, 2, 4, 3, 2, 1, 1, 4, 3, 1, 0, 2, 4, 3, 3, 4, 1, 0, 3, 3, 2, 4, 4, 1, 1, 2, 2, 1, 2, 4, 3, 1, 4, 0, 0, 4, 2, 0, 4, 3, 2, 0, 2, 3, 2, 1, 1, 4, 4, 4, 3, 0, 0, 0, 1, 0, 3, 2, 3, 1, 3, 2, 3, 0, 0, 1, 0, 3, 1, 2, 4, 1, 1, 4, 0, 0, 4, 4, 3, 4, 3, 3, 1]\n",
      "[0, 0, 0, 2, 2, 0, 0, 2, 3, 0, 0, 0, 0, 3, 3, 2, 4, 4, 2, 3, 2, 3, 0, 4, 4, 0, 4, 0, 4, 4, 0, 4, 4, 4, 0, 4, 3, 0, 2, 3, 4, 2, 3, 4, 3, 4, 4, 3, 3, 4, 2, 3, 4, 3, 3, 4, 2, 0, 4, 0, 3, 0, 0, 3, 0, 0, 4, 2, 3, 2, 3, 3, 3, 4, 4, 2, 3, 2, 0, 3, 2, 4, 0, 4, 3, 0, 4, 4, 3, 4, 3, 3, 3, 2, 4, 0, 0, 0, 3, 0, 2, 3, 2, 3, 0, 3, 0, 3, 2, 4, 4, 3, 4, 0, 0, 4, 2, 4, 3, 2, 0, 0, 0, 0, 3, 3, 4, 0, 4, 4, 0, 4, 0, 3, 3, 0, 3, 4, 2, 4, 3, 3, 0, 4, 4, 0, 4, 0, 0, 3, 2, 0, 3, 4, 0, 3, 3, 0, 4, 4, 2, 2, 4, 0, 0, 4, 0, 0, 0, 2, 0, 4, 0, 4, 4, 0, 4, 0, 0, 2, 0, 2, 0, 2, 2, 3, 2, 0, 4, 4, 0, 2, 0, 2, 3, 4, 2, 0, 0, 3, 2, 0, 4, 0, 2, 4, 0, 0, 4, 3, 3, 4, 0, 0, 4, 3, 4, 4, 2, 0, 4, 2, 4, 3, 0, 4, 2, 3, 4, 3, 0, 4, 0, 4, 3, 4, 0, 0, 4, 4, 2, 4, 4, 4, 0, 2, 0, 4, 3, 4, 3, 2, 3, 4, 4, 2, 4, 4, 3, 2, 3, 3, 4, 2, 0, 4, 3, 4, 0, 0, 4, 0, 0, 2, 2, 3, 0, 4, 2, 3, 2, 0, 2, 3, 2, 3, 4, 0, 0, 0, 4, 3, 4, 2, 2, 3, 3, 4, 0, 4, 0, 3, 4, 2, 3, 3, 4, 0, 0, 4, 4, 2, 4, 4, 3, 0, 3, 4, 2, 3, 3, 3, 3, 3, 3, 2, 3, 4, 2, 3, 2, 4, 4, 0, 4, 3, 3, 4, 2, 0, 4, 4, 3, 0, 4, 2, 4, 0, 4, 0, 3, 2, 3, 3, 4, 4, 3, 4, 0, 0, 3, 3, 0, 3, 0, 2, 3, 2, 0, 2, 2, 4, 0, 3, 4, 4, 4, 3, 4, 4, 4, 0, 0, 3, 2, 3, 4, 4, 0, 2, 0, 0, 3, 4, 3, 4, 4, 0, 4, 2, 2, 4, 0, 4, 4, 0, 4, 0, 4, 2, 0, 4, 4, 4, 3, 0, 2, 4, 2, 4, 3, 2, 3, 3, 4, 3, 2, 0, 2, 4, 3, 3, 4, 4, 0, 3, 3, 2, 4, 4, 4, 4, 4, 4, 3, 2, 4, 3, 3, 4, 0, 0, 4, 2, 0, 4, 3, 0, 0, 0, 3, 0, 4, 4, 4, 4, 4, 3, 0, 0, 0, 3, 0, 3, 2, 3, 4, 4, 2, 3, 0, 0, 3, 0, 3, 0, 0, 4, 0, 4, 4, 0, 0, 4, 4, 4, 4, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.71      0.78       100\n",
      "           3       0.71      0.87      0.78       100\n",
      "           4       0.61      0.97      0.75       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.61       500\n",
      "weighted avg       0.57      0.69      0.61       500\n",
      "\n",
      "Val loss: 1.209810547530651, Val acc: 0.69\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22200 - Batch 52/1582 - Train loss: 1.0397524676232968, Train acc: 0.8667452830188679\n",
      "Iteration 22300 - Batch 152/1582 - Train loss: 1.0517469301722409, Train acc: 0.8535539215686274\n",
      "Iteration 22400 - Batch 252/1582 - Train loss: 1.0507452497369216, Train acc: 0.8538784584980237\n",
      "Iteration 22500 - Batch 352/1582 - Train loss: 1.049948591686173, Train acc: 0.8541076487252125\n",
      "Iteration 22600 - Batch 452/1582 - Train loss: 1.048161214682177, Train acc: 0.855546357615894\n",
      "Iteration 22700 - Batch 552/1582 - Train loss: 1.04909559981948, Train acc: 0.8545999095840868\n",
      "Iteration 22800 - Batch 652/1582 - Train loss: 1.0493676272687285, Train acc: 0.8542783307810107\n",
      "Iteration 22900 - Batch 752/1582 - Train loss: 1.0507648542107815, Train acc: 0.8529631474103586\n",
      "Iteration 23000 - Batch 852/1582 - Train loss: 1.048387758826874, Train acc: 0.855436694021102\n",
      "Iteration 23100 - Batch 952/1582 - Train loss: 1.0495615318839722, Train acc: 0.8542431794333684\n",
      "Iteration 23200 - Batch 1052/1582 - Train loss: 1.0494874937129044, Train acc: 0.8542260208926875\n",
      "Iteration 23300 - Batch 1152/1582 - Train loss: 1.0489396790473853, Train acc: 0.8548894189071986\n",
      "Iteration 23400 - Batch 1252/1582 - Train loss: 1.0488466888737507, Train acc: 0.8549980047885076\n",
      "Iteration 23500 - Batch 1352/1582 - Train loss: 1.0489893401453254, Train acc: 0.8546978935698448\n",
      "Iteration 23600 - Batch 1452/1582 - Train loss: 1.0486208624619906, Train acc: 0.8551703372333104\n",
      "Iteration 23700 - Batch 1552/1582 - Train loss: 1.0485869963093872, Train acc: 0.8552599806825499\n",
      "[0, 0, 4, 4, 1, 1, 0, 3, 1, 4, 1, 1, 2, 2, 2, 4, 1, 3, 3, 4, 2, 0, 4, 3, 2, 0, 3, 3, 4, 0, 2, 1, 4, 1, 4, 4, 3, 3, 2, 3, 0, 3, 0, 2, 0, 2, 0, 4, 1, 2, 2, 3, 3, 0, 4, 2, 1, 2, 3, 4, 1, 2, 3, 3, 2, 4, 1, 0, 1, 4, 1, 4, 1, 2, 1, 4, 1, 4, 4, 0, 2, 4, 2, 4, 1, 3, 0, 4, 0, 0, 2, 0, 1, 2, 3, 4, 1, 3, 0, 4, 1, 3, 2, 4, 4, 4, 2, 1, 4, 4, 1, 0, 0, 4, 1, 4, 0, 0, 2, 4, 4, 3, 3, 0, 0, 2, 0, 4, 4, 2, 0, 3, 3, 0, 3, 3, 1, 0, 1, 3, 3, 4, 4, 3, 3, 3, 3, 0, 2, 4, 2, 4, 0, 2, 2, 0, 0, 3, 2, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 1, 4, 4, 2, 1, 1, 2, 4, 4, 1, 3, 4, 0, 1, 2, 4, 2, 4, 1, 1, 3, 4, 2, 2, 1, 1, 0, 2, 2, 1, 0, 4, 2, 2, 1, 2, 1, 0, 4, 3, 1, 4, 1, 4, 4, 3, 3, 4, 1, 1, 3, 3, 0, 2, 3, 4, 4, 0, 0, 1, 4, 4, 3, 2, 4, 0, 0, 2, 2, 0, 3, 0, 1, 0, 3, 2, 3, 2, 4, 3, 0, 2, 2, 0, 1, 4, 2, 0, 1, 3, 1, 3, 1, 3, 1, 1, 3, 4, 1, 3, 2, 1, 1, 2, 0, 2, 1, 4, 0, 1, 4, 2, 2, 4, 2, 3, 1, 4, 4, 0, 1, 4, 2, 4, 4, 1, 0, 1, 3, 4, 4, 3, 0, 1, 0, 1, 2, 3, 3, 2, 2, 1, 2, 4, 2, 4, 0, 2, 1, 3, 3, 3, 2, 1, 4, 2, 3, 2, 0, 0, 1, 4, 3, 0, 4, 0, 4, 0, 2, 2, 1, 2, 2, 1, 3, 1, 1, 2, 3, 3, 3, 3, 0, 0, 2, 0, 1, 4, 3, 1, 0, 2, 3, 1, 0, 1, 2, 0, 2, 1, 1, 0, 0, 1, 2, 0, 3, 2, 2, 1, 2, 0, 3, 4, 1, 4, 2, 0, 0, 0, 4, 0, 0, 4, 2, 3, 4, 0, 4, 3, 2, 4, 3, 0, 2, 0, 2, 0, 4, 1, 1, 3, 1, 3, 4, 0, 2, 1, 4, 4, 0, 4, 0, 3, 3, 3, 4, 4, 1, 1, 1, 2, 3, 3, 1, 2, 3, 4, 3, 3, 0, 2, 3, 0, 3, 0, 3, 0, 2, 4, 3, 2, 3, 1, 2, 4, 3, 0, 0, 1, 4, 4, 2, 1, 3, 0, 4, 4, 0, 3, 1, 2, 3, 3, 3, 0, 1, 1, 2, 2, 2, 1, 3, 0, 4, 0, 0, 3, 0, 2, 2, 3, 3, 1, 3, 0, 1, 3, 3]\n",
      "[0, 0, 4, 4, 2, 3, 0, 3, 3, 4, 3, 3, 2, 2, 2, 4, 4, 3, 4, 4, 0, 0, 4, 3, 2, 4, 3, 3, 4, 0, 2, 3, 4, 4, 4, 3, 3, 3, 2, 3, 0, 3, 0, 2, 0, 2, 0, 4, 3, 2, 2, 4, 3, 0, 4, 2, 4, 2, 4, 4, 4, 2, 3, 3, 2, 4, 3, 0, 4, 4, 3, 4, 3, 2, 4, 3, 0, 4, 4, 0, 2, 4, 2, 4, 4, 3, 0, 4, 0, 0, 3, 0, 4, 2, 3, 4, 4, 3, 0, 4, 4, 3, 2, 4, 4, 4, 2, 4, 4, 4, 4, 0, 0, 4, 0, 4, 0, 0, 2, 4, 4, 3, 3, 0, 4, 2, 0, 4, 4, 2, 0, 3, 4, 2, 3, 3, 3, 0, 0, 3, 3, 4, 4, 3, 3, 3, 4, 0, 0, 4, 2, 4, 4, 2, 2, 0, 4, 3, 0, 0, 4, 0, 0, 0, 3, 0, 2, 4, 2, 3, 0, 4, 4, 4, 2, 4, 4, 2, 4, 4, 3, 3, 4, 0, 4, 2, 4, 3, 4, 4, 4, 4, 3, 2, 2, 3, 0, 0, 2, 2, 4, 0, 4, 2, 2, 3, 2, 2, 0, 4, 3, 4, 4, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 0, 2, 3, 2, 4, 0, 0, 4, 4, 4, 3, 0, 4, 0, 0, 2, 0, 0, 3, 0, 4, 0, 3, 2, 3, 0, 4, 3, 0, 2, 2, 0, 4, 4, 0, 0, 3, 3, 0, 3, 3, 3, 3, 0, 3, 4, 0, 4, 2, 4, 0, 2, 0, 2, 4, 4, 0, 4, 4, 0, 2, 4, 2, 3, 0, 4, 4, 0, 4, 4, 2, 4, 4, 4, 0, 4, 3, 4, 4, 3, 0, 4, 0, 3, 2, 3, 3, 2, 2, 4, 2, 4, 0, 4, 0, 2, 3, 3, 3, 3, 2, 4, 4, 2, 3, 2, 0, 0, 4, 4, 3, 0, 4, 0, 4, 0, 2, 2, 4, 2, 2, 4, 3, 4, 3, 0, 3, 3, 3, 3, 0, 0, 2, 0, 4, 4, 3, 4, 4, 2, 3, 3, 4, 4, 2, 0, 2, 4, 4, 0, 0, 4, 3, 0, 3, 0, 2, 3, 0, 0, 3, 4, 3, 4, 2, 0, 2, 0, 4, 0, 0, 4, 2, 3, 4, 0, 4, 3, 0, 4, 3, 0, 0, 0, 2, 0, 4, 4, 4, 3, 4, 3, 4, 0, 0, 3, 4, 4, 0, 4, 0, 3, 3, 3, 4, 4, 4, 4, 4, 2, 4, 3, 0, 2, 3, 4, 3, 3, 0, 2, 3, 0, 3, 0, 3, 2, 2, 3, 3, 2, 3, 3, 2, 4, 3, 0, 0, 3, 4, 4, 3, 3, 3, 2, 4, 4, 0, 4, 4, 2, 3, 3, 3, 3, 4, 3, 2, 2, 2, 0, 3, 4, 4, 0, 0, 4, 0, 2, 2, 3, 3, 4, 3, 0, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.92      0.81      0.86       100\n",
      "           3       0.68      0.90      0.78       100\n",
      "           4       0.58      0.95      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.63       500\n",
      "weighted avg       0.59      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1957753896713257, Val acc: 0.708\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23800 - Batch 70/1582 - Train loss: 1.0542472055260563, Train acc: 0.8481514084507042\n",
      "Iteration 23900 - Batch 170/1582 - Train loss: 1.0518188650845086, Train acc: 0.8516081871345029\n",
      "Iteration 24000 - Batch 270/1582 - Train loss: 1.0463579560997742, Train acc: 0.8574723247232472\n",
      "Iteration 24100 - Batch 370/1582 - Train loss: 1.0454748260043059, Train acc: 0.858322102425876\n",
      "Iteration 24200 - Batch 470/1582 - Train loss: 1.0479240985686107, Train acc: 0.8554272823779193\n",
      "Iteration 24300 - Batch 570/1582 - Train loss: 1.0479270267820608, Train acc: 0.8556260945709282\n",
      "Iteration 24400 - Batch 670/1582 - Train loss: 1.0505378105956644, Train acc: 0.8532507451564829\n",
      "Iteration 24500 - Batch 770/1582 - Train loss: 1.0500232473730886, Train acc: 0.8538018806744487\n",
      "Iteration 24600 - Batch 870/1582 - Train loss: 1.0495702451871265, Train acc: 0.8542264638346728\n",
      "Iteration 24700 - Batch 970/1582 - Train loss: 1.0489006547677406, Train acc: 0.8547245108135942\n",
      "Iteration 24800 - Batch 1070/1582 - Train loss: 1.048079094410388, Train acc: 0.8553338001867413\n",
      "Iteration 24900 - Batch 1170/1582 - Train loss: 1.0478741937880838, Train acc: 0.8556789069171649\n",
      "Iteration 25000 - Batch 1270/1582 - Train loss: 1.0481055867568796, Train acc: 0.8554533831628639\n",
      "Iteration 25100 - Batch 1370/1582 - Train loss: 1.0478276509076987, Train acc: 0.8556710430342815\n",
      "Iteration 25200 - Batch 1470/1582 - Train loss: 1.0473957436981045, Train acc: 0.8561352821210061\n",
      "Iteration 25300 - Batch 1570/1582 - Train loss: 1.0476168584550436, Train acc: 0.8560033418204965\n",
      "[3, 0, 4, 3, 1, 3, 2, 2, 1, 3, 2, 2, 1, 4, 0, 3, 0, 2, 4, 1, 1, 4, 3, 0, 4, 2, 4, 1, 4, 2, 2, 4, 1, 0, 2, 3, 4, 1, 0, 2, 1, 1, 0, 4, 3, 1, 4, 0, 2, 4, 4, 1, 1, 4, 1, 2, 4, 3, 0, 3, 4, 3, 3, 1, 4, 3, 2, 1, 2, 1, 3, 3, 4, 1, 1, 1, 1, 1, 3, 4, 4, 1, 4, 2, 1, 2, 2, 4, 0, 1, 2, 4, 0, 0, 0, 3, 0, 1, 0, 0, 4, 2, 3, 2, 0, 3, 2, 0, 2, 4, 2, 0, 2, 1, 4, 1, 1, 3, 2, 3, 2, 1, 4, 0, 2, 4, 3, 4, 3, 0, 3, 4, 3, 3, 1, 2, 3, 0, 0, 0, 4, 0, 0, 4, 0, 0, 3, 2, 0, 2, 3, 1, 1, 1, 3, 0, 0, 1, 4, 4, 3, 2, 3, 0, 1, 0, 0, 1, 0, 0, 0, 2, 3, 3, 2, 2, 1, 3, 3, 1, 1, 0, 2, 2, 1, 2, 3, 1, 4, 2, 1, 4, 4, 1, 4, 0, 0, 1, 4, 3, 2, 0, 0, 4, 0, 0, 0, 2, 4, 0, 4, 4, 3, 3, 2, 4, 4, 1, 1, 0, 1, 0, 1, 1, 4, 1, 1, 0, 3, 2, 1, 2, 2, 4, 0, 4, 4, 2, 2, 4, 2, 1, 3, 2, 3, 3, 1, 3, 0, 3, 1, 1, 3, 0, 2, 1, 2, 3, 1, 0, 3, 0, 3, 0, 0, 1, 1, 2, 2, 1, 1, 3, 2, 2, 1, 0, 4, 1, 0, 4, 1, 2, 4, 3, 3, 4, 4, 4, 0, 3, 1, 3, 2, 0, 4, 3, 3, 4, 3, 4, 4, 1, 0, 4, 4, 4, 0, 3, 2, 2, 1, 4, 1, 4, 3, 2, 1, 1, 2, 4, 4, 2, 0, 0, 3, 4, 3, 0, 3, 4, 3, 3, 0, 3, 2, 1, 0, 1, 0, 4, 3, 2, 3, 3, 0, 0, 0, 2, 3, 1, 4, 1, 4, 2, 2, 2, 1, 2, 4, 2, 4, 0, 2, 0, 2, 0, 3, 3, 0, 2, 0, 3, 4, 2, 0, 3, 4, 1, 3, 0, 2, 3, 2, 3, 3, 1, 2, 4, 1, 1, 4, 4, 3, 3, 3, 0, 1, 3, 2, 1, 2, 2, 1, 1, 0, 0, 0, 4, 1, 2, 0, 4, 2, 3, 1, 0, 2, 0, 3, 2, 2, 1, 2, 1, 4, 4, 4, 3, 3, 3, 2, 4, 4, 1, 4, 2, 4, 3, 1, 0, 3, 1, 0, 2, 3, 4, 1, 2, 3, 3, 0, 2, 2, 2, 4, 3, 0, 3, 0, 4, 1, 0, 1, 2, 0, 0, 0, 3, 3, 0, 3, 1, 2, 4, 4, 2, 4, 0, 2, 1, 4, 3, 4, 3, 0, 1, 3, 2, 2, 4, 1, 0, 4, 2, 0, 0, 4, 2, 1, 4]\n",
      "[3, 0, 4, 3, 4, 3, 2, 4, 3, 3, 2, 0, 4, 4, 0, 3, 0, 0, 4, 4, 3, 4, 3, 0, 4, 2, 4, 4, 4, 2, 2, 0, 3, 0, 2, 3, 4, 4, 0, 0, 4, 4, 0, 4, 3, 3, 4, 0, 0, 4, 4, 4, 4, 4, 4, 0, 4, 3, 0, 4, 4, 3, 3, 4, 4, 3, 0, 4, 2, 0, 3, 3, 4, 0, 4, 4, 4, 0, 3, 4, 4, 4, 4, 0, 4, 2, 0, 4, 0, 4, 2, 4, 0, 0, 0, 3, 0, 4, 0, 0, 4, 0, 3, 2, 0, 3, 2, 0, 0, 4, 2, 0, 2, 0, 4, 0, 4, 3, 2, 4, 2, 3, 4, 0, 0, 4, 3, 4, 4, 0, 3, 4, 3, 3, 4, 2, 4, 0, 4, 0, 4, 0, 0, 4, 0, 0, 3, 2, 0, 4, 3, 3, 4, 3, 3, 0, 0, 3, 3, 4, 3, 2, 3, 0, 4, 0, 0, 4, 4, 0, 0, 2, 3, 3, 2, 2, 4, 3, 3, 0, 4, 0, 2, 2, 0, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 0, 0, 3, 4, 3, 0, 0, 0, 4, 0, 0, 0, 2, 4, 0, 4, 4, 3, 4, 2, 4, 4, 3, 4, 0, 2, 0, 0, 4, 4, 3, 4, 0, 3, 2, 4, 2, 0, 4, 4, 4, 4, 2, 2, 4, 2, 4, 3, 2, 3, 3, 3, 3, 0, 3, 3, 4, 3, 0, 2, 3, 2, 3, 0, 0, 3, 0, 4, 0, 0, 3, 4, 2, 2, 2, 2, 3, 4, 0, 4, 0, 4, 4, 4, 4, 3, 2, 4, 3, 3, 4, 4, 4, 0, 3, 4, 3, 2, 0, 4, 3, 3, 4, 3, 4, 4, 3, 0, 4, 4, 4, 0, 3, 0, 2, 4, 4, 3, 4, 3, 2, 4, 3, 2, 4, 4, 0, 2, 0, 4, 4, 3, 0, 3, 4, 3, 3, 0, 3, 2, 4, 0, 0, 0, 4, 3, 2, 3, 3, 0, 0, 0, 0, 3, 4, 4, 0, 3, 2, 2, 2, 0, 2, 4, 2, 2, 0, 2, 0, 0, 0, 3, 3, 0, 2, 0, 3, 4, 2, 0, 3, 4, 0, 3, 4, 2, 3, 2, 3, 3, 4, 2, 4, 4, 4, 4, 4, 3, 3, 4, 0, 4, 3, 2, 4, 2, 2, 0, 4, 0, 0, 0, 4, 0, 2, 0, 4, 2, 3, 3, 0, 2, 2, 3, 2, 0, 4, 2, 4, 4, 4, 4, 3, 3, 3, 2, 4, 4, 4, 4, 2, 4, 3, 4, 0, 3, 4, 0, 2, 3, 4, 4, 0, 4, 3, 0, 2, 2, 2, 0, 3, 0, 4, 0, 4, 0, 0, 3, 2, 4, 0, 0, 3, 3, 0, 0, 4, 0, 4, 4, 2, 4, 0, 2, 3, 4, 3, 4, 3, 0, 4, 3, 2, 2, 4, 4, 0, 4, 2, 0, 0, 4, 2, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.93      0.75      0.83       100\n",
      "           3       0.79      0.88      0.83       100\n",
      "           4       0.55      0.95      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.59      0.70      0.63       500\n",
      "weighted avg       0.59      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2020432353019714, Val acc: 0.7\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25400 - Batch 88/1582 - Train loss: 1.0414520863736614, Train acc: 0.8609550561797753\n",
      "Iteration 25500 - Batch 188/1582 - Train loss: 1.0421069879380485, Train acc: 0.8606150793650794\n",
      "Iteration 25600 - Batch 288/1582 - Train loss: 1.0469940944113947, Train acc: 0.8560769896193772\n",
      "Iteration 25700 - Batch 388/1582 - Train loss: 1.045590610308022, Train acc: 0.8577281491002571\n",
      "Iteration 25800 - Batch 488/1582 - Train loss: 1.0439264590267268, Train acc: 0.8597903885480572\n",
      "Iteration 25900 - Batch 588/1582 - Train loss: 1.044018951053328, Train acc: 0.8597729202037352\n",
      "Iteration 26000 - Batch 688/1582 - Train loss: 1.0444059101175327, Train acc: 0.8592616110304789\n",
      "Iteration 26100 - Batch 788/1582 - Train loss: 1.043603474423006, Train acc: 0.8600285171102662\n",
      "Iteration 26200 - Batch 888/1582 - Train loss: 1.0436790220112582, Train acc: 0.8600604611923509\n",
      "Iteration 26300 - Batch 988/1582 - Train loss: 1.0430127923481385, Train acc: 0.8607178968655207\n",
      "Iteration 26400 - Batch 1088/1582 - Train loss: 1.043147710236636, Train acc: 0.8605945821854912\n",
      "Iteration 26500 - Batch 1188/1582 - Train loss: 1.0418989514482433, Train acc: 0.8618587047939444\n",
      "Iteration 26600 - Batch 1288/1582 - Train loss: 1.0421227852534285, Train acc: 0.8616902637703646\n",
      "Iteration 26700 - Batch 1388/1582 - Train loss: 1.0420995858438242, Train acc: 0.8617485601151907\n",
      "Iteration 26800 - Batch 1488/1582 - Train loss: 1.0422678744336595, Train acc: 0.8615471793149765\n",
      "[0, 2, 0, 2, 1, 2, 4, 4, 3, 0, 0, 0, 0, 3, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 2, 4, 4, 2, 3, 2, 2, 0, 2, 2, 3, 0, 1, 3, 4, 0, 3, 4, 2, 3, 2, 2, 0, 0, 4, 0, 2, 1, 4, 2, 1, 2, 2, 3, 2, 3, 3, 0, 3, 0, 3, 0, 3, 2, 2, 4, 4, 4, 3, 1, 3, 0, 0, 1, 2, 4, 2, 4, 3, 2, 0, 4, 0, 0, 4, 2, 2, 4, 1, 2, 1, 1, 3, 2, 3, 4, 3, 3, 4, 1, 3, 3, 0, 3, 2, 2, 1, 4, 1, 1, 0, 3, 2, 1, 4, 0, 0, 1, 1, 4, 3, 2, 2, 2, 2, 0, 1, 1, 4, 4, 1, 1, 0, 0, 4, 3, 2, 4, 2, 0, 2, 1, 0, 1, 2, 0, 2, 3, 1, 3, 1, 2, 0, 2, 3, 2, 0, 3, 1, 0, 4, 4, 1, 2, 1, 4, 1, 2, 2, 3, 0, 4, 4, 1, 4, 1, 4, 0, 2, 1, 0, 4, 2, 2, 2, 1, 0, 1, 3, 1, 2, 3, 2, 2, 4, 4, 4, 3, 1, 3, 1, 4, 1, 1, 2, 4, 2, 1, 0, 4, 3, 4, 3, 3, 3, 3, 4, 2, 2, 1, 4, 3, 2, 1, 2, 0, 3, 3, 2, 0, 2, 3, 0, 1, 4, 2, 3, 4, 2, 0, 0, 0, 2, 4, 1, 4, 3, 1, 2, 0, 0, 4, 4, 0, 0, 4, 3, 1, 1, 0, 3, 1, 4, 3, 3, 4, 4, 1, 1, 1, 1, 2, 3, 1, 0, 2, 2, 3, 3, 0, 0, 4, 3, 3, 2, 0, 4, 0, 0, 2, 3, 3, 4, 3, 2, 3, 3, 3, 2, 1, 1, 2, 4, 3, 3, 0, 0, 2, 0, 0, 4, 4, 3, 3, 0, 1, 1, 0, 3, 4, 1, 4, 0, 1, 1, 1, 4, 0, 2, 1, 1, 1, 3, 3, 0, 1, 3, 1, 3, 4, 0, 4, 4, 0, 4, 4, 0, 2, 0, 4, 2, 4, 0, 3, 2, 2, 3, 1, 1, 1, 4, 3, 2, 3, 4, 1, 0, 2, 2, 0, 4, 0, 3, 1, 1, 1, 2, 4, 3, 3, 1, 1, 1, 0, 1, 0, 2, 2, 3, 1, 0, 2, 1, 3, 0, 0, 0, 0, 2, 4, 4, 3, 3, 1, 2, 3, 3, 0, 0, 4, 4, 1, 0, 1, 2, 1, 0, 4, 1, 3, 2, 2, 4, 4, 1, 4, 4, 4, 0, 1, 4, 2, 2, 4, 4, 1, 4, 4, 3, 0, 2, 4, 4, 1, 3, 2, 2, 4, 3, 4, 3, 4, 1, 3, 0, 2, 0, 3, 3, 3, 0, 3, 1, 2, 1, 0, 1, 1, 3, 3, 2, 3, 4, 2, 0, 0, 0, 4, 2, 0, 0, 4, 4, 2, 3, 4, 1, 0, 4, 4, 3, 1, 3, 3, 1, 4]\n",
      "[0, 2, 0, 2, 4, 2, 4, 4, 4, 0, 0, 2, 0, 3, 0, 3, 4, 0, 4, 2, 4, 0, 0, 4, 2, 4, 4, 2, 3, 2, 2, 2, 2, 2, 3, 0, 3, 3, 4, 0, 3, 4, 2, 3, 2, 2, 0, 0, 4, 0, 2, 4, 4, 2, 4, 2, 2, 3, 2, 3, 4, 0, 4, 0, 3, 0, 3, 2, 2, 4, 4, 4, 3, 3, 4, 2, 0, 4, 0, 4, 2, 4, 3, 2, 0, 4, 0, 0, 4, 2, 0, 4, 3, 2, 4, 3, 3, 2, 3, 4, 3, 3, 4, 3, 3, 3, 0, 3, 2, 4, 4, 4, 4, 3, 0, 3, 2, 4, 4, 0, 0, 3, 0, 4, 4, 2, 2, 2, 2, 0, 4, 4, 4, 4, 4, 3, 0, 0, 4, 3, 2, 4, 2, 4, 4, 2, 4, 3, 2, 0, 2, 0, 2, 3, 4, 2, 0, 2, 3, 2, 0, 3, 4, 0, 4, 3, 0, 0, 3, 4, 3, 2, 2, 3, 0, 4, 4, 4, 4, 4, 4, 0, 2, 4, 0, 4, 2, 2, 2, 4, 0, 4, 3, 3, 2, 3, 2, 2, 4, 4, 4, 3, 3, 3, 4, 2, 4, 4, 2, 4, 2, 4, 0, 4, 3, 4, 3, 3, 3, 4, 4, 0, 2, 4, 4, 3, 2, 3, 2, 0, 3, 3, 0, 4, 0, 3, 0, 4, 4, 2, 4, 4, 4, 0, 0, 0, 2, 4, 3, 4, 3, 0, 2, 0, 0, 4, 4, 0, 0, 4, 3, 4, 4, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 2, 3, 4, 0, 2, 2, 3, 3, 0, 0, 4, 3, 3, 2, 0, 4, 0, 0, 2, 4, 3, 4, 3, 2, 3, 3, 3, 2, 4, 4, 2, 4, 4, 3, 0, 0, 2, 0, 0, 4, 4, 3, 3, 0, 0, 3, 0, 3, 4, 2, 4, 4, 4, 4, 3, 4, 0, 2, 0, 4, 3, 3, 3, 4, 4, 3, 3, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 0, 4, 2, 4, 2, 3, 0, 2, 3, 4, 4, 4, 4, 3, 2, 3, 2, 2, 0, 2, 0, 0, 0, 0, 3, 0, 4, 3, 2, 4, 3, 3, 4, 4, 4, 0, 4, 0, 2, 2, 3, 0, 0, 0, 4, 3, 2, 0, 0, 0, 2, 4, 4, 3, 3, 0, 0, 4, 4, 0, 4, 4, 4, 3, 0, 4, 2, 4, 0, 4, 3, 3, 2, 2, 3, 4, 3, 4, 3, 4, 0, 3, 4, 2, 2, 4, 4, 4, 4, 4, 3, 0, 2, 4, 4, 4, 4, 2, 2, 4, 3, 4, 3, 4, 4, 3, 0, 2, 0, 3, 3, 3, 4, 3, 4, 2, 3, 0, 3, 4, 3, 3, 2, 3, 4, 0, 0, 0, 0, 4, 2, 0, 0, 4, 4, 2, 3, 4, 4, 0, 4, 4, 3, 4, 3, 3, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.85      0.86       100\n",
      "           3       0.73      0.84      0.78       100\n",
      "           4       0.53      0.94      0.68       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2016634121537209, Val acc: 0.7\n",
      "Epoch 18/30\n",
      "Iteration 26900 - Batch 6/1582 - Train loss: 1.0195537209510803, Train acc: 0.8883928571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27000 - Batch 106/1582 - Train loss: 1.0357679758116463, Train acc: 0.8691588785046729\n",
      "Iteration 27100 - Batch 206/1582 - Train loss: 1.037380926562968, Train acc: 0.8674516908212561\n",
      "Iteration 27200 - Batch 306/1582 - Train loss: 1.0378441674701555, Train acc: 0.8666530944625407\n",
      "Iteration 27300 - Batch 406/1582 - Train loss: 1.0381578477946194, Train acc: 0.8664004914004914\n",
      "Iteration 27400 - Batch 506/1582 - Train loss: 1.0392135100722077, Train acc: 0.8653846153846154\n",
      "Iteration 27500 - Batch 606/1582 - Train loss: 1.0397846546558023, Train acc: 0.8644975288303131\n",
      "Iteration 27600 - Batch 706/1582 - Train loss: 1.0402009315166987, Train acc: 0.8639939886845828\n",
      "Iteration 27700 - Batch 806/1582 - Train loss: 1.041710516703321, Train acc: 0.8625697026022305\n",
      "Iteration 27800 - Batch 906/1582 - Train loss: 1.0415727190566562, Train acc: 0.8627687431091511\n",
      "Iteration 27900 - Batch 1006/1582 - Train loss: 1.0415201097164515, Train acc: 0.8627730883813307\n",
      "Iteration 28000 - Batch 1106/1582 - Train loss: 1.0417763419590669, Train acc: 0.8624661246612466\n",
      "Iteration 28100 - Batch 1206/1582 - Train loss: 1.0431519700854697, Train acc: 0.8609154929577465\n",
      "Iteration 28200 - Batch 1306/1582 - Train loss: 1.0440207611720984, Train acc: 0.8600325172149962\n",
      "Iteration 28300 - Batch 1406/1582 - Train loss: 1.0442900423810426, Train acc: 0.8597858919687278\n",
      "Iteration 28400 - Batch 1506/1582 - Train loss: 1.0444769513630756, Train acc: 0.8595512607830126\n",
      "[4, 1, 3, 3, 3, 1, 1, 1, 2, 2, 4, 1, 2, 4, 3, 2, 0, 2, 0, 3, 2, 2, 0, 0, 3, 2, 3, 4, 4, 4, 3, 0, 0, 4, 0, 2, 0, 0, 4, 1, 3, 3, 0, 0, 3, 0, 0, 0, 3, 1, 2, 2, 1, 4, 0, 2, 4, 3, 2, 4, 4, 0, 2, 1, 1, 4, 0, 1, 1, 0, 4, 1, 3, 2, 4, 3, 0, 4, 1, 4, 4, 3, 3, 1, 0, 2, 0, 1, 1, 1, 1, 0, 4, 1, 1, 4, 0, 3, 0, 3, 4, 1, 2, 3, 3, 3, 2, 3, 2, 2, 3, 0, 1, 4, 0, 4, 0, 2, 2, 1, 1, 2, 3, 3, 4, 1, 0, 1, 3, 3, 1, 3, 1, 4, 4, 2, 4, 1, 0, 4, 4, 3, 3, 4, 3, 4, 2, 2, 4, 3, 2, 4, 2, 0, 3, 2, 2, 4, 2, 0, 1, 1, 1, 4, 2, 0, 3, 1, 4, 1, 0, 4, 4, 0, 3, 0, 3, 3, 4, 0, 4, 1, 1, 3, 1, 2, 2, 1, 4, 3, 0, 2, 2, 4, 0, 2, 0, 3, 1, 0, 2, 4, 2, 1, 3, 1, 0, 0, 1, 3, 3, 1, 0, 4, 4, 1, 4, 3, 3, 4, 4, 1, 0, 4, 0, 0, 1, 1, 1, 2, 2, 2, 3, 2, 0, 2, 0, 3, 4, 0, 1, 1, 0, 4, 3, 3, 2, 0, 2, 2, 4, 3, 0, 2, 4, 1, 2, 3, 2, 1, 2, 3, 2, 4, 0, 2, 4, 0, 4, 2, 4, 1, 2, 1, 0, 4, 1, 3, 4, 3, 3, 3, 0, 1, 0, 2, 1, 1, 1, 4, 2, 0, 2, 3, 4, 0, 4, 3, 0, 4, 0, 2, 1, 3, 2, 1, 2, 2, 4, 1, 3, 0, 1, 0, 1, 3, 3, 0, 1, 3, 4, 4, 3, 0, 0, 3, 2, 0, 1, 3, 1, 3, 1, 4, 2, 1, 0, 2, 4, 3, 0, 4, 2, 4, 3, 0, 2, 3, 3, 3, 0, 4, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 4, 0, 0, 3, 3, 0, 3, 2, 1, 4, 3, 4, 2, 0, 4, 3, 3, 1, 3, 3, 2, 4, 2, 2, 1, 3, 4, 3, 0, 1, 0, 3, 0, 1, 1, 4, 0, 2, 0, 4, 3, 4, 0, 4, 3, 4, 3, 2, 2, 3, 1, 2, 2, 0, 4, 2, 2, 3, 1, 4, 4, 0, 2, 1, 4, 0, 2, 0, 3, 0, 1, 2, 3, 4, 1, 0, 3, 1, 0, 1, 1, 4, 2, 0, 2, 2, 0, 0, 3, 1, 0, 4, 1, 2, 3, 4, 2, 2, 0, 4, 1, 3, 1, 3, 1, 4, 4, 3, 2, 2, 0, 4, 0, 4, 4, 4, 0, 3, 3, 0, 2, 4, 0, 1, 4, 1, 1, 3, 2, 1, 1, 2, 1, 4, 2, 1, 1, 2]\n",
      "[4, 4, 3, 3, 3, 3, 4, 3, 2, 2, 4, 4, 0, 4, 3, 2, 0, 2, 0, 3, 2, 2, 2, 0, 3, 0, 4, 4, 4, 4, 3, 0, 0, 4, 0, 2, 2, 0, 4, 4, 3, 3, 0, 0, 3, 0, 2, 0, 3, 3, 2, 2, 0, 4, 0, 2, 4, 4, 2, 4, 4, 0, 2, 4, 4, 3, 0, 3, 4, 0, 2, 2, 3, 0, 4, 3, 0, 4, 0, 4, 4, 3, 3, 2, 0, 0, 0, 3, 0, 4, 4, 0, 4, 4, 4, 4, 0, 3, 4, 2, 4, 0, 2, 0, 3, 3, 2, 3, 2, 2, 3, 0, 3, 4, 0, 3, 0, 2, 2, 4, 4, 2, 3, 3, 3, 4, 0, 3, 3, 3, 0, 4, 0, 4, 4, 2, 4, 3, 0, 4, 4, 3, 3, 4, 3, 4, 2, 2, 4, 4, 2, 4, 2, 0, 3, 2, 2, 2, 0, 0, 4, 4, 3, 4, 2, 2, 3, 2, 4, 4, 0, 2, 4, 2, 3, 2, 4, 3, 4, 0, 4, 4, 0, 3, 3, 2, 2, 4, 4, 3, 0, 2, 2, 4, 0, 0, 4, 4, 3, 0, 2, 4, 2, 2, 3, 4, 2, 0, 2, 3, 3, 4, 0, 4, 4, 2, 4, 3, 3, 4, 4, 4, 0, 4, 2, 0, 3, 2, 4, 4, 0, 2, 3, 2, 0, 2, 0, 3, 4, 0, 3, 2, 0, 4, 4, 3, 2, 4, 2, 2, 4, 3, 0, 2, 4, 4, 2, 3, 0, 3, 2, 3, 2, 4, 0, 2, 4, 0, 4, 2, 4, 4, 2, 4, 0, 4, 4, 3, 4, 4, 2, 3, 0, 4, 0, 2, 2, 4, 2, 4, 0, 2, 2, 3, 3, 0, 4, 3, 0, 4, 2, 2, 3, 3, 2, 4, 0, 2, 4, 4, 3, 0, 4, 0, 4, 3, 3, 0, 4, 3, 4, 4, 3, 0, 0, 3, 2, 0, 4, 3, 4, 3, 4, 4, 2, 3, 0, 2, 4, 3, 0, 4, 0, 4, 3, 0, 2, 3, 3, 3, 2, 4, 2, 0, 0, 2, 2, 3, 4, 2, 2, 4, 4, 0, 0, 3, 3, 0, 3, 2, 3, 4, 3, 4, 2, 0, 2, 3, 4, 0, 3, 3, 2, 4, 2, 0, 4, 3, 4, 3, 0, 3, 0, 3, 0, 2, 4, 2, 0, 2, 0, 4, 3, 4, 0, 4, 3, 2, 3, 2, 2, 4, 4, 2, 2, 0, 4, 2, 2, 3, 3, 4, 2, 0, 2, 4, 4, 0, 2, 0, 3, 0, 2, 2, 4, 4, 4, 4, 3, 0, 0, 4, 0, 4, 2, 0, 2, 2, 4, 0, 3, 0, 0, 4, 4, 2, 3, 4, 2, 2, 2, 4, 0, 3, 4, 3, 4, 4, 4, 4, 2, 2, 0, 4, 0, 4, 4, 4, 0, 3, 3, 0, 2, 4, 0, 4, 4, 0, 4, 3, 0, 3, 0, 2, 4, 4, 2, 0, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.72      0.86      0.79       100\n",
      "           3       0.77      0.85      0.81       100\n",
      "           4       0.56      0.89      0.69       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.56      0.69      0.61       500\n",
      "weighted avg       0.56      0.69      0.61       500\n",
      "\n",
      "Val loss: 1.2163031920790672, Val acc: 0.686\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28500 - Batch 24/1582 - Train loss: 1.0158225321769714, Train acc: 0.88875\n",
      "Iteration 28600 - Batch 124/1582 - Train loss: 1.043332422733307, Train acc: 0.86075\n",
      "Iteration 28700 - Batch 224/1582 - Train loss: 1.0407331334220038, Train acc: 0.86375\n",
      "Iteration 28800 - Batch 324/1582 - Train loss: 1.0413954065396236, Train acc: 0.8630769230769231\n",
      "Iteration 28900 - Batch 424/1582 - Train loss: 1.039439576513627, Train acc: 0.8655147058823529\n",
      "Iteration 29000 - Batch 524/1582 - Train loss: 1.0402775707699004, Train acc: 0.8643452380952381\n",
      "Iteration 29100 - Batch 624/1582 - Train loss: 1.040124568462372, Train acc: 0.8644\n",
      "Iteration 29200 - Batch 724/1582 - Train loss: 1.0400195885526722, Train acc: 0.8646982758620689\n",
      "Iteration 29300 - Batch 824/1582 - Train loss: 1.0392353065086133, Train acc: 0.8654545454545455\n",
      "Iteration 29400 - Batch 924/1582 - Train loss: 1.039322672341321, Train acc: 0.8652027027027027\n",
      "Iteration 29500 - Batch 1024/1582 - Train loss: 1.0399872854279308, Train acc: 0.8644512195121952\n",
      "Iteration 29600 - Batch 1124/1582 - Train loss: 1.0401526062753466, Train acc: 0.8642222222222222\n",
      "Iteration 29700 - Batch 1224/1582 - Train loss: 1.0396508562808133, Train acc: 0.8646428571428572\n",
      "Iteration 29800 - Batch 1324/1582 - Train loss: 1.0401826795092168, Train acc: 0.864056603773585\n",
      "Iteration 29900 - Batch 1424/1582 - Train loss: 1.0410373813645881, Train acc: 0.8630921052631579\n",
      "Iteration 30000 - Batch 1524/1582 - Train loss: 1.0409886295678186, Train acc: 0.863094262295082\n",
      "[0, 2, 0, 1, 0, 4, 2, 2, 0, 3, 4, 2, 4, 2, 4, 4, 3, 0, 2, 3, 4, 1, 2, 0, 2, 3, 3, 4, 0, 0, 1, 3, 0, 4, 2, 1, 4, 2, 3, 4, 1, 3, 2, 3, 4, 4, 2, 1, 4, 0, 4, 3, 4, 2, 3, 1, 3, 3, 2, 0, 4, 0, 1, 1, 0, 4, 3, 2, 4, 3, 3, 4, 2, 2, 1, 3, 3, 2, 4, 4, 1, 4, 1, 1, 4, 1, 1, 2, 0, 3, 2, 0, 2, 0, 3, 0, 2, 3, 0, 3, 4, 0, 4, 0, 2, 3, 0, 4, 3, 0, 2, 3, 2, 1, 4, 3, 2, 1, 0, 0, 4, 3, 4, 0, 0, 0, 1, 3, 1, 0, 1, 1, 0, 0, 0, 4, 1, 1, 2, 3, 1, 2, 4, 4, 3, 4, 3, 0, 1, 1, 2, 1, 4, 2, 1, 1, 0, 2, 0, 1, 1, 2, 4, 4, 3, 3, 4, 4, 1, 3, 1, 4, 2, 4, 2, 1, 2, 2, 2, 4, 4, 1, 4, 2, 4, 1, 0, 3, 1, 3, 3, 1, 1, 4, 3, 4, 0, 3, 2, 4, 4, 3, 1, 1, 2, 1, 0, 3, 2, 3, 1, 2, 0, 1, 2, 0, 4, 0, 1, 3, 2, 4, 3, 4, 3, 3, 1, 2, 3, 2, 1, 4, 3, 4, 4, 3, 0, 0, 4, 0, 3, 2, 1, 3, 4, 1, 1, 3, 0, 0, 3, 2, 3, 3, 1, 1, 2, 2, 3, 4, 2, 3, 2, 4, 1, 0, 4, 0, 2, 4, 1, 1, 3, 0, 3, 1, 0, 3, 3, 4, 2, 0, 1, 2, 3, 0, 2, 1, 4, 0, 1, 1, 0, 2, 4, 0, 1, 2, 3, 4, 1, 0, 0, 1, 3, 2, 3, 3, 3, 3, 2, 2, 0, 1, 0, 2, 0, 1, 1, 2, 1, 3, 4, 2, 3, 3, 0, 3, 1, 2, 1, 4, 3, 2, 0, 2, 3, 2, 2, 3, 0, 1, 0, 0, 1, 0, 4, 1, 4, 3, 0, 0, 2, 2, 3, 3, 0, 0, 0, 3, 0, 2, 2, 0, 4, 0, 3, 1, 4, 1, 2, 4, 2, 3, 0, 1, 4, 4, 4, 0, 2, 4, 3, 0, 0, 3, 4, 1, 3, 0, 2, 4, 2, 4, 4, 1, 3, 2, 2, 2, 4, 1, 3, 2, 0, 4, 1, 1, 4, 2, 1, 1, 1, 1, 0, 4, 4, 4, 4, 1, 4, 4, 4, 4, 0, 2, 1, 0, 0, 2, 0, 2, 1, 1, 4, 0, 4, 1, 0, 4, 3, 0, 2, 3, 0, 0, 1, 3, 1, 1, 3, 3, 3, 2, 2, 4, 0, 0, 4, 3, 1, 3, 1, 1, 2, 1, 3, 0, 0, 1, 2, 3, 2, 0, 0, 4, 2, 0, 2, 2, 2, 0, 3, 4, 4, 4, 3, 2, 2, 3, 0, 3, 2, 0, 2, 1, 1, 4, 1, 0]\n",
      "[0, 2, 0, 4, 0, 4, 2, 2, 0, 3, 4, 2, 4, 2, 4, 4, 3, 0, 2, 3, 4, 4, 0, 0, 0, 4, 3, 4, 0, 0, 4, 3, 0, 4, 2, 3, 4, 2, 3, 4, 3, 3, 0, 3, 4, 4, 2, 4, 4, 2, 4, 0, 4, 2, 4, 4, 3, 3, 2, 0, 4, 0, 0, 4, 0, 4, 3, 2, 4, 4, 3, 4, 0, 2, 4, 3, 3, 2, 4, 4, 0, 4, 3, 4, 4, 4, 3, 0, 0, 3, 2, 0, 2, 0, 3, 0, 0, 3, 0, 3, 4, 0, 4, 0, 2, 3, 0, 4, 3, 0, 2, 4, 2, 0, 4, 4, 2, 4, 0, 0, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 3, 0, 0, 0, 0, 4, 3, 4, 2, 4, 4, 2, 4, 4, 3, 4, 3, 0, 4, 4, 3, 4, 4, 0, 4, 0, 0, 2, 0, 4, 4, 2, 2, 4, 3, 3, 4, 4, 0, 3, 0, 4, 2, 4, 0, 0, 0, 2, 2, 4, 4, 0, 4, 2, 4, 4, 0, 3, 4, 3, 3, 0, 4, 4, 3, 4, 0, 3, 2, 4, 4, 3, 4, 0, 2, 3, 4, 3, 2, 3, 0, 2, 2, 3, 2, 0, 4, 0, 4, 3, 2, 4, 3, 4, 3, 3, 4, 2, 4, 0, 0, 4, 3, 4, 4, 3, 0, 0, 3, 0, 3, 2, 4, 3, 4, 4, 4, 3, 0, 0, 3, 2, 3, 3, 0, 4, 2, 2, 3, 4, 2, 4, 0, 4, 4, 0, 4, 0, 2, 4, 4, 0, 3, 2, 3, 4, 0, 3, 3, 3, 2, 0, 4, 2, 3, 0, 2, 4, 4, 0, 3, 4, 0, 3, 4, 4, 4, 2, 3, 4, 4, 0, 0, 0, 3, 2, 3, 3, 3, 4, 2, 2, 0, 0, 0, 2, 0, 4, 0, 0, 4, 3, 4, 2, 4, 3, 0, 4, 4, 2, 4, 4, 3, 2, 4, 2, 3, 2, 2, 3, 0, 4, 0, 0, 4, 2, 4, 4, 4, 3, 2, 0, 0, 2, 3, 4, 0, 0, 0, 3, 0, 2, 2, 0, 4, 0, 3, 3, 4, 4, 2, 4, 2, 3, 0, 4, 2, 4, 4, 0, 2, 4, 3, 0, 0, 3, 4, 4, 3, 2, 2, 4, 2, 4, 4, 4, 3, 0, 0, 0, 4, 0, 3, 2, 0, 4, 0, 4, 4, 2, 0, 0, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 2, 4, 0, 0, 2, 0, 2, 4, 4, 4, 0, 4, 4, 0, 4, 3, 0, 0, 3, 0, 0, 4, 3, 4, 0, 3, 3, 4, 2, 2, 4, 0, 0, 4, 3, 3, 3, 4, 0, 3, 4, 3, 0, 2, 4, 2, 3, 2, 0, 0, 4, 2, 0, 2, 2, 2, 0, 3, 4, 4, 4, 4, 2, 2, 3, 0, 3, 2, 0, 2, 4, 3, 4, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.80      0.85       100\n",
      "           3       0.83      0.84      0.84       100\n",
      "           4       0.54      0.96      0.69       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.59      0.70      0.63       500\n",
      "weighted avg       0.59      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1990810632705688, Val acc: 0.7\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30100 - Batch 42/1582 - Train loss: 1.034569640492284, Train acc: 0.8684593023255814\n",
      "Iteration 30200 - Batch 142/1582 - Train loss: 1.0346059190643417, Train acc: 0.8693181818181818\n",
      "Iteration 30300 - Batch 242/1582 - Train loss: 1.0405328923782693, Train acc: 0.8638117283950617\n",
      "Iteration 30400 - Batch 342/1582 - Train loss: 1.0390919994334786, Train acc: 0.8652514577259475\n",
      "Iteration 30500 - Batch 442/1582 - Train loss: 1.0381343249004527, Train acc: 0.8660411963882618\n",
      "Iteration 30600 - Batch 542/1582 - Train loss: 1.0376090700455134, Train acc: 0.8667127071823204\n",
      "Iteration 30700 - Batch 642/1582 - Train loss: 1.0383037345405686, Train acc: 0.8659603421461898\n",
      "Iteration 30800 - Batch 742/1582 - Train loss: 1.040374578970759, Train acc: 0.8636860699865411\n",
      "Iteration 30900 - Batch 842/1582 - Train loss: 1.0404007606659071, Train acc: 0.8635453736654805\n",
      "Iteration 31000 - Batch 942/1582 - Train loss: 1.0403224880217494, Train acc: 0.8638653234358431\n",
      "Iteration 31100 - Batch 1042/1582 - Train loss: 1.040302405078482, Train acc: 0.8639741131351869\n",
      "Iteration 31200 - Batch 1142/1582 - Train loss: 1.0402288829560669, Train acc: 0.8639818460192475\n",
      "Iteration 31300 - Batch 1242/1582 - Train loss: 1.0398394047782389, Train acc: 0.8643403057119872\n",
      "Iteration 31400 - Batch 1342/1582 - Train loss: 1.0401421977971261, Train acc: 0.8641334698436337\n",
      "Iteration 31500 - Batch 1442/1582 - Train loss: 1.0403746426394642, Train acc: 0.8638470200970201\n",
      "Iteration 31600 - Batch 1542/1582 - Train loss: 1.0399263226128366, Train acc: 0.8642457874270901\n",
      "[2, 4, 0, 4, 0, 2, 0, 4, 3, 2, 3, 0, 3, 2, 4, 3, 1, 4, 4, 0, 1, 4, 3, 3, 0, 4, 1, 2, 2, 2, 0, 3, 4, 4, 4, 2, 0, 3, 3, 1, 1, 1, 4, 0, 4, 0, 0, 4, 2, 4, 3, 3, 0, 1, 0, 4, 4, 0, 4, 2, 2, 2, 3, 4, 1, 4, 3, 1, 4, 2, 4, 1, 2, 1, 3, 1, 4, 2, 0, 0, 2, 4, 2, 3, 2, 3, 2, 2, 1, 3, 0, 1, 0, 0, 4, 2, 1, 3, 3, 0, 0, 4, 0, 3, 3, 4, 1, 3, 0, 2, 0, 3, 4, 3, 3, 2, 4, 0, 1, 4, 4, 1, 0, 0, 3, 3, 4, 2, 4, 0, 0, 4, 4, 0, 3, 3, 2, 2, 1, 0, 3, 2, 3, 0, 2, 0, 2, 1, 4, 1, 0, 1, 1, 2, 0, 4, 0, 1, 3, 4, 3, 3, 0, 3, 3, 1, 1, 2, 4, 2, 2, 0, 3, 2, 0, 3, 2, 3, 0, 0, 2, 4, 2, 0, 4, 2, 1, 1, 0, 4, 1, 0, 4, 1, 4, 2, 2, 3, 1, 1, 2, 3, 1, 0, 2, 1, 1, 1, 4, 3, 4, 0, 0, 1, 0, 1, 1, 2, 3, 4, 0, 4, 4, 1, 1, 4, 0, 1, 0, 1, 1, 0, 4, 2, 2, 4, 4, 3, 0, 3, 3, 1, 2, 1, 1, 1, 2, 2, 2, 3, 1, 2, 3, 3, 3, 0, 4, 0, 0, 4, 0, 0, 1, 1, 1, 2, 3, 1, 2, 3, 3, 0, 0, 2, 0, 3, 1, 4, 3, 1, 1, 3, 0, 0, 0, 0, 2, 4, 0, 4, 3, 4, 3, 1, 2, 4, 3, 0, 3, 0, 3, 3, 3, 4, 2, 0, 3, 4, 1, 2, 3, 4, 0, 2, 2, 4, 4, 0, 4, 1, 0, 1, 3, 2, 4, 2, 0, 2, 0, 3, 2, 1, 2, 2, 4, 4, 0, 3, 3, 3, 4, 3, 1, 2, 2, 2, 1, 3, 3, 2, 1, 2, 0, 3, 3, 0, 3, 1, 2, 2, 1, 3, 0, 3, 0, 2, 2, 3, 3, 4, 2, 3, 4, 4, 4, 3, 3, 1, 3, 4, 0, 2, 1, 2, 3, 4, 3, 4, 2, 2, 1, 3, 1, 2, 4, 1, 1, 1, 2, 1, 3, 1, 0, 4, 1, 0, 3, 4, 1, 2, 1, 3, 1, 2, 1, 2, 0, 0, 0, 3, 0, 1, 3, 1, 4, 1, 2, 2, 1, 4, 3, 3, 0, 3, 0, 4, 1, 2, 3, 0, 0, 3, 0, 2, 4, 3, 0, 4, 2, 2, 4, 1, 2, 1, 1, 4, 4, 2, 1, 1, 0, 2, 4, 0, 3, 2, 4, 4, 0, 0, 2, 4, 1, 0, 1, 4, 1, 0, 4, 4, 4, 1, 2, 2, 0, 1, 4, 1, 3, 0, 1, 1, 1, 1, 2, 4, 4, 4, 2, 2]\n",
      "[2, 4, 2, 4, 0, 0, 0, 4, 4, 2, 3, 0, 4, 2, 3, 3, 4, 4, 4, 4, 4, 4, 3, 3, 2, 4, 4, 2, 2, 2, 0, 3, 4, 4, 4, 2, 0, 3, 3, 4, 4, 4, 3, 0, 4, 4, 0, 4, 2, 4, 3, 3, 0, 3, 0, 4, 4, 0, 4, 3, 2, 0, 3, 4, 4, 4, 3, 3, 2, 2, 4, 3, 2, 4, 3, 4, 3, 2, 0, 0, 2, 4, 2, 3, 2, 2, 2, 2, 0, 3, 0, 3, 0, 0, 4, 2, 4, 3, 3, 0, 0, 4, 0, 3, 3, 4, 2, 3, 0, 2, 0, 3, 4, 3, 2, 2, 4, 0, 3, 3, 4, 2, 0, 0, 3, 3, 4, 2, 4, 0, 2, 4, 4, 2, 3, 3, 2, 2, 3, 0, 3, 2, 3, 0, 2, 0, 2, 4, 4, 0, 0, 4, 4, 2, 0, 3, 0, 4, 3, 4, 3, 3, 0, 3, 3, 2, 4, 2, 4, 2, 2, 0, 3, 2, 0, 3, 2, 3, 0, 0, 2, 4, 2, 0, 4, 2, 3, 2, 0, 4, 3, 0, 4, 0, 4, 0, 2, 3, 3, 4, 2, 3, 4, 2, 2, 3, 4, 4, 4, 3, 3, 0, 0, 3, 2, 4, 0, 0, 3, 4, 0, 4, 4, 3, 4, 4, 2, 4, 4, 4, 4, 0, 4, 2, 2, 0, 3, 3, 0, 3, 3, 4, 2, 3, 4, 4, 2, 2, 0, 3, 4, 2, 3, 3, 3, 0, 4, 0, 2, 4, 0, 0, 2, 2, 4, 2, 3, 3, 2, 3, 3, 0, 0, 2, 0, 3, 2, 4, 3, 4, 3, 3, 0, 0, 0, 2, 0, 4, 0, 4, 3, 4, 3, 2, 2, 0, 3, 2, 3, 0, 3, 3, 3, 4, 2, 2, 3, 2, 4, 2, 3, 4, 0, 2, 2, 4, 4, 0, 2, 3, 0, 3, 3, 2, 4, 2, 0, 2, 0, 3, 2, 3, 2, 2, 4, 4, 0, 3, 3, 3, 4, 3, 3, 2, 2, 2, 0, 3, 3, 2, 0, 2, 0, 3, 3, 2, 3, 0, 2, 2, 2, 3, 0, 3, 0, 2, 2, 3, 2, 4, 2, 3, 4, 4, 4, 3, 3, 4, 3, 4, 2, 2, 4, 2, 3, 4, 3, 4, 2, 2, 3, 4, 3, 2, 4, 4, 2, 4, 2, 2, 3, 4, 0, 4, 2, 0, 3, 3, 4, 2, 2, 3, 4, 0, 0, 2, 0, 0, 0, 3, 4, 4, 3, 0, 4, 4, 2, 2, 4, 4, 4, 3, 0, 3, 0, 4, 4, 2, 3, 0, 0, 3, 0, 2, 4, 4, 2, 4, 2, 2, 4, 3, 2, 3, 4, 4, 4, 2, 3, 4, 4, 0, 4, 0, 3, 0, 4, 4, 0, 0, 2, 4, 2, 0, 4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 2, 4, 3, 4, 3, 0, 4, 3, 0, 0, 2, 4, 4, 4, 2, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.72      0.90      0.80       100\n",
      "           3       0.72      0.92      0.81       100\n",
      "           4       0.59      0.86      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.56      0.70      0.62       500\n",
      "weighted avg       0.56      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2122928872704506, Val acc: 0.696\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31700 - Batch 60/1582 - Train loss: 1.0414181898851864, Train acc: 0.8627049180327869\n",
      "Iteration 31800 - Batch 160/1582 - Train loss: 1.040373210210978, Train acc: 0.8635481366459627\n",
      "Iteration 31900 - Batch 260/1582 - Train loss: 1.0413204826614408, Train acc: 0.8623084291187739\n",
      "Iteration 32000 - Batch 360/1582 - Train loss: 1.0412432211257745, Train acc: 0.862707756232687\n",
      "Iteration 32100 - Batch 460/1582 - Train loss: 1.041801733075926, Train acc: 0.8623915401301518\n",
      "Iteration 32200 - Batch 560/1582 - Train loss: 1.0417346532544562, Train acc: 0.8625779857397504\n",
      "Iteration 32300 - Batch 660/1582 - Train loss: 1.0429015507676418, Train acc: 0.8613842662632375\n",
      "Iteration 32400 - Batch 760/1582 - Train loss: 1.0429286775075184, Train acc: 0.8611202365308804\n",
      "Iteration 32500 - Batch 860/1582 - Train loss: 1.0425135099375566, Train acc: 0.8616071428571429\n",
      "Iteration 32600 - Batch 960/1582 - Train loss: 1.0427780370930604, Train acc: 0.8613423517169615\n",
      "Iteration 32700 - Batch 1060/1582 - Train loss: 1.0426033344277787, Train acc: 0.8614809142318567\n",
      "Iteration 32800 - Batch 1160/1582 - Train loss: 1.0417657686553055, Train acc: 0.8623223514211886\n",
      "Iteration 32900 - Batch 1260/1582 - Train loss: 1.041919363102773, Train acc: 0.8621134020618557\n",
      "Iteration 33000 - Batch 1360/1582 - Train loss: 1.0409567544427012, Train acc: 0.8631520940484938\n",
      "Iteration 33100 - Batch 1460/1582 - Train loss: 1.040859311798678, Train acc: 0.8632357973990418\n",
      "Iteration 33200 - Batch 1560/1582 - Train loss: 1.040575237208494, Train acc: 0.8635089686098655\n",
      "[0, 0, 2, 0, 0, 3, 0, 0, 0, 4, 3, 0, 3, 1, 3, 0, 1, 1, 4, 3, 1, 0, 4, 2, 2, 1, 4, 1, 2, 4, 1, 0, 3, 0, 1, 1, 4, 0, 2, 4, 3, 1, 3, 4, 1, 0, 1, 4, 3, 3, 1, 0, 4, 4, 1, 0, 2, 0, 4, 1, 0, 3, 1, 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 2, 4, 0, 0, 0, 4, 1, 4, 1, 3, 4, 4, 1, 3, 2, 4, 0, 2, 3, 2, 2, 1, 4, 2, 0, 1, 3, 2, 4, 2, 1, 4, 3, 1, 3, 2, 2, 3, 4, 0, 2, 2, 0, 0, 1, 2, 0, 2, 1, 0, 0, 0, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 3, 4, 1, 1, 3, 4, 2, 3, 4, 3, 1, 1, 0, 0, 2, 2, 2, 0, 3, 2, 3, 3, 4, 4, 4, 2, 0, 0, 4, 2, 4, 3, 4, 4, 4, 0, 3, 0, 0, 4, 3, 2, 4, 2, 4, 4, 3, 3, 4, 2, 0, 1, 1, 2, 4, 2, 3, 0, 3, 1, 1, 2, 3, 3, 3, 0, 1, 2, 1, 4, 3, 2, 4, 1, 0, 3, 1, 0, 2, 1, 2, 0, 3, 4, 0, 4, 2, 3, 2, 4, 4, 1, 1, 4, 1, 0, 2, 2, 3, 3, 2, 2, 2, 0, 4, 4, 0, 3, 2, 2, 2, 3, 0, 2, 2, 4, 2, 1, 2, 0, 0, 4, 0, 1, 1, 3, 3, 0, 1, 1, 0, 2, 1, 0, 3, 4, 0, 0, 3, 3, 1, 1, 3, 0, 4, 2, 1, 4, 4, 4, 3, 1, 2, 0, 2, 4, 4, 0, 3, 4, 0, 1, 3, 1, 4, 0, 4, 3, 1, 4, 2, 2, 2, 4, 0, 0, 3, 3, 1, 0, 3, 0, 2, 0, 3, 1, 3, 0, 3, 1, 3, 0, 4, 0, 1, 4, 4, 0, 3, 0, 2, 1, 3, 2, 1, 0, 0, 1, 2, 1, 4, 3, 2, 2, 0, 3, 3, 1, 4, 1, 0, 2, 4, 3, 1, 1, 3, 0, 3, 0, 4, 1, 3, 2, 3, 1, 1, 4, 2, 3, 2, 1, 0, 2, 4, 4, 3, 4, 0, 0, 3, 3, 2, 3, 0, 2, 3, 3, 3, 0, 2, 0, 0, 4, 0, 4, 3, 4, 0, 4, 1, 0, 2, 2, 1, 0, 1, 2, 4, 4, 4, 0, 3, 1, 2, 1, 2, 4, 2, 4, 0, 3, 0, 1, 4, 4, 1, 1, 2, 2, 2, 1, 4, 3, 0, 3, 1, 2, 4, 4, 3, 1, 3, 3, 2, 0, 2, 2, 0, 0, 3, 0, 4, 0, 4, 1, 2, 3, 1, 4, 1, 4, 2, 0, 1, 4, 3, 4, 3, 4, 1, 2, 1, 2, 1, 3, 1, 2, 0, 4, 4, 2, 4, 4, 2, 1, 3, 1, 4, 2, 3, 2, 4]\n",
      "[0, 0, 0, 0, 0, 3, 0, 0, 2, 4, 2, 0, 3, 2, 3, 0, 0, 3, 4, 3, 4, 2, 4, 2, 2, 4, 4, 0, 2, 4, 4, 0, 3, 4, 3, 4, 0, 0, 2, 4, 3, 3, 3, 4, 3, 0, 4, 4, 4, 3, 4, 0, 4, 4, 3, 0, 2, 0, 4, 4, 0, 3, 2, 3, 4, 4, 3, 3, 4, 3, 3, 2, 3, 3, 3, 2, 4, 4, 0, 0, 4, 4, 4, 4, 3, 4, 4, 4, 3, 2, 4, 0, 2, 4, 0, 2, 4, 4, 0, 0, 4, 3, 2, 4, 2, 0, 4, 3, 4, 3, 2, 2, 4, 4, 0, 2, 2, 0, 2, 4, 0, 0, 2, 3, 4, 0, 0, 2, 2, 0, 2, 0, 2, 3, 3, 3, 0, 3, 4, 3, 4, 3, 4, 2, 3, 4, 3, 4, 4, 4, 0, 2, 2, 2, 0, 3, 2, 3, 4, 3, 4, 4, 0, 4, 0, 4, 2, 4, 3, 4, 4, 4, 0, 4, 0, 0, 4, 3, 2, 4, 2, 4, 4, 3, 3, 2, 2, 0, 4, 4, 2, 4, 2, 3, 0, 3, 0, 3, 2, 3, 3, 3, 2, 4, 2, 4, 4, 3, 2, 2, 0, 0, 3, 2, 0, 2, 4, 0, 0, 3, 0, 2, 4, 3, 3, 2, 4, 4, 4, 4, 4, 3, 0, 2, 2, 3, 3, 2, 2, 2, 0, 4, 3, 0, 3, 2, 2, 3, 3, 4, 2, 2, 4, 2, 0, 2, 0, 0, 4, 0, 4, 4, 3, 3, 0, 3, 0, 0, 2, 3, 2, 3, 4, 0, 0, 3, 4, 4, 3, 3, 0, 4, 2, 3, 4, 4, 4, 3, 4, 2, 0, 2, 4, 4, 0, 3, 4, 0, 4, 3, 0, 4, 0, 4, 3, 4, 4, 2, 2, 2, 4, 0, 0, 3, 3, 3, 0, 3, 0, 2, 0, 3, 4, 3, 0, 3, 2, 3, 0, 4, 0, 4, 3, 4, 0, 3, 0, 0, 4, 3, 2, 4, 0, 0, 4, 2, 0, 4, 3, 2, 2, 0, 3, 3, 4, 4, 4, 2, 2, 4, 3, 3, 4, 3, 0, 3, 0, 4, 4, 3, 0, 3, 4, 3, 4, 2, 4, 0, 4, 0, 2, 3, 4, 3, 4, 0, 0, 3, 3, 2, 3, 0, 2, 4, 3, 3, 0, 0, 0, 0, 4, 0, 4, 3, 4, 0, 4, 0, 0, 2, 2, 2, 4, 4, 2, 4, 4, 4, 0, 3, 4, 2, 3, 2, 4, 2, 4, 0, 3, 0, 4, 4, 4, 4, 0, 2, 2, 2, 3, 4, 4, 0, 3, 4, 2, 4, 4, 3, 0, 3, 3, 2, 0, 2, 2, 0, 0, 3, 0, 4, 0, 4, 4, 2, 3, 3, 4, 4, 4, 2, 0, 0, 4, 3, 4, 3, 4, 3, 2, 2, 2, 4, 3, 4, 0, 0, 4, 4, 2, 4, 4, 2, 2, 3, 4, 4, 4, 4, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.83      0.84      0.84       100\n",
      "           3       0.74      0.88      0.80       100\n",
      "           4       0.56      0.92      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2031359374523163, Val acc: 0.7\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33300 - Batch 78/1582 - Train loss: 1.0478297539904147, Train acc: 0.8564082278481012\n",
      "Iteration 33400 - Batch 178/1582 - Train loss: 1.0503800478061485, Train acc: 0.854050279329609\n",
      "Iteration 33500 - Batch 278/1582 - Train loss: 1.0462788623293668, Train acc: 0.8577508960573477\n",
      "Iteration 33600 - Batch 378/1582 - Train loss: 1.0456989923379036, Train acc: 0.8585916886543535\n",
      "Iteration 33700 - Batch 478/1582 - Train loss: 1.0447318397135725, Train acc: 0.8592118997912317\n",
      "Iteration 33800 - Batch 578/1582 - Train loss: 1.0458826092240725, Train acc: 0.8579447322970639\n",
      "Iteration 33900 - Batch 678/1582 - Train loss: 1.046594270813623, Train acc: 0.8570047864506627\n",
      "Iteration 34000 - Batch 778/1582 - Train loss: 1.0457077984326304, Train acc: 0.8578706675224647\n",
      "Iteration 34100 - Batch 878/1582 - Train loss: 1.0444051851862797, Train acc: 0.8592861205915814\n",
      "Iteration 34200 - Batch 978/1582 - Train loss: 1.0430482952295212, Train acc: 0.8606996935648621\n",
      "Iteration 34300 - Batch 1078/1582 - Train loss: 1.0434221922522677, Train acc: 0.8604610750695088\n",
      "Iteration 34400 - Batch 1178/1582 - Train loss: 1.0434457170346514, Train acc: 0.8603954622561493\n",
      "Iteration 34500 - Batch 1278/1582 - Train loss: 1.0430386996623406, Train acc: 0.8608043393275997\n",
      "Iteration 34600 - Batch 1378/1582 - Train loss: 1.042674973661092, Train acc: 0.8611539158810733\n",
      "Iteration 34700 - Batch 1478/1582 - Train loss: 1.0420406783973146, Train acc: 0.8618576741041244\n",
      "Iteration 34800 - Batch 1578/1582 - Train loss: 1.0415339421969263, Train acc: 0.8624129195693477\n",
      "[4, 4, 0, 4, 1, 0, 0, 3, 1, 1, 0, 1, 4, 2, 4, 4, 3, 2, 0, 3, 1, 2, 1, 2, 2, 0, 1, 1, 0, 2, 1, 0, 2, 2, 2, 2, 2, 1, 0, 1, 0, 3, 4, 3, 2, 3, 1, 0, 4, 2, 0, 1, 0, 2, 0, 3, 3, 1, 2, 4, 2, 4, 4, 3, 2, 4, 2, 1, 0, 1, 3, 2, 3, 2, 1, 4, 4, 1, 0, 2, 2, 0, 3, 3, 0, 1, 2, 0, 3, 0, 0, 2, 2, 1, 3, 2, 2, 4, 4, 0, 0, 2, 4, 0, 4, 1, 0, 1, 3, 1, 0, 3, 3, 2, 1, 2, 0, 3, 1, 2, 1, 4, 4, 3, 2, 0, 1, 4, 3, 4, 1, 3, 4, 2, 1, 2, 3, 0, 1, 4, 2, 2, 4, 4, 2, 2, 1, 1, 3, 0, 1, 0, 2, 1, 2, 1, 1, 3, 4, 3, 0, 3, 3, 4, 2, 1, 3, 2, 4, 4, 2, 0, 0, 3, 1, 2, 2, 1, 1, 1, 0, 3, 4, 3, 0, 2, 0, 0, 4, 4, 1, 2, 4, 2, 4, 2, 3, 3, 0, 2, 0, 1, 3, 0, 3, 3, 3, 4, 3, 2, 1, 4, 2, 0, 4, 2, 3, 0, 1, 3, 2, 1, 1, 3, 4, 4, 0, 4, 3, 4, 0, 1, 3, 3, 1, 3, 3, 2, 1, 3, 2, 2, 2, 0, 4, 0, 0, 3, 0, 0, 2, 1, 0, 4, 4, 3, 3, 3, 2, 2, 1, 0, 2, 0, 0, 1, 0, 3, 2, 4, 0, 2, 4, 0, 1, 4, 0, 1, 3, 0, 2, 0, 0, 3, 0, 3, 3, 0, 4, 0, 0, 1, 3, 1, 1, 0, 2, 3, 3, 2, 1, 0, 2, 3, 3, 1, 2, 0, 3, 1, 3, 4, 3, 4, 4, 3, 0, 4, 1, 3, 4, 0, 4, 0, 4, 4, 1, 0, 3, 4, 1, 0, 4, 0, 2, 4, 1, 3, 0, 2, 0, 2, 2, 2, 4, 4, 2, 1, 4, 0, 1, 4, 0, 3, 2, 0, 2, 0, 0, 3, 4, 3, 3, 2, 1, 3, 3, 0, 0, 2, 4, 4, 2, 1, 2, 2, 1, 3, 4, 4, 4, 1, 1, 1, 1, 4, 3, 3, 2, 0, 4, 1, 0, 4, 3, 1, 4, 4, 4, 4, 4, 4, 1, 4, 2, 3, 1, 1, 4, 3, 3, 2, 3, 3, 4, 4, 3, 1, 0, 1, 4, 0, 1, 1, 2, 3, 1, 3, 2, 4, 0, 4, 4, 1, 4, 1, 1, 3, 1, 2, 2, 1, 3, 0, 4, 4, 2, 2, 3, 4, 4, 4, 3, 4, 2, 1, 1, 4, 4, 1, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 2, 3, 3, 3, 4, 2, 4, 0, 3, 0, 4, 1, 1, 2, 3, 0, 1, 3, 2, 3, 0, 3, 0, 3, 4, 0, 2, 2, 2, 0]\n",
      "[4, 3, 0, 4, 3, 4, 0, 3, 4, 4, 0, 4, 4, 2, 4, 4, 0, 2, 0, 3, 3, 2, 4, 2, 2, 0, 3, 0, 0, 2, 4, 0, 2, 2, 3, 2, 2, 3, 0, 3, 0, 3, 4, 3, 3, 3, 3, 0, 3, 2, 0, 4, 0, 2, 0, 3, 3, 0, 2, 4, 2, 4, 4, 0, 2, 4, 2, 4, 0, 4, 3, 2, 3, 2, 4, 4, 4, 4, 0, 2, 0, 4, 3, 3, 0, 4, 2, 0, 3, 2, 4, 2, 2, 2, 3, 2, 0, 4, 4, 0, 0, 2, 3, 0, 4, 4, 0, 4, 3, 3, 4, 3, 3, 2, 3, 2, 0, 3, 4, 0, 0, 4, 4, 3, 2, 0, 4, 4, 3, 4, 4, 3, 4, 2, 3, 2, 3, 0, 4, 4, 2, 2, 4, 4, 2, 2, 0, 4, 4, 0, 4, 0, 2, 4, 2, 4, 2, 3, 4, 3, 2, 3, 4, 4, 2, 3, 3, 2, 4, 4, 2, 2, 0, 3, 2, 2, 2, 4, 4, 4, 0, 3, 4, 3, 0, 2, 4, 0, 4, 4, 3, 2, 4, 2, 4, 2, 3, 3, 0, 0, 0, 4, 3, 0, 3, 4, 3, 4, 4, 2, 0, 2, 0, 0, 4, 0, 3, 0, 2, 3, 2, 4, 4, 3, 4, 4, 0, 4, 3, 4, 0, 4, 3, 3, 3, 3, 3, 2, 4, 3, 0, 2, 2, 0, 4, 2, 2, 3, 0, 0, 3, 3, 0, 3, 4, 3, 3, 3, 2, 2, 3, 0, 0, 0, 0, 4, 0, 3, 2, 4, 0, 0, 4, 0, 3, 4, 0, 4, 3, 0, 2, 2, 0, 3, 0, 3, 3, 0, 4, 0, 0, 4, 3, 0, 4, 4, 2, 3, 3, 2, 3, 0, 2, 3, 3, 3, 2, 0, 3, 4, 3, 4, 3, 4, 4, 3, 0, 4, 4, 3, 0, 0, 4, 0, 4, 4, 4, 0, 3, 4, 4, 0, 4, 0, 2, 4, 4, 3, 0, 2, 0, 0, 2, 2, 4, 4, 2, 0, 4, 0, 0, 4, 0, 3, 2, 0, 2, 4, 0, 3, 4, 3, 3, 2, 0, 3, 3, 0, 4, 2, 4, 4, 2, 4, 2, 2, 3, 3, 4, 4, 3, 0, 3, 3, 4, 3, 3, 3, 2, 0, 4, 4, 0, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 3, 0, 4, 3, 3, 4, 2, 4, 3, 4, 4, 3, 0, 2, 0, 4, 0, 3, 4, 2, 3, 3, 3, 0, 4, 2, 4, 4, 4, 3, 4, 4, 3, 4, 2, 2, 4, 3, 2, 4, 4, 0, 2, 3, 4, 4, 4, 3, 0, 0, 3, 3, 4, 4, 4, 0, 0, 0, 3, 3, 0, 0, 0, 0, 4, 2, 3, 3, 4, 4, 2, 3, 0, 3, 0, 4, 0, 4, 2, 3, 0, 4, 3, 2, 4, 0, 3, 0, 3, 4, 0, 2, 0, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.84      0.81      0.83       100\n",
      "           3       0.70      0.90      0.79       100\n",
      "           4       0.55      0.87      0.68       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.56      0.68      0.61       500\n",
      "weighted avg       0.56      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.218818075954914, Val acc: 0.682\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34900 - Batch 96/1582 - Train loss: 1.0380206323161567, Train acc: 0.8646907216494846\n",
      "Iteration 35000 - Batch 196/1582 - Train loss: 1.0384879841417225, Train acc: 0.865006345177665\n",
      "Iteration 35100 - Batch 296/1582 - Train loss: 1.0346718079313284, Train acc: 0.8687920875420876\n",
      "Iteration 35200 - Batch 396/1582 - Train loss: 1.0370059564371854, Train acc: 0.8668136020151134\n",
      "Iteration 35300 - Batch 496/1582 - Train loss: 1.0365310018691019, Train acc: 0.8675176056338029\n",
      "Iteration 35400 - Batch 596/1582 - Train loss: 1.0377026533761016, Train acc: 0.8662060301507538\n",
      "Iteration 35500 - Batch 696/1582 - Train loss: 1.0371407628743514, Train acc: 0.8667055236728838\n",
      "Iteration 35600 - Batch 796/1582 - Train loss: 1.0365022889045132, Train acc: 0.8673541405269761\n",
      "Iteration 35700 - Batch 896/1582 - Train loss: 1.036888612685528, Train acc: 0.8670220178372352\n",
      "Iteration 35800 - Batch 996/1582 - Train loss: 1.0382638955666286, Train acc: 0.8656281344032096\n",
      "Iteration 35900 - Batch 1096/1582 - Train loss: 1.0391570082445414, Train acc: 0.8647162716499545\n",
      "Iteration 36000 - Batch 1196/1582 - Train loss: 1.0386259078282363, Train acc: 0.8652882205513784\n",
      "Iteration 36100 - Batch 1296/1582 - Train loss: 1.0383891642047702, Train acc: 0.8654828450269854\n",
      "Iteration 36200 - Batch 1396/1582 - Train loss: 1.0380825886746858, Train acc: 0.8657390837508948\n",
      "Iteration 36300 - Batch 1496/1582 - Train loss: 1.0376157663468926, Train acc: 0.8662324649298597\n",
      "[2, 1, 1, 3, 4, 3, 1, 2, 1, 1, 2, 4, 4, 1, 3, 1, 3, 0, 2, 3, 2, 1, 2, 1, 4, 4, 0, 4, 4, 0, 4, 4, 2, 3, 1, 4, 4, 2, 3, 0, 4, 0, 4, 2, 1, 4, 4, 4, 0, 2, 0, 4, 0, 1, 2, 1, 1, 3, 2, 3, 0, 4, 1, 1, 1, 1, 2, 4, 2, 0, 2, 4, 1, 3, 3, 1, 0, 2, 2, 2, 3, 0, 2, 3, 1, 0, 0, 3, 3, 0, 1, 3, 0, 3, 0, 3, 2, 1, 2, 3, 0, 0, 1, 0, 0, 1, 1, 3, 1, 2, 0, 0, 2, 2, 3, 2, 4, 2, 4, 4, 2, 0, 4, 1, 4, 2, 4, 4, 0, 3, 0, 0, 1, 4, 2, 3, 3, 2, 3, 1, 1, 0, 0, 3, 1, 1, 0, 3, 0, 0, 3, 2, 1, 3, 4, 3, 0, 3, 1, 2, 2, 4, 0, 0, 1, 0, 1, 2, 4, 4, 3, 3, 0, 2, 2, 3, 3, 2, 1, 3, 3, 3, 1, 4, 2, 2, 1, 4, 1, 3, 2, 3, 4, 3, 4, 2, 4, 1, 1, 1, 0, 0, 3, 1, 2, 0, 1, 0, 3, 3, 3, 2, 1, 2, 2, 4, 4, 2, 2, 3, 3, 0, 1, 4, 4, 2, 3, 0, 0, 4, 3, 1, 4, 1, 3, 3, 0, 4, 0, 2, 3, 1, 4, 1, 0, 0, 4, 1, 0, 0, 0, 3, 3, 1, 3, 0, 3, 3, 3, 3, 1, 4, 4, 0, 3, 4, 4, 3, 1, 0, 0, 2, 2, 4, 0, 3, 0, 2, 2, 0, 0, 0, 2, 0, 3, 4, 0, 2, 0, 2, 3, 0, 1, 0, 0, 4, 2, 2, 0, 4, 3, 1, 4, 3, 0, 2, 4, 2, 0, 0, 3, 0, 2, 2, 4, 4, 4, 4, 4, 4, 2, 0, 1, 0, 2, 4, 4, 2, 0, 2, 0, 3, 1, 4, 1, 0, 4, 2, 2, 3, 3, 1, 3, 0, 1, 3, 4, 4, 1, 2, 3, 0, 1, 2, 1, 1, 3, 2, 4, 2, 2, 3, 1, 3, 3, 2, 0, 0, 2, 1, 3, 2, 3, 4, 3, 0, 3, 4, 4, 0, 0, 4, 1, 0, 0, 4, 3, 4, 2, 3, 3, 0, 1, 2, 4, 2, 0, 3, 2, 1, 4, 1, 3, 4, 1, 2, 3, 0, 4, 3, 0, 2, 1, 4, 1, 1, 1, 2, 1, 1, 4, 2, 2, 0, 1, 3, 4, 3, 0, 4, 2, 4, 4, 1, 4, 3, 2, 1, 1, 2, 4, 4, 2, 1, 3, 2, 2, 1, 1, 2, 1, 0, 3, 2, 2, 1, 0, 0, 2, 3, 4, 1, 0, 3, 2, 4, 2, 4, 0, 3, 1, 4, 1, 0, 4, 1, 1, 4, 3, 1, 4, 4, 2, 1, 3, 1, 3, 4, 2, 2, 1, 4, 1, 3, 4, 0, 4, 1, 0, 0]\n",
      "[2, 2, 2, 3, 4, 3, 3, 2, 4, 4, 0, 4, 4, 3, 3, 0, 3, 0, 2, 3, 2, 4, 2, 4, 4, 4, 0, 4, 4, 0, 4, 4, 2, 3, 3, 4, 4, 2, 3, 0, 4, 0, 4, 2, 3, 4, 4, 4, 0, 2, 0, 4, 0, 3, 2, 0, 4, 3, 2, 3, 0, 4, 3, 4, 4, 2, 2, 4, 2, 0, 2, 4, 0, 3, 3, 3, 0, 2, 2, 2, 3, 0, 2, 3, 4, 0, 0, 3, 3, 0, 3, 3, 0, 3, 0, 3, 2, 4, 2, 4, 0, 0, 4, 4, 0, 3, 4, 3, 4, 2, 0, 0, 2, 2, 3, 0, 4, 2, 4, 4, 0, 0, 4, 4, 3, 0, 0, 4, 0, 3, 0, 0, 0, 4, 0, 2, 3, 0, 3, 0, 3, 0, 0, 3, 4, 3, 0, 3, 0, 0, 3, 2, 0, 3, 4, 3, 4, 3, 0, 2, 2, 3, 0, 0, 4, 0, 4, 2, 4, 4, 3, 3, 0, 0, 2, 3, 3, 2, 4, 3, 3, 3, 3, 4, 2, 0, 3, 4, 4, 4, 0, 2, 4, 3, 4, 2, 4, 3, 4, 4, 0, 0, 3, 0, 2, 0, 2, 0, 3, 3, 3, 2, 4, 2, 2, 4, 4, 2, 2, 3, 3, 0, 4, 4, 3, 2, 3, 0, 0, 3, 3, 3, 4, 3, 3, 3, 0, 4, 0, 2, 3, 3, 4, 0, 0, 2, 4, 4, 0, 0, 4, 3, 3, 4, 3, 0, 3, 3, 3, 3, 4, 4, 4, 0, 3, 4, 2, 3, 0, 0, 0, 2, 2, 3, 0, 3, 0, 2, 2, 0, 0, 0, 2, 0, 3, 4, 0, 0, 4, 3, 3, 0, 0, 0, 0, 4, 2, 2, 0, 3, 3, 4, 4, 3, 0, 2, 4, 2, 0, 0, 3, 0, 2, 0, 2, 4, 4, 4, 4, 4, 2, 0, 3, 0, 2, 4, 4, 2, 0, 2, 0, 3, 3, 4, 4, 0, 4, 2, 2, 3, 2, 0, 3, 0, 4, 3, 4, 4, 2, 2, 3, 0, 3, 2, 3, 3, 3, 2, 4, 2, 2, 3, 0, 3, 3, 2, 0, 0, 2, 3, 3, 2, 4, 4, 3, 0, 3, 3, 4, 0, 0, 4, 3, 0, 0, 4, 3, 4, 0, 3, 3, 0, 4, 2, 4, 2, 2, 3, 2, 4, 4, 4, 3, 4, 3, 2, 3, 0, 4, 3, 0, 0, 4, 4, 4, 3, 0, 2, 4, 4, 4, 2, 2, 0, 4, 3, 4, 3, 0, 4, 2, 4, 3, 3, 3, 3, 2, 4, 3, 2, 4, 4, 2, 2, 3, 2, 2, 3, 4, 2, 0, 0, 3, 2, 2, 4, 0, 0, 0, 3, 4, 4, 0, 3, 0, 4, 2, 4, 0, 3, 3, 4, 0, 4, 4, 4, 4, 3, 3, 3, 4, 4, 2, 4, 3, 2, 3, 4, 2, 0, 2, 4, 4, 3, 4, 0, 3, 0, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.83      0.84       100\n",
      "           3       0.69      0.94      0.79       100\n",
      "           4       0.62      0.86      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1951777040958405, Val acc: 0.712\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36400 - Batch 14/1582 - Train loss: 1.0493094444274902, Train acc: 0.85625\n",
      "Iteration 36500 - Batch 114/1582 - Train loss: 1.0353990850241288, Train acc: 0.8684782608695653\n",
      "Iteration 36600 - Batch 214/1582 - Train loss: 1.0330465474794077, Train acc: 0.8707848837209302\n",
      "Iteration 36700 - Batch 314/1582 - Train loss: 1.0343985638921223, Train acc: 0.8696428571428572\n",
      "Iteration 36800 - Batch 414/1582 - Train loss: 1.035655743386372, Train acc: 0.8684487951807229\n",
      "Iteration 36900 - Batch 514/1582 - Train loss: 1.0359733321134326, Train acc: 0.8682645631067961\n",
      "Iteration 37000 - Batch 614/1582 - Train loss: 1.034903938111251, Train acc: 0.869359756097561\n",
      "Iteration 37100 - Batch 714/1582 - Train loss: 1.034279314454619, Train acc: 0.8700174825174826\n",
      "Iteration 37200 - Batch 814/1582 - Train loss: 1.0333395898707805, Train acc: 0.8708972392638037\n",
      "Iteration 37300 - Batch 914/1582 - Train loss: 1.0328857079881137, Train acc: 0.8712773224043716\n",
      "Iteration 37400 - Batch 1014/1582 - Train loss: 1.032897032011906, Train acc: 0.8712746305418719\n",
      "Iteration 37500 - Batch 1114/1582 - Train loss: 1.0331770254357513, Train acc: 0.8708239910313902\n",
      "Iteration 37600 - Batch 1214/1582 - Train loss: 1.0323098593287998, Train acc: 0.8717078189300411\n",
      "Iteration 37700 - Batch 1314/1582 - Train loss: 1.0329082879276783, Train acc: 0.8711264258555133\n",
      "Iteration 37800 - Batch 1414/1582 - Train loss: 1.0330193725575827, Train acc: 0.871113074204947\n",
      "Iteration 37900 - Batch 1514/1582 - Train loss: 1.0334988243902477, Train acc: 0.8706683168316832\n",
      "[4, 2, 2, 1, 2, 1, 4, 0, 3, 0, 1, 3, 4, 1, 2, 4, 2, 1, 0, 4, 0, 4, 3, 3, 4, 4, 2, 2, 3, 1, 4, 0, 2, 3, 0, 4, 3, 3, 3, 2, 0, 0, 1, 1, 4, 1, 3, 3, 2, 0, 2, 1, 2, 4, 4, 1, 4, 2, 3, 0, 4, 4, 1, 3, 1, 1, 1, 4, 3, 1, 1, 2, 1, 3, 0, 4, 1, 3, 1, 2, 2, 4, 2, 3, 0, 0, 3, 3, 0, 0, 2, 3, 2, 3, 1, 3, 1, 3, 0, 1, 2, 1, 4, 4, 4, 0, 3, 0, 0, 3, 0, 0, 0, 1, 0, 0, 1, 4, 4, 2, 0, 2, 3, 4, 3, 2, 4, 4, 1, 4, 4, 2, 2, 4, 0, 1, 1, 3, 4, 3, 4, 3, 0, 3, 0, 4, 2, 4, 3, 3, 3, 3, 4, 2, 4, 2, 0, 4, 2, 1, 0, 2, 3, 0, 2, 3, 4, 3, 2, 2, 2, 1, 1, 1, 4, 4, 0, 4, 3, 4, 0, 0, 0, 0, 0, 1, 2, 1, 3, 0, 2, 1, 3, 3, 0, 4, 3, 0, 0, 2, 4, 2, 2, 0, 4, 3, 2, 1, 1, 2, 0, 2, 1, 4, 0, 2, 4, 2, 4, 4, 4, 4, 4, 1, 3, 1, 1, 1, 2, 0, 2, 1, 0, 3, 2, 3, 4, 2, 3, 0, 0, 1, 2, 3, 1, 1, 1, 1, 3, 2, 2, 0, 1, 3, 2, 0, 1, 1, 0, 3, 4, 2, 4, 4, 2, 0, 3, 3, 4, 0, 1, 1, 3, 4, 0, 1, 3, 1, 3, 3, 0, 1, 2, 3, 4, 4, 0, 3, 0, 0, 3, 2, 1, 0, 1, 2, 2, 0, 1, 0, 3, 2, 3, 2, 1, 1, 3, 1, 1, 2, 2, 0, 2, 0, 0, 4, 0, 4, 4, 0, 3, 2, 1, 3, 1, 1, 4, 4, 0, 0, 4, 3, 4, 2, 4, 2, 3, 4, 3, 0, 3, 1, 4, 2, 4, 2, 0, 2, 1, 0, 2, 1, 1, 3, 4, 2, 4, 2, 0, 3, 0, 1, 1, 3, 4, 2, 4, 0, 0, 1, 3, 3, 2, 2, 2, 0, 3, 3, 4, 4, 3, 4, 1, 1, 4, 2, 3, 2, 4, 2, 1, 2, 0, 0, 0, 2, 3, 0, 4, 1, 0, 4, 0, 0, 1, 1, 0, 0, 1, 1, 0, 4, 0, 3, 1, 3, 2, 0, 3, 2, 3, 2, 1, 0, 3, 4, 2, 2, 1, 2, 4, 2, 2, 4, 2, 3, 0, 4, 4, 4, 4, 1, 1, 1, 4, 3, 0, 0, 3, 3, 2, 0, 3, 1, 1, 3, 2, 3, 4, 1, 2, 3, 3, 4, 1, 0, 0, 2, 1, 1, 0, 2, 4, 3, 1, 3, 4, 1, 3, 0, 4, 2, 1, 4, 1, 2, 3, 4, 2, 4, 2, 3, 0, 3, 1, 4, 1, 0, 2, 0]\n",
      "[4, 2, 0, 3, 0, 0, 4, 0, 3, 0, 3, 3, 3, 4, 2, 0, 2, 3, 0, 4, 0, 4, 3, 3, 4, 4, 2, 2, 3, 3, 4, 0, 2, 3, 0, 2, 3, 3, 3, 2, 0, 2, 3, 0, 4, 4, 3, 3, 0, 0, 2, 3, 2, 4, 4, 4, 4, 2, 3, 0, 4, 4, 0, 3, 4, 4, 4, 4, 3, 2, 0, 2, 0, 3, 0, 4, 0, 3, 4, 2, 2, 4, 2, 3, 0, 0, 3, 3, 0, 0, 2, 3, 0, 3, 3, 3, 3, 3, 0, 3, 2, 3, 4, 3, 4, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 4, 4, 2, 0, 2, 3, 4, 3, 2, 3, 4, 3, 4, 3, 2, 2, 4, 0, 4, 0, 3, 2, 3, 4, 3, 0, 4, 0, 4, 2, 3, 3, 3, 3, 3, 4, 0, 2, 2, 0, 4, 0, 2, 0, 0, 3, 0, 2, 3, 4, 4, 2, 2, 2, 4, 4, 0, 4, 4, 0, 4, 3, 4, 0, 0, 0, 0, 0, 4, 2, 4, 3, 0, 2, 4, 3, 3, 0, 4, 3, 0, 0, 0, 3, 2, 2, 0, 3, 3, 0, 3, 3, 2, 0, 0, 4, 4, 0, 2, 4, 2, 4, 4, 4, 4, 4, 0, 3, 3, 3, 4, 2, 0, 0, 3, 0, 3, 2, 3, 4, 2, 3, 0, 0, 4, 2, 3, 4, 4, 2, 4, 3, 2, 2, 0, 2, 3, 2, 0, 0, 3, 0, 3, 4, 2, 4, 4, 2, 0, 3, 3, 4, 0, 3, 4, 3, 4, 0, 3, 3, 3, 3, 3, 0, 4, 0, 3, 4, 4, 0, 3, 0, 0, 3, 2, 4, 0, 0, 2, 2, 0, 3, 0, 3, 2, 3, 2, 3, 3, 3, 4, 4, 2, 2, 0, 0, 0, 0, 4, 0, 4, 4, 0, 3, 2, 2, 3, 2, 3, 4, 4, 0, 0, 4, 3, 4, 2, 4, 2, 3, 4, 3, 0, 3, 4, 4, 2, 4, 2, 0, 2, 4, 0, 2, 3, 3, 3, 3, 2, 4, 2, 0, 3, 0, 4, 4, 3, 4, 2, 4, 0, 0, 0, 3, 3, 2, 0, 2, 0, 3, 3, 4, 3, 3, 4, 0, 4, 4, 2, 3, 2, 4, 2, 0, 2, 0, 4, 0, 2, 3, 0, 4, 0, 0, 4, 0, 0, 3, 4, 0, 0, 3, 4, 4, 3, 0, 3, 0, 3, 0, 0, 3, 2, 2, 2, 2, 4, 3, 4, 2, 2, 4, 2, 4, 2, 2, 4, 3, 3, 0, 4, 4, 4, 4, 3, 0, 3, 4, 3, 0, 0, 3, 3, 2, 0, 3, 0, 3, 3, 2, 3, 4, 0, 0, 3, 3, 4, 4, 0, 0, 2, 3, 0, 0, 2, 4, 3, 3, 4, 4, 3, 3, 0, 4, 2, 4, 4, 4, 0, 3, 4, 2, 4, 2, 3, 0, 3, 4, 4, 3, 0, 2, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.96      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.82      0.84       100\n",
      "           3       0.67      0.95      0.79       100\n",
      "           4       0.67      0.86      0.75       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.58      0.72      0.64       500\n",
      "weighted avg       0.58      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1848918125033379, Val acc: 0.718\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38000 - Batch 32/1582 - Train loss: 1.0316481138720657, Train acc: 0.8712121212121212\n",
      "Iteration 38100 - Batch 132/1582 - Train loss: 1.0314588174784094, Train acc: 0.8714755639097744\n",
      "Iteration 38200 - Batch 232/1582 - Train loss: 1.031779723617652, Train acc: 0.8715128755364807\n",
      "Iteration 38300 - Batch 332/1582 - Train loss: 1.0312940566031426, Train acc: 0.8720908408408409\n",
      "Iteration 38400 - Batch 432/1582 - Train loss: 1.033630609512329, Train acc: 0.8697315242494227\n",
      "Iteration 38500 - Batch 532/1582 - Train loss: 1.0339253005793574, Train acc: 0.8696060037523452\n",
      "Iteration 38600 - Batch 632/1582 - Train loss: 1.0343375273790405, Train acc: 0.8691745655608215\n",
      "Iteration 38700 - Batch 732/1582 - Train loss: 1.0350410956965626, Train acc: 0.8687329467939973\n",
      "Iteration 38800 - Batch 832/1582 - Train loss: 1.035007781269742, Train acc: 0.8688100240096038\n",
      "Iteration 38900 - Batch 932/1582 - Train loss: 1.0343835167307307, Train acc: 0.8693729903536977\n",
      "Iteration 39000 - Batch 1032/1582 - Train loss: 1.0344374543930415, Train acc: 0.8693429332042595\n",
      "Iteration 39100 - Batch 1132/1582 - Train loss: 1.0345992462780238, Train acc: 0.8692906001765225\n",
      "Iteration 39200 - Batch 1232/1582 - Train loss: 1.034201045057586, Train acc: 0.8696522708840227\n",
      "Iteration 39300 - Batch 1332/1582 - Train loss: 1.034228723208348, Train acc: 0.8697018004501126\n",
      "Iteration 39400 - Batch 1432/1582 - Train loss: 1.0343151947292346, Train acc: 0.869678995115143\n",
      "Iteration 39500 - Batch 1532/1582 - Train loss: 1.0347944831272704, Train acc: 0.869190313111546\n",
      "[4, 2, 2, 4, 4, 4, 2, 1, 2, 0, 0, 1, 4, 0, 3, 2, 0, 0, 3, 2, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 0, 2, 0, 3, 0, 2, 4, 3, 3, 0, 4, 0, 2, 3, 1, 2, 2, 3, 0, 0, 4, 4, 3, 4, 1, 4, 2, 2, 1, 3, 4, 0, 3, 3, 1, 3, 3, 4, 0, 0, 2, 1, 2, 1, 1, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 3, 0, 3, 2, 3, 4, 1, 4, 0, 0, 3, 4, 1, 0, 3, 0, 1, 2, 3, 3, 4, 1, 3, 4, 1, 0, 1, 4, 3, 2, 3, 4, 3, 2, 0, 2, 3, 2, 4, 4, 3, 3, 2, 3, 3, 0, 4, 3, 0, 3, 0, 0, 0, 2, 2, 2, 0, 4, 2, 4, 3, 2, 1, 4, 1, 1, 4, 4, 2, 3, 2, 1, 0, 3, 0, 0, 1, 2, 3, 4, 2, 0, 1, 2, 0, 1, 2, 2, 1, 4, 4, 1, 2, 1, 3, 2, 4, 4, 1, 1, 2, 2, 2, 1, 4, 1, 2, 0, 0, 2, 3, 3, 2, 3, 0, 4, 0, 3, 0, 1, 0, 4, 1, 0, 2, 1, 1, 1, 0, 3, 3, 3, 3, 0, 3, 4, 0, 0, 4, 4, 4, 0, 4, 4, 2, 4, 0, 4, 2, 0, 4, 1, 2, 3, 4, 3, 4, 3, 3, 3, 3, 0, 0, 4, 2, 0, 3, 0, 1, 2, 0, 0, 2, 3, 0, 3, 0, 4, 0, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 0, 4, 1, 3, 1, 3, 1, 4, 0, 4, 0, 4, 3, 0, 2, 1, 1, 1, 2, 0, 4, 3, 3, 0, 1, 1, 4, 0, 3, 1, 2, 4, 3, 4, 1, 4, 1, 2, 2, 1, 2, 4, 3, 2, 1, 3, 3, 4, 2, 3, 4, 1, 3, 4, 4, 0, 1, 1, 1, 4, 3, 4, 1, 4, 1, 0, 0, 2, 2, 1, 3, 4, 3, 0, 3, 0, 0, 1, 0, 3, 4, 3, 3, 1, 2, 4, 0, 4, 4, 3, 1, 0, 3, 3, 3, 1, 0, 1, 2, 3, 1, 4, 2, 0, 3, 1, 4, 2, 0, 4, 4, 3, 1, 2, 0, 0, 3, 1, 4, 3, 2, 1, 1, 3, 0, 1, 3, 0, 0, 4, 2, 4, 1, 0, 0, 2, 1, 1, 1, 0, 3, 2, 2, 1, 4, 1, 1, 1, 1, 1, 1, 2, 4, 1, 4, 0, 1, 1, 0, 2, 3, 0, 2, 4, 2, 2, 1, 4, 3, 2, 3, 2, 2, 4, 3, 3, 0, 3, 1, 2, 3, 2, 2, 0, 1, 3, 0, 3, 2, 0, 2, 1, 2, 2, 2, 4, 3, 4, 2, 2, 1, 3, 0, 4, 0, 4, 1, 0, 1, 2, 3, 0, 3, 2, 1, 1, 4, 0, 0, 2, 4, 1]\n",
      "[3, 2, 2, 4, 4, 4, 0, 4, 2, 0, 0, 4, 4, 0, 4, 2, 0, 0, 4, 2, 0, 2, 3, 4, 4, 4, 0, 4, 2, 2, 3, 4, 4, 0, 4, 0, 3, 0, 0, 4, 4, 3, 0, 4, 0, 2, 3, 4, 0, 2, 3, 0, 0, 4, 4, 3, 4, 4, 4, 2, 2, 3, 3, 0, 0, 3, 3, 2, 2, 3, 2, 0, 0, 0, 4, 0, 2, 0, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 0, 3, 0, 3, 2, 3, 4, 4, 4, 0, 0, 3, 4, 3, 0, 3, 0, 0, 0, 0, 3, 4, 4, 3, 4, 0, 0, 0, 4, 3, 2, 3, 3, 3, 0, 0, 2, 3, 0, 4, 4, 3, 3, 2, 3, 3, 4, 4, 3, 0, 3, 0, 0, 0, 2, 2, 2, 0, 4, 0, 4, 3, 2, 0, 4, 4, 4, 4, 4, 2, 3, 2, 3, 0, 3, 0, 0, 3, 2, 3, 4, 2, 0, 4, 2, 0, 3, 0, 2, 0, 4, 4, 3, 2, 4, 3, 2, 4, 4, 0, 4, 0, 2, 0, 4, 4, 4, 0, 0, 0, 2, 3, 3, 2, 3, 0, 4, 0, 3, 0, 0, 0, 4, 4, 4, 2, 0, 4, 4, 0, 3, 3, 3, 4, 0, 3, 4, 0, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 2, 0, 4, 0, 0, 4, 4, 3, 4, 2, 3, 3, 3, 0, 2, 4, 2, 0, 3, 0, 4, 2, 0, 0, 2, 3, 0, 3, 0, 4, 0, 0, 3, 2, 0, 0, 2, 4, 4, 2, 0, 0, 4, 4, 3, 2, 3, 4, 4, 0, 4, 0, 4, 3, 0, 2, 0, 4, 4, 2, 0, 4, 3, 3, 0, 4, 0, 4, 0, 4, 0, 0, 4, 3, 4, 4, 4, 3, 2, 2, 4, 2, 4, 3, 2, 4, 3, 4, 4, 2, 3, 4, 0, 3, 4, 4, 0, 4, 4, 4, 4, 4, 4, 3, 4, 3, 0, 0, 2, 0, 0, 3, 4, 3, 0, 3, 0, 0, 0, 0, 4, 4, 3, 4, 4, 2, 2, 0, 4, 4, 3, 4, 0, 3, 4, 3, 4, 0, 4, 0, 3, 3, 4, 2, 0, 3, 4, 4, 2, 0, 4, 4, 3, 0, 2, 0, 0, 3, 0, 4, 3, 2, 4, 3, 3, 0, 0, 3, 0, 0, 4, 2, 4, 2, 0, 0, 2, 0, 4, 4, 0, 3, 2, 2, 3, 3, 4, 3, 3, 4, 3, 4, 2, 4, 4, 4, 0, 0, 4, 0, 2, 3, 0, 2, 4, 2, 0, 4, 4, 3, 2, 3, 0, 2, 4, 4, 3, 0, 3, 3, 2, 3, 0, 2, 0, 4, 4, 0, 3, 2, 0, 2, 3, 2, 2, 2, 4, 3, 4, 2, 2, 4, 4, 0, 4, 0, 4, 4, 0, 4, 2, 3, 0, 3, 2, 4, 4, 4, 0, 4, 0, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.95      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.75      0.82       100\n",
      "           3       0.80      0.83      0.81       100\n",
      "           4       0.56      0.94      0.70       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.58      0.69      0.62       500\n",
      "weighted avg       0.58      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.21047443151474, Val acc: 0.694\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39600 - Batch 50/1582 - Train loss: 1.0459333132295048, Train acc: 0.8578431372549019\n",
      "Iteration 39700 - Batch 150/1582 - Train loss: 1.0387276103164975, Train acc: 0.8658940397350994\n",
      "Iteration 39800 - Batch 250/1582 - Train loss: 1.0376669814387165, Train acc: 0.8669073705179283\n",
      "Iteration 39900 - Batch 350/1582 - Train loss: 1.0365980802438197, Train acc: 0.8677884615384616\n",
      "Iteration 40000 - Batch 450/1582 - Train loss: 1.034635564704692, Train acc: 0.8700803769401331\n",
      "Iteration 40100 - Batch 550/1582 - Train loss: 1.033464538531814, Train acc: 0.8710866606170599\n",
      "Iteration 40200 - Batch 650/1582 - Train loss: 1.0336220837591614, Train acc: 0.8708717357910907\n",
      "Iteration 40300 - Batch 750/1582 - Train loss: 1.0320983390992238, Train acc: 0.8727529960053262\n",
      "Iteration 40400 - Batch 850/1582 - Train loss: 1.0328784865862335, Train acc: 0.8717685076380729\n",
      "Iteration 40500 - Batch 950/1582 - Train loss: 1.0325936567896172, Train acc: 0.8720754468980021\n",
      "Iteration 40600 - Batch 1050/1582 - Train loss: 1.0327231663391774, Train acc: 0.8719969077069457\n",
      "Iteration 40700 - Batch 1150/1582 - Train loss: 1.0324886398249145, Train acc: 0.8722306689834927\n",
      "Iteration 40800 - Batch 1250/1582 - Train loss: 1.0326290390760207, Train acc: 0.8721023181454837\n",
      "Iteration 40900 - Batch 1350/1582 - Train loss: 1.0328576361841841, Train acc: 0.8717847890451518\n",
      "Iteration 41000 - Batch 1450/1582 - Train loss: 1.0335571201072735, Train acc: 0.8711233631977946\n",
      "Iteration 41100 - Batch 1550/1582 - Train loss: 1.0331278306526341, Train acc: 0.8715143455834945\n",
      "[4, 2, 2, 4, 4, 2, 1, 0, 1, 0, 3, 3, 4, 3, 3, 3, 4, 1, 2, 0, 1, 0, 1, 2, 2, 0, 2, 3, 1, 2, 0, 0, 4, 1, 3, 3, 2, 3, 3, 2, 3, 1, 3, 0, 1, 0, 0, 1, 1, 3, 4, 3, 3, 0, 3, 1, 1, 3, 2, 1, 4, 4, 1, 1, 0, 4, 1, 0, 2, 4, 2, 3, 0, 3, 1, 2, 1, 0, 0, 3, 4, 1, 3, 3, 4, 4, 1, 4, 1, 3, 2, 1, 4, 0, 1, 4, 2, 2, 2, 4, 1, 3, 3, 3, 4, 3, 2, 0, 4, 0, 0, 4, 1, 1, 3, 0, 3, 4, 1, 0, 0, 0, 4, 3, 4, 1, 3, 2, 3, 0, 0, 2, 1, 1, 0, 0, 3, 0, 1, 4, 3, 3, 4, 1, 2, 2, 0, 0, 2, 3, 4, 3, 1, 4, 3, 4, 2, 0, 2, 3, 0, 1, 3, 4, 4, 4, 0, 0, 0, 1, 2, 2, 2, 1, 4, 4, 4, 1, 1, 0, 4, 3, 2, 0, 0, 0, 1, 1, 1, 2, 4, 0, 4, 0, 1, 4, 4, 3, 0, 4, 1, 1, 2, 0, 3, 1, 0, 0, 2, 1, 4, 0, 3, 3, 3, 4, 2, 1, 3, 1, 1, 1, 4, 1, 1, 1, 0, 0, 2, 2, 0, 2, 4, 4, 1, 1, 4, 3, 1, 4, 0, 4, 0, 1, 3, 4, 4, 1, 1, 1, 3, 2, 0, 1, 3, 4, 0, 3, 0, 3, 4, 3, 3, 2, 4, 2, 1, 2, 0, 3, 3, 0, 2, 2, 0, 4, 1, 1, 3, 0, 4, 2, 3, 1, 1, 2, 2, 3, 0, 1, 2, 2, 1, 2, 4, 0, 2, 0, 2, 4, 3, 2, 2, 3, 0, 2, 2, 4, 4, 4, 0, 3, 1, 3, 4, 0, 0, 0, 2, 3, 1, 1, 4, 0, 0, 2, 1, 2, 3, 4, 2, 4, 2, 2, 2, 4, 1, 3, 0, 0, 4, 1, 4, 2, 0, 0, 3, 2, 1, 2, 2, 2, 0, 3, 0, 4, 1, 4, 2, 3, 4, 0, 3, 4, 1, 4, 0, 3, 1, 0, 3, 0, 1, 2, 0, 0, 4, 1, 1, 2, 1, 4, 2, 1, 1, 0, 1, 1, 0, 1, 3, 2, 3, 3, 3, 1, 4, 4, 2, 1, 3, 0, 3, 1, 2, 0, 3, 0, 0, 1, 3, 0, 4, 4, 4, 3, 3, 3, 0, 4, 2, 0, 2, 3, 3, 3, 2, 3, 3, 3, 4, 2, 0, 2, 4, 4, 2, 0, 2, 2, 3, 2, 0, 4, 4, 0, 4, 1, 3, 4, 2, 4, 3, 0, 0, 1, 3, 1, 2, 1, 1, 4, 3, 4, 3, 0, 2, 4, 2, 2, 2, 3, 4, 2, 2, 2, 2, 1, 0, 2, 0, 0, 2, 4, 3, 4, 4, 1, 4, 2, 2, 4, 2, 2, 4, 4, 1, 2, 3, 3]\n",
      "[4, 2, 2, 4, 4, 2, 0, 0, 4, 0, 3, 3, 4, 3, 4, 3, 4, 4, 0, 0, 3, 0, 4, 2, 2, 0, 2, 3, 3, 2, 0, 0, 0, 0, 3, 3, 2, 3, 3, 0, 3, 2, 3, 2, 4, 0, 2, 2, 2, 3, 4, 3, 3, 0, 3, 4, 0, 3, 2, 4, 4, 4, 4, 4, 0, 4, 4, 0, 2, 4, 3, 3, 2, 3, 3, 2, 4, 0, 0, 3, 4, 3, 3, 3, 3, 2, 4, 4, 2, 3, 2, 0, 4, 0, 0, 4, 2, 0, 2, 4, 4, 3, 3, 3, 4, 3, 2, 0, 4, 0, 0, 4, 4, 3, 4, 0, 3, 4, 4, 0, 0, 0, 4, 3, 4, 4, 3, 2, 3, 2, 0, 0, 4, 4, 0, 0, 3, 0, 4, 4, 3, 4, 4, 4, 2, 2, 0, 0, 2, 3, 4, 3, 4, 2, 0, 4, 2, 0, 2, 3, 0, 0, 3, 4, 0, 4, 0, 0, 0, 4, 2, 2, 2, 2, 4, 4, 4, 3, 3, 0, 4, 3, 2, 0, 0, 0, 0, 3, 2, 0, 4, 0, 4, 0, 4, 4, 4, 2, 0, 4, 4, 0, 2, 0, 3, 0, 0, 0, 2, 4, 4, 0, 3, 3, 4, 4, 0, 4, 4, 4, 4, 3, 3, 4, 4, 2, 0, 0, 2, 2, 0, 2, 4, 2, 4, 4, 0, 3, 4, 4, 0, 4, 0, 4, 3, 4, 4, 3, 0, 2, 3, 2, 0, 2, 3, 4, 2, 3, 0, 3, 2, 3, 3, 2, 2, 2, 4, 2, 2, 3, 3, 0, 2, 2, 2, 4, 3, 3, 4, 2, 0, 0, 3, 4, 3, 2, 2, 4, 0, 0, 2, 2, 4, 2, 3, 0, 2, 0, 2, 4, 3, 2, 2, 3, 0, 2, 2, 4, 4, 4, 0, 3, 2, 3, 4, 0, 0, 0, 2, 3, 4, 2, 4, 2, 0, 2, 3, 0, 3, 4, 2, 3, 2, 2, 2, 4, 4, 3, 0, 0, 3, 4, 4, 2, 0, 0, 4, 2, 4, 0, 2, 2, 0, 3, 2, 2, 3, 4, 2, 3, 4, 0, 3, 4, 0, 4, 0, 2, 0, 0, 3, 0, 4, 2, 0, 0, 4, 4, 4, 2, 3, 3, 2, 2, 0, 0, 3, 2, 0, 3, 3, 2, 3, 3, 3, 3, 4, 2, 2, 0, 3, 0, 3, 0, 0, 0, 3, 0, 0, 2, 3, 0, 4, 4, 4, 3, 3, 3, 4, 4, 2, 0, 2, 3, 3, 3, 2, 3, 3, 3, 4, 2, 0, 2, 4, 4, 2, 0, 2, 2, 3, 0, 0, 4, 3, 0, 4, 0, 3, 4, 2, 4, 3, 0, 2, 4, 3, 4, 2, 4, 4, 4, 3, 4, 3, 0, 2, 4, 2, 2, 2, 3, 4, 2, 2, 2, 2, 3, 0, 2, 0, 0, 2, 4, 3, 4, 4, 3, 4, 2, 2, 4, 0, 2, 4, 4, 4, 2, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.72      0.87      0.79       100\n",
      "           3       0.75      0.89      0.82       100\n",
      "           4       0.59      0.82      0.69       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.56      0.69      0.62       500\n",
      "weighted avg       0.56      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2054863721132278, Val acc: 0.692\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41200 - Batch 68/1582 - Train loss: 1.0328418266945991, Train acc: 0.8713768115942029\n",
      "Iteration 41300 - Batch 168/1582 - Train loss: 1.044699661477783, Train acc: 0.858542899408284\n",
      "Iteration 41400 - Batch 268/1582 - Train loss: 1.0374853575539855, Train acc: 0.8659386617100372\n",
      "Iteration 41500 - Batch 368/1582 - Train loss: 1.0360929597684039, Train acc: 0.8672086720867209\n",
      "Iteration 41600 - Batch 468/1582 - Train loss: 1.0341401297146324, Train acc: 0.8695362473347548\n",
      "Iteration 41700 - Batch 568/1582 - Train loss: 1.0346560521159314, Train acc: 0.8689586994727593\n",
      "Iteration 41800 - Batch 668/1582 - Train loss: 1.0347484481174316, Train acc: 0.8688807922272048\n",
      "Iteration 41900 - Batch 768/1582 - Train loss: 1.0342092350493481, Train acc: 0.8696765279583876\n",
      "Iteration 42000 - Batch 868/1582 - Train loss: 1.0349935884442785, Train acc: 0.8688866513233602\n",
      "Iteration 42100 - Batch 968/1582 - Train loss: 1.0343582087010914, Train acc: 0.8695497936016512\n",
      "Iteration 42200 - Batch 1068/1582 - Train loss: 1.0349368823254856, Train acc: 0.8689780168381666\n",
      "Iteration 42300 - Batch 1168/1582 - Train loss: 1.0345994252440662, Train acc: 0.8693327630453379\n",
      "Iteration 42400 - Batch 1268/1582 - Train loss: 1.0340840332709118, Train acc: 0.8698039795114263\n",
      "Iteration 42500 - Batch 1368/1582 - Train loss: 1.0337503649963786, Train acc: 0.8701835281227173\n",
      "Iteration 42600 - Batch 1468/1582 - Train loss: 1.0336959048791188, Train acc: 0.8701710347174949\n",
      "Iteration 42700 - Batch 1568/1582 - Train loss: 1.0338612253913613, Train acc: 0.8699211281070746\n",
      "[0, 1, 3, 1, 2, 4, 0, 0, 4, 1, 3, 3, 0, 1, 0, 2, 2, 1, 3, 1, 1, 3, 3, 2, 2, 3, 2, 0, 4, 3, 3, 1, 4, 4, 1, 4, 4, 3, 2, 4, 4, 3, 2, 0, 4, 0, 1, 3, 1, 2, 0, 4, 0, 2, 0, 2, 2, 0, 0, 4, 3, 1, 1, 4, 0, 4, 0, 0, 4, 4, 2, 1, 4, 2, 0, 0, 4, 0, 3, 1, 1, 4, 3, 2, 4, 3, 0, 3, 0, 4, 4, 3, 3, 4, 4, 4, 1, 2, 3, 4, 1, 2, 4, 4, 4, 4, 4, 0, 2, 3, 3, 3, 0, 2, 0, 4, 2, 1, 2, 1, 3, 1, 4, 3, 0, 3, 0, 0, 0, 1, 0, 1, 2, 4, 1, 3, 1, 2, 4, 1, 0, 0, 0, 2, 4, 1, 4, 0, 2, 2, 3, 2, 0, 4, 0, 3, 3, 0, 0, 0, 0, 3, 0, 2, 3, 3, 0, 4, 4, 0, 3, 0, 3, 4, 3, 3, 3, 1, 1, 3, 2, 3, 1, 3, 0, 4, 2, 1, 1, 4, 0, 4, 2, 0, 4, 4, 0, 2, 1, 3, 1, 1, 2, 0, 2, 0, 0, 1, 4, 0, 0, 4, 1, 3, 3, 3, 3, 1, 1, 0, 1, 2, 2, 1, 2, 4, 2, 0, 2, 1, 0, 0, 2, 0, 2, 4, 2, 3, 1, 0, 4, 1, 3, 3, 3, 1, 2, 3, 3, 1, 4, 4, 3, 4, 4, 3, 0, 2, 1, 4, 4, 0, 3, 0, 1, 1, 3, 2, 2, 2, 2, 1, 1, 4, 4, 3, 2, 2, 3, 2, 0, 2, 3, 3, 4, 2, 0, 3, 3, 2, 1, 1, 2, 1, 4, 4, 3, 3, 4, 4, 1, 4, 4, 0, 4, 2, 2, 0, 1, 2, 2, 3, 2, 1, 3, 4, 3, 4, 1, 3, 2, 2, 0, 2, 2, 1, 2, 0, 4, 4, 4, 4, 0, 1, 1, 0, 4, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 0, 4, 4, 4, 3, 2, 3, 1, 2, 0, 1, 4, 1, 1, 3, 2, 0, 1, 0, 3, 0, 4, 0, 0, 3, 3, 0, 4, 0, 0, 2, 2, 1, 3, 4, 4, 3, 3, 4, 2, 1, 0, 3, 4, 2, 3, 3, 1, 2, 0, 1, 3, 3, 0, 2, 0, 2, 0, 1, 1, 1, 2, 2, 4, 0, 2, 3, 3, 1, 2, 1, 2, 2, 1, 4, 2, 4, 0, 0, 1, 3, 3, 2, 2, 1, 4, 2, 4, 2, 1, 3, 0, 0, 4, 2, 3, 2, 3, 0, 3, 1, 2, 1, 1, 1, 4, 1, 0, 1, 2, 2, 1, 1, 3, 4, 2, 4, 3, 0, 2, 3, 1, 4, 4, 4, 3, 3, 4, 0, 2, 3, 1, 1, 3, 1, 3, 2, 0, 2, 0, 1, 0, 3, 0, 2, 0, 3, 2, 4, 0, 2, 0, 4]\n",
      "[0, 3, 3, 4, 2, 4, 0, 0, 4, 4, 3, 3, 0, 4, 0, 2, 2, 0, 3, 4, 4, 3, 3, 0, 2, 3, 2, 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 3, 0, 4, 4, 3, 2, 0, 4, 0, 4, 3, 0, 4, 0, 4, 0, 2, 0, 2, 2, 0, 0, 4, 3, 0, 0, 4, 0, 4, 0, 0, 4, 4, 2, 4, 4, 2, 0, 0, 4, 0, 3, 4, 4, 3, 4, 2, 4, 4, 4, 3, 0, 4, 4, 4, 3, 4, 4, 4, 4, 0, 3, 4, 3, 2, 4, 4, 4, 4, 4, 2, 0, 3, 3, 3, 0, 2, 0, 4, 2, 4, 0, 3, 3, 3, 4, 3, 0, 3, 0, 0, 0, 4, 0, 4, 2, 3, 4, 3, 0, 2, 3, 4, 0, 0, 0, 2, 4, 3, 4, 0, 2, 0, 3, 2, 4, 4, 0, 3, 3, 0, 0, 0, 0, 3, 0, 2, 3, 3, 0, 4, 0, 0, 3, 0, 3, 4, 3, 3, 4, 4, 3, 3, 0, 3, 3, 4, 0, 4, 2, 3, 0, 3, 0, 4, 2, 0, 4, 4, 0, 0, 4, 3, 4, 4, 2, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 3, 3, 3, 3, 4, 0, 0, 4, 2, 2, 3, 0, 4, 2, 0, 2, 4, 0, 0, 2, 0, 2, 4, 2, 3, 4, 0, 4, 3, 3, 3, 3, 3, 2, 3, 3, 0, 3, 4, 3, 4, 4, 3, 0, 2, 4, 4, 4, 0, 3, 0, 4, 4, 3, 2, 2, 0, 3, 4, 3, 4, 4, 3, 2, 2, 3, 0, 0, 2, 3, 3, 2, 2, 0, 3, 3, 2, 4, 0, 2, 4, 4, 4, 2, 3, 4, 4, 4, 4, 4, 0, 4, 2, 2, 0, 4, 2, 2, 3, 0, 4, 3, 4, 3, 4, 0, 3, 2, 2, 0, 2, 0, 0, 2, 0, 4, 4, 4, 4, 0, 4, 3, 0, 4, 4, 0, 2, 3, 0, 2, 4, 4, 4, 3, 0, 4, 4, 4, 3, 0, 3, 4, 2, 0, 4, 4, 3, 4, 4, 2, 0, 4, 0, 3, 4, 4, 0, 0, 3, 3, 0, 4, 0, 0, 0, 2, 4, 3, 4, 3, 3, 3, 4, 0, 4, 0, 3, 4, 2, 3, 3, 2, 2, 0, 4, 4, 4, 0, 2, 0, 2, 4, 3, 3, 4, 2, 2, 4, 0, 2, 3, 3, 0, 2, 0, 0, 0, 3, 4, 2, 4, 0, 0, 3, 3, 3, 0, 0, 3, 4, 2, 3, 2, 3, 4, 0, 0, 4, 2, 3, 2, 3, 0, 3, 3, 2, 4, 0, 3, 4, 3, 0, 3, 2, 2, 4, 4, 3, 4, 0, 4, 3, 0, 2, 3, 4, 4, 4, 4, 3, 3, 4, 0, 2, 3, 4, 4, 3, 4, 4, 2, 0, 2, 0, 3, 0, 3, 0, 2, 4, 3, 2, 4, 0, 2, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.94      0.76      0.84       100\n",
      "           3       0.72      0.89      0.79       100\n",
      "           4       0.56      0.91      0.69       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2016765549778938, Val acc: 0.698\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42800 - Batch 86/1582 - Train loss: 1.024955733754169, Train acc: 0.8793103448275862\n",
      "Iteration 42900 - Batch 186/1582 - Train loss: 1.030339070182433, Train acc: 0.8734959893048129\n",
      "Iteration 43000 - Batch 286/1582 - Train loss: 1.0293164811898607, Train acc: 0.8747822299651568\n",
      "Iteration 43100 - Batch 386/1582 - Train loss: 1.0302208127593502, Train acc: 0.8738695090439277\n",
      "Iteration 43200 - Batch 486/1582 - Train loss: 1.0328848595736697, Train acc: 0.8712140657084189\n",
      "Iteration 43300 - Batch 586/1582 - Train loss: 1.0337230716490868, Train acc: 0.8703151618398637\n",
      "Iteration 43400 - Batch 686/1582 - Train loss: 1.0329049545431068, Train acc: 0.8709516011644832\n",
      "Iteration 43500 - Batch 786/1582 - Train loss: 1.0330778297505505, Train acc: 0.8708703939008895\n",
      "Iteration 43600 - Batch 886/1582 - Train loss: 1.0322162049330075, Train acc: 0.8717235062006764\n",
      "Iteration 43700 - Batch 986/1582 - Train loss: 1.0312849226452054, Train acc: 0.8727203647416414\n",
      "Iteration 43800 - Batch 1086/1582 - Train loss: 1.0316691523093966, Train acc: 0.8722976080956761\n",
      "Iteration 43900 - Batch 1186/1582 - Train loss: 1.032347540345228, Train acc: 0.8717354675652906\n",
      "Iteration 44000 - Batch 1286/1582 - Train loss: 1.032055811031715, Train acc: 0.8719648407148407\n",
      "Iteration 44100 - Batch 1386/1582 - Train loss: 1.0314395713479552, Train acc: 0.8724540374909877\n",
      "Iteration 44200 - Batch 1486/1582 - Train loss: 1.0313002763374908, Train acc: 0.8725622057834567\n",
      "[1, 0, 2, 2, 2, 4, 2, 0, 1, 4, 3, 3, 4, 0, 2, 0, 3, 0, 3, 2, 0, 0, 0, 1, 2, 3, 3, 3, 1, 1, 2, 3, 3, 1, 3, 4, 2, 2, 2, 2, 1, 0, 1, 2, 1, 0, 0, 4, 4, 2, 2, 4, 1, 4, 1, 2, 3, 3, 1, 1, 2, 4, 3, 0, 2, 2, 2, 1, 4, 3, 1, 2, 4, 2, 4, 0, 3, 1, 0, 0, 0, 0, 2, 0, 1, 0, 1, 3, 3, 4, 4, 0, 3, 0, 2, 1, 1, 3, 4, 4, 1, 3, 0, 1, 3, 0, 2, 2, 1, 2, 3, 0, 2, 0, 4, 4, 3, 1, 3, 4, 4, 3, 1, 2, 4, 2, 1, 2, 0, 1, 0, 2, 3, 0, 3, 3, 4, 3, 0, 3, 4, 1, 3, 1, 3, 0, 4, 0, 1, 4, 3, 2, 1, 3, 4, 3, 0, 0, 2, 2, 0, 0, 0, 1, 1, 2, 3, 0, 0, 1, 2, 4, 4, 4, 4, 0, 3, 1, 4, 0, 3, 2, 4, 2, 0, 2, 1, 2, 0, 3, 3, 2, 3, 1, 2, 1, 2, 4, 2, 1, 4, 4, 3, 4, 2, 2, 1, 0, 4, 3, 0, 1, 3, 3, 0, 2, 0, 0, 0, 4, 2, 4, 3, 3, 3, 1, 3, 3, 1, 3, 1, 1, 4, 3, 2, 1, 0, 3, 4, 3, 2, 2, 4, 1, 2, 4, 3, 0, 0, 2, 0, 1, 2, 2, 1, 3, 3, 0, 4, 2, 0, 3, 2, 1, 2, 3, 1, 3, 0, 2, 4, 4, 3, 3, 0, 3, 2, 0, 4, 4, 4, 1, 0, 4, 3, 3, 1, 2, 2, 0, 1, 4, 4, 1, 0, 2, 2, 0, 4, 4, 1, 4, 0, 1, 1, 4, 4, 2, 1, 2, 3, 3, 1, 1, 1, 4, 4, 4, 2, 0, 1, 4, 0, 3, 2, 1, 4, 3, 3, 2, 3, 4, 0, 0, 3, 4, 4, 1, 3, 0, 0, 4, 3, 4, 0, 4, 2, 4, 2, 1, 4, 1, 4, 4, 3, 0, 1, 1, 4, 0, 1, 3, 2, 3, 3, 1, 0, 2, 2, 4, 4, 1, 1, 0, 3, 1, 3, 2, 0, 2, 1, 1, 2, 1, 3, 1, 2, 2, 0, 4, 1, 4, 3, 0, 4, 4, 0, 0, 2, 2, 3, 3, 3, 4, 3, 0, 3, 0, 2, 1, 1, 4, 0, 1, 1, 3, 0, 1, 0, 3, 0, 0, 4, 1, 0, 0, 2, 1, 1, 2, 4, 0, 4, 0, 1, 0, 2, 1, 2, 4, 1, 1, 1, 3, 2, 3, 4, 4, 2, 1, 4, 2, 2, 4, 2, 3, 1, 0, 2, 3, 4, 4, 3, 4, 2, 0, 2, 3, 0, 2, 3, 0, 0, 1, 0, 0, 3, 0, 3, 3, 2, 4, 1, 4, 1, 4, 2, 3, 4, 1, 4, 4, 0, 2, 4, 1, 1, 4, 2, 0]\n",
      "[0, 0, 2, 2, 0, 4, 0, 0, 0, 4, 3, 3, 4, 0, 0, 0, 3, 0, 3, 3, 0, 2, 0, 4, 0, 3, 3, 3, 4, 4, 0, 3, 3, 3, 3, 4, 2, 2, 0, 2, 3, 0, 3, 2, 4, 0, 0, 0, 4, 2, 2, 4, 2, 4, 0, 2, 3, 3, 3, 0, 2, 4, 3, 4, 0, 2, 2, 4, 4, 0, 3, 2, 4, 2, 4, 0, 3, 0, 4, 0, 4, 0, 2, 2, 0, 0, 3, 3, 3, 4, 4, 0, 3, 0, 2, 4, 4, 3, 4, 3, 4, 3, 0, 2, 3, 0, 2, 2, 4, 0, 3, 0, 2, 0, 4, 4, 3, 0, 3, 4, 4, 3, 3, 2, 4, 2, 0, 2, 0, 4, 0, 2, 3, 0, 3, 3, 4, 4, 0, 3, 4, 4, 3, 3, 3, 0, 4, 0, 3, 4, 3, 2, 4, 3, 4, 3, 0, 4, 2, 2, 0, 0, 0, 3, 3, 2, 3, 0, 0, 4, 2, 4, 4, 4, 4, 2, 3, 4, 4, 0, 3, 0, 4, 2, 0, 2, 4, 2, 0, 3, 3, 2, 3, 3, 2, 3, 2, 4, 2, 4, 4, 4, 3, 4, 2, 2, 0, 0, 4, 3, 0, 3, 3, 3, 0, 2, 0, 0, 0, 2, 0, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 4, 3, 2, 2, 0, 3, 4, 3, 2, 2, 3, 3, 2, 4, 3, 0, 0, 2, 0, 2, 2, 2, 3, 3, 3, 0, 4, 2, 0, 3, 0, 4, 2, 3, 4, 3, 0, 0, 4, 4, 3, 3, 0, 3, 0, 0, 3, 3, 4, 4, 0, 4, 3, 3, 0, 2, 2, 0, 0, 4, 4, 3, 0, 2, 2, 0, 4, 4, 3, 4, 0, 4, 3, 4, 4, 2, 4, 2, 3, 3, 4, 2, 3, 4, 4, 3, 2, 4, 4, 4, 0, 3, 0, 3, 4, 3, 3, 2, 3, 4, 0, 0, 3, 4, 4, 3, 3, 0, 0, 3, 3, 4, 0, 4, 2, 4, 2, 2, 4, 0, 4, 2, 3, 0, 3, 3, 4, 0, 3, 3, 2, 3, 3, 3, 0, 2, 2, 4, 3, 4, 3, 0, 3, 2, 3, 2, 0, 0, 3, 3, 2, 2, 3, 4, 2, 2, 0, 4, 2, 4, 3, 0, 4, 4, 0, 0, 2, 2, 3, 3, 3, 4, 3, 0, 3, 0, 2, 4, 4, 4, 0, 4, 4, 3, 0, 4, 0, 3, 0, 0, 4, 4, 0, 0, 2, 0, 3, 2, 4, 2, 4, 0, 4, 0, 2, 3, 2, 4, 3, 3, 0, 3, 2, 3, 4, 4, 2, 3, 4, 0, 2, 4, 2, 3, 3, 0, 2, 3, 4, 4, 3, 4, 2, 2, 2, 3, 0, 0, 3, 0, 0, 4, 0, 0, 3, 0, 4, 4, 2, 4, 3, 4, 4, 4, 0, 3, 4, 4, 3, 4, 0, 2, 3, 0, 4, 4, 2, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.84      0.81      0.82       100\n",
      "           3       0.67      0.96      0.79       100\n",
      "           4       0.66      0.88      0.75       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1928188279271126, Val acc: 0.71\n",
      "Epoch 29/30\n",
      "Iteration 44300 - Batch 4/1582 - Train loss: 1.0320542335510254, Train acc: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44400 - Batch 104/1582 - Train loss: 1.0312622388203938, Train acc: 0.8738095238095238\n",
      "Iteration 44500 - Batch 204/1582 - Train loss: 1.0365064591896243, Train acc: 0.8684451219512195\n",
      "Iteration 44600 - Batch 304/1582 - Train loss: 1.033143115239065, Train acc: 0.871516393442623\n",
      "Iteration 44700 - Batch 404/1582 - Train loss: 1.0309715194466673, Train acc: 0.8736882716049382\n",
      "Iteration 44800 - Batch 504/1582 - Train loss: 1.0306190977002134, Train acc: 0.8735148514851485\n",
      "Iteration 44900 - Batch 604/1582 - Train loss: 1.029419513674807, Train acc: 0.8745351239669421\n",
      "Iteration 45000 - Batch 704/1582 - Train loss: 1.0291609952635798, Train acc: 0.8745567375886525\n",
      "Iteration 45100 - Batch 804/1582 - Train loss: 1.028685982701201, Train acc: 0.875\n",
      "Iteration 45200 - Batch 904/1582 - Train loss: 1.0288639569809424, Train acc: 0.874896408839779\n",
      "Iteration 45300 - Batch 1004/1582 - Train loss: 1.0290089910896263, Train acc: 0.8749378109452737\n",
      "Iteration 45400 - Batch 1104/1582 - Train loss: 1.0296525031732757, Train acc: 0.8742929864253394\n",
      "Iteration 45500 - Batch 1204/1582 - Train loss: 1.0305339681657024, Train acc: 0.8733661825726141\n",
      "Iteration 45600 - Batch 1304/1582 - Train loss: 1.031252321886377, Train acc: 0.8726532567049808\n",
      "Iteration 45700 - Batch 1404/1582 - Train loss: 1.0317303535352822, Train acc: 0.8721752669039146\n",
      "Iteration 45800 - Batch 1504/1582 - Train loss: 1.0324736604262823, Train acc: 0.8713455149501661\n",
      "[0, 4, 2, 0, 1, 2, 0, 3, 3, 2, 2, 4, 4, 3, 1, 2, 3, 0, 4, 2, 1, 4, 3, 1, 0, 0, 1, 0, 0, 0, 4, 0, 0, 3, 0, 4, 4, 4, 4, 1, 3, 4, 1, 2, 3, 3, 2, 4, 1, 4, 3, 2, 1, 3, 0, 3, 1, 0, 3, 4, 1, 0, 0, 4, 3, 4, 1, 1, 3, 1, 2, 1, 3, 3, 0, 3, 1, 1, 4, 2, 3, 3, 1, 4, 4, 0, 3, 4, 0, 0, 2, 2, 1, 3, 2, 2, 1, 0, 2, 4, 2, 2, 4, 2, 2, 4, 0, 3, 0, 1, 1, 2, 4, 2, 2, 4, 1, 1, 4, 3, 4, 0, 2, 3, 0, 3, 0, 1, 2, 0, 0, 4, 4, 0, 2, 2, 3, 4, 2, 0, 1, 0, 1, 3, 2, 1, 1, 2, 0, 2, 3, 3, 4, 2, 2, 4, 1, 4, 0, 4, 0, 2, 1, 3, 0, 4, 4, 4, 0, 3, 3, 2, 4, 3, 4, 2, 2, 0, 1, 4, 3, 1, 0, 3, 4, 2, 4, 1, 1, 4, 2, 2, 1, 3, 0, 3, 0, 1, 4, 3, 0, 1, 3, 3, 3, 2, 1, 3, 4, 4, 1, 1, 0, 2, 2, 0, 4, 4, 0, 1, 0, 3, 2, 1, 0, 2, 4, 4, 1, 3, 4, 4, 3, 3, 2, 1, 4, 0, 3, 3, 0, 4, 3, 3, 4, 1, 1, 4, 4, 0, 2, 3, 3, 4, 3, 0, 1, 3, 0, 0, 1, 3, 3, 2, 2, 1, 2, 3, 1, 1, 4, 0, 3, 1, 1, 2, 2, 1, 4, 3, 4, 3, 2, 1, 1, 1, 3, 0, 0, 3, 0, 4, 3, 2, 1, 3, 3, 0, 0, 3, 4, 1, 2, 1, 1, 1, 1, 3, 4, 3, 0, 2, 2, 2, 1, 4, 0, 4, 1, 4, 2, 4, 2, 4, 0, 3, 0, 4, 3, 4, 3, 0, 3, 0, 3, 0, 4, 0, 2, 4, 0, 2, 2, 2, 4, 2, 0, 3, 4, 1, 4, 2, 4, 2, 3, 0, 1, 1, 4, 0, 1, 0, 1, 2, 3, 1, 1, 2, 1, 3, 2, 3, 0, 2, 2, 1, 0, 0, 0, 2, 1, 0, 1, 0, 3, 3, 3, 1, 2, 2, 1, 1, 2, 2, 0, 3, 3, 0, 2, 1, 1, 4, 0, 3, 4, 1, 2, 0, 4, 2, 4, 4, 2, 2, 2, 4, 4, 2, 0, 4, 4, 4, 3, 2, 4, 1, 2, 0, 2, 3, 2, 2, 1, 3, 0, 1, 2, 0, 2, 3, 3, 0, 3, 4, 0, 0, 4, 3, 3, 1, 4, 4, 3, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 4, 1, 1, 3, 0, 0, 4, 4, 2, 2, 1, 1, 2, 0, 0, 1, 3, 3, 2, 0, 0, 4, 2, 0, 3, 2, 3, 2, 4, 4, 0, 4, 3, 1, 1]\n",
      "[0, 4, 2, 0, 3, 2, 0, 4, 3, 0, 2, 4, 4, 3, 4, 2, 3, 0, 4, 2, 4, 4, 3, 4, 0, 2, 0, 0, 0, 4, 4, 0, 0, 3, 0, 4, 4, 4, 4, 2, 3, 4, 4, 2, 3, 4, 2, 4, 0, 4, 3, 0, 4, 3, 0, 3, 3, 0, 3, 4, 0, 0, 0, 4, 3, 4, 3, 3, 3, 0, 0, 4, 3, 3, 0, 3, 3, 4, 4, 2, 4, 3, 3, 4, 4, 0, 3, 4, 0, 2, 2, 2, 4, 3, 2, 2, 3, 0, 2, 4, 0, 2, 4, 0, 2, 4, 4, 3, 0, 4, 4, 2, 0, 2, 0, 4, 4, 4, 4, 3, 4, 0, 2, 4, 0, 3, 0, 4, 2, 0, 0, 4, 4, 0, 2, 0, 3, 4, 0, 0, 3, 0, 3, 3, 2, 4, 0, 0, 0, 2, 4, 3, 4, 2, 2, 4, 3, 4, 0, 2, 0, 2, 3, 3, 0, 4, 4, 4, 0, 3, 3, 2, 4, 3, 4, 2, 2, 0, 0, 4, 3, 3, 0, 3, 4, 2, 4, 4, 4, 4, 2, 2, 4, 3, 0, 3, 0, 3, 4, 3, 0, 4, 3, 3, 3, 2, 4, 3, 4, 4, 3, 4, 0, 2, 2, 0, 4, 4, 0, 3, 4, 3, 0, 4, 0, 2, 4, 4, 3, 3, 4, 4, 3, 3, 2, 0, 4, 0, 3, 3, 0, 4, 3, 3, 4, 0, 4, 3, 4, 0, 2, 3, 3, 4, 3, 4, 4, 3, 0, 0, 4, 3, 3, 4, 2, 4, 2, 3, 4, 4, 4, 0, 4, 0, 4, 2, 2, 4, 3, 3, 4, 3, 2, 3, 4, 3, 3, 0, 4, 3, 2, 4, 4, 2, 4, 4, 3, 0, 0, 3, 4, 3, 0, 3, 4, 0, 4, 3, 4, 3, 0, 2, 2, 2, 4, 4, 0, 4, 3, 4, 2, 4, 2, 4, 2, 3, 0, 4, 3, 3, 3, 0, 4, 0, 3, 0, 4, 0, 2, 4, 0, 2, 2, 2, 4, 0, 0, 3, 4, 4, 4, 2, 4, 2, 3, 0, 4, 0, 4, 0, 4, 0, 4, 2, 3, 4, 4, 2, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 0, 2, 4, 0, 3, 0, 3, 3, 3, 4, 2, 2, 4, 0, 0, 2, 0, 3, 3, 0, 2, 3, 0, 3, 0, 3, 4, 0, 2, 0, 4, 2, 4, 4, 0, 2, 2, 4, 4, 2, 0, 4, 4, 4, 3, 2, 4, 4, 2, 0, 2, 3, 0, 2, 3, 3, 0, 3, 2, 0, 2, 3, 3, 0, 3, 4, 4, 0, 4, 3, 3, 3, 4, 4, 3, 2, 0, 3, 0, 0, 4, 0, 3, 4, 3, 2, 0, 4, 4, 4, 3, 0, 0, 4, 4, 2, 2, 0, 3, 2, 0, 0, 3, 3, 3, 2, 0, 0, 4, 3, 0, 3, 2, 3, 2, 4, 4, 0, 4, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.93      0.81      0.87       100\n",
      "           3       0.71      0.91      0.79       100\n",
      "           4       0.59      0.94      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1894845888018608, Val acc: 0.712\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45900 - Batch 22/1582 - Train loss: 1.0172975659370422, Train acc: 0.8872282608695652\n",
      "Iteration 46000 - Batch 122/1582 - Train loss: 1.0287408974112533, Train acc: 0.8747459349593496\n",
      "Iteration 46100 - Batch 222/1582 - Train loss: 1.0287572506297329, Train acc: 0.8747197309417041\n",
      "Iteration 46200 - Batch 322/1582 - Train loss: 1.029108626554625, Train acc: 0.8744195046439629\n",
      "Iteration 46300 - Batch 422/1582 - Train loss: 1.0288263683341636, Train acc: 0.8746306146572104\n",
      "Iteration 46400 - Batch 522/1582 - Train loss: 1.0291065321825659, Train acc: 0.874581739961759\n",
      "Iteration 46500 - Batch 622/1582 - Train loss: 1.0297838971855935, Train acc: 0.8740971107544141\n",
      "Iteration 46600 - Batch 722/1582 - Train loss: 1.0303453436201209, Train acc: 0.8734007607192255\n",
      "Iteration 46700 - Batch 822/1582 - Train loss: 1.0310971194454994, Train acc: 0.8725698663426489\n",
      "Iteration 46800 - Batch 922/1582 - Train loss: 1.0305341548031097, Train acc: 0.8731378656554712\n",
      "Iteration 46900 - Batch 1022/1582 - Train loss: 1.031516556399542, Train acc: 0.8720369012707723\n",
      "Iteration 47000 - Batch 1122/1582 - Train loss: 1.0310908328287323, Train acc: 0.8724677203918076\n",
      "Iteration 47100 - Batch 1222/1582 - Train loss: 1.0308752724213963, Train acc: 0.8727514309076042\n",
      "Iteration 47200 - Batch 1322/1582 - Train loss: 1.0307608306723297, Train acc: 0.8728977702191988\n",
      "Iteration 47300 - Batch 1422/1582 - Train loss: 1.029676083184763, Train acc: 0.8740556921995783\n",
      "Iteration 47400 - Batch 1522/1582 - Train loss: 1.0293896358731696, Train acc: 0.8743434011818779\n",
      "[4, 3, 0, 3, 1, 1, 2, 4, 1, 0, 0, 4, 1, 3, 1, 1, 2, 1, 1, 2, 3, 1, 0, 4, 2, 3, 0, 1, 0, 3, 4, 0, 4, 2, 1, 3, 2, 1, 1, 4, 4, 3, 4, 2, 1, 3, 2, 4, 1, 4, 4, 3, 0, 2, 3, 2, 3, 0, 3, 2, 2, 2, 2, 0, 0, 2, 1, 1, 3, 1, 3, 0, 2, 2, 2, 4, 3, 2, 1, 3, 4, 0, 4, 2, 0, 0, 0, 1, 1, 4, 1, 4, 1, 4, 4, 2, 2, 2, 4, 0, 2, 1, 3, 1, 0, 2, 4, 1, 0, 4, 2, 3, 2, 3, 1, 2, 3, 2, 3, 4, 4, 1, 0, 3, 0, 4, 0, 1, 2, 2, 4, 1, 2, 0, 3, 3, 4, 0, 3, 0, 4, 1, 4, 4, 0, 3, 3, 3, 4, 0, 0, 0, 1, 2, 2, 0, 1, 3, 2, 4, 0, 4, 4, 3, 3, 0, 0, 0, 4, 0, 3, 4, 0, 0, 4, 0, 1, 4, 1, 0, 4, 0, 4, 2, 1, 0, 2, 0, 1, 1, 4, 3, 2, 0, 3, 2, 1, 0, 3, 4, 4, 2, 3, 1, 1, 0, 1, 0, 2, 4, 1, 1, 3, 0, 1, 3, 2, 3, 4, 2, 0, 4, 3, 3, 4, 0, 1, 3, 3, 4, 4, 1, 3, 1, 0, 0, 0, 3, 2, 0, 3, 0, 4, 4, 2, 4, 3, 4, 3, 2, 3, 0, 0, 2, 2, 3, 1, 3, 0, 3, 4, 1, 3, 3, 4, 2, 2, 3, 4, 0, 3, 1, 3, 1, 4, 2, 1, 2, 3, 3, 1, 1, 1, 1, 1, 4, 1, 3, 2, 1, 3, 0, 0, 3, 4, 4, 0, 0, 0, 2, 1, 3, 0, 3, 0, 3, 1, 1, 3, 4, 1, 3, 4, 4, 1, 0, 0, 1, 1, 2, 3, 2, 1, 4, 1, 4, 3, 1, 1, 2, 0, 1, 0, 3, 4, 1, 3, 2, 3, 4, 1, 0, 4, 2, 2, 2, 1, 0, 3, 2, 4, 4, 0, 2, 1, 1, 2, 3, 4, 2, 4, 1, 4, 1, 4, 3, 3, 0, 2, 2, 2, 2, 2, 4, 1, 0, 0, 4, 3, 1, 0, 2, 1, 1, 2, 3, 0, 3, 0, 2, 0, 3, 0, 1, 1, 4, 4, 3, 2, 0, 4, 0, 2, 2, 2, 1, 2, 2, 3, 0, 0, 1, 4, 2, 3, 0, 0, 1, 3, 2, 0, 1, 3, 3, 3, 2, 0, 1, 0, 1, 1, 3, 3, 0, 1, 4, 4, 3, 1, 2, 4, 3, 2, 3, 4, 4, 1, 4, 4, 4, 3, 4, 4, 2, 3, 2, 3, 2, 4, 4, 2, 4, 3, 0, 4, 2, 2, 2, 4, 2, 4, 2, 0, 0, 3, 0, 2, 2, 0, 0, 4, 0, 3, 4, 1, 1, 0, 2, 4, 2, 0, 2, 3, 4, 2, 0, 1, 2, 1, 1]\n",
      "[4, 3, 0, 3, 0, 4, 2, 3, 4, 0, 0, 4, 3, 3, 4, 4, 0, 4, 4, 2, 3, 4, 0, 4, 2, 3, 0, 4, 0, 3, 3, 0, 4, 0, 0, 3, 2, 3, 4, 4, 4, 3, 4, 2, 3, 3, 2, 4, 4, 4, 4, 3, 0, 2, 3, 2, 3, 0, 3, 2, 2, 2, 2, 0, 0, 2, 4, 4, 4, 4, 3, 0, 2, 2, 0, 4, 3, 0, 3, 3, 4, 0, 4, 0, 0, 0, 0, 3, 0, 4, 3, 4, 0, 4, 4, 2, 2, 2, 3, 0, 2, 2, 3, 0, 0, 2, 4, 3, 0, 4, 2, 3, 2, 3, 4, 2, 3, 0, 3, 4, 4, 3, 0, 3, 0, 4, 0, 2, 2, 2, 4, 0, 2, 0, 3, 3, 4, 0, 4, 0, 4, 3, 4, 4, 0, 3, 4, 3, 2, 0, 0, 0, 4, 2, 0, 2, 2, 3, 2, 4, 0, 4, 4, 3, 3, 2, 0, 0, 2, 0, 3, 4, 0, 0, 4, 0, 4, 4, 3, 0, 4, 0, 4, 2, 4, 0, 2, 0, 0, 3, 4, 3, 2, 0, 3, 2, 4, 0, 3, 4, 4, 2, 3, 3, 4, 0, 2, 0, 2, 4, 3, 4, 3, 0, 3, 3, 0, 3, 4, 2, 0, 4, 3, 3, 4, 0, 0, 3, 3, 4, 4, 3, 4, 3, 0, 4, 0, 3, 2, 0, 3, 0, 4, 4, 2, 4, 4, 0, 3, 2, 3, 4, 0, 2, 3, 3, 4, 3, 0, 3, 4, 2, 3, 3, 4, 2, 2, 3, 4, 0, 3, 0, 3, 3, 4, 2, 2, 2, 4, 3, 4, 4, 3, 3, 4, 4, 0, 3, 2, 4, 3, 0, 0, 3, 4, 4, 0, 0, 0, 2, 0, 3, 0, 3, 2, 3, 0, 0, 3, 4, 2, 3, 4, 4, 3, 0, 0, 4, 4, 2, 3, 2, 3, 4, 0, 4, 3, 4, 4, 2, 0, 4, 0, 3, 4, 3, 3, 2, 3, 4, 4, 0, 4, 2, 2, 2, 3, 0, 3, 2, 4, 4, 0, 2, 3, 4, 2, 3, 4, 0, 4, 0, 4, 0, 4, 3, 3, 0, 2, 2, 2, 2, 2, 4, 0, 0, 0, 4, 3, 0, 0, 2, 0, 4, 4, 3, 0, 3, 0, 2, 0, 3, 0, 0, 4, 3, 4, 3, 0, 0, 4, 0, 2, 2, 2, 0, 2, 2, 4, 0, 0, 3, 4, 2, 3, 0, 4, 4, 3, 2, 0, 3, 3, 0, 3, 2, 0, 4, 0, 4, 0, 3, 3, 0, 4, 4, 4, 3, 3, 2, 4, 3, 2, 3, 4, 4, 3, 4, 4, 4, 3, 4, 3, 2, 3, 2, 3, 0, 3, 4, 2, 4, 3, 0, 4, 0, 2, 2, 4, 0, 4, 2, 0, 0, 3, 0, 2, 2, 0, 0, 4, 0, 3, 4, 0, 0, 2, 2, 4, 0, 0, 0, 3, 0, 2, 0, 3, 0, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.82      0.84       100\n",
      "           3       0.71      0.92      0.80       100\n",
      "           4       0.64      0.90      0.75       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.64       500\n",
      "weighted avg       0.58      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1949785575270653, Val acc: 0.714\n",
      "Tiempo total de entrenamiento: 635.7783 [s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curves=trainer(train_loader,val_loader,epochs=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con datos generados por GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "z_dim = 64\n",
    "num_img=1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 supernovas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_1 = Generator(z_dim).to(device)\n",
    "gen_1.load_state_dict(torch.load('dcgan'))\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen.load_state_dict(torch.load('wgangp'))\n",
    "fake_noise = get_noise(num_img, z_dim, device=device)\n",
    "fake_dcgan = gen_1(fake_noise)\n",
    "fake_wgangp= gen(fake_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14542,  2396, 14523,  9599, 10534])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,val_loader=get_training_loaders(synthetic_SN=fake_dcgan.detach().cpu(),batch_size=32,file_name=\"stamp_dataset_only_images_63.pkl\",label_as_strings=True)\n",
    "torch.bincount(train_loader.dataset.labels.to(torch.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Iteration 0 - Batch 0/1613 - Train loss: 1.615712285041809, Train acc: 0.09375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 - Batch 100/1613 - Train loss: 1.4675021112555324, Train acc: 0.5037128712871287\n",
      "Iteration 200 - Batch 200/1613 - Train loss: 1.413902146899285, Train acc: 0.5379353233830846\n",
      "Iteration 300 - Batch 300/1613 - Train loss: 1.3822576175892471, Train acc: 0.5573089700996677\n",
      "Iteration 400 - Batch 400/1613 - Train loss: 1.3658001714216503, Train acc: 0.5670978802992519\n",
      "Iteration 500 - Batch 500/1613 - Train loss: 1.3512627302767513, Train acc: 0.5775948103792415\n",
      "Iteration 600 - Batch 600/1613 - Train loss: 1.3385969073125805, Train acc: 0.5873024126455907\n",
      "Iteration 700 - Batch 700/1613 - Train loss: 1.3280934823222574, Train acc: 0.5942849500713266\n",
      "Iteration 800 - Batch 800/1613 - Train loss: 1.3134016329876046, Train acc: 0.6074048064918851\n",
      "Iteration 900 - Batch 900/1613 - Train loss: 1.2994134596793951, Train acc: 0.6201789678135405\n",
      "Iteration 1000 - Batch 1000/1613 - Train loss: 1.2856213634426181, Train acc: 0.6330232267732268\n",
      "Iteration 1100 - Batch 1100/1613 - Train loss: 1.2739035596531376, Train acc: 0.6437045867393278\n",
      "Iteration 1200 - Batch 1200/1613 - Train loss: 1.2634597044503262, Train acc: 0.6532056619483764\n",
      "Iteration 1300 - Batch 1300/1613 - Train loss: 1.2559495679146504, Train acc: 0.6599971176018448\n",
      "Iteration 1400 - Batch 1400/1613 - Train loss: 1.2474819144378977, Train acc: 0.6677596359743041\n",
      "Iteration 1500 - Batch 1500/1613 - Train loss: 1.2397490367342996, Train acc: 0.6747793137908061\n",
      "Iteration 1600 - Batch 1600/1613 - Train loss: 1.2334337138072318, Train acc: 0.6803560274828232\n",
      "[3, 2, 0, 2, 1, 2, 0, 0, 3, 4, 1, 0, 3, 3, 4, 3, 2, 4, 1, 1, 1, 4, 4, 4, 4, 3, 1, 3, 4, 3, 0, 2, 4, 2, 3, 0, 2, 3, 1, 1, 2, 3, 0, 0, 0, 2, 1, 2, 0, 3, 0, 3, 2, 3, 2, 1, 3, 3, 1, 1, 4, 2, 3, 2, 3, 3, 1, 0, 1, 4, 0, 3, 0, 3, 3, 1, 0, 1, 4, 1, 2, 1, 1, 1, 1, 0, 2, 3, 2, 2, 1, 1, 0, 0, 1, 2, 2, 4, 4, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 4, 4, 4, 0, 0, 2, 4, 3, 3, 3, 1, 2, 4, 1, 3, 3, 3, 0, 4, 3, 4, 2, 3, 1, 0, 2, 2, 3, 3, 3, 2, 2, 0, 3, 2, 0, 2, 3, 2, 3, 1, 1, 3, 2, 0, 0, 4, 4, 0, 1, 0, 1, 0, 1, 0, 3, 2, 2, 4, 2, 2, 4, 3, 0, 1, 1, 2, 1, 4, 4, 3, 4, 0, 1, 4, 0, 2, 1, 2, 4, 2, 1, 1, 3, 2, 4, 2, 2, 1, 4, 0, 1, 0, 1, 0, 3, 3, 2, 1, 0, 3, 3, 1, 1, 0, 4, 3, 2, 4, 1, 0, 4, 2, 1, 0, 1, 4, 1, 0, 4, 1, 1, 0, 4, 2, 4, 4, 1, 1, 0, 0, 3, 3, 3, 4, 2, 1, 1, 2, 4, 0, 4, 0, 4, 4, 0, 0, 4, 2, 1, 0, 0, 0, 3, 4, 2, 3, 3, 0, 2, 3, 4, 1, 2, 0, 4, 3, 2, 1, 4, 2, 2, 1, 2, 3, 4, 1, 1, 1, 1, 4, 1, 0, 4, 1, 3, 0, 3, 0, 3, 0, 1, 2, 0, 0, 3, 0, 1, 1, 1, 4, 1, 4, 1, 1, 2, 4, 2, 1, 2, 2, 4, 4, 0, 0, 2, 0, 4, 1, 2, 2, 0, 0, 2, 1, 1, 2, 3, 3, 4, 4, 0, 4, 1, 0, 0, 4, 1, 3, 4, 0, 2, 2, 3, 3, 2, 3, 4, 0, 2, 4, 2, 2, 3, 4, 4, 2, 1, 0, 0, 0, 0, 1, 4, 3, 4, 3, 4, 4, 3, 4, 0, 4, 1, 3, 2, 2, 0, 3, 3, 0, 0, 1, 3, 3, 1, 1, 0, 0, 1, 4, 2, 1, 4, 4, 0, 3, 3, 4, 4, 1, 4, 4, 0, 4, 1, 1, 2, 3, 3, 0, 0, 4, 2, 4, 4, 2, 2, 4, 1, 1, 4, 2, 1, 3, 0, 4, 0, 3, 0, 3, 0, 1, 0, 0, 3, 3, 2, 1, 3, 2, 3, 3, 4, 4, 4, 4, 0, 0, 2, 2, 0, 3, 0, 4, 2, 3, 4, 4, 2, 3, 0, 1, 2, 1, 2, 3, 1, 4, 0, 2, 2, 4, 4, 3, 1, 2, 2, 0, 3, 2, 2, 2, 0, 4, 0, 1, 1, 4, 3, 0]\n",
      "[0, 0, 0, 2, 4, 2, 0, 0, 3, 4, 0, 0, 3, 3, 2, 4, 3, 4, 4, 0, 0, 4, 4, 2, 2, 3, 0, 3, 4, 3, 0, 2, 4, 2, 3, 0, 0, 3, 0, 0, 2, 3, 0, 0, 2, 0, 4, 2, 4, 3, 0, 3, 2, 3, 2, 2, 4, 3, 4, 2, 4, 2, 2, 2, 4, 3, 2, 0, 0, 4, 4, 3, 0, 3, 4, 0, 0, 4, 4, 4, 2, 2, 4, 4, 3, 0, 2, 2, 2, 2, 0, 0, 0, 0, 4, 2, 2, 4, 4, 2, 2, 2, 3, 2, 3, 3, 2, 3, 3, 4, 4, 4, 0, 0, 2, 4, 3, 3, 3, 0, 2, 4, 4, 3, 3, 3, 0, 4, 3, 2, 2, 3, 4, 0, 0, 3, 3, 4, 3, 2, 2, 0, 3, 2, 2, 3, 4, 2, 3, 4, 0, 3, 2, 0, 0, 4, 4, 0, 4, 0, 0, 4, 4, 0, 3, 2, 2, 4, 2, 2, 4, 3, 0, 2, 3, 2, 0, 4, 2, 3, 4, 0, 4, 4, 0, 0, 4, 2, 4, 2, 0, 2, 3, 2, 4, 2, 2, 2, 4, 0, 4, 0, 3, 0, 3, 4, 2, 4, 0, 3, 3, 4, 4, 0, 4, 3, 2, 0, 4, 0, 4, 0, 4, 0, 0, 4, 4, 0, 0, 2, 4, 0, 4, 0, 2, 4, 3, 2, 2, 0, 3, 3, 3, 4, 2, 3, 3, 0, 0, 0, 4, 2, 4, 4, 0, 2, 4, 2, 2, 0, 0, 0, 3, 4, 0, 4, 3, 0, 2, 3, 4, 0, 2, 0, 4, 3, 2, 4, 4, 2, 2, 0, 2, 3, 4, 0, 2, 0, 4, 4, 3, 0, 4, 0, 3, 0, 3, 0, 2, 2, 4, 2, 0, 0, 3, 4, 0, 4, 4, 4, 0, 0, 0, 3, 2, 4, 0, 4, 2, 2, 4, 4, 0, 0, 2, 0, 4, 3, 0, 2, 0, 2, 2, 4, 0, 2, 3, 3, 4, 4, 0, 4, 0, 4, 0, 4, 0, 3, 4, 0, 2, 2, 3, 3, 2, 3, 4, 0, 0, 4, 2, 2, 3, 4, 3, 0, 2, 2, 4, 0, 0, 3, 4, 3, 4, 3, 4, 4, 3, 4, 0, 4, 3, 3, 2, 2, 0, 0, 3, 0, 0, 4, 3, 3, 0, 2, 0, 0, 0, 4, 2, 0, 4, 4, 0, 3, 3, 4, 4, 0, 4, 4, 0, 3, 4, 3, 2, 3, 3, 0, 0, 2, 2, 4, 4, 2, 2, 4, 3, 4, 4, 2, 0, 4, 0, 3, 0, 3, 0, 3, 0, 4, 2, 2, 3, 3, 2, 4, 3, 0, 4, 3, 4, 4, 4, 4, 0, 0, 2, 2, 0, 3, 0, 4, 2, 3, 4, 4, 2, 3, 0, 4, 2, 4, 2, 3, 3, 4, 0, 0, 0, 2, 4, 3, 0, 2, 2, 0, 3, 2, 2, 2, 0, 4, 2, 0, 0, 4, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.69      0.81      0.75       100\n",
      "           3       0.81      0.84      0.82       100\n",
      "           4       0.61      0.85      0.71       100\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.54      0.67      0.59       500\n",
      "weighted avg       0.54      0.67      0.59       500\n",
      "\n",
      "Val loss: 1.2334198504686356, Val acc: 0.666\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1700 - Batch 87/1613 - Train loss: 1.1452631130814552, Train acc: 0.7581676136363636\n",
      "Iteration 1800 - Batch 187/1613 - Train loss: 1.138886329658488, Train acc: 0.7647938829787234\n",
      "Iteration 1900 - Batch 287/1613 - Train loss: 1.1312476719419162, Train acc: 0.7728949652777778\n",
      "Iteration 2000 - Batch 387/1613 - Train loss: 1.1258708487466438, Train acc: 0.7787532216494846\n",
      "Iteration 2100 - Batch 487/1613 - Train loss: 1.1243162809825333, Train acc: 0.7798411885245902\n",
      "Iteration 2200 - Batch 587/1613 - Train loss: 1.125187178351441, Train acc: 0.7791772959183674\n",
      "Iteration 2300 - Batch 687/1613 - Train loss: 1.123708788305521, Train acc: 0.7802053052325582\n",
      "Iteration 2400 - Batch 787/1613 - Train loss: 1.1234329567494126, Train acc: 0.7802189086294417\n",
      "Iteration 2500 - Batch 887/1613 - Train loss: 1.1214256066459793, Train acc: 0.7821649774774775\n",
      "Iteration 2600 - Batch 987/1613 - Train loss: 1.1197238491493682, Train acc: 0.7837803643724697\n",
      "Iteration 2700 - Batch 1087/1613 - Train loss: 1.119679704253726, Train acc: 0.7838637408088235\n",
      "Iteration 2800 - Batch 1187/1613 - Train loss: 1.118821780388604, Train acc: 0.7847485269360269\n",
      "Iteration 2900 - Batch 1287/1613 - Train loss: 1.1177384523871523, Train acc: 0.7858113354037267\n",
      "Iteration 3000 - Batch 1387/1613 - Train loss: 1.1169110202909547, Train acc: 0.7864958573487032\n",
      "Iteration 3100 - Batch 1487/1613 - Train loss: 1.1161092740073, Train acc: 0.7873403897849462\n",
      "Iteration 3200 - Batch 1587/1613 - Train loss: 1.1153888945615562, Train acc: 0.7879801637279596\n",
      "[0, 0, 4, 1, 0, 0, 3, 0, 1, 4, 0, 1, 3, 2, 4, 3, 1, 0, 0, 2, 3, 1, 3, 4, 3, 1, 4, 1, 2, 1, 1, 2, 3, 1, 2, 0, 2, 1, 3, 4, 2, 3, 0, 2, 1, 0, 4, 0, 2, 4, 0, 4, 1, 2, 4, 2, 0, 3, 4, 0, 2, 0, 0, 4, 4, 1, 1, 3, 3, 3, 3, 2, 3, 4, 4, 4, 1, 1, 1, 3, 0, 1, 3, 0, 1, 2, 3, 4, 3, 1, 4, 0, 2, 2, 0, 3, 0, 4, 0, 0, 3, 3, 4, 2, 0, 3, 0, 1, 2, 1, 2, 4, 4, 3, 0, 2, 1, 0, 1, 2, 4, 3, 1, 0, 3, 3, 2, 0, 3, 1, 3, 4, 0, 2, 0, 0, 2, 4, 0, 4, 2, 2, 0, 3, 3, 2, 3, 2, 2, 3, 0, 4, 4, 3, 3, 1, 3, 2, 3, 1, 3, 4, 0, 0, 2, 3, 3, 3, 3, 1, 1, 2, 4, 0, 4, 4, 0, 3, 4, 3, 3, 4, 2, 3, 4, 0, 4, 1, 3, 4, 3, 4, 4, 1, 2, 1, 3, 4, 4, 1, 3, 2, 2, 4, 0, 0, 3, 2, 1, 0, 0, 1, 1, 0, 0, 4, 0, 1, 0, 3, 3, 2, 2, 4, 0, 1, 1, 1, 1, 2, 0, 2, 1, 0, 1, 4, 3, 3, 4, 0, 2, 4, 1, 3, 2, 4, 1, 1, 3, 2, 1, 3, 1, 0, 1, 4, 1, 1, 0, 4, 4, 4, 4, 3, 4, 3, 4, 3, 2, 1, 1, 2, 0, 0, 4, 1, 0, 3, 1, 3, 1, 2, 3, 1, 1, 2, 3, 0, 1, 1, 2, 0, 2, 4, 4, 4, 3, 1, 1, 2, 2, 2, 0, 1, 3, 1, 2, 4, 0, 2, 1, 2, 4, 2, 2, 0, 0, 2, 0, 2, 0, 2, 4, 4, 4, 0, 4, 1, 2, 1, 4, 2, 3, 0, 2, 2, 4, 1, 4, 0, 0, 0, 1, 2, 1, 4, 2, 3, 4, 0, 3, 2, 2, 0, 4, 1, 4, 0, 0, 0, 0, 3, 2, 4, 1, 1, 1, 1, 2, 3, 4, 3, 4, 2, 0, 4, 2, 3, 1, 1, 4, 1, 2, 0, 2, 4, 0, 4, 2, 1, 1, 0, 0, 0, 2, 1, 3, 3, 4, 2, 3, 3, 2, 2, 1, 4, 2, 3, 0, 3, 1, 2, 0, 2, 0, 3, 2, 2, 2, 0, 4, 3, 0, 2, 4, 0, 0, 3, 4, 0, 0, 2, 4, 3, 1, 3, 0, 3, 0, 0, 4, 1, 4, 2, 1, 3, 0, 1, 3, 3, 1, 2, 2, 2, 4, 4, 2, 2, 1, 4, 4, 4, 1, 0, 4, 4, 4, 3, 1, 3, 3, 3, 2, 0, 1, 1, 2, 3, 2, 1, 4, 0, 3, 2, 4, 4, 2, 1, 3, 1, 2, 3, 3, 4, 0, 3, 4, 1, 1, 3]\n",
      "[0, 0, 4, 2, 0, 0, 3, 3, 3, 4, 0, 4, 3, 2, 4, 3, 4, 0, 0, 2, 3, 3, 3, 4, 3, 2, 4, 4, 2, 0, 0, 2, 3, 3, 2, 4, 2, 4, 3, 4, 3, 3, 0, 2, 3, 0, 4, 0, 2, 4, 0, 4, 3, 3, 4, 2, 2, 3, 4, 0, 2, 0, 0, 4, 3, 0, 4, 3, 3, 3, 3, 2, 3, 3, 4, 4, 3, 3, 4, 3, 0, 4, 3, 0, 3, 2, 4, 4, 3, 0, 4, 2, 2, 2, 0, 3, 0, 4, 0, 2, 3, 3, 3, 2, 2, 3, 0, 3, 2, 4, 2, 4, 4, 4, 0, 2, 3, 4, 3, 2, 4, 3, 4, 0, 4, 3, 2, 0, 3, 2, 3, 4, 0, 2, 0, 2, 2, 4, 0, 4, 2, 2, 0, 3, 3, 2, 3, 0, 2, 3, 0, 4, 4, 3, 3, 4, 3, 0, 3, 4, 3, 4, 0, 0, 3, 3, 3, 3, 3, 2, 3, 2, 4, 2, 4, 4, 0, 3, 4, 3, 3, 4, 0, 3, 4, 0, 4, 0, 3, 4, 3, 4, 4, 0, 0, 4, 3, 4, 4, 0, 3, 2, 2, 4, 0, 0, 3, 2, 0, 0, 0, 0, 3, 0, 0, 4, 0, 2, 0, 3, 3, 2, 2, 0, 0, 0, 3, 3, 2, 2, 0, 2, 0, 0, 2, 4, 3, 3, 4, 2, 2, 4, 3, 3, 2, 4, 2, 3, 3, 2, 0, 3, 4, 0, 3, 3, 4, 4, 0, 0, 4, 4, 4, 3, 4, 3, 4, 3, 2, 3, 4, 2, 0, 0, 4, 3, 0, 3, 3, 3, 0, 2, 3, 3, 2, 2, 3, 0, 3, 4, 2, 0, 0, 3, 4, 4, 3, 0, 3, 2, 0, 2, 0, 0, 0, 4, 2, 4, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 4, 4, 4, 3, 4, 3, 2, 3, 2, 2, 3, 0, 3, 2, 4, 0, 4, 0, 0, 0, 3, 2, 3, 4, 2, 3, 4, 0, 3, 3, 2, 0, 4, 0, 4, 0, 2, 0, 2, 3, 2, 4, 4, 2, 3, 0, 2, 3, 4, 4, 4, 2, 0, 4, 2, 3, 0, 3, 3, 3, 2, 2, 2, 0, 0, 4, 2, 4, 0, 0, 2, 0, 2, 2, 3, 3, 3, 2, 3, 4, 2, 2, 0, 0, 2, 3, 0, 3, 2, 2, 2, 2, 0, 3, 2, 2, 2, 4, 4, 3, 0, 0, 2, 0, 0, 3, 3, 2, 0, 2, 4, 4, 0, 3, 2, 3, 0, 0, 4, 4, 4, 2, 3, 3, 0, 0, 3, 4, 2, 2, 2, 2, 4, 4, 2, 2, 3, 2, 4, 4, 3, 0, 4, 4, 4, 3, 0, 3, 3, 3, 2, 0, 0, 4, 2, 3, 2, 3, 2, 0, 3, 2, 2, 4, 0, 3, 3, 3, 2, 3, 3, 4, 0, 3, 4, 0, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.72      0.87      0.79       100\n",
      "           3       0.64      0.92      0.75       100\n",
      "           4       0.72      0.82      0.77       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.55      0.68      0.61       500\n",
      "weighted avg       0.55      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.216065563261509, Val acc: 0.682\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3300 - Batch 74/1613 - Train loss: 1.1033382638295492, Train acc: 0.8029166666666666\n",
      "Iteration 3400 - Batch 174/1613 - Train loss: 1.1000987461635046, Train acc: 0.805\n",
      "Iteration 3500 - Batch 274/1613 - Train loss: 1.100101718902588, Train acc: 0.8044318181818182\n",
      "Iteration 3600 - Batch 374/1613 - Train loss: 1.0960403779347738, Train acc: 0.8083333333333333\n",
      "Iteration 3700 - Batch 474/1613 - Train loss: 1.0959613884122748, Train acc: 0.8082236842105263\n",
      "Iteration 3800 - Batch 574/1613 - Train loss: 1.0964818315920621, Train acc: 0.8076630434782609\n",
      "Iteration 3900 - Batch 674/1613 - Train loss: 1.0973570372440198, Train acc: 0.8068055555555556\n",
      "Iteration 4000 - Batch 774/1613 - Train loss: 1.095243026364234, Train acc: 0.8087096774193548\n",
      "Iteration 4100 - Batch 874/1613 - Train loss: 1.095078806604658, Train acc: 0.8089642857142857\n",
      "Iteration 4200 - Batch 974/1613 - Train loss: 1.0954616686625358, Train acc: 0.8085576923076923\n",
      "Iteration 4300 - Batch 1074/1613 - Train loss: 1.0954678633046704, Train acc: 0.8086046511627907\n",
      "Iteration 4400 - Batch 1174/1613 - Train loss: 1.0946960571978954, Train acc: 0.8093351063829787\n",
      "Iteration 4500 - Batch 1274/1613 - Train loss: 1.0951610352011287, Train acc: 0.8088725490196078\n",
      "Iteration 4600 - Batch 1374/1613 - Train loss: 1.093796203916723, Train acc: 0.8102727272727273\n",
      "Iteration 4700 - Batch 1474/1613 - Train loss: 1.0935677893283005, Train acc: 0.8105720338983051\n",
      "Iteration 4800 - Batch 1574/1613 - Train loss: 1.0932524367741177, Train acc: 0.8107539682539683\n",
      "[1, 2, 0, 2, 0, 3, 4, 3, 3, 2, 4, 4, 1, 2, 1, 4, 2, 3, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 3, 1, 0, 0, 4, 2, 0, 0, 2, 1, 1, 3, 1, 4, 0, 0, 4, 3, 4, 2, 1, 2, 1, 4, 0, 2, 3, 1, 1, 0, 3, 2, 2, 3, 4, 2, 4, 3, 4, 2, 3, 1, 3, 1, 4, 3, 3, 1, 2, 1, 3, 2, 1, 0, 2, 1, 4, 1, 1, 3, 4, 3, 1, 1, 1, 4, 3, 4, 1, 1, 2, 4, 3, 3, 4, 0, 3, 4, 2, 0, 1, 4, 3, 4, 2, 2, 3, 1, 3, 3, 4, 2, 1, 0, 4, 2, 0, 1, 4, 0, 1, 3, 3, 4, 2, 0, 3, 4, 3, 1, 4, 2, 4, 2, 4, 4, 0, 1, 4, 3, 0, 1, 3, 4, 1, 3, 4, 3, 0, 0, 1, 1, 3, 2, 0, 4, 3, 0, 3, 3, 2, 2, 2, 1, 4, 1, 3, 3, 2, 0, 0, 3, 3, 2, 0, 4, 1, 3, 4, 0, 1, 1, 0, 1, 3, 2, 3, 3, 2, 4, 2, 2, 0, 3, 1, 3, 2, 2, 2, 4, 1, 1, 1, 3, 3, 0, 0, 4, 0, 1, 3, 2, 3, 0, 0, 4, 4, 3, 4, 3, 0, 2, 0, 1, 4, 4, 1, 4, 2, 3, 4, 2, 3, 0, 1, 2, 1, 1, 0, 0, 1, 2, 3, 3, 4, 4, 0, 1, 4, 0, 0, 2, 0, 4, 2, 1, 3, 0, 4, 0, 2, 2, 2, 1, 4, 4, 1, 4, 2, 0, 4, 2, 2, 0, 3, 4, 0, 2, 0, 3, 0, 0, 2, 1, 4, 3, 2, 3, 0, 0, 4, 4, 4, 4, 1, 3, 1, 0, 1, 1, 0, 0, 4, 0, 4, 2, 4, 2, 4, 0, 0, 0, 2, 4, 4, 0, 1, 3, 3, 3, 0, 1, 3, 2, 2, 1, 3, 3, 2, 1, 1, 4, 4, 3, 3, 1, 0, 3, 4, 1, 4, 3, 1, 1, 2, 2, 2, 2, 2, 1, 1, 4, 3, 0, 3, 2, 0, 2, 1, 3, 4, 3, 0, 2, 2, 0, 0, 1, 2, 0, 4, 0, 2, 0, 3, 0, 3, 1, 1, 2, 2, 3, 3, 1, 0, 4, 2, 0, 4, 2, 2, 0, 4, 4, 2, 2, 0, 2, 4, 0, 2, 1, 0, 1, 1, 3, 4, 2, 3, 0, 4, 2, 0, 2, 4, 1, 1, 2, 3, 1, 3, 1, 4, 2, 4, 4, 2, 1, 3, 3, 0, 1, 4, 1, 0, 1, 3, 1, 2, 0, 4, 4, 0, 3, 3, 4, 0, 0, 1, 0, 2, 4, 4, 3, 3, 0, 2, 2, 4, 4, 2, 4, 1, 1, 0, 1, 3, 1, 3, 2, 1, 3, 0, 2, 4, 2, 0, 0, 1, 3, 3, 2, 1, 3, 3, 4, 1, 4, 4, 0]\n",
      "[0, 2, 0, 2, 0, 2, 3, 3, 3, 0, 4, 4, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 3, 2, 3, 0, 0, 0, 4, 0, 0, 0, 2, 4, 4, 3, 4, 4, 0, 0, 4, 3, 4, 2, 0, 2, 3, 4, 0, 2, 3, 4, 3, 0, 3, 0, 2, 4, 4, 2, 4, 3, 4, 2, 3, 4, 3, 0, 4, 3, 4, 3, 2, 4, 3, 2, 3, 0, 2, 3, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 3, 4, 3, 0, 0, 4, 3, 3, 4, 0, 3, 4, 2, 4, 0, 4, 3, 4, 2, 2, 3, 4, 3, 3, 2, 2, 3, 0, 4, 0, 4, 2, 4, 0, 3, 3, 3, 4, 2, 0, 3, 4, 3, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 3, 0, 0, 3, 4, 4, 3, 4, 3, 0, 0, 3, 4, 4, 3, 0, 4, 3, 0, 3, 3, 2, 2, 0, 4, 4, 2, 3, 3, 0, 0, 0, 3, 3, 2, 0, 4, 3, 3, 3, 0, 3, 4, 0, 4, 3, 2, 3, 3, 2, 4, 4, 2, 0, 0, 3, 3, 2, 2, 2, 4, 0, 0, 3, 3, 3, 0, 0, 4, 0, 3, 3, 0, 3, 0, 0, 4, 4, 3, 4, 3, 0, 2, 0, 3, 4, 4, 4, 3, 0, 3, 4, 2, 3, 0, 4, 2, 4, 4, 0, 0, 4, 2, 3, 4, 4, 4, 0, 4, 4, 0, 0, 2, 0, 4, 2, 2, 3, 0, 4, 0, 2, 0, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 0, 3, 4, 0, 2, 4, 3, 0, 0, 2, 4, 4, 3, 2, 3, 0, 0, 4, 4, 4, 4, 4, 3, 4, 0, 0, 0, 0, 0, 4, 0, 4, 2, 4, 2, 4, 0, 0, 0, 2, 4, 4, 0, 4, 3, 3, 3, 0, 4, 3, 2, 3, 4, 3, 3, 0, 3, 3, 3, 4, 3, 3, 3, 0, 3, 4, 3, 4, 3, 4, 4, 2, 2, 0, 2, 2, 0, 4, 4, 3, 0, 3, 0, 0, 0, 4, 3, 4, 3, 0, 0, 2, 0, 0, 4, 2, 0, 4, 0, 2, 0, 3, 0, 3, 4, 3, 2, 0, 4, 3, 4, 2, 4, 2, 0, 4, 0, 2, 4, 4, 4, 0, 2, 0, 2, 3, 0, 2, 0, 0, 4, 4, 3, 4, 2, 3, 4, 4, 0, 0, 2, 3, 3, 0, 2, 3, 4, 3, 4, 4, 2, 4, 4, 0, 4, 3, 3, 0, 2, 4, 0, 0, 3, 3, 3, 2, 3, 4, 4, 0, 3, 3, 4, 0, 0, 3, 0, 2, 4, 4, 3, 3, 0, 0, 2, 4, 4, 2, 4, 2, 3, 2, 2, 3, 0, 3, 2, 3, 3, 0, 2, 4, 2, 0, 0, 4, 3, 3, 2, 0, 3, 3, 4, 0, 4, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.74      0.80       100\n",
      "           3       0.70      0.93      0.80       100\n",
      "           4       0.62      0.93      0.74       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.204908512532711, Val acc: 0.7\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4900 - Batch 61/1613 - Train loss: 1.0857780047001377, Train acc: 0.8170362903225806\n",
      "Iteration 5000 - Batch 161/1613 - Train loss: 1.0811072315698789, Train acc: 0.8219521604938271\n",
      "Iteration 5100 - Batch 261/1613 - Train loss: 1.0805469405560093, Train acc: 0.8227576335877863\n",
      "Iteration 5200 - Batch 361/1613 - Train loss: 1.0797170860003371, Train acc: 0.8238950276243094\n",
      "Iteration 5300 - Batch 461/1613 - Train loss: 1.080581316571215, Train acc: 0.8229166666666666\n",
      "Iteration 5400 - Batch 561/1613 - Train loss: 1.0811797387871454, Train acc: 0.8222864768683275\n",
      "Iteration 5500 - Batch 661/1613 - Train loss: 1.0812508609719866, Train acc: 0.8222715256797583\n",
      "Iteration 5600 - Batch 761/1613 - Train loss: 1.0824983193492639, Train acc: 0.8207841207349081\n",
      "Iteration 5700 - Batch 861/1613 - Train loss: 1.0828719392868316, Train acc: 0.8207294083526682\n",
      "Iteration 5800 - Batch 961/1613 - Train loss: 1.0828286845570048, Train acc: 0.8208809771309772\n",
      "Iteration 5900 - Batch 1061/1613 - Train loss: 1.0824227276382699, Train acc: 0.8212099811676082\n",
      "Iteration 6000 - Batch 1161/1613 - Train loss: 1.0808244314743607, Train acc: 0.8228270223752151\n",
      "Iteration 6100 - Batch 1261/1613 - Train loss: 1.0806872645856462, Train acc: 0.8229249207606973\n",
      "Iteration 6200 - Batch 1361/1613 - Train loss: 1.0807085206592661, Train acc: 0.8229625550660793\n",
      "Iteration 6300 - Batch 1461/1613 - Train loss: 1.0803948270638566, Train acc: 0.8233797879616963\n",
      "Iteration 6400 - Batch 1561/1613 - Train loss: 1.0799698936115, Train acc: 0.8238436299615877\n",
      "[2, 0, 1, 3, 1, 2, 1, 2, 3, 2, 0, 2, 0, 2, 3, 2, 2, 1, 0, 4, 1, 0, 4, 1, 2, 4, 2, 3, 4, 3, 0, 0, 4, 1, 1, 2, 2, 2, 2, 0, 4, 1, 3, 0, 3, 3, 2, 3, 1, 1, 0, 3, 0, 2, 4, 2, 2, 2, 3, 2, 2, 2, 1, 3, 0, 1, 3, 2, 0, 0, 2, 4, 3, 2, 2, 2, 2, 3, 4, 2, 3, 3, 3, 4, 1, 3, 0, 3, 3, 4, 3, 0, 2, 2, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4, 4, 1, 3, 3, 0, 3, 4, 0, 0, 3, 3, 1, 0, 0, 1, 2, 0, 2, 1, 4, 4, 0, 4, 1, 0, 4, 3, 1, 3, 1, 3, 1, 2, 4, 4, 3, 0, 4, 0, 1, 4, 2, 4, 4, 2, 1, 3, 3, 3, 0, 4, 0, 4, 2, 1, 0, 0, 2, 2, 4, 0, 4, 1, 4, 4, 3, 4, 2, 4, 1, 4, 4, 0, 1, 1, 4, 1, 1, 4, 4, 4, 4, 1, 0, 1, 0, 0, 2, 4, 4, 4, 4, 3, 2, 1, 1, 3, 1, 1, 3, 1, 4, 3, 0, 4, 1, 0, 4, 4, 2, 1, 3, 0, 4, 4, 3, 1, 0, 3, 2, 2, 1, 3, 0, 1, 0, 1, 1, 3, 4, 1, 4, 3, 4, 3, 2, 3, 3, 0, 3, 3, 3, 0, 2, 4, 2, 0, 3, 0, 2, 2, 4, 2, 2, 4, 2, 4, 1, 1, 4, 1, 4, 3, 4, 2, 0, 4, 0, 2, 4, 3, 3, 4, 1, 2, 0, 4, 4, 4, 4, 3, 4, 0, 3, 0, 1, 0, 3, 0, 4, 1, 0, 0, 0, 3, 1, 1, 0, 0, 4, 2, 0, 4, 1, 1, 4, 0, 0, 4, 0, 4, 4, 0, 3, 2, 2, 1, 1, 3, 2, 2, 3, 1, 1, 3, 2, 1, 3, 0, 0, 4, 1, 2, 0, 2, 3, 2, 2, 1, 3, 1, 0, 2, 1, 4, 2, 0, 2, 0, 4, 4, 3, 0, 2, 2, 0, 1, 0, 1, 3, 1, 0, 2, 4, 0, 2, 1, 2, 0, 3, 2, 1, 3, 3, 1, 0, 4, 0, 2, 1, 1, 2, 0, 2, 1, 3, 2, 4, 4, 1, 4, 1, 2, 0, 3, 1, 3, 3, 2, 2, 0, 0, 1, 4, 0, 4, 0, 2, 3, 3, 1, 0, 3, 1, 3, 3, 0, 1, 4, 0, 1, 2, 1, 2, 4, 2, 3, 3, 1, 4, 1, 0, 2, 2, 1, 2, 4, 1, 3, 4, 0, 1, 4, 4, 0, 0, 1, 1, 0, 2, 3, 0, 0, 2, 3, 2, 0, 4, 2, 1, 2, 3, 1, 0, 0, 4, 1, 4, 3, 0, 2, 1, 2, 4, 3, 4, 1, 1, 4, 1, 1, 2, 1, 3, 0, 4, 2, 0, 3, 4, 3, 0, 1]\n",
      "[2, 4, 4, 3, 4, 2, 3, 2, 3, 2, 0, 0, 0, 2, 3, 2, 2, 3, 0, 4, 3, 0, 4, 4, 2, 4, 0, 3, 4, 3, 0, 0, 4, 4, 3, 2, 3, 2, 2, 0, 4, 0, 3, 0, 3, 3, 2, 3, 4, 3, 0, 3, 0, 2, 4, 0, 2, 2, 3, 2, 0, 2, 0, 3, 0, 4, 3, 2, 0, 0, 2, 4, 3, 0, 2, 2, 2, 3, 4, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 2, 3, 0, 2, 0, 0, 2, 3, 3, 3, 3, 3, 2, 3, 3, 3, 2, 4, 4, 0, 3, 4, 0, 4, 4, 0, 0, 3, 3, 4, 0, 0, 3, 2, 0, 2, 4, 4, 4, 0, 3, 4, 0, 4, 3, 4, 3, 3, 3, 4, 2, 4, 4, 3, 0, 4, 0, 4, 4, 0, 4, 4, 0, 3, 3, 3, 3, 0, 4, 0, 4, 2, 4, 0, 0, 2, 3, 4, 0, 4, 3, 4, 4, 3, 4, 2, 4, 3, 4, 4, 0, 4, 4, 4, 3, 0, 4, 4, 4, 4, 4, 0, 4, 0, 4, 2, 4, 4, 4, 4, 3, 0, 3, 4, 3, 0, 4, 3, 0, 4, 3, 0, 0, 3, 0, 4, 4, 2, 4, 3, 0, 4, 4, 3, 4, 0, 3, 2, 2, 4, 3, 0, 3, 0, 4, 2, 3, 4, 3, 4, 3, 4, 3, 2, 3, 4, 0, 3, 3, 3, 0, 2, 4, 0, 0, 3, 0, 2, 2, 4, 2, 0, 4, 0, 4, 3, 4, 4, 4, 4, 0, 4, 2, 2, 4, 0, 2, 4, 3, 3, 4, 3, 2, 0, 4, 4, 4, 4, 3, 4, 0, 3, 0, 4, 0, 4, 0, 4, 3, 0, 0, 0, 3, 3, 4, 0, 0, 4, 2, 0, 4, 0, 0, 4, 0, 0, 4, 0, 4, 2, 2, 3, 2, 2, 4, 4, 3, 2, 2, 3, 0, 4, 3, 2, 3, 3, 0, 0, 4, 4, 2, 0, 2, 3, 2, 2, 0, 3, 3, 0, 0, 0, 3, 0, 0, 2, 0, 4, 4, 3, 0, 2, 0, 0, 4, 0, 0, 3, 2, 0, 3, 2, 0, 0, 4, 0, 0, 3, 2, 0, 3, 3, 4, 0, 4, 0, 2, 0, 4, 2, 0, 2, 3, 3, 0, 4, 4, 4, 3, 0, 2, 0, 3, 4, 3, 3, 3, 2, 0, 0, 4, 0, 0, 4, 0, 2, 3, 3, 2, 0, 3, 0, 3, 3, 4, 4, 4, 4, 0, 2, 4, 2, 4, 2, 3, 4, 3, 4, 4, 0, 2, 2, 4, 0, 4, 4, 3, 4, 0, 0, 4, 4, 0, 0, 4, 0, 0, 2, 4, 0, 0, 2, 3, 0, 3, 4, 2, 4, 2, 3, 4, 0, 0, 4, 3, 4, 3, 0, 0, 4, 2, 4, 3, 4, 0, 3, 3, 0, 4, 2, 2, 3, 0, 4, 2, 0, 4, 3, 3, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.93      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.74      0.80       100\n",
      "           3       0.71      0.91      0.80       100\n",
      "           4       0.60      0.89      0.71       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2132306024432182, Val acc: 0.694\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6500 - Batch 48/1613 - Train loss: 1.0726186815573244, Train acc: 0.8303571428571429\n",
      "Iteration 6600 - Batch 148/1613 - Train loss: 1.076561206139174, Train acc: 0.8252936241610739\n",
      "Iteration 6700 - Batch 248/1613 - Train loss: 1.0780796119008198, Train acc: 0.8246736947791165\n",
      "Iteration 6800 - Batch 348/1613 - Train loss: 1.07861960976035, Train acc: 0.8243194842406877\n",
      "Iteration 6900 - Batch 448/1613 - Train loss: 1.0765454901884288, Train acc: 0.8265590200445434\n",
      "Iteration 7000 - Batch 548/1613 - Train loss: 1.0773516684933437, Train acc: 0.82599043715847\n",
      "Iteration 7100 - Batch 648/1613 - Train loss: 1.0781385137230295, Train acc: 0.825115562403698\n",
      "Iteration 7200 - Batch 748/1613 - Train loss: 1.0772385528791093, Train acc: 0.8259345794392523\n",
      "Iteration 7300 - Batch 848/1613 - Train loss: 1.0769158831333525, Train acc: 0.8262293875147232\n",
      "Iteration 7400 - Batch 948/1613 - Train loss: 1.0755618710789214, Train acc: 0.8275158061116965\n",
      "Iteration 7500 - Batch 1048/1613 - Train loss: 1.0751729221771285, Train acc: 0.8282292659675882\n",
      "Iteration 7600 - Batch 1148/1613 - Train loss: 1.074570521050894, Train acc: 0.8290089208006962\n",
      "Iteration 7700 - Batch 1248/1613 - Train loss: 1.0740756309920068, Train acc: 0.8294885908726981\n",
      "Iteration 7800 - Batch 1348/1613 - Train loss: 1.0736113292716714, Train acc: 0.8300824684951816\n",
      "Iteration 7900 - Batch 1448/1613 - Train loss: 1.0731718206997984, Train acc: 0.8305512422360248\n",
      "Iteration 8000 - Batch 1548/1613 - Train loss: 1.0732024781853249, Train acc: 0.8304954809554551\n",
      "[4, 4, 4, 4, 1, 3, 1, 4, 2, 4, 1, 1, 3, 4, 4, 0, 2, 0, 4, 0, 1, 1, 2, 4, 4, 0, 0, 4, 3, 1, 0, 4, 3, 1, 4, 3, 2, 4, 0, 1, 0, 1, 1, 0, 1, 1, 0, 3, 2, 2, 3, 1, 2, 3, 2, 3, 1, 0, 4, 4, 4, 3, 3, 3, 0, 0, 0, 2, 3, 2, 4, 0, 4, 4, 4, 3, 3, 2, 2, 0, 4, 1, 4, 2, 2, 0, 4, 0, 3, 2, 3, 3, 1, 4, 2, 0, 3, 4, 3, 2, 0, 0, 2, 2, 3, 3, 0, 0, 1, 0, 2, 0, 0, 0, 3, 1, 2, 0, 1, 3, 0, 0, 4, 0, 2, 0, 4, 4, 0, 0, 2, 3, 1, 1, 2, 4, 2, 4, 1, 0, 2, 4, 1, 2, 4, 1, 3, 0, 3, 4, 3, 4, 2, 0, 2, 3, 2, 0, 3, 2, 4, 4, 4, 3, 3, 0, 3, 0, 1, 3, 3, 2, 2, 2, 4, 0, 1, 3, 1, 0, 3, 0, 0, 3, 1, 2, 4, 3, 1, 1, 4, 2, 0, 2, 3, 3, 3, 2, 2, 3, 2, 2, 1, 4, 3, 0, 0, 2, 4, 1, 4, 4, 1, 0, 3, 2, 4, 4, 0, 1, 0, 1, 3, 0, 1, 1, 1, 0, 3, 0, 2, 1, 1, 0, 4, 0, 1, 4, 2, 4, 4, 1, 0, 0, 2, 2, 2, 0, 0, 1, 1, 3, 3, 3, 0, 2, 1, 3, 3, 0, 2, 2, 3, 1, 4, 2, 2, 4, 1, 4, 0, 4, 3, 1, 1, 0, 3, 1, 4, 0, 0, 2, 1, 0, 2, 2, 1, 3, 4, 1, 0, 2, 1, 4, 3, 4, 2, 2, 1, 4, 2, 2, 2, 1, 3, 4, 2, 0, 0, 1, 4, 3, 3, 2, 3, 1, 3, 3, 4, 3, 2, 1, 1, 3, 4, 4, 1, 4, 4, 3, 1, 3, 0, 3, 2, 1, 0, 2, 2, 4, 0, 4, 1, 1, 3, 3, 2, 2, 2, 3, 2, 4, 1, 0, 1, 2, 2, 3, 3, 2, 4, 3, 4, 2, 4, 0, 4, 2, 4, 2, 3, 4, 0, 0, 1, 2, 4, 2, 4, 0, 1, 3, 0, 0, 4, 0, 1, 0, 4, 3, 2, 0, 0, 2, 1, 1, 1, 4, 1, 4, 2, 0, 0, 2, 1, 3, 1, 0, 2, 3, 1, 3, 1, 3, 4, 1, 0, 1, 3, 4, 2, 2, 2, 1, 4, 0, 1, 1, 3, 0, 2, 1, 1, 1, 0, 2, 1, 3, 1, 1, 3, 1, 3, 0, 1, 0, 1, 0, 4, 4, 0, 2, 2, 1, 3, 4, 0, 3, 0, 3, 0, 3, 4, 4, 3, 2, 4, 1, 3, 1, 3, 3, 3, 4, 4, 3, 2, 4, 3, 0, 4, 1, 1, 0, 4, 2, 4, 1, 2, 3, 3, 0, 4, 2, 2, 4, 2, 2, 3, 1]\n",
      "[4, 4, 4, 4, 0, 3, 4, 4, 0, 4, 0, 3, 3, 4, 4, 0, 2, 0, 4, 0, 4, 4, 2, 4, 3, 4, 0, 4, 3, 3, 0, 4, 4, 0, 4, 3, 2, 4, 0, 0, 0, 4, 4, 0, 4, 2, 0, 4, 2, 2, 3, 0, 0, 3, 2, 3, 0, 0, 4, 4, 4, 4, 3, 3, 0, 0, 0, 2, 4, 3, 4, 0, 4, 4, 4, 3, 3, 2, 2, 0, 4, 4, 4, 2, 0, 0, 3, 0, 3, 2, 3, 3, 4, 4, 2, 0, 3, 4, 3, 2, 0, 0, 0, 2, 3, 3, 4, 0, 4, 0, 2, 0, 2, 0, 3, 4, 2, 0, 3, 4, 0, 0, 4, 0, 0, 0, 4, 4, 0, 0, 2, 3, 4, 2, 2, 4, 2, 4, 0, 4, 2, 4, 3, 0, 4, 3, 4, 0, 3, 4, 3, 4, 2, 4, 2, 3, 2, 0, 3, 2, 4, 4, 4, 3, 3, 0, 3, 0, 3, 3, 3, 2, 0, 2, 4, 0, 0, 3, 0, 0, 3, 0, 0, 3, 2, 0, 4, 3, 3, 0, 4, 3, 4, 0, 3, 3, 3, 2, 2, 3, 2, 0, 3, 4, 3, 0, 4, 2, 4, 4, 4, 4, 3, 0, 3, 2, 2, 4, 0, 4, 0, 3, 3, 2, 3, 4, 4, 0, 3, 0, 2, 4, 4, 0, 4, 2, 3, 4, 2, 4, 4, 4, 0, 0, 2, 2, 2, 4, 0, 2, 2, 3, 3, 3, 0, 2, 4, 3, 3, 0, 2, 2, 3, 4, 4, 2, 2, 4, 4, 4, 0, 4, 4, 3, 3, 0, 4, 3, 4, 0, 0, 2, 4, 0, 2, 0, 2, 3, 4, 4, 0, 0, 4, 4, 4, 4, 2, 2, 4, 4, 2, 2, 0, 4, 3, 4, 2, 0, 0, 4, 4, 0, 3, 0, 3, 4, 3, 3, 4, 3, 2, 4, 4, 3, 4, 4, 0, 4, 4, 3, 4, 3, 0, 3, 2, 4, 0, 2, 0, 4, 0, 4, 4, 2, 3, 3, 2, 2, 2, 3, 2, 4, 0, 0, 4, 2, 2, 3, 3, 2, 4, 4, 4, 2, 4, 0, 4, 0, 4, 2, 3, 4, 0, 0, 4, 0, 2, 2, 4, 0, 4, 3, 0, 0, 4, 4, 4, 0, 4, 3, 2, 4, 0, 3, 4, 3, 0, 2, 0, 4, 2, 0, 4, 2, 4, 3, 4, 0, 2, 3, 0, 3, 3, 3, 4, 2, 0, 3, 3, 4, 2, 2, 2, 0, 4, 0, 3, 4, 3, 0, 2, 4, 4, 4, 0, 2, 3, 3, 4, 4, 3, 4, 3, 0, 4, 0, 2, 0, 4, 4, 0, 2, 2, 4, 4, 4, 0, 3, 0, 3, 0, 3, 4, 4, 3, 2, 4, 4, 3, 0, 4, 3, 3, 4, 4, 4, 4, 4, 3, 0, 4, 4, 3, 0, 4, 2, 4, 4, 2, 3, 3, 0, 4, 2, 2, 4, 2, 2, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.84      0.79      0.81       100\n",
      "           3       0.77      0.86      0.81       100\n",
      "           4       0.55      0.95      0.70       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2085180133581161, Val acc: 0.694\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8100 - Batch 35/1613 - Train loss: 1.0678715225723054, Train acc: 0.8368055555555556\n",
      "Iteration 8200 - Batch 135/1613 - Train loss: 1.0805992685696657, Train acc: 0.8235294117647058\n",
      "Iteration 8300 - Batch 235/1613 - Train loss: 1.0813560177714139, Train acc: 0.8229608050847458\n",
      "Iteration 8400 - Batch 335/1613 - Train loss: 1.0803780821817262, Train acc: 0.8239397321428571\n",
      "Iteration 8500 - Batch 435/1613 - Train loss: 1.0761286218505386, Train acc: 0.8278383027522935\n",
      "Iteration 8600 - Batch 535/1613 - Train loss: 1.0779521307393687, Train acc: 0.8256763059701493\n",
      "Iteration 8700 - Batch 635/1613 - Train loss: 1.0773608818556528, Train acc: 0.8262087264150944\n",
      "Iteration 8800 - Batch 735/1613 - Train loss: 1.0769189208260048, Train acc: 0.8265964673913043\n",
      "Iteration 8900 - Batch 835/1613 - Train loss: 1.0762755602740786, Train acc: 0.8274147727272727\n",
      "Iteration 9000 - Batch 935/1613 - Train loss: 1.075853749918632, Train acc: 0.8279914529914529\n",
      "Iteration 9100 - Batch 1035/1613 - Train loss: 1.0757690330384782, Train acc: 0.8279440154440154\n",
      "Iteration 9200 - Batch 1135/1613 - Train loss: 1.0751088677157818, Train acc: 0.8287852112676056\n",
      "Iteration 9300 - Batch 1235/1613 - Train loss: 1.075428730606261, Train acc: 0.8285295307443366\n",
      "Iteration 9400 - Batch 1335/1613 - Train loss: 1.0751425337024079, Train acc: 0.8286395958083832\n",
      "Iteration 9500 - Batch 1435/1613 - Train loss: 1.0748277627824077, Train acc: 0.8289954735376045\n",
      "Iteration 9600 - Batch 1535/1613 - Train loss: 1.0745882370198767, Train acc: 0.8291829427083334\n",
      "[0, 4, 3, 3, 0, 0, 2, 2, 0, 2, 3, 3, 4, 0, 4, 3, 3, 3, 3, 1, 0, 1, 1, 2, 3, 0, 1, 0, 2, 3, 4, 1, 1, 4, 0, 0, 2, 0, 0, 0, 3, 1, 3, 1, 4, 4, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 2, 4, 2, 3, 0, 4, 1, 4, 2, 0, 0, 3, 3, 4, 1, 3, 0, 2, 0, 4, 1, 4, 0, 4, 0, 2, 3, 0, 3, 4, 0, 2, 1, 0, 0, 2, 0, 4, 4, 0, 3, 1, 0, 2, 1, 3, 0, 0, 3, 4, 2, 4, 2, 3, 1, 3, 0, 2, 0, 4, 4, 2, 0, 2, 4, 1, 0, 4, 1, 0, 0, 2, 3, 0, 2, 0, 1, 4, 1, 0, 1, 2, 4, 3, 3, 2, 3, 4, 2, 1, 1, 1, 4, 2, 4, 0, 1, 4, 0, 3, 4, 2, 0, 0, 4, 4, 1, 2, 0, 1, 2, 0, 4, 1, 0, 4, 4, 1, 3, 1, 3, 4, 4, 1, 2, 0, 0, 2, 3, 4, 3, 1, 4, 2, 4, 2, 0, 1, 4, 4, 4, 0, 0, 3, 4, 1, 4, 1, 4, 1, 4, 4, 3, 4, 0, 2, 2, 3, 4, 1, 3, 1, 3, 2, 0, 2, 1, 2, 4, 2, 0, 2, 1, 3, 2, 2, 3, 0, 1, 2, 2, 0, 3, 4, 0, 0, 0, 3, 2, 0, 0, 1, 3, 3, 0, 1, 3, 1, 0, 0, 0, 3, 0, 1, 0, 2, 3, 3, 1, 1, 4, 0, 2, 0, 0, 2, 1, 2, 2, 2, 2, 4, 0, 2, 1, 3, 1, 0, 4, 0, 3, 4, 2, 1, 2, 2, 2, 1, 1, 3, 1, 1, 3, 2, 0, 1, 4, 3, 0, 2, 3, 3, 3, 3, 2, 2, 2, 2, 3, 0, 1, 1, 1, 4, 2, 1, 4, 4, 2, 4, 2, 0, 1, 3, 0, 0, 3, 1, 2, 1, 3, 4, 1, 1, 2, 3, 2, 3, 1, 2, 0, 4, 4, 0, 1, 1, 3, 1, 2, 4, 3, 1, 2, 1, 1, 4, 0, 2, 1, 0, 2, 2, 3, 1, 3, 0, 1, 2, 4, 2, 2, 3, 3, 3, 1, 3, 2, 1, 1, 3, 4, 2, 4, 2, 4, 3, 4, 2, 3, 1, 1, 3, 0, 3, 4, 0, 3, 1, 4, 2, 0, 3, 1, 4, 1, 0, 3, 3, 4, 4, 3, 1, 4, 1, 1, 3, 0, 4, 3, 2, 2, 1, 4, 4, 3, 2, 2, 0, 2, 4, 0, 0, 4, 2, 2, 3, 1, 0, 4, 2, 4, 1, 2, 4, 1, 3, 3, 0, 0, 1, 0, 3, 4, 2, 1, 3, 1, 1, 1, 4, 1, 4, 3, 4, 0, 0, 2, 1, 2, 0, 4, 3, 0, 3, 2, 3, 1, 1, 3, 2, 0, 2, 2, 4, 2, 4, 4, 4, 1, 1, 4, 4, 3, 2]\n",
      "[0, 4, 3, 3, 0, 0, 2, 2, 0, 0, 3, 3, 4, 0, 4, 3, 3, 3, 3, 4, 2, 0, 3, 2, 3, 0, 0, 0, 2, 3, 4, 3, 4, 4, 0, 0, 2, 0, 0, 0, 3, 3, 4, 3, 4, 2, 3, 4, 3, 3, 4, 4, 3, 4, 4, 3, 2, 2, 2, 3, 0, 4, 2, 4, 2, 0, 0, 3, 3, 4, 0, 3, 0, 2, 0, 4, 3, 4, 0, 4, 0, 2, 3, 0, 3, 4, 0, 0, 4, 0, 0, 0, 0, 4, 4, 0, 3, 4, 0, 0, 4, 3, 0, 0, 3, 4, 2, 4, 2, 3, 4, 3, 0, 2, 2, 4, 4, 2, 0, 3, 4, 4, 0, 4, 4, 0, 4, 2, 3, 0, 2, 0, 0, 4, 4, 0, 2, 0, 4, 3, 3, 2, 3, 4, 2, 4, 0, 0, 4, 2, 4, 0, 4, 4, 0, 4, 4, 2, 0, 0, 4, 4, 4, 3, 0, 4, 0, 0, 0, 0, 0, 4, 4, 4, 3, 3, 3, 4, 4, 3, 2, 0, 4, 2, 3, 4, 3, 4, 4, 2, 4, 2, 0, 3, 4, 4, 4, 0, 0, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 0, 2, 2, 4, 4, 4, 3, 4, 3, 2, 0, 2, 4, 2, 2, 2, 4, 0, 4, 3, 0, 2, 3, 0, 3, 2, 0, 0, 4, 4, 0, 0, 4, 3, 2, 0, 0, 4, 3, 3, 0, 4, 3, 3, 0, 2, 0, 3, 0, 3, 0, 2, 3, 3, 4, 0, 4, 0, 0, 4, 0, 2, 4, 2, 2, 2, 2, 4, 4, 0, 0, 3, 3, 0, 4, 0, 3, 4, 2, 4, 2, 2, 0, 3, 0, 3, 4, 4, 3, 2, 0, 3, 4, 4, 4, 2, 3, 3, 3, 3, 3, 2, 0, 0, 3, 0, 3, 4, 3, 4, 2, 0, 0, 4, 2, 4, 2, 0, 4, 3, 0, 0, 3, 4, 2, 4, 4, 4, 2, 4, 2, 3, 2, 3, 4, 2, 0, 4, 4, 0, 4, 0, 3, 4, 0, 4, 3, 3, 2, 3, 4, 3, 0, 0, 3, 4, 2, 0, 3, 4, 3, 0, 4, 0, 4, 2, 2, 3, 3, 3, 2, 3, 2, 0, 0, 0, 4, 2, 4, 0, 4, 3, 4, 2, 3, 0, 4, 3, 0, 3, 4, 0, 3, 3, 3, 2, 0, 3, 4, 4, 3, 0, 3, 3, 4, 4, 3, 4, 4, 4, 4, 3, 2, 4, 3, 2, 0, 4, 4, 4, 3, 2, 2, 0, 0, 4, 0, 0, 4, 2, 0, 3, 0, 0, 4, 3, 4, 4, 0, 4, 0, 3, 3, 0, 4, 4, 0, 3, 4, 2, 4, 3, 4, 4, 4, 4, 3, 4, 3, 4, 0, 0, 0, 3, 2, 0, 4, 3, 0, 3, 2, 3, 3, 3, 3, 2, 0, 0, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 0, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.71      0.78       100\n",
      "           3       0.74      0.91      0.82       100\n",
      "           4       0.57      0.93      0.71       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.57      0.68      0.61       500\n",
      "weighted avg       0.57      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2172771096229553, Val acc: 0.684\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9700 - Batch 22/1613 - Train loss: 1.061913832374241, Train acc: 0.84375\n",
      "Iteration 9800 - Batch 122/1613 - Train loss: 1.0521925033592596, Train acc: 0.851880081300813\n",
      "Iteration 9900 - Batch 222/1613 - Train loss: 1.0608111614603632, Train acc: 0.8427690582959642\n",
      "Iteration 10000 - Batch 322/1613 - Train loss: 1.0606987175557636, Train acc: 0.8430727554179567\n",
      "Iteration 10100 - Batch 422/1613 - Train loss: 1.0616721881478672, Train acc: 0.8420508274231678\n",
      "Iteration 10200 - Batch 522/1613 - Train loss: 1.0628285566433895, Train acc: 0.8407624282982792\n",
      "Iteration 10300 - Batch 622/1613 - Train loss: 1.064809969493321, Train acc: 0.8390850722311396\n",
      "Iteration 10400 - Batch 722/1613 - Train loss: 1.0665087038715515, Train acc: 0.8375691562932227\n",
      "Iteration 10500 - Batch 822/1613 - Train loss: 1.0670975110655423, Train acc: 0.8369152490886999\n",
      "Iteration 10600 - Batch 922/1613 - Train loss: 1.0664442596172072, Train acc: 0.8375880281690141\n",
      "Iteration 10700 - Batch 1022/1613 - Train loss: 1.0673609417321512, Train acc: 0.8368462854349951\n",
      "Iteration 10800 - Batch 1122/1613 - Train loss: 1.0671253338628652, Train acc: 0.8369323241317899\n",
      "Iteration 10900 - Batch 1222/1613 - Train loss: 1.0675402519552804, Train acc: 0.8364932542927228\n",
      "Iteration 11000 - Batch 1322/1613 - Train loss: 1.0674527126645286, Train acc: 0.8365693499622071\n",
      "Iteration 11100 - Batch 1422/1613 - Train loss: 1.0671369793208987, Train acc: 0.8369421995783556\n",
      "Iteration 11200 - Batch 1522/1613 - Train loss: 1.0664235911162683, Train acc: 0.837717498358503\n",
      "[4, 1, 3, 1, 3, 3, 0, 2, 1, 3, 1, 1, 3, 2, 4, 3, 3, 1, 4, 1, 0, 2, 1, 2, 0, 2, 0, 3, 0, 0, 3, 3, 2, 1, 4, 2, 0, 2, 4, 0, 2, 2, 3, 2, 0, 4, 3, 2, 4, 4, 0, 0, 1, 3, 2, 4, 1, 3, 2, 3, 2, 2, 2, 4, 1, 2, 0, 4, 2, 3, 1, 1, 1, 3, 1, 3, 2, 4, 1, 2, 0, 3, 0, 1, 3, 0, 0, 3, 3, 4, 1, 4, 3, 0, 3, 2, 2, 4, 1, 4, 1, 4, 3, 1, 1, 1, 3, 1, 3, 1, 2, 4, 0, 1, 0, 1, 3, 1, 3, 2, 3, 4, 4, 2, 0, 2, 0, 4, 1, 0, 4, 4, 0, 3, 2, 2, 4, 3, 1, 4, 1, 1, 4, 3, 3, 4, 3, 1, 0, 2, 2, 3, 2, 2, 1, 4, 3, 0, 4, 1, 2, 1, 4, 2, 0, 3, 3, 1, 0, 2, 4, 0, 4, 3, 1, 1, 0, 2, 1, 0, 4, 0, 1, 2, 3, 0, 1, 2, 0, 2, 2, 3, 3, 1, 1, 1, 3, 4, 1, 3, 1, 1, 3, 4, 4, 4, 0, 1, 2, 0, 2, 3, 4, 1, 4, 3, 3, 0, 0, 4, 1, 0, 4, 2, 2, 2, 0, 4, 1, 1, 2, 4, 2, 2, 3, 0, 4, 1, 1, 1, 3, 4, 3, 3, 3, 4, 0, 1, 3, 2, 1, 0, 3, 4, 2, 1, 4, 3, 0, 3, 1, 4, 1, 1, 4, 4, 1, 1, 1, 4, 0, 4, 3, 4, 2, 3, 0, 4, 1, 2, 0, 1, 4, 0, 2, 0, 2, 0, 0, 1, 2, 0, 4, 2, 0, 1, 4, 1, 0, 0, 0, 0, 0, 2, 2, 4, 0, 2, 1, 0, 1, 2, 0, 4, 3, 0, 0, 2, 4, 1, 4, 4, 3, 1, 3, 4, 2, 3, 2, 4, 0, 3, 2, 0, 3, 1, 0, 1, 4, 0, 2, 2, 0, 3, 0, 0, 1, 2, 4, 2, 1, 3, 1, 0, 4, 0, 4, 1, 4, 4, 4, 3, 1, 0, 4, 0, 2, 4, 1, 3, 2, 3, 3, 2, 0, 2, 2, 4, 0, 0, 3, 0, 2, 2, 2, 4, 1, 3, 0, 0, 0, 1, 3, 0, 3, 3, 2, 1, 4, 1, 3, 0, 1, 4, 2, 2, 3, 3, 4, 0, 4, 0, 4, 3, 4, 3, 1, 0, 2, 1, 3, 0, 2, 0, 0, 4, 4, 0, 4, 4, 4, 4, 0, 3, 0, 3, 2, 2, 4, 0, 3, 3, 4, 3, 0, 3, 3, 4, 2, 3, 1, 2, 3, 1, 0, 0, 1, 0, 2, 3, 1, 1, 2, 3, 4, 4, 4, 2, 3, 3, 0, 4, 2, 2, 0, 2, 2, 3, 1, 1, 3, 2, 1, 0, 4, 4, 2, 1, 4, 2, 2, 0, 4, 3, 2, 1, 2, 2, 4, 3]\n",
      "[4, 4, 3, 3, 3, 3, 0, 2, 3, 3, 0, 3, 3, 0, 3, 4, 3, 3, 4, 4, 0, 2, 4, 2, 0, 2, 0, 3, 0, 0, 3, 3, 2, 3, 2, 2, 0, 2, 4, 0, 0, 2, 3, 2, 0, 4, 3, 2, 3, 3, 0, 0, 4, 3, 2, 4, 4, 3, 2, 3, 0, 2, 0, 4, 4, 2, 0, 4, 0, 0, 3, 3, 4, 3, 3, 3, 2, 4, 0, 2, 0, 3, 0, 4, 3, 0, 2, 3, 3, 4, 3, 4, 3, 0, 3, 2, 2, 4, 0, 2, 4, 4, 3, 2, 3, 2, 3, 4, 3, 4, 2, 4, 0, 4, 0, 0, 3, 4, 3, 2, 3, 4, 4, 0, 0, 2, 0, 4, 0, 0, 4, 4, 0, 3, 2, 2, 4, 3, 3, 4, 3, 4, 4, 3, 4, 4, 3, 0, 0, 2, 2, 3, 2, 2, 4, 4, 3, 0, 4, 4, 2, 3, 4, 2, 0, 3, 3, 2, 0, 2, 4, 0, 4, 3, 4, 0, 0, 2, 3, 3, 4, 0, 3, 2, 4, 0, 3, 2, 0, 2, 3, 3, 3, 0, 2, 4, 3, 4, 4, 3, 3, 0, 3, 4, 4, 3, 0, 0, 2, 3, 0, 4, 4, 4, 4, 3, 3, 0, 4, 4, 3, 0, 4, 0, 2, 2, 0, 4, 3, 4, 0, 4, 2, 2, 3, 0, 4, 2, 0, 4, 3, 4, 3, 3, 3, 4, 0, 0, 3, 2, 0, 0, 3, 4, 2, 0, 4, 3, 4, 3, 3, 4, 0, 4, 4, 4, 0, 4, 4, 4, 0, 4, 3, 4, 2, 3, 0, 4, 4, 2, 0, 0, 4, 0, 2, 0, 2, 0, 0, 4, 0, 0, 4, 2, 0, 4, 4, 3, 0, 0, 0, 0, 0, 2, 2, 4, 0, 0, 0, 0, 0, 3, 0, 4, 3, 0, 0, 0, 4, 4, 4, 4, 3, 0, 3, 0, 2, 3, 2, 4, 0, 3, 2, 0, 3, 4, 0, 4, 4, 0, 2, 0, 2, 3, 0, 0, 3, 2, 4, 2, 0, 3, 4, 0, 4, 0, 4, 0, 4, 2, 4, 3, 3, 4, 4, 0, 3, 4, 3, 3, 2, 3, 3, 2, 0, 0, 2, 4, 0, 0, 3, 0, 2, 2, 2, 4, 3, 4, 0, 0, 0, 4, 3, 0, 3, 3, 2, 3, 4, 4, 3, 0, 4, 4, 2, 2, 3, 3, 4, 0, 4, 0, 4, 3, 4, 3, 3, 0, 2, 3, 3, 0, 0, 0, 0, 4, 4, 0, 4, 4, 4, 4, 0, 3, 0, 3, 2, 2, 4, 0, 3, 3, 4, 3, 0, 3, 3, 4, 2, 3, 3, 0, 3, 3, 0, 0, 4, 4, 2, 3, 3, 4, 2, 3, 4, 4, 3, 2, 3, 3, 0, 4, 2, 0, 0, 2, 2, 3, 4, 3, 3, 2, 3, 0, 4, 4, 2, 3, 4, 2, 2, 0, 4, 3, 2, 3, 2, 0, 2, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.79      0.83       100\n",
      "           3       0.68      0.94      0.79       100\n",
      "           4       0.66      0.90      0.76       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1946076303720474, Val acc: 0.71\n",
      "Epoch 8/30\n",
      "Iteration 11300 - Batch 9/1613 - Train loss: 1.0650193095207214, Train acc: 0.840625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11400 - Batch 109/1613 - Train loss: 1.0572237394072792, Train acc: 0.8460227272727273\n",
      "Iteration 11500 - Batch 209/1613 - Train loss: 1.0625809371471404, Train acc: 0.8404761904761905\n",
      "Iteration 11600 - Batch 309/1613 - Train loss: 1.064456562265273, Train acc: 0.8382056451612904\n",
      "Iteration 11700 - Batch 409/1613 - Train loss: 1.0639947660085631, Train acc: 0.8391006097560976\n",
      "Iteration 11800 - Batch 509/1613 - Train loss: 1.064471343685599, Train acc: 0.8388480392156863\n",
      "Iteration 11900 - Batch 609/1613 - Train loss: 1.0643951461940515, Train acc: 0.8390881147540984\n",
      "Iteration 12000 - Batch 709/1613 - Train loss: 1.063520328679555, Train acc: 0.8398327464788733\n",
      "Iteration 12100 - Batch 809/1613 - Train loss: 1.062883049323235, Train acc: 0.8404706790123457\n",
      "Iteration 12200 - Batch 909/1613 - Train loss: 1.0630155705488644, Train acc: 0.8404532967032967\n",
      "Iteration 12300 - Batch 1009/1613 - Train loss: 1.063147761798141, Train acc: 0.8404393564356436\n",
      "Iteration 12400 - Batch 1109/1613 - Train loss: 1.0623856166461567, Train acc: 0.841188063063063\n",
      "Iteration 12500 - Batch 1209/1613 - Train loss: 1.0618315744991145, Train acc: 0.8418388429752066\n",
      "Iteration 12600 - Batch 1309/1613 - Train loss: 1.0621761993597483, Train acc: 0.84143606870229\n",
      "Iteration 12700 - Batch 1409/1613 - Train loss: 1.0629799771816173, Train acc: 0.8408244680851064\n",
      "Iteration 12800 - Batch 1509/1613 - Train loss: 1.062911713794367, Train acc: 0.8409147350993378\n",
      "Iteration 12900 - Batch 1609/1613 - Train loss: 1.0631608516903397, Train acc: 0.8407026397515528\n",
      "[2, 0, 2, 0, 2, 3, 4, 3, 2, 2, 2, 2, 0, 0, 0, 1, 2, 0, 3, 2, 1, 4, 1, 4, 0, 0, 3, 3, 2, 2, 3, 3, 0, 0, 4, 4, 1, 3, 0, 1, 2, 3, 2, 2, 0, 3, 4, 4, 1, 2, 4, 3, 1, 1, 4, 0, 0, 1, 0, 3, 1, 2, 4, 2, 2, 3, 1, 0, 4, 3, 1, 1, 1, 2, 3, 3, 3, 0, 2, 3, 3, 2, 1, 1, 1, 3, 2, 3, 3, 3, 2, 1, 0, 4, 0, 3, 1, 1, 2, 1, 1, 0, 1, 0, 4, 1, 1, 0, 1, 1, 1, 0, 0, 2, 3, 4, 1, 3, 1, 0, 4, 1, 0, 2, 0, 0, 4, 0, 2, 2, 4, 1, 0, 2, 1, 0, 4, 3, 3, 1, 3, 3, 1, 3, 1, 0, 2, 0, 3, 2, 2, 0, 4, 0, 4, 4, 2, 2, 0, 4, 2, 0, 0, 2, 1, 1, 2, 3, 1, 4, 0, 3, 2, 0, 2, 2, 4, 3, 2, 4, 2, 1, 0, 4, 2, 4, 0, 0, 3, 2, 4, 1, 1, 2, 3, 4, 3, 1, 4, 0, 0, 4, 4, 1, 2, 2, 2, 4, 2, 0, 2, 0, 1, 0, 3, 3, 2, 3, 3, 2, 2, 1, 4, 2, 0, 4, 4, 1, 4, 0, 3, 1, 0, 4, 4, 1, 2, 3, 3, 3, 0, 3, 2, 2, 1, 2, 1, 0, 1, 3, 1, 0, 1, 2, 0, 4, 4, 2, 0, 0, 4, 1, 4, 1, 0, 2, 3, 1, 3, 1, 0, 4, 0, 3, 1, 3, 4, 0, 3, 1, 3, 0, 2, 1, 2, 0, 1, 0, 1, 3, 4, 2, 0, 4, 3, 4, 1, 3, 4, 4, 4, 4, 1, 1, 3, 4, 3, 1, 1, 3, 0, 1, 1, 0, 4, 4, 2, 1, 4, 4, 1, 4, 3, 0, 3, 3, 4, 2, 2, 3, 1, 2, 0, 4, 0, 2, 3, 2, 0, 3, 1, 1, 4, 2, 3, 1, 0, 0, 1, 2, 2, 2, 4, 3, 0, 0, 4, 1, 2, 0, 4, 2, 4, 2, 2, 2, 0, 3, 4, 4, 2, 3, 1, 1, 3, 1, 2, 2, 3, 0, 0, 4, 4, 0, 0, 0, 0, 1, 4, 2, 4, 3, 4, 0, 1, 1, 4, 4, 3, 2, 4, 0, 4, 4, 4, 2, 0, 3, 3, 1, 2, 3, 4, 0, 4, 2, 2, 4, 4, 1, 3, 0, 2, 3, 0, 3, 4, 1, 3, 3, 4, 0, 4, 3, 3, 1, 0, 3, 0, 4, 2, 3, 3, 1, 3, 2, 1, 4, 4, 4, 2, 1, 2, 4, 3, 4, 0, 4, 3, 4, 0, 2, 0, 4, 2, 1, 3, 2, 4, 1, 3, 0, 3, 1, 4, 3, 3, 4, 1, 4, 3, 2, 2, 3, 3, 2, 0, 0, 4, 1, 4, 2, 1, 0, 1, 1, 0, 3, 1, 3]\n",
      "[2, 0, 0, 0, 0, 3, 4, 3, 2, 2, 2, 2, 2, 0, 0, 4, 2, 0, 3, 0, 3, 4, 3, 4, 0, 0, 3, 3, 2, 0, 3, 2, 0, 0, 3, 4, 4, 3, 0, 0, 2, 3, 2, 2, 0, 3, 4, 4, 3, 2, 4, 3, 4, 3, 4, 0, 0, 4, 0, 3, 4, 2, 4, 2, 0, 3, 3, 2, 4, 3, 4, 0, 0, 2, 4, 3, 3, 0, 2, 4, 3, 2, 4, 3, 4, 3, 0, 3, 3, 3, 2, 4, 0, 4, 0, 3, 0, 3, 2, 3, 4, 0, 3, 0, 4, 4, 3, 0, 0, 4, 4, 0, 0, 2, 3, 4, 4, 3, 2, 0, 4, 3, 0, 0, 0, 0, 4, 0, 0, 2, 4, 3, 0, 0, 4, 0, 4, 3, 3, 4, 3, 3, 3, 3, 0, 0, 2, 0, 3, 2, 2, 0, 4, 2, 3, 4, 2, 2, 0, 4, 2, 0, 0, 2, 4, 0, 2, 3, 0, 4, 2, 3, 2, 2, 2, 2, 4, 3, 2, 4, 2, 4, 0, 4, 2, 4, 0, 0, 3, 3, 4, 0, 3, 3, 3, 4, 3, 3, 4, 0, 0, 4, 4, 0, 2, 2, 2, 4, 2, 0, 2, 0, 3, 0, 3, 3, 3, 3, 3, 2, 2, 3, 4, 2, 0, 2, 4, 4, 4, 4, 3, 4, 0, 0, 4, 3, 2, 3, 3, 3, 0, 3, 2, 2, 3, 2, 0, 2, 3, 3, 4, 0, 0, 2, 0, 4, 4, 2, 0, 0, 4, 4, 4, 3, 4, 2, 3, 2, 3, 4, 0, 4, 0, 3, 0, 3, 4, 0, 3, 2, 4, 0, 2, 3, 2, 0, 0, 2, 2, 4, 4, 2, 0, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 0, 3, 0, 3, 4, 4, 4, 4, 0, 4, 4, 4, 3, 4, 3, 0, 3, 3, 4, 2, 2, 3, 0, 2, 0, 4, 0, 2, 3, 2, 0, 3, 4, 4, 4, 2, 3, 3, 0, 2, 4, 2, 2, 2, 2, 3, 0, 0, 4, 3, 2, 0, 4, 2, 4, 2, 2, 2, 0, 3, 4, 4, 2, 3, 4, 3, 3, 4, 2, 2, 3, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 2, 4, 3, 4, 0, 4, 0, 4, 4, 0, 0, 4, 0, 4, 4, 4, 2, 0, 3, 3, 4, 0, 3, 4, 0, 4, 2, 0, 4, 4, 0, 3, 0, 2, 3, 2, 3, 4, 0, 3, 3, 4, 0, 4, 3, 3, 3, 0, 3, 0, 4, 2, 3, 3, 0, 3, 0, 4, 4, 3, 4, 2, 4, 0, 4, 3, 4, 0, 3, 3, 3, 0, 2, 0, 4, 0, 2, 3, 2, 4, 3, 3, 2, 3, 4, 3, 3, 3, 4, 3, 4, 3, 2, 2, 3, 3, 0, 2, 0, 4, 3, 4, 2, 4, 0, 4, 4, 0, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.81      0.80      0.80       100\n",
      "           3       0.69      0.94      0.79       100\n",
      "           4       0.65      0.91      0.76       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.56      0.70      0.62       500\n",
      "weighted avg       0.56      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2033558636903763, Val acc: 0.698\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13000 - Batch 96/1613 - Train loss: 1.0591817787013103, Train acc: 0.8456829896907216\n",
      "Iteration 13100 - Batch 196/1613 - Train loss: 1.0611839878377576, Train acc: 0.8418464467005076\n",
      "Iteration 13200 - Batch 296/1613 - Train loss: 1.0639149731257147, Train acc: 0.8385942760942761\n",
      "Iteration 13300 - Batch 396/1613 - Train loss: 1.0637184795864885, Train acc: 0.8391057934508817\n",
      "Iteration 13400 - Batch 496/1613 - Train loss: 1.0629267560644169, Train acc: 0.8402288732394366\n",
      "Iteration 13500 - Batch 596/1613 - Train loss: 1.064056497722415, Train acc: 0.8391436348408711\n",
      "Iteration 13600 - Batch 696/1613 - Train loss: 1.0656040836783016, Train acc: 0.8376972740315638\n",
      "Iteration 13700 - Batch 796/1613 - Train loss: 1.0648732136004841, Train acc: 0.8386527603513174\n",
      "Iteration 13800 - Batch 896/1613 - Train loss: 1.0629243685250298, Train acc: 0.8405797101449275\n",
      "Iteration 13900 - Batch 996/1613 - Train loss: 1.063463176683772, Train acc: 0.840176780341023\n",
      "Iteration 14000 - Batch 1096/1613 - Train loss: 1.0623143235443935, Train acc: 0.8413286235186873\n",
      "Iteration 14100 - Batch 1196/1613 - Train loss: 1.0608050095208406, Train acc: 0.8429667919799498\n",
      "Iteration 14200 - Batch 1296/1613 - Train loss: 1.060817021908168, Train acc: 0.8428585196607556\n",
      "Iteration 14300 - Batch 1396/1613 - Train loss: 1.0604838757064399, Train acc: 0.8431460272011453\n",
      "Iteration 14400 - Batch 1496/1613 - Train loss: 1.0612772913399584, Train acc: 0.8423096192384769\n",
      "Iteration 14500 - Batch 1596/1613 - Train loss: 1.0609468986410309, Train acc: 0.8427128991859737\n",
      "[4, 3, 4, 4, 1, 0, 0, 3, 1, 1, 3, 4, 4, 1, 2, 4, 4, 2, 3, 2, 2, 0, 2, 2, 0, 0, 4, 0, 1, 4, 2, 4, 0, 0, 4, 4, 1, 2, 1, 3, 2, 2, 1, 2, 1, 4, 4, 0, 2, 3, 4, 4, 1, 1, 3, 2, 2, 0, 1, 4, 0, 0, 2, 0, 3, 2, 3, 4, 4, 1, 1, 4, 2, 4, 2, 3, 1, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 3, 0, 1, 2, 0, 2, 3, 0, 3, 4, 0, 2, 4, 0, 0, 0, 2, 4, 0, 1, 4, 1, 0, 1, 3, 3, 2, 4, 3, 3, 4, 1, 0, 1, 0, 4, 2, 4, 0, 2, 1, 0, 3, 3, 1, 1, 0, 1, 0, 0, 1, 2, 1, 2, 4, 4, 0, 3, 1, 2, 1, 4, 4, 0, 4, 4, 0, 2, 1, 1, 3, 0, 3, 3, 3, 2, 3, 2, 3, 3, 2, 0, 4, 4, 2, 1, 4, 2, 3, 3, 4, 2, 0, 2, 3, 1, 3, 0, 3, 4, 0, 2, 1, 4, 0, 0, 2, 0, 2, 0, 0, 4, 0, 4, 1, 1, 1, 0, 4, 0, 1, 3, 1, 4, 4, 2, 0, 4, 3, 3, 1, 3, 0, 2, 1, 4, 4, 4, 0, 0, 2, 4, 3, 0, 4, 1, 0, 4, 3, 3, 3, 3, 0, 2, 4, 0, 0, 2, 0, 1, 4, 1, 2, 0, 1, 1, 4, 3, 3, 0, 0, 1, 4, 0, 3, 2, 2, 1, 1, 4, 2, 4, 3, 4, 1, 4, 1, 0, 0, 3, 1, 3, 3, 3, 0, 3, 3, 1, 3, 1, 1, 3, 3, 4, 3, 2, 4, 2, 1, 2, 1, 3, 0, 0, 3, 1, 2, 1, 1, 3, 0, 1, 2, 3, 2, 3, 0, 3, 2, 2, 1, 2, 3, 2, 3, 4, 1, 1, 2, 1, 4, 4, 4, 2, 0, 4, 4, 4, 2, 2, 2, 1, 3, 4, 1, 4, 3, 0, 2, 1, 0, 4, 4, 4, 2, 4, 1, 4, 1, 4, 2, 3, 1, 2, 3, 0, 2, 0, 1, 2, 2, 1, 0, 1, 1, 2, 1, 3, 3, 3, 4, 2, 2, 2, 4, 4, 1, 1, 1, 3, 2, 0, 3, 2, 3, 0, 2, 0, 4, 0, 1, 4, 4, 0, 3, 4, 2, 3, 4, 0, 0, 2, 2, 0, 3, 4, 3, 1, 4, 4, 0, 2, 0, 0, 0, 0, 0, 3, 0, 1, 3, 2, 3, 3, 1, 0, 3, 1, 3, 3, 1, 3, 4, 2, 2, 1, 2, 2, 1, 1, 3, 3, 3, 2, 4, 2, 1, 3, 0, 2, 2, 4, 1, 4, 0, 3, 1, 3, 2, 4, 3, 0, 3, 4, 0, 0, 3, 0, 1, 2, 1, 3, 0, 0, 4, 0, 0, 2, 2, 2, 3, 1, 1, 2, 4, 2, 0, 3, 2, 4, 3, 0, 1]\n",
      "[4, 3, 4, 4, 0, 0, 0, 3, 0, 4, 3, 4, 2, 4, 2, 4, 4, 0, 3, 2, 2, 0, 0, 2, 0, 0, 4, 0, 4, 4, 0, 4, 0, 0, 4, 4, 0, 2, 0, 3, 2, 2, 4, 0, 0, 4, 3, 0, 0, 3, 4, 3, 4, 3, 3, 2, 2, 0, 4, 4, 0, 0, 2, 0, 3, 2, 3, 4, 4, 0, 3, 4, 2, 0, 2, 4, 4, 4, 0, 3, 2, 3, 4, 2, 2, 3, 4, 4, 0, 4, 2, 0, 2, 3, 0, 3, 4, 0, 2, 4, 0, 0, 0, 2, 4, 0, 0, 4, 4, 0, 0, 3, 3, 2, 3, 3, 3, 4, 4, 0, 0, 0, 4, 2, 4, 0, 2, 0, 0, 3, 3, 0, 0, 0, 2, 0, 0, 3, 2, 3, 2, 4, 4, 0, 3, 4, 2, 0, 4, 4, 0, 4, 4, 0, 0, 3, 3, 3, 0, 4, 3, 3, 2, 3, 2, 3, 3, 2, 0, 4, 4, 0, 3, 4, 2, 3, 3, 4, 2, 0, 2, 3, 0, 3, 0, 3, 3, 0, 0, 0, 4, 0, 0, 2, 0, 3, 0, 0, 0, 0, 4, 3, 3, 3, 0, 4, 0, 4, 3, 4, 4, 4, 2, 0, 4, 3, 4, 4, 3, 0, 2, 3, 4, 4, 4, 0, 0, 2, 4, 4, 0, 4, 0, 0, 2, 3, 4, 3, 3, 0, 2, 4, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 3, 4, 3, 3, 0, 0, 4, 4, 0, 3, 2, 2, 0, 0, 4, 2, 2, 3, 4, 3, 4, 4, 4, 0, 3, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 4, 3, 3, 4, 3, 0, 0, 2, 4, 0, 0, 3, 0, 0, 2, 0, 2, 3, 4, 3, 0, 0, 0, 3, 0, 3, 0, 3, 2, 2, 0, 2, 4, 2, 3, 4, 3, 4, 0, 0, 4, 4, 4, 0, 0, 4, 4, 4, 2, 2, 2, 0, 3, 4, 4, 4, 3, 0, 2, 4, 3, 4, 4, 4, 0, 4, 4, 4, 4, 4, 2, 3, 3, 2, 3, 0, 0, 0, 4, 2, 2, 0, 0, 0, 4, 2, 4, 3, 3, 3, 4, 2, 2, 2, 4, 3, 3, 4, 3, 3, 0, 0, 3, 2, 3, 0, 2, 0, 4, 0, 0, 4, 4, 0, 3, 4, 2, 3, 4, 0, 0, 2, 2, 0, 3, 4, 3, 3, 4, 4, 0, 2, 0, 0, 2, 0, 0, 3, 0, 3, 3, 2, 3, 3, 2, 0, 3, 4, 3, 3, 0, 0, 4, 0, 2, 4, 0, 2, 0, 4, 3, 3, 3, 2, 4, 2, 3, 3, 0, 2, 2, 4, 3, 4, 0, 3, 2, 3, 0, 4, 3, 0, 3, 3, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 4, 0, 0, 2, 2, 2, 3, 0, 0, 2, 4, 2, 0, 3, 2, 3, 4, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.96      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.76      0.81       100\n",
      "           3       0.72      0.90      0.80       100\n",
      "           4       0.66      0.87      0.75       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2039993926882744, Val acc: 0.698\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14600 - Batch 83/1613 - Train loss: 1.0617582812195732, Train acc: 0.8411458333333334\n",
      "Iteration 14700 - Batch 183/1613 - Train loss: 1.0632961907464524, Train acc: 0.8396739130434783\n",
      "Iteration 14800 - Batch 283/1613 - Train loss: 1.0617380719369567, Train acc: 0.8416593309859155\n",
      "Iteration 14900 - Batch 383/1613 - Train loss: 1.0580108887515962, Train acc: 0.845458984375\n",
      "Iteration 15000 - Batch 483/1613 - Train loss: 1.0577475376858199, Train acc: 0.8457515495867769\n",
      "Iteration 15100 - Batch 583/1613 - Train loss: 1.0569061855339024, Train acc: 0.8468000856164384\n",
      "Iteration 15200 - Batch 683/1613 - Train loss: 1.0569983199674484, Train acc: 0.84671966374269\n",
      "Iteration 15300 - Batch 783/1613 - Train loss: 1.057038457037843, Train acc: 0.8467793367346939\n",
      "Iteration 15400 - Batch 883/1613 - Train loss: 1.0575340879718642, Train acc: 0.8463305995475113\n",
      "Iteration 15500 - Batch 983/1613 - Train loss: 1.0573391861062709, Train acc: 0.8465129573170732\n",
      "Iteration 15600 - Batch 1083/1613 - Train loss: 1.0562240167407533, Train acc: 0.8477859778597786\n",
      "Iteration 15700 - Batch 1183/1613 - Train loss: 1.0565003211534507, Train acc: 0.8474978885135135\n",
      "Iteration 15800 - Batch 1283/1613 - Train loss: 1.0576354397513041, Train acc: 0.8462811526479751\n",
      "Iteration 15900 - Batch 1383/1613 - Train loss: 1.0583549360233235, Train acc: 0.8456240968208093\n",
      "Iteration 16000 - Batch 1483/1613 - Train loss: 1.057843333547006, Train acc: 0.8461716644204852\n",
      "Iteration 16100 - Batch 1583/1613 - Train loss: 1.0577924297840307, Train acc: 0.8461766098484849\n",
      "[3, 0, 2, 1, 1, 2, 2, 2, 4, 1, 4, 0, 3, 0, 4, 3, 3, 0, 2, 4, 2, 1, 2, 1, 3, 1, 4, 1, 2, 4, 3, 3, 1, 0, 2, 4, 4, 4, 3, 4, 2, 3, 2, 1, 4, 0, 3, 4, 4, 3, 4, 4, 2, 2, 0, 4, 0, 3, 4, 4, 2, 0, 0, 1, 2, 3, 0, 1, 0, 0, 1, 1, 1, 4, 3, 0, 0, 4, 3, 0, 1, 3, 0, 2, 1, 1, 0, 4, 4, 2, 3, 1, 2, 3, 4, 2, 3, 0, 1, 4, 3, 2, 0, 2, 3, 3, 4, 2, 0, 1, 2, 2, 4, 0, 4, 0, 2, 0, 2, 0, 0, 4, 1, 0, 3, 3, 0, 4, 4, 3, 3, 0, 0, 0, 0, 1, 1, 0, 1, 4, 1, 1, 4, 3, 4, 2, 2, 0, 3, 4, 1, 2, 2, 3, 0, 0, 4, 2, 0, 3, 3, 2, 1, 3, 4, 1, 0, 3, 4, 3, 2, 0, 1, 3, 1, 2, 4, 4, 0, 1, 1, 2, 2, 1, 4, 1, 4, 2, 3, 3, 2, 0, 4, 4, 1, 4, 2, 3, 2, 4, 3, 2, 2, 2, 3, 3, 1, 2, 1, 3, 0, 1, 0, 2, 4, 0, 1, 1, 2, 1, 0, 3, 3, 0, 4, 1, 2, 0, 4, 2, 4, 3, 3, 2, 2, 3, 3, 2, 0, 3, 1, 2, 1, 3, 0, 0, 0, 3, 1, 3, 1, 3, 4, 0, 1, 1, 1, 3, 4, 2, 2, 2, 0, 1, 1, 4, 4, 2, 3, 3, 1, 4, 1, 4, 4, 3, 2, 0, 0, 4, 0, 2, 0, 1, 0, 0, 4, 2, 0, 3, 2, 3, 1, 3, 4, 3, 1, 2, 1, 3, 1, 0, 0, 4, 3, 2, 4, 0, 4, 2, 4, 3, 0, 0, 1, 1, 3, 1, 4, 4, 1, 2, 4, 2, 4, 3, 3, 4, 0, 1, 3, 0, 4, 0, 4, 2, 3, 1, 1, 1, 4, 4, 3, 2, 2, 1, 0, 1, 3, 2, 0, 1, 2, 1, 0, 0, 0, 2, 2, 0, 4, 3, 3, 4, 0, 4, 1, 3, 2, 2, 2, 4, 2, 3, 1, 2, 0, 2, 1, 2, 1, 0, 0, 4, 4, 2, 2, 3, 4, 2, 1, 3, 2, 1, 3, 4, 1, 2, 0, 2, 3, 2, 2, 4, 3, 1, 0, 0, 4, 1, 1, 3, 4, 1, 3, 1, 1, 0, 3, 1, 1, 2, 1, 3, 3, 4, 1, 3, 1, 4, 1, 1, 2, 1, 0, 2, 2, 0, 3, 2, 4, 3, 3, 3, 0, 3, 0, 3, 2, 0, 0, 3, 3, 1, 4, 3, 1, 2, 1, 3, 4, 4, 3, 0, 4, 0, 2, 0, 4, 1, 4, 1, 0, 3, 1, 0, 0, 4, 4, 2, 4, 1, 4, 2, 4, 0, 2, 1, 0, 0, 4, 4, 2, 3, 2, 4, 3, 0, 0, 0]\n",
      "[0, 0, 2, 2, 0, 2, 2, 2, 4, 4, 4, 0, 3, 0, 4, 3, 3, 0, 2, 4, 2, 4, 0, 3, 3, 3, 4, 4, 2, 4, 3, 3, 4, 0, 2, 4, 4, 4, 3, 4, 2, 3, 2, 3, 2, 4, 3, 4, 4, 3, 4, 4, 0, 2, 0, 4, 0, 3, 4, 4, 2, 0, 0, 4, 2, 3, 0, 4, 0, 0, 0, 0, 4, 4, 3, 0, 0, 4, 3, 0, 0, 3, 0, 2, 3, 0, 2, 4, 3, 2, 3, 3, 2, 3, 4, 2, 3, 0, 4, 4, 3, 2, 0, 2, 3, 3, 4, 0, 4, 4, 2, 2, 4, 0, 4, 0, 2, 2, 0, 0, 0, 4, 0, 0, 3, 3, 0, 3, 4, 3, 3, 0, 0, 0, 0, 4, 3, 0, 3, 4, 0, 3, 0, 3, 4, 0, 2, 2, 3, 4, 0, 2, 2, 3, 0, 0, 4, 2, 0, 3, 3, 2, 3, 3, 4, 2, 0, 3, 2, 3, 2, 2, 0, 3, 3, 2, 4, 4, 0, 4, 3, 2, 2, 0, 4, 0, 4, 0, 3, 3, 2, 2, 4, 4, 3, 4, 0, 3, 2, 4, 3, 2, 2, 2, 3, 3, 0, 2, 4, 3, 2, 4, 0, 2, 4, 0, 2, 2, 0, 3, 0, 3, 3, 0, 2, 4, 2, 0, 4, 2, 4, 3, 3, 2, 2, 3, 3, 2, 0, 3, 0, 2, 0, 3, 0, 0, 0, 3, 2, 3, 4, 3, 4, 0, 0, 0, 4, 3, 4, 2, 2, 2, 0, 4, 2, 4, 4, 2, 3, 3, 4, 3, 0, 4, 4, 3, 2, 0, 0, 4, 0, 2, 0, 3, 0, 0, 4, 2, 0, 4, 2, 3, 3, 3, 4, 4, 3, 2, 0, 3, 4, 0, 0, 4, 3, 2, 4, 0, 4, 2, 4, 3, 0, 0, 4, 3, 3, 0, 4, 4, 3, 2, 4, 2, 4, 3, 3, 0, 0, 3, 3, 0, 4, 0, 4, 2, 3, 4, 3, 3, 4, 4, 3, 0, 2, 4, 0, 0, 3, 4, 0, 3, 2, 4, 2, 0, 0, 2, 2, 0, 2, 4, 3, 4, 0, 4, 2, 3, 2, 3, 0, 0, 2, 3, 0, 0, 0, 2, 2, 0, 3, 0, 0, 4, 4, 2, 2, 4, 4, 2, 4, 3, 2, 0, 3, 2, 4, 2, 0, 3, 3, 2, 2, 4, 3, 0, 2, 0, 4, 4, 4, 3, 4, 4, 3, 0, 4, 0, 4, 4, 4, 2, 0, 3, 3, 4, 0, 3, 4, 4, 3, 3, 2, 0, 0, 2, 2, 0, 3, 2, 0, 2, 3, 3, 0, 3, 0, 3, 2, 0, 0, 3, 3, 2, 4, 3, 4, 2, 4, 3, 4, 4, 3, 0, 4, 2, 2, 0, 4, 4, 4, 4, 2, 3, 0, 2, 0, 4, 4, 2, 0, 4, 4, 2, 4, 0, 2, 0, 0, 0, 4, 4, 2, 3, 2, 4, 3, 0, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.74       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.77      0.85      0.81       100\n",
      "           3       0.76      0.93      0.83       100\n",
      "           4       0.66      0.87      0.75       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1974612846970558, Val acc: 0.704\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16200 - Batch 70/1613 - Train loss: 1.0437206105447152, Train acc: 0.8600352112676056\n",
      "Iteration 16300 - Batch 170/1613 - Train loss: 1.046854988176223, Train acc: 0.8569078947368421\n",
      "Iteration 16400 - Batch 270/1613 - Train loss: 1.0513958266740355, Train acc: 0.8527444649446494\n",
      "Iteration 16500 - Batch 370/1613 - Train loss: 1.0525692947148635, Train acc: 0.8518362533692723\n",
      "Iteration 16600 - Batch 470/1613 - Train loss: 1.0517468153797644, Train acc: 0.8527070063694268\n",
      "Iteration 16700 - Batch 570/1613 - Train loss: 1.0520148946399654, Train acc: 0.8522329246935202\n",
      "Iteration 16800 - Batch 670/1613 - Train loss: 1.0520000452433897, Train acc: 0.8522727272727273\n",
      "Iteration 16900 - Batch 770/1613 - Train loss: 1.0522695564883537, Train acc: 0.8519374189364461\n",
      "Iteration 17000 - Batch 870/1613 - Train loss: 1.0523722995025555, Train acc: 0.8516073478760046\n",
      "Iteration 17100 - Batch 970/1613 - Train loss: 1.0517621013948772, Train acc: 0.8524073120494335\n",
      "Iteration 17200 - Batch 1070/1613 - Train loss: 1.0524588200001934, Train acc: 0.8517156862745098\n",
      "Iteration 17300 - Batch 1170/1613 - Train loss: 1.0528183530580275, Train acc: 0.8512489325362937\n",
      "Iteration 17400 - Batch 1270/1613 - Train loss: 1.0531088268541144, Train acc: 0.8509293863099922\n",
      "Iteration 17500 - Batch 1370/1613 - Train loss: 1.0535346466985434, Train acc: 0.8504741064916119\n",
      "Iteration 17600 - Batch 1470/1613 - Train loss: 1.053668289140809, Train acc: 0.8504418762746431\n",
      "Iteration 17700 - Batch 1570/1613 - Train loss: 1.0535652500895616, Train acc: 0.8505529917250159\n",
      "[3, 1, 1, 2, 2, 1, 3, 1, 3, 3, 0, 4, 3, 2, 3, 0, 1, 1, 0, 2, 1, 3, 2, 2, 3, 0, 0, 1, 2, 0, 0, 3, 1, 2, 4, 2, 2, 1, 4, 4, 1, 4, 4, 1, 1, 4, 0, 2, 2, 1, 2, 0, 3, 1, 2, 2, 0, 1, 1, 2, 1, 2, 0, 3, 3, 0, 0, 4, 4, 4, 3, 1, 1, 1, 3, 2, 2, 4, 0, 0, 4, 4, 3, 1, 4, 1, 0, 1, 0, 0, 2, 3, 4, 2, 3, 2, 0, 1, 2, 4, 0, 0, 1, 2, 2, 2, 3, 1, 1, 3, 3, 4, 0, 2, 1, 2, 4, 1, 0, 3, 3, 2, 4, 4, 0, 3, 4, 0, 4, 1, 3, 4, 0, 1, 0, 3, 3, 2, 2, 3, 1, 1, 4, 2, 1, 0, 1, 4, 2, 3, 1, 0, 1, 2, 3, 4, 3, 4, 3, 2, 2, 3, 4, 1, 1, 4, 4, 0, 4, 1, 3, 1, 0, 3, 0, 3, 0, 0, 3, 1, 3, 2, 2, 0, 2, 2, 1, 2, 4, 0, 4, 3, 1, 4, 4, 1, 2, 3, 1, 3, 4, 4, 1, 4, 3, 2, 0, 4, 2, 1, 1, 0, 1, 4, 0, 3, 0, 2, 4, 4, 3, 2, 1, 2, 3, 0, 0, 3, 2, 4, 4, 2, 0, 2, 2, 2, 0, 3, 0, 1, 4, 1, 2, 3, 4, 1, 4, 0, 2, 3, 2, 3, 2, 1, 2, 3, 2, 0, 0, 1, 3, 0, 3, 0, 2, 1, 1, 1, 4, 4, 1, 1, 1, 1, 4, 0, 3, 0, 1, 2, 3, 0, 2, 3, 0, 4, 4, 1, 3, 3, 4, 3, 4, 3, 0, 4, 3, 2, 0, 2, 2, 4, 3, 3, 0, 1, 3, 4, 3, 4, 2, 0, 4, 4, 3, 1, 1, 3, 3, 4, 0, 4, 1, 4, 2, 4, 1, 2, 0, 4, 2, 0, 1, 3, 3, 2, 4, 3, 3, 1, 3, 2, 3, 2, 1, 2, 1, 4, 2, 1, 4, 1, 2, 1, 2, 2, 0, 0, 1, 0, 3, 3, 3, 1, 0, 1, 3, 0, 4, 0, 0, 2, 4, 1, 1, 2, 0, 4, 4, 0, 2, 0, 0, 2, 4, 3, 4, 2, 0, 2, 0, 1, 1, 3, 2, 0, 0, 0, 3, 2, 0, 0, 4, 1, 3, 3, 1, 4, 2, 0, 4, 3, 4, 3, 3, 3, 0, 1, 2, 1, 0, 1, 2, 4, 0, 0, 3, 3, 4, 3, 1, 2, 4, 1, 1, 4, 4, 2, 3, 4, 4, 3, 3, 4, 0, 2, 0, 0, 2, 2, 2, 3, 0, 0, 2, 4, 4, 2, 0, 4, 4, 0, 4, 3, 0, 0, 4, 1, 3, 0, 3, 0, 4, 3, 1, 3, 1, 0, 2, 2, 2, 0, 1, 4, 2, 1, 0, 0, 4, 4, 1, 4, 3, 0, 4, 2, 4, 3, 1, 4]\n",
      "[3, 3, 3, 2, 0, 0, 3, 4, 4, 3, 0, 3, 3, 2, 3, 0, 4, 4, 0, 2, 4, 3, 2, 2, 3, 0, 0, 4, 0, 0, 0, 3, 3, 3, 4, 2, 2, 4, 4, 4, 4, 4, 0, 3, 4, 4, 0, 2, 2, 3, 2, 0, 3, 0, 2, 2, 0, 3, 4, 2, 2, 2, 0, 3, 3, 2, 0, 2, 4, 4, 3, 3, 0, 3, 3, 2, 2, 4, 0, 0, 4, 4, 4, 4, 4, 3, 4, 0, 0, 0, 0, 3, 4, 2, 3, 2, 0, 0, 2, 4, 2, 0, 0, 2, 2, 2, 3, 2, 4, 3, 3, 4, 0, 0, 4, 2, 4, 3, 0, 3, 3, 2, 3, 4, 0, 3, 4, 0, 4, 4, 3, 4, 0, 2, 0, 3, 0, 2, 2, 3, 4, 4, 4, 2, 2, 0, 4, 4, 2, 3, 3, 0, 4, 2, 3, 4, 3, 4, 3, 0, 2, 3, 4, 0, 4, 4, 3, 0, 3, 4, 3, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 2, 2, 0, 2, 2, 2, 2, 0, 0, 4, 3, 3, 4, 4, 4, 0, 3, 4, 3, 4, 4, 3, 3, 4, 2, 0, 4, 0, 4, 3, 0, 4, 4, 0, 3, 0, 2, 3, 4, 3, 2, 0, 2, 3, 0, 0, 3, 2, 4, 4, 2, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 4, 0, 4, 0, 2, 3, 2, 3, 2, 3, 2, 3, 2, 0, 0, 4, 3, 0, 3, 0, 2, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 0, 3, 0, 4, 2, 3, 0, 2, 3, 0, 4, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4, 3, 2, 0, 2, 0, 4, 3, 3, 2, 3, 3, 4, 3, 4, 2, 0, 4, 4, 3, 4, 3, 3, 3, 4, 0, 4, 3, 4, 2, 4, 4, 2, 0, 4, 2, 4, 4, 3, 3, 0, 4, 3, 3, 0, 3, 2, 3, 0, 0, 2, 3, 4, 2, 3, 4, 4, 2, 4, 0, 2, 0, 0, 4, 4, 3, 3, 3, 3, 0, 4, 3, 0, 4, 4, 0, 2, 4, 3, 4, 2, 0, 4, 4, 0, 2, 0, 0, 2, 4, 3, 4, 2, 0, 2, 0, 0, 4, 3, 2, 2, 0, 0, 3, 2, 0, 0, 4, 0, 3, 3, 4, 4, 3, 2, 4, 3, 4, 3, 3, 3, 0, 3, 0, 4, 0, 0, 2, 4, 0, 0, 3, 3, 4, 4, 4, 2, 4, 4, 3, 4, 4, 2, 3, 4, 4, 3, 3, 2, 0, 2, 0, 0, 2, 2, 2, 3, 0, 0, 2, 3, 4, 0, 0, 4, 4, 0, 4, 3, 2, 0, 4, 3, 3, 0, 3, 4, 4, 3, 3, 3, 3, 0, 2, 2, 2, 0, 0, 4, 2, 4, 0, 0, 4, 4, 4, 4, 3, 0, 4, 2, 4, 3, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.81      0.83       100\n",
      "           3       0.70      0.95      0.81       100\n",
      "           4       0.61      0.88      0.72       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1985369771718979, Val acc: 0.702\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17800 - Batch 57/1613 - Train loss: 1.0522339631771218, Train acc: 0.8502155172413793\n",
      "Iteration 17900 - Batch 157/1613 - Train loss: 1.0508102363423457, Train acc: 0.8528481012658228\n",
      "Iteration 18000 - Batch 257/1613 - Train loss: 1.0542100386102071, Train acc: 0.8492005813953488\n",
      "Iteration 18100 - Batch 357/1613 - Train loss: 1.0536294514573485, Train acc: 0.8498603351955307\n",
      "Iteration 18200 - Batch 457/1613 - Train loss: 1.0519520053436662, Train acc: 0.851596615720524\n",
      "Iteration 18300 - Batch 557/1613 - Train loss: 1.0516116329632352, Train acc: 0.8519825268817204\n",
      "Iteration 18400 - Batch 657/1613 - Train loss: 1.0517870946858068, Train acc: 0.8518712006079028\n",
      "Iteration 18500 - Batch 757/1613 - Train loss: 1.0509016579877104, Train acc: 0.8527786939313984\n",
      "Iteration 18600 - Batch 857/1613 - Train loss: 1.0520482468299377, Train acc: 0.8515078671328671\n",
      "Iteration 18700 - Batch 957/1613 - Train loss: 1.050597429462166, Train acc: 0.8530793319415448\n",
      "Iteration 18800 - Batch 1057/1613 - Train loss: 1.0496960329648903, Train acc: 0.8539697542533081\n",
      "Iteration 18900 - Batch 1157/1613 - Train loss: 1.0510625803202958, Train acc: 0.8525474956822107\n",
      "Iteration 19000 - Batch 1257/1613 - Train loss: 1.0506707724592455, Train acc: 0.8530156995230525\n",
      "Iteration 19100 - Batch 1357/1613 - Train loss: 1.0493483769437175, Train acc: 0.8544044550810015\n",
      "Iteration 19200 - Batch 1457/1613 - Train loss: 1.0502055628718336, Train acc: 0.8535450960219478\n",
      "Iteration 19300 - Batch 1557/1613 - Train loss: 1.051204293621979, Train acc: 0.8525553594351734\n",
      "[0, 3, 0, 0, 0, 0, 4, 0, 2, 2, 3, 1, 3, 2, 2, 2, 3, 4, 1, 1, 1, 0, 0, 0, 2, 1, 3, 1, 0, 4, 4, 2, 0, 3, 2, 1, 1, 0, 3, 2, 3, 2, 1, 4, 0, 3, 3, 1, 2, 2, 3, 1, 2, 2, 1, 2, 4, 2, 4, 4, 1, 1, 3, 3, 4, 3, 2, 4, 1, 0, 3, 3, 3, 2, 1, 4, 0, 3, 3, 2, 4, 2, 1, 1, 4, 2, 1, 0, 2, 3, 4, 0, 0, 0, 4, 0, 2, 4, 3, 2, 2, 2, 0, 0, 1, 4, 2, 1, 2, 0, 1, 2, 0, 2, 1, 1, 0, 4, 2, 0, 2, 2, 0, 0, 2, 3, 2, 3, 1, 3, 0, 4, 0, 3, 0, 1, 0, 0, 0, 3, 4, 4, 0, 4, 2, 1, 3, 4, 0, 3, 2, 1, 0, 1, 1, 1, 2, 3, 1, 3, 3, 4, 3, 1, 3, 2, 1, 2, 3, 1, 3, 0, 1, 4, 3, 0, 0, 0, 1, 3, 2, 1, 2, 1, 2, 2, 1, 3, 1, 4, 2, 4, 2, 1, 0, 3, 4, 0, 4, 3, 0, 1, 4, 4, 3, 3, 2, 3, 0, 4, 3, 1, 0, 4, 2, 3, 4, 0, 2, 4, 2, 2, 4, 2, 1, 2, 0, 4, 2, 3, 0, 0, 2, 4, 1, 3, 0, 2, 3, 4, 1, 0, 2, 1, 4, 0, 2, 3, 2, 4, 2, 0, 3, 4, 2, 4, 3, 4, 4, 4, 2, 3, 4, 2, 3, 4, 3, 0, 1, 3, 0, 2, 0, 4, 3, 3, 4, 4, 3, 2, 2, 1, 4, 2, 1, 3, 1, 0, 0, 2, 3, 1, 4, 4, 3, 4, 2, 2, 3, 1, 1, 2, 4, 2, 4, 2, 1, 0, 4, 1, 2, 0, 1, 3, 3, 1, 4, 4, 2, 3, 4, 4, 1, 0, 2, 4, 3, 1, 4, 4, 2, 3, 4, 1, 3, 1, 1, 0, 1, 0, 4, 3, 1, 0, 0, 0, 1, 0, 2, 3, 4, 2, 2, 1, 4, 2, 4, 3, 3, 4, 3, 4, 4, 4, 0, 0, 1, 0, 3, 0, 0, 4, 1, 0, 1, 3, 3, 0, 0, 0, 3, 1, 0, 2, 1, 0, 2, 2, 1, 0, 3, 4, 1, 3, 1, 1, 3, 4, 0, 4, 1, 1, 3, 4, 3, 3, 2, 2, 3, 3, 2, 4, 0, 1, 3, 3, 1, 1, 0, 4, 4, 1, 4, 0, 4, 4, 1, 0, 1, 3, 2, 3, 1, 0, 1, 0, 1, 0, 0, 0, 4, 1, 1, 0, 0, 1, 1, 4, 1, 0, 0, 0, 2, 0, 1, 1, 2, 2, 4, 4, 2, 2, 1, 1, 4, 3, 3, 0, 1, 4, 2, 4, 3, 2, 4, 2, 3, 0, 3, 4, 0, 4, 2, 4, 1, 4, 4, 3, 3, 3, 2, 1, 2, 2, 3, 3, 4, 4, 0, 3]\n",
      "[0, 4, 0, 0, 2, 0, 4, 0, 0, 2, 3, 4, 3, 2, 2, 2, 3, 4, 0, 4, 4, 0, 2, 0, 2, 3, 3, 0, 0, 4, 4, 2, 0, 3, 2, 3, 4, 2, 4, 2, 3, 2, 4, 4, 0, 3, 3, 0, 0, 2, 3, 4, 2, 2, 0, 2, 4, 2, 4, 4, 0, 3, 3, 3, 4, 3, 2, 4, 3, 0, 3, 3, 3, 2, 4, 4, 0, 3, 3, 2, 4, 2, 4, 4, 4, 2, 4, 0, 2, 3, 4, 0, 0, 0, 4, 0, 0, 4, 4, 2, 0, 2, 0, 2, 4, 4, 2, 0, 2, 0, 3, 2, 0, 2, 0, 4, 2, 4, 2, 0, 2, 2, 0, 0, 2, 3, 2, 3, 0, 3, 0, 4, 4, 3, 0, 4, 0, 0, 0, 3, 3, 2, 0, 4, 2, 0, 3, 3, 0, 3, 0, 3, 2, 3, 3, 0, 2, 3, 4, 3, 3, 4, 3, 3, 3, 2, 4, 2, 3, 4, 3, 2, 3, 4, 3, 0, 0, 0, 4, 3, 0, 0, 0, 0, 2, 0, 4, 3, 0, 0, 2, 4, 2, 4, 0, 3, 4, 0, 4, 3, 0, 3, 4, 2, 3, 3, 2, 3, 0, 4, 3, 4, 0, 4, 2, 3, 4, 0, 2, 4, 2, 2, 4, 2, 0, 2, 0, 4, 0, 3, 0, 0, 0, 4, 4, 3, 0, 2, 3, 4, 2, 0, 2, 2, 4, 0, 2, 3, 0, 4, 2, 0, 3, 4, 2, 4, 3, 4, 4, 4, 2, 3, 4, 2, 3, 4, 3, 0, 0, 3, 0, 2, 0, 4, 3, 3, 4, 4, 3, 2, 0, 4, 4, 2, 3, 3, 0, 0, 0, 2, 3, 4, 4, 4, 3, 4, 3, 3, 3, 0, 2, 2, 4, 2, 4, 2, 0, 0, 4, 0, 2, 2, 4, 3, 3, 0, 4, 4, 2, 0, 4, 4, 0, 0, 2, 4, 3, 4, 4, 4, 2, 3, 4, 4, 2, 3, 3, 0, 3, 0, 4, 3, 4, 0, 0, 0, 4, 0, 2, 3, 4, 2, 2, 0, 4, 2, 0, 3, 3, 4, 3, 4, 4, 4, 0, 0, 4, 0, 3, 0, 0, 4, 3, 0, 0, 4, 3, 0, 0, 2, 3, 3, 0, 2, 4, 0, 2, 2, 3, 0, 3, 4, 3, 3, 4, 3, 3, 4, 0, 4, 3, 0, 3, 4, 3, 3, 0, 2, 3, 3, 2, 4, 0, 0, 3, 3, 3, 0, 0, 4, 2, 4, 4, 0, 4, 4, 2, 4, 4, 3, 2, 3, 3, 0, 4, 0, 3, 0, 0, 0, 4, 3, 4, 2, 0, 3, 0, 4, 2, 0, 0, 0, 2, 0, 0, 2, 2, 2, 4, 0, 0, 2, 4, 4, 4, 3, 3, 0, 2, 3, 2, 4, 3, 2, 4, 2, 3, 0, 3, 4, 0, 4, 0, 4, 0, 2, 4, 3, 4, 3, 2, 3, 2, 2, 3, 3, 4, 4, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.83      0.81       100\n",
      "           3       0.74      0.93      0.83       100\n",
      "           4       0.67      0.90      0.77       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1938899382948875, Val acc: 0.708\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19400 - Batch 44/1613 - Train loss: 1.0442994819747078, Train acc: 0.8576388888888888\n",
      "Iteration 19500 - Batch 144/1613 - Train loss: 1.0531637849478885, Train acc: 0.8497844827586207\n",
      "Iteration 19600 - Batch 244/1613 - Train loss: 1.0525516831144994, Train acc: 0.8507653061224489\n",
      "Iteration 19700 - Batch 344/1613 - Train loss: 1.0506662368774413, Train acc: 0.852626811594203\n",
      "Iteration 19800 - Batch 444/1613 - Train loss: 1.0524215996935127, Train acc: 0.8509831460674158\n",
      "Iteration 19900 - Batch 544/1613 - Train loss: 1.0528683896458477, Train acc: 0.8508600917431193\n",
      "Iteration 20000 - Batch 644/1613 - Train loss: 1.0533570472584215, Train acc: 0.850484496124031\n",
      "Iteration 20100 - Batch 744/1613 - Train loss: 1.0527516273844162, Train acc: 0.8510486577181208\n",
      "Iteration 20200 - Batch 844/1613 - Train loss: 1.054005035634577, Train acc: 0.8497041420118343\n",
      "Iteration 20300 - Batch 944/1613 - Train loss: 1.0540261672918128, Train acc: 0.8497023809523809\n",
      "Iteration 20400 - Batch 1044/1613 - Train loss: 1.0536451798877078, Train acc: 0.85002990430622\n",
      "Iteration 20500 - Batch 1144/1613 - Train loss: 1.0533571699821271, Train acc: 0.8503275109170305\n",
      "Iteration 20600 - Batch 1244/1613 - Train loss: 1.0546685406960636, Train acc: 0.8489206827309237\n",
      "Iteration 20700 - Batch 1344/1613 - Train loss: 1.0546325080899943, Train acc: 0.8489544609665427\n",
      "Iteration 20800 - Batch 1444/1613 - Train loss: 1.0545467658438896, Train acc: 0.8491349480968858\n",
      "Iteration 20900 - Batch 1544/1613 - Train loss: 1.0545548315187103, Train acc: 0.8491302588996764\n",
      "[2, 3, 0, 0, 2, 4, 3, 2, 1, 4, 4, 2, 1, 1, 3, 4, 2, 0, 4, 2, 4, 4, 0, 2, 2, 2, 2, 3, 2, 4, 0, 3, 3, 3, 0, 1, 3, 1, 4, 1, 1, 3, 3, 3, 1, 2, 3, 3, 0, 1, 0, 3, 1, 0, 4, 4, 1, 0, 1, 4, 4, 0, 2, 2, 2, 4, 3, 0, 4, 4, 0, 1, 3, 3, 2, 2, 3, 4, 3, 0, 1, 0, 2, 2, 0, 2, 3, 2, 2, 2, 4, 2, 4, 1, 2, 2, 3, 3, 2, 4, 0, 2, 0, 2, 0, 4, 3, 3, 0, 2, 3, 4, 1, 0, 1, 2, 3, 0, 1, 1, 0, 2, 1, 2, 0, 3, 3, 4, 4, 1, 0, 2, 4, 1, 0, 2, 2, 4, 0, 1, 2, 0, 0, 4, 4, 2, 4, 4, 1, 2, 2, 0, 4, 1, 4, 1, 0, 3, 2, 1, 0, 1, 3, 4, 1, 4, 0, 3, 3, 2, 1, 0, 4, 0, 1, 3, 2, 0, 0, 3, 0, 4, 1, 3, 2, 4, 3, 2, 1, 2, 3, 4, 0, 3, 4, 4, 1, 1, 0, 2, 0, 0, 1, 1, 0, 3, 2, 3, 4, 3, 3, 0, 2, 1, 4, 0, 0, 0, 2, 3, 2, 0, 2, 4, 0, 0, 0, 2, 0, 4, 0, 3, 4, 0, 0, 4, 1, 1, 0, 0, 0, 2, 2, 1, 4, 1, 1, 4, 3, 4, 0, 1, 0, 2, 1, 4, 4, 4, 3, 3, 3, 1, 3, 1, 3, 3, 4, 3, 1, 3, 1, 3, 1, 1, 3, 3, 1, 2, 2, 4, 4, 4, 4, 3, 3, 4, 4, 0, 3, 1, 4, 2, 1, 1, 1, 2, 0, 4, 2, 4, 2, 3, 0, 0, 1, 3, 2, 3, 0, 0, 0, 0, 0, 2, 0, 4, 1, 3, 4, 1, 2, 1, 2, 3, 1, 2, 4, 0, 4, 3, 3, 1, 1, 2, 0, 3, 4, 2, 2, 4, 0, 2, 1, 2, 3, 4, 3, 2, 1, 3, 4, 3, 0, 0, 2, 2, 0, 1, 0, 0, 1, 2, 1, 3, 3, 0, 1, 1, 3, 2, 4, 4, 0, 0, 4, 0, 2, 3, 1, 3, 3, 0, 1, 3, 1, 1, 2, 1, 3, 2, 4, 2, 1, 2, 1, 3, 1, 3, 4, 1, 0, 1, 1, 1, 3, 1, 4, 2, 4, 0, 3, 2, 4, 4, 1, 4, 0, 3, 4, 1, 3, 4, 1, 0, 0, 2, 0, 2, 3, 0, 2, 2, 4, 3, 0, 3, 4, 4, 2, 1, 1, 1, 4, 2, 1, 0, 1, 1, 4, 1, 1, 0, 4, 3, 4, 3, 4, 1, 4, 3, 2, 3, 1, 0, 2, 0, 4, 3, 3, 2, 3, 2, 0, 4, 1, 4, 1, 2, 4, 3, 2, 0, 1, 0, 3, 4, 0, 2, 1, 3, 4, 4, 2, 2, 4, 3, 4, 3, 0, 2]\n",
      "[0, 3, 0, 0, 2, 4, 3, 2, 3, 4, 4, 2, 0, 0, 3, 4, 2, 0, 3, 2, 4, 3, 0, 3, 3, 0, 2, 3, 0, 3, 0, 3, 3, 3, 0, 4, 3, 3, 4, 4, 4, 3, 3, 3, 0, 2, 3, 3, 0, 4, 0, 3, 2, 0, 4, 4, 4, 0, 4, 0, 4, 0, 0, 2, 0, 4, 3, 4, 4, 4, 0, 4, 3, 3, 2, 2, 3, 4, 3, 0, 3, 4, 2, 2, 0, 2, 3, 2, 2, 0, 4, 2, 4, 4, 0, 2, 3, 3, 2, 4, 0, 2, 0, 2, 2, 4, 3, 3, 0, 2, 3, 4, 2, 0, 2, 2, 3, 0, 4, 3, 0, 2, 0, 0, 0, 3, 3, 4, 2, 3, 0, 2, 4, 0, 0, 2, 2, 4, 0, 0, 2, 0, 0, 4, 4, 2, 4, 4, 3, 2, 2, 0, 4, 4, 4, 2, 0, 3, 0, 0, 0, 4, 3, 4, 4, 4, 0, 3, 3, 2, 0, 0, 4, 0, 3, 3, 2, 0, 0, 3, 0, 4, 4, 3, 2, 4, 3, 2, 4, 0, 3, 4, 0, 3, 2, 4, 0, 4, 0, 2, 0, 4, 0, 0, 0, 4, 2, 3, 4, 3, 3, 0, 2, 3, 4, 0, 0, 0, 2, 3, 2, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 3, 4, 0, 0, 4, 4, 3, 0, 0, 0, 2, 2, 3, 3, 0, 0, 4, 3, 4, 0, 3, 0, 2, 3, 3, 4, 4, 4, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 4, 0, 4, 4, 3, 3, 3, 2, 2, 4, 4, 4, 4, 3, 3, 4, 4, 0, 3, 0, 4, 2, 3, 4, 3, 2, 0, 4, 2, 4, 2, 3, 4, 0, 2, 3, 2, 3, 0, 0, 0, 0, 0, 2, 0, 4, 4, 3, 0, 3, 2, 2, 2, 3, 4, 0, 3, 0, 4, 3, 3, 3, 4, 0, 0, 3, 4, 2, 2, 3, 0, 2, 3, 2, 3, 4, 2, 2, 0, 3, 4, 3, 0, 0, 2, 2, 0, 0, 0, 0, 4, 2, 4, 3, 3, 0, 3, 3, 3, 2, 4, 4, 0, 0, 4, 0, 2, 3, 3, 3, 3, 0, 4, 3, 3, 3, 2, 4, 3, 2, 4, 2, 0, 2, 0, 3, 3, 4, 4, 3, 0, 4, 2, 4, 3, 4, 4, 2, 4, 0, 3, 2, 4, 4, 4, 4, 0, 3, 4, 4, 3, 4, 4, 0, 0, 0, 0, 2, 4, 0, 2, 0, 4, 3, 0, 3, 4, 4, 2, 2, 2, 0, 4, 2, 4, 0, 3, 0, 4, 2, 4, 0, 4, 3, 2, 3, 4, 2, 4, 3, 3, 3, 2, 0, 2, 0, 4, 3, 3, 2, 3, 0, 0, 4, 4, 4, 4, 0, 4, 3, 2, 0, 3, 0, 3, 4, 0, 2, 3, 3, 4, 4, 2, 2, 4, 3, 4, 3, 0, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.81      0.81      0.81       100\n",
      "           3       0.70      0.94      0.80       100\n",
      "           4       0.65      0.85      0.74       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1866994425654411, Val acc: 0.71\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21000 - Batch 31/1613 - Train loss: 1.0597222279757261, Train acc: 0.8447265625\n",
      "Iteration 21100 - Batch 131/1613 - Train loss: 1.0542454904679097, Train acc: 0.8496685606060606\n",
      "Iteration 21200 - Batch 231/1613 - Train loss: 1.0530906866850525, Train acc: 0.8511584051724138\n",
      "Iteration 21300 - Batch 331/1613 - Train loss: 1.0528892582080451, Train acc: 0.8512801204819277\n",
      "Iteration 21400 - Batch 431/1613 - Train loss: 1.053318919820918, Train acc: 0.8505497685185185\n",
      "Iteration 21500 - Batch 531/1613 - Train loss: 1.0508663313729423, Train acc: 0.8530897556390977\n",
      "Iteration 21600 - Batch 631/1613 - Train loss: 1.0510563408083553, Train acc: 0.8527492088607594\n",
      "Iteration 21700 - Batch 731/1613 - Train loss: 1.0503538265580037, Train acc: 0.8533555327868853\n",
      "Iteration 21800 - Batch 831/1613 - Train loss: 1.0488422244357376, Train acc: 0.8548302283653846\n",
      "Iteration 21900 - Batch 931/1613 - Train loss: 1.0482694069203389, Train acc: 0.8553513948497854\n",
      "Iteration 22000 - Batch 1031/1613 - Train loss: 1.0469427020974862, Train acc: 0.8566799903100775\n",
      "Iteration 22100 - Batch 1131/1613 - Train loss: 1.0468580108333392, Train acc: 0.856780035335689\n",
      "Iteration 22200 - Batch 1231/1613 - Train loss: 1.0466011394928028, Train acc: 0.857218952922078\n",
      "Iteration 22300 - Batch 1331/1613 - Train loss: 1.0470009707473777, Train acc: 0.8568412162162162\n",
      "Iteration 22400 - Batch 1431/1613 - Train loss: 1.0469512506986463, Train acc: 0.8568435754189944\n",
      "Iteration 22500 - Batch 1531/1613 - Train loss: 1.0468820947035173, Train acc: 0.8569068211488251\n",
      "[3, 3, 1, 2, 2, 0, 3, 0, 4, 2, 0, 1, 1, 3, 0, 4, 4, 3, 1, 3, 1, 1, 2, 3, 4, 1, 1, 0, 4, 4, 2, 3, 1, 4, 2, 4, 2, 2, 3, 4, 1, 4, 4, 4, 1, 4, 3, 0, 1, 1, 0, 1, 2, 4, 1, 2, 2, 3, 0, 4, 0, 2, 2, 1, 0, 0, 3, 4, 3, 3, 1, 3, 4, 1, 1, 2, 2, 4, 2, 2, 2, 4, 2, 3, 1, 3, 2, 0, 0, 4, 0, 1, 2, 1, 3, 0, 1, 0, 3, 1, 0, 0, 1, 0, 4, 0, 3, 0, 1, 1, 3, 3, 1, 4, 2, 2, 2, 3, 2, 1, 0, 3, 1, 1, 4, 2, 4, 2, 2, 1, 4, 4, 4, 2, 0, 1, 0, 1, 4, 0, 1, 4, 4, 0, 4, 1, 2, 0, 2, 1, 3, 1, 4, 3, 0, 3, 1, 0, 0, 3, 2, 1, 1, 4, 0, 4, 4, 2, 3, 4, 4, 2, 3, 4, 2, 1, 1, 4, 3, 0, 3, 3, 3, 1, 2, 2, 1, 4, 3, 3, 2, 3, 0, 2, 3, 4, 1, 0, 4, 3, 4, 1, 3, 1, 4, 4, 2, 2, 3, 3, 0, 2, 3, 3, 0, 2, 2, 3, 0, 3, 1, 4, 2, 3, 0, 3, 4, 2, 2, 1, 2, 4, 0, 3, 1, 0, 0, 2, 2, 2, 0, 2, 4, 0, 1, 3, 0, 3, 3, 0, 0, 1, 2, 1, 0, 1, 4, 4, 0, 1, 1, 3, 0, 4, 4, 2, 0, 0, 0, 4, 0, 3, 4, 0, 0, 3, 1, 2, 1, 0, 0, 1, 3, 3, 0, 4, 1, 4, 2, 0, 3, 0, 0, 2, 3, 3, 4, 2, 2, 0, 2, 2, 4, 1, 4, 4, 4, 4, 0, 4, 1, 0, 2, 4, 3, 0, 3, 1, 3, 3, 3, 2, 4, 0, 2, 0, 1, 1, 2, 0, 1, 3, 4, 1, 3, 1, 3, 2, 1, 3, 4, 3, 2, 2, 1, 2, 2, 2, 4, 1, 4, 3, 0, 3, 4, 4, 4, 0, 2, 0, 1, 1, 3, 1, 0, 2, 4, 3, 0, 2, 1, 2, 0, 2, 2, 4, 3, 1, 4, 2, 0, 3, 1, 4, 1, 4, 0, 1, 4, 1, 4, 1, 1, 3, 3, 4, 0, 0, 3, 3, 1, 0, 2, 2, 3, 0, 4, 2, 1, 2, 4, 2, 1, 3, 2, 3, 2, 1, 0, 1, 0, 3, 3, 2, 3, 1, 4, 3, 0, 0, 1, 1, 2, 2, 4, 4, 1, 0, 3, 2, 1, 3, 2, 2, 0, 4, 3, 0, 0, 0, 0, 4, 4, 4, 1, 2, 2, 1, 2, 0, 1, 1, 3, 4, 3, 2, 0, 3, 4, 3, 2, 3, 4, 4, 4, 4, 0, 1, 0, 3, 2, 1, 2, 0, 2, 4, 0, 0, 4, 3, 0, 2, 3, 0, 4, 0, 1, 3, 4, 3]\n",
      "[3, 3, 4, 2, 2, 4, 3, 0, 4, 2, 0, 0, 0, 3, 0, 4, 4, 3, 3, 4, 3, 4, 2, 3, 4, 0, 4, 0, 4, 2, 2, 3, 3, 4, 2, 4, 2, 2, 3, 4, 0, 4, 4, 4, 3, 4, 3, 0, 3, 4, 0, 2, 2, 4, 4, 0, 2, 3, 0, 4, 0, 2, 2, 3, 0, 0, 3, 4, 3, 3, 4, 3, 4, 0, 4, 0, 2, 4, 0, 2, 2, 4, 0, 3, 4, 3, 2, 0, 0, 4, 0, 4, 2, 4, 3, 0, 3, 0, 3, 4, 0, 0, 4, 0, 3, 0, 3, 0, 3, 4, 3, 3, 4, 4, 2, 2, 2, 3, 0, 4, 0, 3, 4, 4, 4, 2, 4, 2, 2, 4, 3, 2, 4, 2, 0, 0, 0, 4, 4, 0, 3, 4, 4, 0, 4, 4, 2, 0, 2, 4, 3, 3, 4, 3, 0, 3, 0, 0, 0, 3, 2, 3, 4, 4, 0, 4, 4, 2, 3, 4, 4, 2, 3, 4, 0, 4, 4, 4, 3, 0, 2, 4, 3, 4, 2, 2, 0, 4, 3, 3, 0, 3, 0, 2, 3, 4, 4, 0, 4, 3, 4, 3, 3, 0, 4, 4, 2, 0, 3, 3, 0, 0, 3, 3, 0, 2, 2, 4, 0, 3, 4, 4, 2, 3, 0, 3, 4, 2, 2, 4, 2, 4, 0, 3, 0, 0, 0, 0, 2, 2, 0, 2, 4, 0, 3, 3, 0, 3, 3, 0, 0, 3, 2, 4, 0, 4, 4, 4, 0, 0, 4, 3, 0, 3, 4, 0, 0, 0, 0, 4, 0, 3, 4, 0, 0, 3, 3, 2, 3, 0, 0, 4, 3, 3, 4, 4, 0, 4, 2, 0, 3, 0, 0, 2, 3, 3, 4, 0, 2, 0, 2, 2, 4, 2, 4, 4, 4, 4, 0, 4, 4, 0, 2, 4, 3, 0, 4, 4, 0, 3, 3, 2, 3, 2, 2, 0, 4, 3, 0, 0, 0, 3, 4, 4, 3, 4, 3, 2, 4, 3, 4, 3, 0, 2, 4, 2, 2, 2, 4, 4, 4, 3, 0, 3, 4, 4, 4, 0, 2, 0, 2, 4, 3, 0, 0, 3, 4, 3, 0, 0, 4, 2, 0, 2, 2, 4, 3, 4, 2, 2, 0, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 3, 2, 3, 3, 4, 0, 0, 3, 3, 0, 0, 2, 0, 3, 4, 4, 2, 4, 2, 4, 2, 0, 3, 2, 3, 2, 0, 2, 4, 4, 3, 3, 2, 3, 4, 4, 3, 0, 0, 3, 4, 2, 2, 4, 4, 0, 0, 3, 2, 4, 3, 2, 2, 0, 0, 3, 0, 0, 0, 0, 4, 4, 4, 4, 2, 0, 4, 0, 0, 3, 2, 3, 4, 3, 2, 0, 3, 4, 3, 2, 3, 4, 4, 4, 4, 0, 4, 0, 3, 2, 4, 2, 0, 2, 4, 0, 0, 4, 3, 0, 2, 3, 0, 4, 0, 3, 4, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.81      0.84       100\n",
      "           3       0.78      0.92      0.84       100\n",
      "           4       0.58      0.92      0.71       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.183025874197483, Val acc: 0.716\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22600 - Batch 18/1613 - Train loss: 1.0408697316521092, Train acc: 0.8651315789473685\n",
      "Iteration 22700 - Batch 118/1613 - Train loss: 1.0466025521775253, Train acc: 0.8566176470588235\n",
      "Iteration 22800 - Batch 218/1613 - Train loss: 1.0516904562575633, Train acc: 0.8517408675799086\n",
      "Iteration 22900 - Batch 318/1613 - Train loss: 1.0504377878571753, Train acc: 0.8531543887147336\n",
      "Iteration 23000 - Batch 418/1613 - Train loss: 1.0497625777431205, Train acc: 0.8539677804295943\n",
      "Iteration 23100 - Batch 518/1613 - Train loss: 1.0500730140590484, Train acc: 0.8538053949903661\n",
      "Iteration 23200 - Batch 618/1613 - Train loss: 1.05024632768215, Train acc: 0.85359450726979\n",
      "Iteration 23300 - Batch 718/1613 - Train loss: 1.049489604829913, Train acc: 0.8543550069541029\n",
      "Iteration 23400 - Batch 818/1613 - Train loss: 1.0500492599129823, Train acc: 0.8539758852258852\n",
      "Iteration 23500 - Batch 918/1613 - Train loss: 1.05071532791146, Train acc: 0.8532712187159956\n",
      "Iteration 23600 - Batch 1018/1613 - Train loss: 1.0502303573170402, Train acc: 0.8537475466143277\n",
      "Iteration 23700 - Batch 1118/1613 - Train loss: 1.0503184414527797, Train acc: 0.8536639857015192\n",
      "Iteration 23800 - Batch 1218/1613 - Train loss: 1.0499720936725139, Train acc: 0.8540043068088597\n",
      "Iteration 23900 - Batch 1318/1613 - Train loss: 1.050324889951985, Train acc: 0.8536533358605004\n",
      "Iteration 24000 - Batch 1418/1613 - Train loss: 1.0506739700823455, Train acc: 0.853219696969697\n",
      "Iteration 24100 - Batch 1518/1613 - Train loss: 1.0501856885904384, Train acc: 0.8536660631994734\n",
      "[1, 4, 4, 1, 0, 1, 2, 2, 1, 4, 4, 2, 3, 2, 4, 4, 0, 3, 4, 4, 2, 0, 0, 2, 3, 2, 0, 4, 3, 0, 1, 1, 1, 0, 3, 3, 3, 3, 3, 3, 2, 4, 2, 3, 0, 1, 0, 1, 0, 2, 2, 3, 2, 3, 4, 4, 1, 1, 3, 3, 1, 0, 3, 3, 0, 2, 1, 0, 0, 1, 1, 1, 3, 2, 0, 2, 2, 3, 3, 0, 2, 3, 3, 0, 2, 4, 3, 3, 1, 3, 3, 3, 2, 2, 4, 3, 0, 1, 2, 4, 3, 0, 3, 4, 1, 3, 1, 4, 1, 4, 4, 2, 2, 3, 3, 4, 2, 4, 2, 0, 2, 2, 0, 0, 0, 1, 3, 2, 2, 1, 1, 2, 1, 0, 0, 1, 1, 3, 3, 4, 0, 4, 2, 1, 4, 2, 4, 0, 2, 0, 3, 4, 0, 1, 0, 3, 2, 3, 0, 1, 2, 3, 4, 4, 4, 2, 3, 4, 4, 0, 0, 4, 0, 1, 0, 0, 0, 4, 3, 1, 4, 0, 1, 1, 3, 0, 3, 2, 4, 2, 1, 0, 0, 4, 3, 3, 2, 1, 0, 3, 2, 2, 4, 4, 1, 0, 3, 1, 1, 1, 4, 4, 2, 3, 0, 1, 2, 1, 4, 2, 2, 2, 2, 1, 4, 2, 4, 3, 2, 3, 3, 3, 0, 0, 4, 1, 1, 1, 2, 4, 2, 4, 3, 3, 4, 2, 2, 1, 3, 4, 2, 1, 2, 2, 2, 0, 2, 0, 1, 4, 1, 3, 1, 4, 3, 4, 3, 4, 2, 4, 4, 4, 1, 0, 1, 3, 0, 0, 4, 0, 1, 4, 4, 4, 3, 3, 0, 1, 4, 0, 4, 3, 2, 2, 0, 3, 3, 4, 3, 4, 0, 0, 1, 4, 0, 0, 0, 1, 2, 3, 3, 3, 2, 2, 0, 0, 1, 3, 2, 2, 4, 2, 2, 0, 1, 4, 0, 4, 0, 2, 1, 0, 0, 4, 4, 4, 3, 1, 4, 0, 2, 1, 2, 1, 4, 3, 4, 1, 0, 4, 2, 1, 4, 3, 2, 0, 1, 1, 3, 1, 0, 0, 0, 1, 3, 4, 2, 1, 1, 3, 1, 0, 0, 4, 1, 1, 3, 4, 2, 3, 3, 4, 2, 0, 3, 2, 1, 0, 4, 2, 4, 4, 4, 1, 1, 2, 3, 4, 1, 1, 1, 2, 2, 0, 3, 2, 2, 3, 0, 0, 0, 3, 4, 3, 2, 3, 4, 0, 2, 3, 2, 1, 4, 0, 3, 0, 2, 4, 3, 3, 0, 0, 3, 0, 1, 1, 2, 4, 0, 0, 4, 3, 1, 0, 0, 2, 0, 4, 2, 1, 4, 3, 0, 4, 0, 4, 3, 1, 1, 2, 2, 2, 1, 1, 1, 2, 3, 1, 3, 2, 4, 1, 3, 2, 0, 0, 0, 0, 4, 4, 0, 1, 2, 1, 3, 1, 4, 0, 2, 1, 1, 4, 3, 1, 4, 3, 1, 1, 2, 2]\n",
      "[4, 4, 4, 0, 0, 4, 2, 0, 4, 4, 4, 2, 3, 0, 4, 4, 0, 3, 4, 4, 2, 0, 0, 2, 3, 2, 0, 4, 3, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 4, 2, 4, 0, 4, 0, 2, 0, 2, 0, 2, 2, 3, 2, 3, 4, 4, 0, 0, 3, 3, 4, 2, 3, 3, 0, 2, 4, 0, 0, 0, 2, 3, 3, 2, 0, 2, 2, 3, 3, 0, 2, 3, 3, 0, 2, 3, 3, 3, 3, 0, 3, 4, 0, 2, 4, 2, 0, 3, 2, 4, 4, 0, 3, 4, 4, 3, 0, 4, 0, 4, 4, 2, 0, 4, 3, 4, 2, 4, 2, 0, 2, 2, 0, 4, 0, 4, 3, 0, 0, 4, 4, 0, 3, 0, 0, 0, 4, 3, 3, 4, 0, 4, 2, 4, 4, 2, 4, 0, 0, 0, 3, 4, 0, 4, 0, 3, 0, 3, 4, 4, 2, 3, 4, 4, 4, 2, 4, 4, 4, 0, 0, 4, 0, 3, 0, 0, 0, 4, 3, 0, 4, 0, 4, 4, 4, 0, 3, 2, 4, 2, 4, 0, 0, 4, 3, 3, 2, 0, 0, 3, 0, 2, 4, 3, 4, 0, 3, 4, 0, 3, 4, 4, 0, 3, 2, 3, 0, 4, 4, 2, 2, 2, 2, 3, 4, 2, 4, 3, 2, 4, 3, 3, 0, 0, 4, 4, 3, 4, 2, 4, 2, 4, 3, 3, 2, 2, 2, 4, 3, 4, 2, 0, 2, 2, 0, 0, 2, 0, 2, 4, 4, 3, 4, 4, 3, 4, 3, 4, 0, 4, 2, 3, 0, 0, 4, 3, 0, 0, 4, 0, 0, 4, 4, 4, 3, 3, 0, 3, 4, 0, 4, 3, 2, 2, 2, 3, 3, 4, 3, 4, 0, 0, 4, 4, 0, 2, 0, 3, 2, 3, 4, 4, 0, 2, 4, 0, 3, 3, 2, 2, 4, 2, 2, 0, 3, 4, 0, 4, 0, 2, 4, 0, 0, 4, 4, 4, 3, 4, 4, 0, 2, 4, 2, 4, 4, 3, 4, 4, 0, 4, 2, 4, 4, 3, 2, 0, 0, 0, 3, 4, 0, 0, 0, 2, 3, 4, 2, 4, 3, 3, 3, 0, 4, 4, 0, 4, 3, 4, 2, 4, 3, 4, 2, 0, 3, 2, 0, 0, 4, 2, 4, 4, 4, 3, 3, 0, 2, 4, 0, 0, 4, 2, 0, 0, 3, 2, 2, 3, 0, 0, 0, 3, 4, 3, 2, 3, 4, 0, 0, 3, 2, 4, 4, 0, 3, 0, 2, 4, 4, 4, 0, 4, 4, 0, 4, 4, 0, 0, 0, 0, 4, 3, 4, 0, 0, 2, 4, 4, 0, 0, 4, 3, 0, 4, 0, 4, 3, 3, 3, 2, 2, 2, 4, 4, 4, 2, 3, 4, 3, 2, 4, 2, 4, 2, 0, 0, 0, 0, 4, 4, 0, 4, 2, 4, 3, 4, 4, 0, 2, 4, 4, 4, 3, 4, 4, 3, 4, 4, 2, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.79      0.82       100\n",
      "           3       0.77      0.82      0.80       100\n",
      "           4       0.56      0.94      0.70       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2115267738699913, Val acc: 0.69\n",
      "Epoch 16/30\n",
      "Iteration 24200 - Batch 5/1613 - Train loss: 1.024141550064087, Train acc: 0.8802083333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24300 - Batch 105/1613 - Train loss: 1.0365514400995002, Train acc: 0.8685141509433962\n",
      "Iteration 24400 - Batch 205/1613 - Train loss: 1.0416893614727316, Train acc: 0.8630157766990292\n",
      "Iteration 24500 - Batch 305/1613 - Train loss: 1.0459567296738719, Train acc: 0.8583537581699346\n",
      "Iteration 24600 - Batch 405/1613 - Train loss: 1.0434538556143569, Train acc: 0.8610683497536946\n",
      "Iteration 24700 - Batch 505/1613 - Train loss: 1.0412841103529271, Train acc: 0.8634510869565217\n",
      "Iteration 24800 - Batch 605/1613 - Train loss: 1.0414415990362074, Train acc: 0.8630878712871287\n",
      "Iteration 24900 - Batch 705/1613 - Train loss: 1.0423792000363974, Train acc: 0.8618537535410765\n",
      "Iteration 25000 - Batch 805/1613 - Train loss: 1.0433610372300774, Train acc: 0.8609258684863523\n",
      "Iteration 25100 - Batch 905/1613 - Train loss: 1.0430930096318916, Train acc: 0.8610651214128036\n",
      "Iteration 25200 - Batch 1005/1613 - Train loss: 1.0438741569964596, Train acc: 0.8599652087475149\n",
      "Iteration 25300 - Batch 1105/1613 - Train loss: 1.0441299249530915, Train acc: 0.8597988245931284\n",
      "Iteration 25400 - Batch 1205/1613 - Train loss: 1.0451418412463187, Train acc: 0.8588049336650083\n",
      "Iteration 25500 - Batch 1305/1613 - Train loss: 1.045661587673161, Train acc: 0.8582025267993875\n",
      "Iteration 25600 - Batch 1405/1613 - Train loss: 1.0456962674474648, Train acc: 0.8581303342816501\n",
      "Iteration 25700 - Batch 1505/1613 - Train loss: 1.0457594612363483, Train acc: 0.8580677290836654\n",
      "Iteration 25800 - Batch 1605/1613 - Train loss: 1.0449129476642252, Train acc: 0.8589663760896638\n",
      "[4, 2, 2, 0, 0, 4, 4, 0, 1, 1, 2, 0, 4, 4, 1, 1, 2, 1, 3, 3, 0, 0, 2, 4, 1, 4, 1, 2, 0, 1, 2, 3, 1, 4, 2, 2, 2, 4, 1, 4, 0, 3, 2, 4, 3, 4, 3, 2, 0, 0, 2, 2, 2, 4, 0, 4, 3, 3, 2, 4, 3, 3, 3, 2, 0, 2, 1, 1, 1, 3, 4, 4, 0, 0, 4, 3, 0, 2, 4, 1, 3, 1, 1, 1, 1, 1, 1, 2, 3, 2, 4, 3, 0, 3, 3, 4, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 3, 4, 0, 2, 2, 4, 4, 3, 0, 3, 2, 1, 1, 1, 4, 2, 3, 4, 1, 4, 4, 0, 3, 0, 3, 1, 2, 0, 2, 2, 0, 2, 2, 0, 1, 0, 0, 4, 3, 0, 4, 4, 2, 0, 1, 4, 4, 2, 3, 1, 1, 0, 1, 0, 4, 0, 2, 4, 0, 3, 3, 4, 4, 3, 1, 0, 3, 3, 4, 3, 3, 3, 3, 0, 4, 2, 3, 2, 0, 4, 1, 2, 3, 2, 1, 4, 0, 3, 0, 1, 3, 0, 4, 2, 2, 0, 0, 0, 2, 1, 0, 1, 2, 3, 4, 2, 3, 1, 3, 4, 4, 1, 1, 3, 3, 1, 1, 2, 1, 4, 0, 4, 0, 2, 3, 4, 0, 4, 3, 0, 4, 3, 4, 2, 1, 0, 2, 2, 0, 2, 1, 2, 3, 0, 4, 4, 3, 3, 2, 0, 4, 1, 3, 0, 2, 2, 0, 4, 2, 4, 4, 1, 2, 0, 2, 1, 2, 3, 3, 3, 1, 1, 1, 4, 1, 3, 0, 2, 1, 3, 4, 4, 4, 0, 0, 4, 2, 0, 3, 4, 2, 3, 0, 1, 4, 2, 3, 3, 2, 4, 3, 3, 2, 2, 3, 1, 4, 3, 0, 2, 2, 1, 3, 0, 2, 4, 1, 2, 2, 0, 4, 1, 1, 0, 0, 1, 2, 2, 2, 1, 0, 3, 0, 0, 0, 0, 3, 2, 2, 4, 3, 4, 0, 1, 0, 1, 1, 2, 0, 1, 3, 3, 1, 3, 0, 1, 4, 1, 4, 4, 4, 0, 1, 2, 1, 4, 1, 4, 4, 4, 2, 3, 2, 3, 1, 1, 2, 3, 2, 4, 1, 4, 2, 2, 0, 2, 0, 3, 0, 1, 2, 3, 1, 3, 1, 1, 2, 0, 4, 2, 3, 2, 4, 1, 2, 0, 0, 0, 2, 1, 2, 1, 4, 2, 3, 3, 4, 1, 1, 0, 2, 4, 4, 3, 2, 2, 3, 4, 1, 0, 4, 4, 3, 4, 0, 0, 3, 4, 4, 1, 2, 3, 0, 2, 4, 4, 4, 0, 3, 2, 1, 3, 3, 3, 3, 2, 3, 0, 1, 4, 3, 3, 4, 3, 1, 4, 1, 1, 2, 0, 2, 2, 3, 3, 0, 4, 1, 1, 1, 1, 3, 1, 3, 4, 0, 0, 0, 3, 1, 3]\n",
      "[4, 2, 2, 2, 4, 4, 4, 0, 3, 4, 2, 0, 4, 4, 4, 4, 2, 0, 3, 3, 0, 0, 2, 4, 2, 4, 3, 2, 0, 3, 2, 3, 4, 2, 2, 2, 2, 4, 4, 4, 0, 3, 2, 4, 3, 4, 3, 0, 2, 0, 2, 0, 2, 4, 0, 4, 3, 3, 2, 4, 3, 3, 3, 2, 0, 2, 2, 4, 4, 3, 3, 4, 0, 0, 3, 3, 0, 2, 4, 0, 3, 4, 3, 3, 2, 4, 4, 2, 3, 2, 4, 3, 0, 3, 3, 4, 0, 2, 4, 0, 3, 0, 3, 0, 0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 2, 4, 4, 3, 0, 3, 2, 0, 0, 0, 4, 2, 4, 4, 0, 2, 4, 0, 4, 0, 3, 4, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 4, 3, 0, 4, 4, 2, 2, 3, 4, 4, 2, 3, 3, 4, 0, 4, 2, 4, 0, 2, 4, 0, 3, 3, 4, 4, 3, 4, 0, 3, 3, 4, 3, 3, 3, 3, 0, 4, 2, 3, 2, 0, 4, 4, 2, 3, 4, 4, 4, 0, 3, 0, 3, 3, 0, 4, 2, 0, 0, 4, 4, 2, 4, 0, 4, 2, 3, 4, 2, 3, 0, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 4, 4, 0, 4, 2, 2, 3, 4, 0, 4, 3, 0, 4, 3, 4, 2, 4, 0, 2, 2, 0, 2, 3, 2, 3, 4, 4, 4, 3, 3, 0, 0, 4, 4, 3, 0, 2, 2, 0, 4, 2, 4, 4, 3, 2, 0, 2, 2, 2, 3, 3, 4, 4, 3, 0, 4, 0, 3, 0, 2, 4, 3, 4, 4, 4, 0, 0, 4, 2, 0, 4, 4, 2, 3, 0, 0, 4, 2, 3, 3, 2, 4, 3, 3, 0, 0, 3, 4, 4, 3, 0, 2, 0, 3, 3, 0, 2, 4, 4, 2, 2, 0, 4, 2, 4, 0, 0, 4, 2, 2, 3, 0, 0, 3, 2, 0, 2, 0, 3, 2, 2, 4, 3, 4, 0, 3, 0, 0, 4, 2, 0, 3, 4, 3, 2, 3, 0, 4, 4, 3, 4, 4, 3, 0, 3, 2, 4, 4, 4, 4, 4, 4, 2, 3, 2, 3, 0, 4, 2, 3, 2, 4, 3, 4, 2, 2, 0, 2, 2, 3, 2, 3, 2, 3, 4, 3, 4, 4, 2, 0, 4, 2, 3, 0, 4, 0, 0, 0, 0, 0, 2, 4, 2, 3, 4, 2, 3, 3, 4, 0, 2, 0, 2, 4, 4, 2, 2, 2, 3, 4, 3, 0, 4, 4, 3, 4, 2, 0, 3, 4, 4, 2, 2, 3, 0, 2, 4, 4, 4, 2, 3, 2, 3, 3, 3, 3, 4, 2, 3, 2, 0, 4, 4, 3, 4, 4, 3, 4, 4, 4, 2, 0, 2, 2, 3, 3, 0, 4, 3, 3, 4, 3, 3, 4, 3, 4, 0, 0, 0, 3, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.78      0.86      0.82       100\n",
      "           3       0.73      0.90      0.81       100\n",
      "           4       0.61      0.95      0.75       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1934822872281075, Val acc: 0.71\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25900 - Batch 92/1613 - Train loss: 1.0395460699194221, Train acc: 0.866263440860215\n",
      "Iteration 26000 - Batch 192/1613 - Train loss: 1.0419566526314137, Train acc: 0.8626943005181347\n",
      "Iteration 26100 - Batch 292/1613 - Train loss: 1.040025285486475, Train acc: 0.8647610921501706\n",
      "Iteration 26200 - Batch 392/1613 - Train loss: 1.044679499612813, Train acc: 0.8596533078880407\n",
      "Iteration 26300 - Batch 492/1613 - Train loss: 1.0478511151629093, Train acc: 0.8564274847870182\n",
      "Iteration 26400 - Batch 592/1613 - Train loss: 1.0469063856147394, Train acc: 0.8571880269814502\n",
      "Iteration 26500 - Batch 692/1613 - Train loss: 1.0457995049709194, Train acc: 0.8579545454545454\n",
      "Iteration 26600 - Batch 792/1613 - Train loss: 1.044521936627685, Train acc: 0.8590006305170239\n",
      "Iteration 26700 - Batch 892/1613 - Train loss: 1.044759550927601, Train acc: 0.8588675811870101\n",
      "Iteration 26800 - Batch 992/1613 - Train loss: 1.043944281573742, Train acc: 0.859673967774421\n",
      "Iteration 26900 - Batch 1092/1613 - Train loss: 1.0430519488680177, Train acc: 0.8606758920402562\n",
      "Iteration 27000 - Batch 1192/1613 - Train loss: 1.0430456374936612, Train acc: 0.8607764040234702\n",
      "Iteration 27100 - Batch 1292/1613 - Train loss: 1.0432048560295193, Train acc: 0.8606680201082754\n",
      "Iteration 27200 - Batch 1392/1613 - Train loss: 1.0437851806210685, Train acc: 0.8601489590811199\n",
      "Iteration 27300 - Batch 1492/1613 - Train loss: 1.0440487085934542, Train acc: 0.859908740790355\n",
      "Iteration 27400 - Batch 1592/1613 - Train loss: 1.04418730623529, Train acc: 0.859816384180791\n",
      "[1, 3, 1, 2, 2, 3, 4, 2, 0, 4, 2, 3, 0, 0, 4, 2, 1, 4, 2, 4, 1, 2, 1, 2, 1, 4, 0, 2, 1, 1, 1, 3, 1, 2, 3, 0, 0, 3, 1, 4, 3, 4, 1, 2, 2, 3, 3, 2, 2, 1, 4, 1, 0, 0, 3, 0, 1, 1, 0, 2, 0, 3, 4, 2, 4, 4, 0, 2, 0, 2, 1, 0, 2, 4, 0, 2, 1, 1, 4, 2, 2, 0, 2, 4, 3, 3, 0, 2, 1, 2, 4, 3, 3, 3, 3, 3, 3, 3, 0, 1, 3, 1, 0, 2, 3, 2, 4, 4, 0, 4, 0, 4, 2, 0, 1, 4, 2, 0, 0, 3, 1, 2, 1, 3, 0, 2, 3, 0, 0, 4, 1, 1, 3, 1, 2, 2, 4, 3, 2, 1, 0, 1, 1, 4, 1, 2, 3, 0, 0, 4, 4, 1, 0, 2, 4, 1, 4, 4, 3, 1, 2, 0, 3, 0, 1, 2, 3, 2, 4, 0, 4, 0, 4, 4, 1, 1, 3, 1, 0, 0, 4, 4, 3, 1, 4, 3, 1, 0, 3, 1, 0, 3, 3, 0, 1, 1, 1, 1, 3, 0, 1, 4, 3, 3, 1, 3, 2, 1, 4, 3, 4, 1, 4, 0, 0, 0, 2, 1, 0, 2, 1, 3, 4, 2, 0, 1, 1, 4, 2, 0, 4, 3, 1, 4, 4, 3, 2, 2, 3, 2, 1, 1, 3, 1, 3, 3, 0, 3, 2, 3, 4, 1, 1, 2, 3, 1, 1, 3, 3, 4, 2, 1, 2, 4, 1, 1, 0, 2, 2, 2, 1, 4, 2, 1, 4, 1, 0, 0, 2, 2, 2, 4, 3, 2, 4, 2, 0, 2, 2, 4, 0, 3, 2, 3, 4, 1, 2, 3, 3, 0, 3, 3, 4, 0, 2, 0, 4, 2, 2, 1, 4, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 4, 4, 1, 1, 0, 1, 4, 2, 1, 1, 3, 0, 1, 2, 0, 0, 3, 4, 1, 1, 4, 2, 3, 0, 4, 3, 3, 3, 2, 4, 1, 2, 3, 0, 1, 2, 2, 3, 3, 3, 4, 1, 3, 0, 1, 3, 0, 0, 2, 0, 2, 0, 4, 4, 0, 0, 0, 1, 4, 4, 0, 1, 4, 4, 2, 0, 2, 3, 0, 1, 2, 4, 1, 3, 4, 0, 1, 4, 0, 0, 2, 0, 1, 4, 4, 4, 3, 4, 4, 4, 0, 1, 4, 2, 1, 0, 2, 2, 0, 1, 2, 4, 3, 2, 0, 0, 0, 3, 2, 0, 2, 2, 3, 0, 3, 0, 4, 0, 3, 0, 1, 2, 1, 0, 3, 0, 1, 3, 3, 4, 3, 3, 0, 1, 2, 4, 2, 0, 4, 4, 4, 1, 0, 4, 3, 1, 2, 1, 4, 2, 3, 2, 2, 4, 2, 2, 1, 0, 4, 2, 3, 4, 4, 3, 0, 3, 4, 4, 4, 4, 2, 3, 2, 0, 3, 1, 4, 4, 0]\n",
      "[3, 3, 4, 2, 2, 3, 4, 2, 3, 4, 2, 3, 0, 2, 4, 2, 3, 4, 2, 4, 0, 2, 0, 2, 2, 4, 0, 2, 0, 4, 2, 3, 0, 2, 3, 0, 4, 3, 4, 4, 3, 4, 3, 2, 2, 3, 3, 2, 2, 0, 4, 2, 0, 2, 3, 0, 0, 0, 0, 2, 0, 3, 4, 2, 4, 4, 0, 0, 0, 2, 3, 0, 2, 4, 0, 2, 0, 2, 4, 2, 2, 2, 2, 4, 3, 3, 0, 2, 4, 2, 4, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 4, 0, 2, 3, 2, 2, 4, 0, 4, 0, 2, 2, 0, 0, 4, 2, 0, 0, 3, 4, 2, 4, 3, 0, 2, 3, 0, 0, 4, 3, 3, 3, 2, 2, 2, 4, 3, 2, 4, 0, 4, 4, 4, 4, 2, 3, 0, 0, 4, 4, 4, 0, 2, 4, 0, 4, 3, 3, 4, 2, 0, 3, 0, 3, 2, 3, 0, 3, 4, 4, 0, 4, 4, 4, 4, 3, 3, 0, 0, 2, 4, 3, 0, 4, 3, 4, 0, 3, 0, 0, 3, 3, 0, 4, 3, 2, 3, 3, 0, 4, 4, 3, 3, 3, 3, 2, 4, 3, 3, 4, 0, 4, 2, 0, 0, 2, 0, 0, 2, 0, 3, 4, 2, 0, 3, 4, 2, 2, 2, 4, 3, 3, 4, 4, 4, 2, 2, 3, 2, 2, 0, 3, 3, 3, 3, 0, 2, 2, 3, 4, 2, 4, 2, 3, 4, 4, 3, 3, 4, 2, 3, 2, 4, 3, 0, 0, 4, 0, 0, 4, 4, 2, 4, 4, 0, 0, 0, 2, 0, 2, 4, 3, 0, 4, 2, 0, 2, 0, 4, 0, 3, 2, 4, 3, 4, 0, 3, 3, 2, 3, 3, 4, 0, 0, 0, 4, 0, 2, 4, 4, 3, 2, 3, 3, 0, 3, 4, 3, 0, 3, 4, 4, 0, 4, 2, 3, 2, 2, 3, 3, 3, 2, 3, 2, 0, 0, 3, 4, 4, 2, 4, 2, 3, 2, 4, 3, 3, 3, 2, 4, 4, 2, 3, 0, 3, 2, 2, 3, 3, 3, 0, 0, 3, 0, 4, 3, 0, 0, 2, 0, 2, 2, 4, 0, 0, 0, 0, 3, 4, 4, 0, 3, 4, 4, 2, 0, 2, 3, 0, 0, 2, 4, 4, 4, 4, 0, 0, 4, 0, 0, 0, 2, 3, 4, 4, 4, 3, 4, 4, 4, 2, 4, 3, 2, 3, 2, 2, 2, 2, 3, 0, 4, 3, 2, 0, 2, 0, 3, 2, 0, 2, 2, 3, 0, 3, 0, 4, 0, 3, 0, 2, 2, 0, 0, 4, 0, 3, 3, 3, 4, 2, 3, 0, 0, 3, 4, 2, 0, 4, 4, 3, 3, 0, 4, 3, 4, 2, 4, 4, 3, 3, 2, 2, 4, 2, 2, 4, 0, 4, 2, 3, 4, 4, 3, 0, 3, 4, 4, 4, 4, 0, 3, 2, 3, 3, 4, 4, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.71      0.84      0.77       100\n",
      "           3       0.70      0.93      0.80       100\n",
      "           4       0.66      0.87      0.75       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.55      0.69      0.61       500\n",
      "weighted avg       0.55      0.69      0.61       500\n",
      "\n",
      "Val loss: 1.21063581854105, Val acc: 0.686\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27500 - Batch 79/1613 - Train loss: 1.0357017755508422, Train acc: 0.868359375\n",
      "Iteration 27600 - Batch 179/1613 - Train loss: 1.0417047924465603, Train acc: 0.8616319444444445\n",
      "Iteration 27700 - Batch 279/1613 - Train loss: 1.0367522984743118, Train acc: 0.8671875\n",
      "Iteration 27800 - Batch 379/1613 - Train loss: 1.0376791704642145, Train acc: 0.8664473684210526\n",
      "Iteration 27900 - Batch 479/1613 - Train loss: 1.0415451403707265, Train acc: 0.8624348958333333\n",
      "Iteration 28000 - Batch 579/1613 - Train loss: 1.0425080460721048, Train acc: 0.8612068965517241\n",
      "Iteration 28100 - Batch 679/1613 - Train loss: 1.0426026695791413, Train acc: 0.8610753676470588\n",
      "Iteration 28200 - Batch 779/1613 - Train loss: 1.043157914815805, Train acc: 0.8606570512820513\n",
      "Iteration 28300 - Batch 879/1613 - Train loss: 1.0435770462859761, Train acc: 0.8602272727272727\n",
      "Iteration 28400 - Batch 979/1613 - Train loss: 1.0428074403076755, Train acc: 0.8610969387755102\n",
      "Iteration 28500 - Batch 1079/1613 - Train loss: 1.042880830389482, Train acc: 0.8611689814814815\n",
      "Iteration 28600 - Batch 1179/1613 - Train loss: 1.042410685349319, Train acc: 0.8616525423728814\n",
      "Iteration 28700 - Batch 1279/1613 - Train loss: 1.0425211581867189, Train acc: 0.8614990234375\n",
      "Iteration 28800 - Batch 1379/1613 - Train loss: 1.042732606763425, Train acc: 0.8612998188405797\n",
      "Iteration 28900 - Batch 1479/1613 - Train loss: 1.043006647398343, Train acc: 0.8611275337837838\n",
      "Iteration 29000 - Batch 1579/1613 - Train loss: 1.0426591870905477, Train acc: 0.8614715189873418\n",
      "[2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 2, 3, 1, 1, 3, 2, 3, 0, 1, 3, 1, 4, 3, 3, 3, 0, 0, 1, 0, 0, 0, 1, 3, 3, 4, 4, 2, 0, 3, 4, 2, 4, 2, 3, 4, 0, 4, 2, 1, 2, 0, 2, 4, 4, 3, 3, 1, 3, 2, 3, 0, 2, 1, 0, 3, 4, 0, 3, 4, 2, 0, 0, 2, 2, 1, 1, 0, 1, 3, 3, 0, 3, 4, 3, 1, 4, 4, 0, 4, 3, 2, 4, 1, 1, 2, 0, 1, 4, 4, 1, 4, 0, 4, 0, 0, 4, 1, 0, 0, 3, 1, 3, 0, 4, 1, 3, 3, 3, 4, 0, 3, 3, 3, 1, 3, 2, 4, 4, 4, 0, 1, 1, 1, 4, 4, 1, 3, 0, 3, 4, 4, 4, 3, 2, 1, 3, 0, 1, 1, 2, 1, 0, 3, 2, 1, 1, 4, 3, 1, 3, 2, 1, 1, 0, 4, 2, 0, 1, 0, 0, 1, 0, 4, 0, 1, 2, 3, 2, 3, 4, 0, 0, 3, 1, 4, 2, 1, 2, 0, 0, 4, 3, 2, 4, 0, 1, 2, 2, 1, 2, 0, 3, 3, 4, 4, 0, 4, 1, 4, 1, 1, 0, 0, 2, 4, 1, 2, 3, 0, 3, 0, 1, 2, 3, 4, 1, 4, 2, 0, 4, 2, 2, 1, 2, 4, 3, 2, 1, 1, 2, 0, 3, 0, 1, 0, 4, 0, 1, 0, 3, 2, 1, 4, 0, 4, 1, 1, 4, 2, 4, 0, 4, 3, 2, 2, 4, 2, 4, 4, 3, 0, 4, 1, 4, 2, 3, 4, 4, 2, 0, 1, 1, 2, 1, 1, 2, 2, 2, 2, 4, 1, 1, 1, 0, 2, 2, 2, 0, 3, 0, 3, 2, 1, 4, 2, 4, 0, 2, 0, 4, 1, 3, 3, 1, 0, 3, 4, 0, 0, 4, 4, 2, 1, 1, 0, 0, 1, 2, 0, 3, 2, 3, 2, 4, 3, 1, 4, 0, 3, 0, 1, 2, 4, 2, 4, 3, 2, 1, 0, 3, 2, 1, 4, 4, 3, 3, 3, 1, 2, 4, 4, 3, 0, 1, 1, 2, 3, 3, 2, 2, 3, 0, 4, 2, 4, 3, 1, 4, 0, 2, 1, 2, 3, 2, 0, 1, 1, 3, 1, 2, 4, 4, 1, 2, 4, 0, 0, 0, 3, 2, 0, 1, 4, 0, 3, 4, 1, 2, 3, 0, 0, 1, 0, 1, 2, 0, 2, 2, 2, 4, 2, 3, 2, 1, 1, 3, 3, 2, 4, 1, 0, 2, 4, 4, 1, 1, 0, 3, 4, 3, 2, 2, 1, 3, 0, 1, 2, 1, 4, 2, 3, 2, 4, 0, 0, 4, 2, 2, 4, 3, 4, 0, 0, 3, 0, 1, 1, 4, 0, 4, 1, 0, 4, 3, 3, 2, 3, 4, 4, 4, 0, 2, 3, 2, 1, 0, 3, 4, 0, 2, 3, 3, 2, 1, 0, 0, 0, 3, 1, 0]\n",
      "[2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 0, 3, 2, 3, 0, 3, 0, 4, 4, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3, 4, 4, 2, 0, 3, 4, 2, 4, 2, 3, 4, 0, 4, 2, 0, 2, 0, 2, 4, 4, 3, 3, 0, 3, 2, 3, 0, 2, 4, 0, 3, 4, 0, 3, 4, 2, 0, 0, 2, 2, 4, 2, 0, 4, 3, 3, 0, 3, 4, 3, 4, 4, 4, 0, 4, 3, 2, 4, 3, 2, 2, 4, 2, 4, 4, 4, 4, 3, 0, 0, 2, 4, 4, 0, 0, 3, 3, 3, 0, 4, 4, 3, 3, 3, 4, 0, 4, 3, 3, 4, 3, 2, 4, 2, 4, 2, 4, 4, 4, 4, 4, 3, 3, 0, 4, 4, 4, 4, 4, 2, 4, 3, 0, 4, 3, 2, 3, 0, 4, 2, 3, 3, 4, 3, 4, 3, 2, 2, 4, 0, 4, 0, 2, 4, 0, 0, 0, 0, 4, 0, 0, 2, 3, 2, 3, 4, 0, 0, 3, 4, 4, 2, 0, 3, 0, 0, 4, 3, 2, 4, 0, 4, 0, 0, 4, 0, 4, 3, 3, 4, 4, 0, 4, 3, 4, 4, 3, 0, 0, 2, 4, 4, 2, 3, 0, 3, 0, 3, 2, 3, 4, 3, 4, 2, 0, 4, 2, 2, 4, 2, 4, 3, 2, 0, 4, 0, 0, 3, 0, 4, 2, 4, 0, 3, 0, 3, 0, 3, 4, 4, 4, 4, 3, 4, 2, 4, 0, 4, 3, 2, 2, 4, 0, 4, 4, 3, 0, 4, 3, 4, 2, 3, 4, 4, 2, 0, 2, 3, 2, 4, 0, 2, 0, 2, 2, 4, 3, 3, 4, 0, 2, 2, 4, 0, 3, 0, 3, 2, 4, 4, 2, 4, 0, 2, 0, 4, 4, 4, 3, 0, 0, 3, 4, 0, 0, 4, 4, 2, 0, 4, 0, 0, 3, 2, 0, 3, 2, 4, 2, 4, 3, 4, 4, 0, 3, 0, 4, 2, 4, 2, 4, 3, 3, 3, 0, 3, 0, 4, 4, 4, 3, 3, 3, 0, 2, 4, 3, 3, 2, 4, 4, 0, 3, 3, 2, 0, 3, 0, 4, 2, 4, 3, 4, 4, 0, 3, 0, 2, 3, 2, 0, 3, 3, 3, 3, 2, 4, 4, 0, 2, 4, 0, 0, 0, 3, 2, 0, 3, 4, 0, 4, 4, 3, 2, 3, 0, 0, 0, 0, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 4, 4, 4, 3, 2, 4, 4, 0, 0, 4, 4, 4, 3, 0, 3, 4, 3, 2, 2, 4, 3, 0, 4, 2, 4, 3, 2, 3, 2, 4, 0, 0, 4, 2, 2, 4, 4, 4, 0, 0, 4, 0, 2, 3, 4, 0, 4, 4, 0, 4, 3, 3, 2, 3, 4, 4, 3, 0, 2, 3, 2, 4, 0, 3, 4, 2, 2, 3, 3, 2, 4, 4, 0, 0, 4, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.84      0.85       100\n",
      "           3       0.69      0.88      0.77       100\n",
      "           4       0.60      0.94      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1947750821709633, Val acc: 0.708\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29100 - Batch 66/1613 - Train loss: 1.0368082630100535, Train acc: 0.8652052238805971\n",
      "Iteration 29200 - Batch 166/1613 - Train loss: 1.0404389268623855, Train acc: 0.8630239520958084\n",
      "Iteration 29300 - Batch 266/1613 - Train loss: 1.041704365376676, Train acc: 0.8622425093632958\n",
      "Iteration 29400 - Batch 366/1613 - Train loss: 1.0441202586288347, Train acc: 0.8596730245231607\n",
      "Iteration 29500 - Batch 466/1613 - Train loss: 1.0450232406755076, Train acc: 0.8585385438972163\n",
      "Iteration 29600 - Batch 566/1613 - Train loss: 1.0478843488390484, Train acc: 0.8559854497354498\n",
      "Iteration 29700 - Batch 666/1613 - Train loss: 1.0475399113487804, Train acc: 0.8563062218890555\n",
      "Iteration 29800 - Batch 766/1613 - Train loss: 1.0473397417671522, Train acc: 0.8564618644067796\n",
      "Iteration 29900 - Batch 866/1613 - Train loss: 1.046333346193637, Train acc: 0.857590830449827\n",
      "Iteration 30000 - Batch 966/1613 - Train loss: 1.0451298497825274, Train acc: 0.858712512926577\n",
      "Iteration 30100 - Batch 1066/1613 - Train loss: 1.0446519896932707, Train acc: 0.8591846298031866\n",
      "Iteration 30200 - Batch 1166/1613 - Train loss: 1.044015766977753, Train acc: 0.8599507283633248\n",
      "Iteration 30300 - Batch 1266/1613 - Train loss: 1.0434995242339378, Train acc: 0.8604972375690608\n",
      "Iteration 30400 - Batch 1366/1613 - Train loss: 1.044245792551466, Train acc: 0.8596607534747622\n",
      "Iteration 30500 - Batch 1466/1613 - Train loss: 1.044741772963388, Train acc: 0.8591087252897068\n",
      "Iteration 30600 - Batch 1566/1613 - Train loss: 1.0440271186007004, Train acc: 0.8597838225909381\n",
      "[4, 0, 3, 1, 0, 2, 4, 0, 4, 1, 4, 3, 2, 0, 1, 2, 1, 1, 0, 4, 3, 2, 0, 4, 0, 1, 4, 3, 4, 4, 0, 3, 0, 2, 3, 1, 0, 4, 2, 2, 3, 4, 4, 4, 3, 3, 0, 1, 1, 1, 0, 3, 2, 3, 1, 4, 0, 4, 4, 1, 4, 0, 4, 2, 1, 3, 2, 0, 4, 0, 4, 2, 1, 2, 0, 1, 0, 4, 3, 1, 2, 1, 2, 1, 2, 0, 0, 0, 2, 1, 4, 1, 3, 0, 2, 3, 3, 3, 1, 3, 2, 4, 1, 3, 3, 1, 1, 3, 0, 2, 3, 1, 4, 4, 0, 2, 0, 2, 0, 2, 4, 0, 3, 3, 0, 1, 3, 4, 2, 4, 3, 4, 4, 4, 1, 1, 0, 1, 4, 4, 2, 3, 0, 4, 1, 2, 4, 4, 1, 0, 0, 4, 3, 3, 1, 1, 0, 0, 4, 4, 2, 0, 4, 1, 3, 1, 3, 3, 0, 3, 3, 3, 0, 2, 1, 3, 3, 2, 0, 2, 2, 0, 4, 1, 1, 3, 0, 4, 4, 3, 2, 4, 2, 1, 0, 3, 2, 2, 3, 2, 2, 0, 4, 1, 3, 1, 4, 0, 2, 3, 4, 0, 1, 2, 4, 2, 0, 4, 2, 1, 3, 2, 4, 2, 2, 3, 4, 1, 3, 2, 0, 3, 1, 0, 3, 1, 1, 1, 3, 0, 2, 0, 2, 0, 2, 2, 0, 0, 4, 1, 2, 0, 1, 2, 0, 4, 1, 1, 2, 2, 1, 1, 2, 2, 2, 3, 4, 2, 2, 1, 4, 3, 0, 4, 1, 0, 3, 0, 3, 0, 4, 1, 2, 3, 2, 4, 3, 2, 0, 2, 4, 3, 3, 1, 3, 4, 4, 4, 0, 3, 2, 1, 2, 4, 0, 4, 2, 3, 0, 2, 3, 0, 1, 3, 2, 3, 3, 0, 0, 4, 0, 0, 0, 1, 1, 3, 2, 4, 4, 3, 4, 1, 4, 1, 4, 2, 3, 2, 2, 3, 4, 4, 2, 3, 3, 2, 1, 2, 3, 1, 4, 3, 4, 2, 0, 3, 0, 0, 4, 0, 3, 4, 4, 0, 0, 3, 2, 0, 3, 1, 0, 1, 3, 0, 4, 0, 2, 3, 1, 4, 4, 3, 1, 4, 0, 3, 3, 4, 1, 3, 0, 0, 2, 4, 3, 4, 0, 4, 3, 2, 2, 1, 4, 1, 4, 2, 0, 0, 4, 3, 2, 1, 3, 3, 1, 1, 2, 0, 4, 2, 2, 1, 3, 0, 0, 1, 0, 3, 4, 4, 2, 3, 2, 2, 2, 0, 1, 4, 3, 1, 0, 2, 2, 0, 2, 1, 4, 4, 1, 0, 1, 3, 1, 1, 1, 0, 3, 4, 3, 3, 4, 1, 1, 2, 1, 2, 2, 2, 4, 4, 1, 1, 0, 1, 3, 0, 0, 1, 3, 2, 1, 2, 1, 0, 1, 4, 0, 2, 1, 2, 0, 1, 0, 1, 3, 4, 2, 1, 3, 3]\n",
      "[4, 0, 3, 4, 0, 2, 0, 0, 4, 4, 4, 3, 2, 0, 4, 2, 3, 4, 0, 4, 4, 2, 0, 4, 4, 4, 4, 3, 4, 4, 4, 3, 0, 2, 3, 3, 2, 4, 2, 2, 3, 4, 4, 4, 4, 3, 0, 4, 0, 0, 0, 4, 0, 3, 0, 4, 0, 4, 4, 4, 4, 0, 4, 0, 4, 3, 2, 0, 4, 0, 4, 2, 3, 2, 0, 4, 0, 4, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 3, 4, 3, 3, 0, 2, 3, 3, 3, 0, 3, 2, 4, 4, 3, 3, 3, 3, 3, 0, 2, 3, 4, 4, 4, 0, 0, 0, 2, 0, 2, 4, 0, 3, 3, 2, 0, 4, 4, 0, 3, 3, 4, 4, 4, 0, 3, 0, 4, 4, 4, 2, 3, 0, 4, 0, 0, 4, 4, 4, 0, 0, 4, 3, 3, 4, 4, 0, 0, 3, 4, 0, 0, 4, 0, 3, 4, 4, 3, 0, 3, 3, 3, 0, 2, 2, 3, 3, 0, 0, 2, 2, 0, 4, 0, 4, 3, 2, 4, 4, 3, 2, 4, 0, 4, 0, 3, 2, 2, 4, 4, 2, 0, 4, 0, 3, 4, 4, 0, 2, 3, 4, 0, 4, 2, 4, 2, 0, 4, 2, 0, 3, 2, 4, 2, 2, 3, 4, 3, 3, 2, 0, 3, 0, 0, 3, 4, 0, 3, 3, 0, 2, 0, 2, 0, 2, 0, 0, 4, 4, 4, 3, 0, 0, 2, 0, 4, 4, 3, 2, 2, 4, 4, 2, 2, 2, 3, 4, 2, 0, 3, 4, 3, 0, 4, 4, 0, 3, 0, 3, 0, 4, 4, 2, 3, 2, 4, 3, 2, 2, 2, 4, 3, 3, 3, 3, 4, 4, 4, 0, 3, 0, 3, 2, 4, 0, 4, 2, 3, 0, 2, 3, 0, 4, 3, 2, 3, 4, 0, 0, 4, 0, 0, 0, 4, 3, 3, 2, 4, 4, 3, 4, 4, 2, 4, 4, 2, 3, 2, 2, 3, 4, 4, 0, 3, 3, 0, 0, 2, 3, 4, 4, 0, 4, 0, 0, 3, 4, 0, 4, 0, 3, 4, 4, 0, 0, 3, 2, 0, 3, 4, 0, 3, 3, 0, 4, 0, 2, 4, 3, 4, 4, 3, 4, 4, 0, 3, 4, 4, 4, 4, 0, 4, 2, 4, 3, 4, 0, 4, 3, 0, 2, 4, 4, 0, 4, 2, 0, 0, 4, 4, 2, 4, 3, 3, 4, 3, 2, 0, 4, 2, 2, 0, 3, 0, 0, 4, 4, 4, 4, 4, 2, 3, 2, 2, 2, 0, 0, 4, 3, 3, 0, 2, 0, 0, 2, 4, 4, 4, 4, 2, 3, 3, 3, 3, 0, 0, 3, 4, 4, 3, 4, 0, 4, 3, 3, 2, 2, 2, 4, 4, 4, 4, 0, 2, 3, 0, 0, 4, 3, 2, 0, 2, 4, 0, 4, 4, 0, 0, 4, 0, 0, 4, 0, 3, 3, 4, 2, 4, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.78      0.83       100\n",
      "           3       0.75      0.86      0.80       100\n",
      "           4       0.58      0.96      0.72       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.62       500\n",
      "weighted avg       0.58      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2081595361232758, Val acc: 0.698\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30700 - Batch 53/1613 - Train loss: 1.042114273265556, Train acc: 0.8616898148148148\n",
      "Iteration 30800 - Batch 153/1613 - Train loss: 1.0409701733620136, Train acc: 0.8628246753246753\n",
      "Iteration 30900 - Batch 253/1613 - Train loss: 1.0378428477001942, Train acc: 0.8660187007874016\n",
      "Iteration 31000 - Batch 353/1613 - Train loss: 1.0392080245718445, Train acc: 0.8645833333333334\n",
      "Iteration 31100 - Batch 453/1613 - Train loss: 1.0396762104286497, Train acc: 0.8643997797356828\n",
      "Iteration 31200 - Batch 553/1613 - Train loss: 1.039739784996432, Train acc: 0.8643388989169675\n",
      "Iteration 31300 - Batch 653/1613 - Train loss: 1.0402281088384284, Train acc: 0.8637710244648318\n",
      "Iteration 31400 - Batch 753/1613 - Train loss: 1.0409702275254682, Train acc: 0.8630222148541115\n",
      "Iteration 31500 - Batch 853/1613 - Train loss: 1.041003149622218, Train acc: 0.8630342505854801\n",
      "Iteration 31600 - Batch 953/1613 - Train loss: 1.0413538375615574, Train acc: 0.8625851677148847\n",
      "Iteration 31700 - Batch 1053/1613 - Train loss: 1.041656611031328, Train acc: 0.8622805977229602\n",
      "Iteration 31800 - Batch 1153/1613 - Train loss: 1.0416830839069506, Train acc: 0.8624079289428076\n",
      "Iteration 31900 - Batch 1253/1613 - Train loss: 1.0410455969151888, Train acc: 0.8630382775119617\n",
      "Iteration 32000 - Batch 1353/1613 - Train loss: 1.0414893696720173, Train acc: 0.8626292466765141\n",
      "Iteration 32100 - Batch 1453/1613 - Train loss: 1.0410988409138775, Train acc: 0.8629642365887208\n",
      "Iteration 32200 - Batch 1553/1613 - Train loss: 1.0412119761243597, Train acc: 0.8628338159588159\n",
      "[1, 2, 2, 1, 0, 4, 4, 3, 3, 1, 1, 1, 0, 3, 0, 0, 1, 2, 1, 2, 0, 3, 4, 4, 1, 0, 1, 1, 3, 3, 2, 2, 3, 2, 1, 3, 1, 2, 3, 1, 4, 3, 0, 3, 2, 1, 2, 3, 3, 2, 2, 2, 2, 1, 0, 4, 0, 1, 0, 3, 0, 2, 2, 2, 0, 3, 3, 0, 0, 1, 2, 4, 1, 2, 2, 4, 2, 1, 1, 0, 3, 3, 2, 2, 0, 4, 4, 3, 3, 3, 4, 3, 2, 1, 3, 0, 1, 0, 3, 1, 4, 4, 4, 2, 0, 3, 3, 3, 0, 2, 0, 3, 1, 2, 1, 0, 0, 1, 0, 3, 4, 0, 3, 2, 3, 1, 2, 1, 4, 0, 0, 1, 0, 4, 0, 0, 0, 0, 2, 0, 3, 1, 0, 2, 1, 3, 0, 1, 4, 0, 4, 3, 3, 1, 0, 3, 3, 4, 4, 2, 2, 1, 0, 2, 0, 4, 0, 2, 4, 1, 4, 4, 3, 0, 4, 2, 3, 4, 2, 2, 1, 2, 3, 0, 3, 4, 0, 4, 0, 3, 1, 1, 3, 2, 4, 4, 3, 3, 4, 1, 4, 4, 0, 3, 2, 0, 2, 0, 2, 2, 4, 2, 0, 4, 4, 4, 2, 1, 1, 4, 3, 3, 0, 4, 4, 3, 2, 1, 0, 4, 0, 2, 3, 3, 4, 4, 2, 1, 3, 0, 2, 1, 2, 0, 4, 1, 3, 1, 4, 0, 2, 3, 3, 0, 4, 2, 2, 3, 0, 4, 3, 1, 1, 2, 2, 2, 0, 0, 0, 1, 4, 2, 3, 1, 0, 3, 1, 1, 0, 2, 4, 4, 4, 4, 4, 1, 4, 2, 3, 2, 4, 2, 0, 1, 4, 2, 4, 4, 4, 0, 0, 1, 3, 3, 1, 3, 1, 0, 2, 2, 0, 1, 1, 2, 0, 4, 0, 1, 4, 2, 4, 2, 0, 4, 4, 1, 4, 2, 0, 2, 2, 1, 2, 0, 3, 0, 2, 3, 0, 2, 4, 3, 4, 1, 2, 4, 3, 1, 4, 4, 0, 4, 1, 1, 4, 1, 0, 1, 3, 0, 3, 0, 4, 1, 4, 4, 1, 0, 1, 1, 0, 2, 4, 4, 4, 0, 3, 3, 1, 1, 3, 0, 4, 2, 4, 4, 3, 3, 2, 3, 2, 1, 4, 3, 2, 1, 3, 2, 1, 1, 3, 0, 1, 1, 1, 4, 0, 1, 4, 4, 0, 1, 1, 4, 1, 4, 2, 4, 3, 2, 3, 4, 4, 4, 2, 3, 2, 2, 0, 4, 4, 1, 3, 0, 0, 3, 2, 3, 4, 0, 2, 1, 2, 1, 3, 1, 3, 1, 1, 1, 0, 3, 2, 2, 4, 0, 3, 2, 2, 0, 2, 3, 1, 2, 3, 1, 2, 2, 0, 0, 4, 1, 3, 0, 0, 1, 0, 3, 4, 0, 2, 3, 3, 3, 4, 3, 3, 3, 2, 1, 4, 3, 0, 1, 1, 3, 0, 0, 1, 2]\n",
      "[3, 2, 2, 4, 0, 2, 4, 3, 3, 2, 2, 4, 2, 3, 0, 0, 4, 2, 0, 2, 0, 3, 4, 4, 4, 0, 4, 0, 3, 4, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 4, 3, 0, 3, 2, 3, 2, 3, 3, 2, 2, 2, 2, 0, 0, 4, 0, 3, 0, 3, 0, 2, 0, 0, 3, 2, 3, 4, 0, 4, 2, 4, 4, 0, 0, 4, 0, 3, 4, 4, 0, 4, 2, 2, 0, 4, 4, 3, 3, 3, 4, 3, 0, 4, 3, 0, 3, 4, 4, 4, 4, 4, 4, 2, 0, 3, 3, 3, 0, 2, 0, 3, 0, 2, 0, 0, 0, 2, 0, 3, 4, 0, 4, 2, 3, 3, 0, 4, 4, 0, 0, 3, 4, 2, 0, 0, 0, 0, 2, 2, 3, 4, 0, 2, 4, 4, 0, 4, 4, 2, 4, 4, 3, 0, 0, 3, 4, 4, 4, 0, 2, 4, 0, 0, 2, 4, 0, 2, 4, 2, 4, 4, 3, 0, 4, 2, 4, 4, 2, 2, 3, 2, 3, 0, 3, 4, 0, 4, 0, 3, 4, 2, 3, 2, 4, 4, 3, 3, 4, 0, 4, 4, 0, 3, 2, 0, 3, 4, 2, 2, 4, 0, 0, 4, 4, 4, 2, 4, 0, 4, 3, 3, 0, 4, 4, 3, 2, 0, 0, 4, 0, 2, 3, 3, 4, 4, 2, 4, 3, 2, 2, 4, 3, 0, 4, 3, 3, 2, 4, 0, 2, 3, 3, 0, 4, 2, 2, 3, 2, 4, 3, 0, 2, 2, 2, 3, 0, 0, 0, 4, 4, 2, 3, 0, 0, 3, 0, 0, 0, 2, 4, 4, 4, 4, 4, 3, 4, 2, 3, 2, 2, 2, 0, 3, 4, 2, 4, 4, 4, 2, 0, 4, 3, 3, 3, 3, 4, 0, 2, 2, 0, 3, 4, 2, 0, 4, 0, 2, 4, 2, 4, 2, 0, 4, 4, 4, 3, 2, 0, 2, 2, 3, 2, 0, 3, 0, 2, 3, 0, 2, 4, 3, 4, 4, 2, 4, 3, 4, 4, 4, 0, 4, 4, 4, 2, 4, 0, 0, 3, 2, 3, 0, 4, 4, 4, 4, 3, 0, 4, 4, 2, 2, 4, 4, 4, 0, 4, 3, 3, 2, 3, 2, 4, 0, 4, 3, 3, 3, 2, 4, 2, 4, 4, 3, 2, 3, 3, 2, 4, 4, 3, 0, 4, 3, 4, 4, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 3, 2, 4, 4, 4, 4, 2, 3, 2, 0, 2, 4, 4, 4, 3, 0, 0, 3, 2, 3, 4, 0, 2, 4, 2, 4, 3, 4, 3, 2, 3, 4, 0, 3, 0, 2, 4, 0, 3, 2, 2, 2, 2, 3, 0, 2, 3, 4, 2, 2, 0, 0, 4, 4, 3, 0, 0, 3, 0, 3, 4, 0, 2, 3, 3, 3, 4, 3, 3, 3, 2, 4, 4, 3, 0, 4, 4, 3, 0, 0, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.74      0.84      0.79       100\n",
      "           3       0.76      0.87      0.81       100\n",
      "           4       0.58      0.93      0.71       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.56      0.69      0.62       500\n",
      "weighted avg       0.56      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2073258236050606, Val acc: 0.69\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32300 - Batch 40/1613 - Train loss: 1.0413905135015162, Train acc: 0.8612804878048781\n",
      "Iteration 32400 - Batch 140/1613 - Train loss: 1.0368912541274484, Train acc: 0.867686170212766\n",
      "Iteration 32500 - Batch 240/1613 - Train loss: 1.0367754532093825, Train acc: 0.8676089211618258\n",
      "Iteration 32600 - Batch 340/1613 - Train loss: 1.0358688231787023, Train acc: 0.8688599706744868\n",
      "Iteration 32700 - Batch 440/1613 - Train loss: 1.0335760493667758, Train acc: 0.8709608843537415\n",
      "Iteration 32800 - Batch 540/1613 - Train loss: 1.033914788703601, Train acc: 0.8707255083179297\n",
      "Iteration 32900 - Batch 640/1613 - Train loss: 1.03499789859129, Train acc: 0.8695397815912637\n",
      "Iteration 33000 - Batch 740/1613 - Train loss: 1.0351152925195322, Train acc: 0.8693066801619433\n",
      "Iteration 33100 - Batch 840/1613 - Train loss: 1.0354522857172737, Train acc: 0.8689060642092746\n",
      "Iteration 33200 - Batch 940/1613 - Train loss: 1.0358813562758038, Train acc: 0.8684245483528161\n",
      "Iteration 33300 - Batch 1040/1613 - Train loss: 1.0380963574912432, Train acc: 0.8660842939481268\n",
      "Iteration 33400 - Batch 1140/1613 - Train loss: 1.0396260944089797, Train acc: 0.8645376862401403\n",
      "Iteration 33500 - Batch 1240/1613 - Train loss: 1.0404575234166467, Train acc: 0.8636684125705076\n",
      "Iteration 33600 - Batch 1340/1613 - Train loss: 1.04024943071546, Train acc: 0.8637677106636839\n",
      "Iteration 33700 - Batch 1440/1613 - Train loss: 1.0398754233456915, Train acc: 0.8642652671755725\n",
      "Iteration 33800 - Batch 1540/1613 - Train loss: 1.0390398442397095, Train acc: 0.8651443867618429\n",
      "[2, 2, 2, 4, 1, 1, 2, 4, 3, 4, 1, 2, 3, 2, 3, 0, 0, 3, 2, 0, 3, 3, 1, 2, 0, 2, 2, 2, 2, 0, 3, 4, 0, 3, 0, 0, 3, 0, 2, 2, 1, 2, 4, 1, 3, 3, 1, 2, 0, 3, 1, 3, 0, 0, 2, 2, 4, 3, 4, 2, 4, 4, 2, 4, 3, 0, 3, 0, 1, 3, 0, 4, 1, 4, 2, 1, 1, 3, 1, 1, 2, 3, 4, 2, 2, 2, 1, 1, 2, 2, 1, 3, 0, 2, 3, 3, 2, 2, 2, 2, 1, 4, 3, 3, 1, 0, 2, 4, 1, 2, 3, 0, 1, 1, 0, 3, 2, 3, 0, 1, 0, 2, 0, 2, 2, 0, 2, 4, 4, 2, 0, 3, 1, 1, 1, 4, 2, 0, 4, 3, 2, 3, 1, 1, 3, 3, 1, 3, 4, 0, 1, 1, 1, 1, 0, 4, 2, 3, 1, 1, 3, 0, 3, 0, 4, 0, 1, 2, 2, 1, 3, 1, 0, 4, 3, 2, 1, 3, 3, 4, 1, 3, 2, 3, 2, 4, 3, 4, 2, 0, 4, 2, 0, 3, 2, 0, 3, 3, 0, 4, 0, 0, 4, 3, 4, 3, 1, 1, 4, 1, 3, 4, 1, 0, 4, 4, 4, 3, 3, 4, 4, 1, 3, 4, 3, 0, 0, 2, 4, 3, 2, 1, 4, 0, 3, 0, 3, 0, 4, 0, 2, 4, 1, 4, 3, 0, 3, 1, 3, 4, 0, 1, 0, 3, 1, 4, 0, 4, 2, 1, 2, 0, 3, 1, 3, 4, 3, 4, 2, 0, 4, 0, 0, 2, 4, 3, 0, 1, 0, 4, 4, 2, 4, 1, 4, 1, 0, 4, 1, 2, 0, 1, 1, 4, 1, 4, 1, 0, 2, 4, 2, 2, 1, 1, 2, 4, 3, 4, 1, 1, 0, 1, 4, 2, 1, 1, 1, 1, 3, 2, 3, 4, 4, 3, 3, 1, 0, 3, 0, 2, 4, 1, 1, 4, 1, 3, 4, 3, 4, 0, 4, 1, 2, 2, 2, 3, 4, 4, 2, 0, 1, 4, 0, 3, 1, 4, 1, 3, 1, 1, 2, 0, 4, 0, 3, 0, 1, 0, 1, 4, 2, 0, 0, 0, 3, 3, 4, 1, 3, 3, 2, 0, 2, 0, 4, 3, 3, 2, 4, 2, 1, 2, 2, 3, 3, 1, 2, 2, 4, 2, 2, 3, 3, 3, 3, 3, 1, 1, 0, 1, 0, 1, 0, 4, 4, 2, 2, 2, 0, 0, 0, 1, 2, 3, 2, 2, 4, 0, 1, 1, 0, 4, 0, 0, 0, 2, 4, 0, 0, 3, 0, 0, 4, 3, 0, 2, 1, 4, 1, 0, 2, 2, 0, 0, 3, 4, 0, 1, 0, 1, 1, 4, 4, 4, 2, 3, 3, 4, 4, 4, 2, 1, 3, 4, 1, 3, 4, 0, 0, 1, 4, 2, 2, 0, 2, 3, 4, 0, 4, 2, 4, 3, 2, 0, 0, 1, 0, 3, 4, 4]\n",
      "[2, 2, 2, 4, 0, 4, 2, 4, 3, 4, 4, 2, 3, 2, 3, 0, 0, 3, 2, 0, 3, 4, 2, 0, 0, 0, 2, 4, 2, 4, 3, 0, 0, 3, 0, 0, 3, 0, 2, 2, 3, 2, 4, 0, 3, 3, 4, 0, 0, 3, 4, 3, 0, 0, 2, 2, 4, 3, 4, 2, 4, 4, 3, 4, 0, 0, 3, 0, 4, 3, 0, 4, 4, 4, 2, 4, 3, 3, 3, 4, 2, 3, 4, 2, 0, 2, 4, 4, 2, 2, 4, 3, 0, 0, 3, 3, 2, 0, 2, 0, 4, 4, 4, 3, 4, 4, 2, 4, 0, 2, 3, 0, 0, 4, 0, 3, 2, 3, 0, 0, 0, 2, 0, 2, 2, 0, 2, 4, 4, 2, 0, 3, 0, 3, 4, 4, 2, 0, 4, 3, 2, 3, 3, 4, 3, 3, 2, 3, 2, 0, 4, 4, 2, 0, 0, 4, 2, 4, 4, 4, 3, 0, 3, 0, 4, 0, 3, 2, 2, 3, 3, 3, 0, 4, 3, 0, 3, 3, 3, 4, 3, 3, 2, 3, 2, 4, 3, 4, 2, 0, 4, 2, 0, 3, 2, 0, 3, 3, 0, 4, 0, 0, 4, 3, 4, 3, 4, 0, 4, 4, 3, 4, 4, 0, 4, 4, 4, 3, 3, 4, 4, 0, 3, 4, 3, 0, 0, 2, 4, 3, 0, 4, 4, 0, 3, 4, 3, 0, 3, 0, 2, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 0, 0, 3, 4, 4, 0, 4, 2, 3, 2, 0, 3, 0, 3, 4, 3, 4, 0, 0, 4, 0, 0, 2, 4, 3, 0, 4, 0, 4, 4, 2, 4, 0, 4, 3, 0, 4, 4, 2, 0, 4, 4, 3, 4, 4, 3, 0, 2, 4, 2, 2, 2, 3, 2, 4, 3, 4, 4, 3, 0, 4, 4, 2, 3, 3, 4, 0, 3, 2, 3, 3, 4, 3, 3, 3, 0, 3, 0, 2, 4, 4, 0, 4, 3, 3, 4, 3, 4, 0, 4, 4, 4, 2, 2, 3, 4, 4, 2, 0, 3, 4, 0, 3, 4, 4, 4, 4, 4, 3, 0, 0, 4, 3, 3, 0, 3, 0, 4, 4, 2, 4, 0, 4, 4, 3, 4, 4, 3, 3, 2, 0, 2, 0, 3, 3, 3, 0, 4, 2, 0, 2, 2, 3, 3, 4, 2, 2, 4, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 3, 0, 4, 0, 4, 4, 4, 2, 2, 0, 0, 0, 3, 2, 3, 2, 2, 4, 0, 3, 4, 0, 4, 0, 0, 0, 2, 4, 0, 0, 3, 0, 0, 4, 3, 0, 2, 2, 4, 3, 0, 0, 2, 0, 0, 3, 4, 0, 4, 0, 4, 4, 4, 4, 4, 0, 3, 3, 4, 3, 4, 2, 0, 3, 4, 0, 3, 3, 0, 2, 0, 4, 0, 2, 0, 2, 3, 4, 0, 4, 2, 4, 3, 2, 0, 0, 4, 0, 3, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.92      0.81      0.86       100\n",
      "           3       0.73      0.94      0.82       100\n",
      "           4       0.59      0.92      0.72       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1833102703094482, Val acc: 0.716\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33900 - Batch 27/1613 - Train loss: 1.0423916833741325, Train acc: 0.8604910714285714\n",
      "Iteration 34000 - Batch 127/1613 - Train loss: 1.0386853641830385, Train acc: 0.8642578125\n",
      "Iteration 34100 - Batch 227/1613 - Train loss: 1.0349376695720773, Train acc: 0.868421052631579\n",
      "Iteration 34200 - Batch 327/1613 - Train loss: 1.0351301478903467, Train acc: 0.868235518292683\n",
      "Iteration 34300 - Batch 427/1613 - Train loss: 1.0344251562780309, Train acc: 0.8689398364485982\n",
      "Iteration 34400 - Batch 527/1613 - Train loss: 1.0350127931345592, Train acc: 0.8683120265151515\n",
      "Iteration 34500 - Batch 627/1613 - Train loss: 1.0345921314256206, Train acc: 0.8687798566878981\n",
      "Iteration 34600 - Batch 727/1613 - Train loss: 1.0349626695880523, Train acc: 0.8684323489010989\n",
      "Iteration 34700 - Batch 827/1613 - Train loss: 1.0357502048862153, Train acc: 0.867602657004831\n",
      "Iteration 34800 - Batch 927/1613 - Train loss: 1.036011525975733, Train acc: 0.8673558728448276\n",
      "Iteration 34900 - Batch 1027/1613 - Train loss: 1.0370368996366917, Train acc: 0.8664275291828794\n",
      "Iteration 35000 - Batch 1127/1613 - Train loss: 1.03764660487361, Train acc: 0.8658577127659575\n",
      "Iteration 35100 - Batch 1227/1613 - Train loss: 1.0380601789741641, Train acc: 0.865558835504886\n",
      "Iteration 35200 - Batch 1327/1613 - Train loss: 1.0384695958570545, Train acc: 0.865234375\n",
      "Iteration 35300 - Batch 1427/1613 - Train loss: 1.0386319115382283, Train acc: 0.8651741946778712\n",
      "Iteration 35400 - Batch 1527/1613 - Train loss: 1.0386721602207079, Train acc: 0.8651832460732984\n",
      "[0, 1, 2, 3, 0, 2, 1, 2, 4, 3, 0, 3, 2, 1, 4, 3, 1, 1, 3, 2, 1, 0, 0, 1, 0, 1, 4, 0, 2, 4, 4, 0, 1, 2, 4, 2, 1, 4, 2, 4, 2, 1, 4, 0, 3, 4, 0, 4, 2, 2, 4, 4, 4, 0, 0, 0, 0, 4, 2, 1, 3, 1, 1, 0, 2, 3, 4, 2, 0, 3, 2, 0, 4, 1, 1, 4, 1, 4, 3, 3, 1, 0, 0, 4, 2, 1, 3, 1, 4, 1, 1, 0, 3, 0, 0, 2, 1, 4, 0, 3, 1, 0, 4, 3, 0, 4, 3, 3, 1, 2, 4, 3, 1, 1, 2, 2, 2, 3, 4, 1, 1, 4, 1, 4, 4, 2, 3, 3, 0, 1, 1, 0, 4, 3, 3, 2, 3, 4, 4, 0, 4, 2, 1, 0, 0, 1, 3, 3, 4, 3, 1, 4, 0, 2, 2, 3, 0, 1, 4, 4, 3, 4, 3, 2, 4, 1, 0, 3, 3, 1, 0, 1, 4, 2, 3, 3, 2, 3, 2, 3, 2, 2, 4, 0, 4, 3, 1, 3, 0, 1, 0, 3, 2, 4, 3, 2, 2, 1, 4, 1, 0, 2, 0, 2, 3, 4, 1, 1, 4, 4, 1, 0, 3, 1, 2, 3, 0, 3, 3, 2, 1, 1, 2, 2, 2, 0, 2, 2, 0, 0, 3, 3, 4, 4, 2, 0, 4, 3, 4, 3, 0, 0, 2, 1, 0, 0, 1, 2, 0, 0, 1, 3, 2, 3, 4, 1, 0, 1, 2, 2, 1, 2, 3, 2, 0, 1, 2, 0, 0, 0, 1, 1, 1, 4, 4, 3, 3, 2, 3, 1, 3, 4, 4, 4, 3, 4, 4, 1, 0, 2, 0, 1, 3, 1, 2, 3, 0, 1, 4, 4, 2, 3, 1, 3, 0, 2, 4, 3, 3, 3, 1, 4, 3, 2, 1, 0, 4, 4, 1, 0, 2, 1, 2, 1, 0, 4, 0, 1, 0, 3, 0, 2, 2, 1, 3, 2, 2, 4, 3, 2, 4, 1, 2, 2, 1, 3, 0, 2, 1, 2, 3, 0, 0, 0, 2, 4, 1, 3, 3, 3, 4, 4, 4, 2, 0, 3, 1, 0, 0, 4, 2, 2, 2, 0, 1, 2, 3, 3, 3, 2, 2, 0, 0, 3, 1, 2, 3, 4, 3, 2, 4, 4, 2, 4, 2, 2, 0, 3, 4, 3, 3, 1, 3, 4, 1, 0, 1, 0, 0, 4, 4, 1, 2, 3, 4, 0, 4, 2, 0, 0, 4, 0, 1, 2, 3, 2, 1, 2, 1, 2, 4, 3, 0, 4, 1, 4, 4, 1, 3, 0, 0, 4, 2, 4, 4, 1, 2, 3, 1, 3, 4, 4, 2, 4, 0, 1, 3, 0, 4, 3, 0, 1, 3, 3, 3, 1, 3, 0, 4, 1, 2, 4, 1, 4, 4, 0, 0, 4, 2, 1, 2, 0, 0, 2, 0, 3, 3, 2, 3, 1, 0, 1, 0, 1, 0, 2, 1, 3, 2, 0]\n",
      "[0, 4, 2, 3, 0, 2, 0, 0, 4, 3, 0, 3, 2, 0, 4, 3, 4, 0, 3, 2, 4, 0, 0, 0, 0, 0, 3, 0, 2, 4, 4, 0, 2, 2, 4, 0, 3, 2, 2, 4, 2, 2, 4, 0, 3, 4, 0, 4, 2, 2, 4, 4, 4, 0, 0, 0, 0, 4, 2, 3, 3, 3, 3, 0, 2, 3, 4, 2, 0, 3, 2, 0, 4, 0, 3, 4, 3, 4, 3, 3, 0, 0, 2, 4, 2, 4, 2, 4, 4, 3, 3, 0, 3, 0, 0, 2, 3, 4, 2, 3, 0, 0, 3, 3, 0, 4, 3, 3, 4, 2, 4, 3, 0, 3, 2, 2, 2, 3, 4, 4, 4, 4, 3, 4, 4, 2, 3, 4, 0, 0, 2, 0, 4, 3, 3, 2, 3, 0, 4, 0, 4, 2, 0, 0, 0, 4, 3, 3, 4, 3, 4, 4, 0, 2, 0, 4, 4, 0, 4, 4, 3, 4, 4, 0, 4, 4, 0, 3, 3, 4, 0, 0, 4, 2, 3, 3, 2, 3, 2, 3, 2, 2, 4, 0, 4, 3, 0, 4, 0, 3, 0, 3, 2, 4, 3, 2, 2, 4, 4, 4, 0, 0, 0, 2, 3, 4, 4, 4, 4, 4, 4, 0, 3, 3, 2, 3, 0, 3, 3, 2, 3, 0, 2, 2, 0, 0, 2, 2, 0, 0, 3, 3, 4, 4, 2, 4, 4, 3, 4, 3, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 3, 3, 2, 3, 4, 3, 0, 2, 2, 2, 4, 2, 3, 2, 0, 4, 0, 0, 0, 0, 4, 4, 4, 4, 4, 3, 3, 2, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 4, 3, 4, 0, 3, 0, 3, 4, 4, 2, 3, 4, 3, 0, 2, 4, 0, 3, 3, 2, 4, 3, 2, 4, 0, 4, 4, 4, 0, 2, 4, 2, 4, 0, 3, 0, 0, 4, 3, 0, 2, 2, 0, 3, 2, 2, 4, 3, 2, 4, 0, 2, 2, 4, 3, 0, 0, 4, 0, 3, 0, 0, 0, 2, 4, 4, 3, 3, 3, 4, 4, 4, 2, 0, 3, 2, 0, 0, 4, 2, 2, 2, 0, 0, 2, 3, 3, 2, 2, 2, 0, 0, 3, 4, 2, 3, 4, 3, 2, 3, 4, 0, 4, 2, 0, 0, 3, 4, 3, 3, 0, 3, 4, 4, 0, 4, 0, 0, 4, 4, 0, 2, 3, 4, 2, 4, 0, 0, 0, 4, 0, 3, 2, 4, 2, 3, 2, 0, 2, 4, 3, 0, 4, 3, 4, 4, 0, 3, 0, 0, 4, 2, 4, 4, 4, 2, 3, 0, 3, 4, 4, 2, 4, 0, 4, 3, 0, 4, 3, 0, 3, 3, 3, 3, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 0, 0, 4, 2, 4, 2, 0, 0, 2, 0, 3, 3, 3, 3, 4, 0, 4, 0, 3, 4, 2, 0, 3, 2, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.84      0.86       100\n",
      "           3       0.77      0.91      0.83       100\n",
      "           4       0.62      0.94      0.75       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1805544570088387, Val acc: 0.722\n",
      "Epoch 23/30\n",
      "Iteration 35500 - Batch 14/1613 - Train loss: 1.0207396467526755, Train acc: 0.88125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35600 - Batch 114/1613 - Train loss: 1.037411353899085, Train acc: 0.8660326086956521\n",
      "Iteration 35700 - Batch 214/1613 - Train loss: 1.0393291495567145, Train acc: 0.864389534883721\n",
      "Iteration 35800 - Batch 314/1613 - Train loss: 1.0361530818636455, Train acc: 0.8674603174603175\n",
      "Iteration 35900 - Batch 414/1613 - Train loss: 1.0327743745711913, Train acc: 0.8711596385542169\n",
      "Iteration 36000 - Batch 514/1613 - Train loss: 1.0357355492786295, Train acc: 0.8679004854368932\n",
      "Iteration 36100 - Batch 614/1613 - Train loss: 1.0368562151746052, Train acc: 0.8669207317073171\n",
      "Iteration 36200 - Batch 714/1613 - Train loss: 1.0353337541326777, Train acc: 0.8684003496503496\n",
      "Iteration 36300 - Batch 814/1613 - Train loss: 1.0349604353582933, Train acc: 0.8688650306748467\n",
      "Iteration 36400 - Batch 914/1613 - Train loss: 1.0362516872869814, Train acc: 0.8675887978142076\n",
      "Iteration 36500 - Batch 1014/1613 - Train loss: 1.0358381333022282, Train acc: 0.8678879310344828\n",
      "Iteration 36600 - Batch 1114/1613 - Train loss: 1.0359195284244727, Train acc: 0.8677410313901345\n",
      "Iteration 36700 - Batch 1214/1613 - Train loss: 1.0365167159602475, Train acc: 0.8672839506172839\n",
      "Iteration 36800 - Batch 1314/1613 - Train loss: 1.0366627109821305, Train acc: 0.867134030418251\n",
      "Iteration 36900 - Batch 1414/1613 - Train loss: 1.037350886575746, Train acc: 0.866386925795053\n",
      "Iteration 37000 - Batch 1514/1613 - Train loss: 1.0374800425158082, Train acc: 0.8663366336633663\n",
      "[3, 1, 0, 2, 1, 4, 4, 0, 0, 3, 0, 1, 3, 2, 3, 3, 2, 4, 1, 0, 3, 0, 2, 3, 4, 4, 4, 2, 4, 1, 0, 0, 0, 2, 4, 2, 2, 3, 4, 4, 4, 4, 2, 1, 0, 3, 3, 4, 2, 4, 1, 4, 3, 2, 2, 2, 0, 3, 2, 4, 2, 1, 0, 2, 4, 3, 1, 4, 0, 0, 3, 1, 0, 1, 2, 1, 2, 2, 2, 4, 0, 3, 0, 1, 3, 0, 3, 4, 0, 4, 0, 0, 3, 1, 1, 1, 3, 3, 3, 4, 2, 4, 0, 3, 0, 1, 1, 3, 1, 1, 3, 3, 0, 3, 2, 3, 1, 0, 1, 3, 4, 1, 1, 4, 2, 2, 2, 0, 1, 1, 1, 4, 2, 4, 3, 1, 0, 1, 1, 0, 0, 0, 3, 3, 0, 4, 2, 0, 0, 1, 1, 1, 3, 3, 1, 0, 3, 4, 0, 2, 4, 4, 0, 1, 3, 4, 3, 4, 1, 1, 2, 2, 4, 2, 1, 3, 4, 1, 3, 0, 0, 0, 4, 0, 3, 2, 1, 1, 0, 1, 2, 2, 4, 0, 4, 2, 0, 3, 0, 0, 1, 4, 1, 4, 4, 3, 4, 3, 1, 3, 3, 1, 1, 4, 0, 3, 1, 4, 4, 2, 1, 2, 0, 2, 1, 4, 1, 0, 2, 4, 0, 2, 2, 1, 0, 0, 4, 2, 2, 3, 2, 1, 4, 1, 1, 1, 0, 2, 3, 1, 4, 2, 3, 2, 3, 0, 3, 0, 3, 4, 2, 0, 0, 1, 2, 2, 3, 1, 4, 2, 2, 3, 2, 3, 0, 1, 0, 1, 2, 4, 1, 3, 4, 4, 0, 3, 4, 4, 1, 2, 3, 0, 4, 3, 1, 2, 0, 0, 4, 0, 0, 0, 4, 1, 2, 0, 1, 3, 1, 3, 3, 1, 2, 3, 4, 4, 0, 2, 2, 2, 1, 1, 0, 4, 4, 0, 4, 2, 2, 2, 1, 3, 0, 0, 0, 2, 3, 3, 4, 3, 0, 0, 1, 2, 0, 1, 1, 3, 0, 3, 1, 3, 4, 3, 4, 2, 1, 0, 2, 0, 0, 3, 2, 2, 3, 4, 2, 0, 2, 2, 4, 3, 2, 0, 2, 2, 3, 2, 1, 2, 1, 0, 3, 0, 1, 4, 4, 4, 3, 1, 4, 4, 1, 0, 4, 1, 4, 2, 2, 4, 3, 1, 0, 4, 3, 3, 3, 2, 4, 4, 1, 4, 2, 4, 4, 2, 3, 3, 4, 0, 1, 1, 3, 0, 3, 0, 4, 4, 0, 2, 3, 0, 4, 1, 1, 2, 2, 0, 0, 4, 2, 1, 2, 2, 2, 1, 4, 3, 4, 0, 1, 4, 1, 3, 1, 4, 1, 3, 3, 3, 4, 3, 2, 4, 3, 1, 0, 1, 2, 3, 0, 0, 0, 2, 2, 0, 4, 2, 3, 4, 3, 3, 4, 2, 3, 2, 4, 2, 1, 1, 1, 0, 0, 2, 3, 2, 3, 1, 4, 3]\n",
      "[3, 4, 0, 2, 0, 4, 4, 2, 0, 4, 0, 4, 3, 2, 3, 3, 2, 4, 3, 0, 3, 0, 2, 3, 4, 3, 4, 2, 4, 3, 0, 0, 0, 0, 3, 2, 2, 3, 4, 4, 4, 4, 2, 3, 0, 3, 3, 4, 0, 4, 4, 4, 3, 2, 2, 0, 0, 3, 2, 4, 2, 3, 0, 2, 3, 3, 4, 4, 0, 0, 3, 3, 0, 3, 0, 3, 2, 2, 2, 3, 0, 3, 0, 3, 3, 0, 3, 4, 0, 4, 0, 0, 3, 3, 3, 4, 3, 3, 3, 4, 2, 2, 0, 3, 0, 3, 4, 3, 4, 3, 3, 3, 4, 4, 2, 3, 3, 0, 4, 3, 4, 4, 3, 4, 2, 2, 4, 0, 0, 4, 3, 4, 2, 4, 3, 4, 0, 4, 4, 0, 0, 0, 3, 4, 4, 4, 2, 0, 0, 4, 4, 4, 3, 3, 4, 0, 3, 4, 0, 2, 4, 4, 0, 4, 3, 4, 3, 4, 4, 4, 2, 2, 4, 2, 2, 3, 4, 3, 3, 0, 0, 0, 4, 0, 3, 2, 4, 3, 0, 4, 2, 0, 4, 0, 4, 2, 0, 3, 2, 0, 0, 0, 4, 4, 0, 3, 4, 3, 4, 3, 3, 4, 4, 4, 0, 3, 3, 4, 4, 2, 4, 0, 0, 2, 4, 4, 4, 0, 2, 4, 0, 2, 2, 4, 0, 0, 4, 2, 0, 3, 2, 4, 4, 4, 0, 0, 0, 2, 3, 0, 4, 2, 4, 2, 3, 0, 3, 0, 3, 4, 3, 0, 0, 0, 2, 2, 3, 2, 4, 0, 4, 3, 2, 3, 0, 4, 0, 3, 2, 4, 0, 3, 4, 4, 0, 3, 4, 4, 4, 2, 3, 0, 4, 3, 2, 2, 0, 0, 4, 0, 2, 0, 4, 0, 0, 0, 0, 3, 2, 3, 3, 0, 2, 3, 4, 4, 0, 2, 2, 3, 2, 0, 0, 4, 2, 0, 4, 2, 2, 0, 4, 3, 0, 0, 0, 2, 3, 3, 4, 3, 0, 0, 0, 2, 0, 4, 3, 3, 0, 3, 4, 3, 4, 4, 4, 2, 3, 0, 2, 0, 0, 3, 2, 2, 3, 4, 2, 0, 2, 2, 4, 3, 2, 0, 0, 2, 3, 2, 2, 2, 4, 4, 3, 4, 0, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 4, 2, 2, 4, 3, 4, 0, 4, 4, 3, 3, 0, 4, 4, 4, 4, 2, 4, 4, 2, 3, 3, 4, 0, 3, 2, 3, 0, 3, 0, 4, 4, 0, 2, 3, 0, 4, 4, 3, 2, 2, 0, 0, 4, 2, 3, 2, 2, 2, 0, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 3, 3, 3, 4, 3, 2, 4, 3, 4, 0, 3, 2, 3, 0, 2, 0, 2, 2, 0, 4, 2, 3, 4, 3, 3, 4, 2, 3, 2, 4, 2, 0, 4, 3, 0, 0, 0, 3, 2, 3, 4, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.83      0.85       100\n",
      "           3       0.74      0.93      0.82       100\n",
      "           4       0.59      0.92      0.72       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1860291510820389, Val acc: 0.718\n",
      "Epoch 24/30\n",
      "Iteration 37100 - Batch 1/1613 - Train loss: 1.0301280617713928, Train acc: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37200 - Batch 101/1613 - Train loss: 1.042053362902473, Train acc: 0.8633578431372549\n",
      "Iteration 37300 - Batch 201/1613 - Train loss: 1.0425235605475927, Train acc: 0.8623143564356436\n",
      "Iteration 37400 - Batch 301/1613 - Train loss: 1.0418747663497925, Train acc: 0.8626862582781457\n",
      "Iteration 37500 - Batch 401/1613 - Train loss: 1.0393278186594075, Train acc: 0.865282960199005\n",
      "Iteration 37600 - Batch 501/1613 - Train loss: 1.0381726949100951, Train acc: 0.8662848605577689\n",
      "Iteration 37700 - Batch 601/1613 - Train loss: 1.0360402191596174, Train acc: 0.8683554817275747\n",
      "Iteration 37800 - Batch 701/1613 - Train loss: 1.0367592132499075, Train acc: 0.8676103988603988\n",
      "Iteration 37900 - Batch 801/1613 - Train loss: 1.0370565443264874, Train acc: 0.8672069825436409\n",
      "Iteration 38000 - Batch 901/1613 - Train loss: 1.0366026928974625, Train acc: 0.8677591463414634\n",
      "Iteration 38100 - Batch 1001/1613 - Train loss: 1.0359712384061186, Train acc: 0.8682322854291418\n",
      "Iteration 38200 - Batch 1101/1613 - Train loss: 1.0361070964492167, Train acc: 0.8680524047186933\n",
      "Iteration 38300 - Batch 1201/1613 - Train loss: 1.0364323370964477, Train acc: 0.8678764559068219\n",
      "Iteration 38400 - Batch 1301/1613 - Train loss: 1.0363049271377733, Train acc: 0.8679195468509985\n",
      "Iteration 38500 - Batch 1401/1613 - Train loss: 1.0364516873587555, Train acc: 0.8678004636233951\n",
      "Iteration 38600 - Batch 1501/1613 - Train loss: 1.0362059725981736, Train acc: 0.8680717376830892\n",
      "Iteration 38700 - Batch 1601/1613 - Train loss: 1.0361407346716534, Train acc: 0.8681335830212235\n",
      "[1, 4, 0, 2, 1, 4, 2, 3, 2, 0, 2, 4, 0, 0, 1, 1, 2, 0, 4, 0, 0, 0, 1, 2, 1, 4, 1, 3, 3, 4, 2, 3, 1, 0, 0, 2, 3, 2, 3, 0, 0, 4, 4, 4, 2, 0, 4, 0, 4, 3, 2, 4, 0, 2, 4, 2, 3, 1, 3, 3, 1, 2, 2, 0, 1, 3, 2, 1, 4, 4, 2, 4, 0, 1, 3, 1, 4, 1, 1, 0, 0, 4, 1, 3, 1, 2, 1, 4, 2, 4, 0, 0, 3, 3, 0, 0, 3, 1, 0, 1, 3, 4, 0, 0, 0, 2, 0, 1, 1, 3, 0, 0, 4, 2, 0, 3, 1, 3, 2, 1, 2, 3, 4, 4, 1, 2, 0, 2, 1, 0, 4, 1, 1, 1, 3, 2, 4, 3, 2, 0, 3, 0, 2, 0, 0, 1, 3, 2, 1, 3, 2, 2, 3, 1, 3, 4, 3, 2, 3, 4, 4, 4, 3, 4, 2, 2, 1, 0, 0, 2, 4, 4, 4, 3, 0, 2, 1, 0, 0, 2, 1, 0, 3, 2, 4, 1, 2, 3, 3, 0, 3, 1, 2, 1, 0, 0, 3, 4, 2, 2, 2, 1, 4, 1, 3, 4, 3, 3, 4, 1, 4, 4, 1, 3, 1, 3, 0, 4, 0, 1, 3, 3, 3, 0, 0, 1, 1, 4, 4, 0, 2, 0, 0, 0, 3, 3, 3, 4, 1, 4, 3, 3, 4, 2, 0, 2, 4, 0, 4, 4, 4, 2, 4, 2, 1, 0, 1, 2, 3, 1, 1, 1, 2, 0, 3, 3, 1, 4, 0, 3, 4, 3, 2, 0, 3, 2, 0, 1, 1, 1, 2, 4, 3, 0, 3, 0, 1, 2, 0, 0, 0, 0, 2, 3, 1, 4, 1, 1, 3, 2, 4, 1, 0, 0, 3, 2, 1, 3, 3, 2, 1, 2, 4, 3, 3, 1, 4, 0, 2, 1, 2, 0, 0, 1, 3, 4, 1, 2, 4, 4, 2, 2, 4, 4, 4, 1, 2, 2, 1, 1, 0, 3, 0, 2, 2, 3, 2, 3, 3, 3, 2, 3, 2, 4, 4, 2, 0, 0, 1, 1, 1, 2, 3, 0, 4, 3, 4, 2, 0, 1, 4, 3, 3, 0, 0, 3, 2, 1, 1, 4, 4, 4, 0, 2, 1, 3, 2, 1, 1, 2, 4, 0, 3, 1, 2, 3, 4, 0, 4, 3, 1, 1, 1, 2, 0, 1, 0, 4, 4, 0, 3, 4, 1, 1, 3, 4, 3, 2, 0, 4, 3, 3, 2, 4, 1, 0, 4, 3, 4, 4, 0, 1, 0, 2, 0, 2, 2, 3, 4, 0, 3, 0, 1, 2, 2, 1, 4, 4, 2, 4, 2, 2, 2, 4, 2, 4, 1, 0, 3, 2, 3, 0, 2, 3, 1, 3, 4, 4, 3, 1, 4, 3, 2, 1, 0, 2, 2, 3, 1, 1, 0, 2, 1, 3, 0, 4, 4, 3, 1, 3, 4, 4, 4, 0, 0, 1, 3, 2, 4, 2]\n",
      "[0, 3, 0, 2, 0, 4, 2, 3, 2, 0, 2, 4, 0, 0, 3, 4, 2, 0, 4, 0, 0, 0, 3, 2, 4, 4, 3, 3, 3, 4, 2, 3, 0, 0, 0, 2, 3, 2, 3, 0, 0, 4, 4, 4, 0, 0, 4, 0, 4, 3, 0, 4, 0, 2, 4, 2, 3, 4, 3, 3, 4, 2, 2, 0, 0, 3, 0, 0, 4, 4, 2, 4, 0, 3, 3, 4, 4, 3, 0, 0, 0, 4, 4, 3, 4, 2, 0, 4, 2, 4, 4, 0, 3, 3, 0, 0, 0, 0, 0, 4, 3, 4, 0, 0, 0, 0, 0, 4, 0, 3, 0, 0, 4, 3, 0, 3, 0, 3, 0, 4, 2, 4, 4, 2, 3, 0, 0, 2, 4, 0, 4, 0, 0, 0, 3, 2, 4, 3, 2, 0, 3, 0, 2, 0, 0, 3, 4, 0, 0, 3, 2, 2, 3, 4, 3, 4, 3, 2, 3, 4, 3, 4, 3, 4, 2, 2, 4, 0, 0, 0, 0, 4, 4, 3, 0, 0, 4, 0, 0, 0, 0, 0, 3, 2, 4, 0, 0, 3, 3, 0, 3, 0, 0, 0, 0, 0, 3, 4, 2, 2, 2, 4, 4, 0, 3, 4, 3, 3, 3, 3, 4, 4, 4, 3, 0, 3, 0, 4, 0, 4, 3, 3, 3, 0, 0, 0, 3, 4, 4, 0, 2, 0, 0, 0, 3, 3, 3, 4, 4, 0, 3, 3, 0, 2, 0, 0, 2, 0, 4, 4, 4, 2, 4, 0, 0, 0, 2, 2, 3, 4, 3, 3, 0, 0, 3, 3, 3, 4, 0, 3, 4, 3, 2, 0, 3, 2, 0, 3, 0, 0, 2, 4, 3, 0, 3, 0, 4, 2, 2, 0, 0, 0, 2, 3, 0, 4, 3, 0, 3, 2, 4, 4, 4, 0, 3, 2, 4, 3, 3, 0, 4, 2, 4, 3, 3, 0, 4, 0, 2, 0, 2, 0, 0, 3, 3, 4, 3, 0, 4, 4, 2, 2, 4, 4, 4, 3, 2, 2, 3, 3, 0, 3, 0, 3, 2, 3, 2, 3, 3, 3, 2, 3, 2, 4, 4, 0, 0, 0, 4, 4, 0, 2, 4, 0, 4, 3, 4, 2, 0, 2, 4, 3, 3, 0, 0, 3, 2, 0, 3, 4, 4, 4, 0, 0, 3, 3, 0, 4, 4, 2, 4, 0, 3, 2, 0, 3, 4, 0, 4, 3, 0, 3, 0, 2, 0, 4, 0, 4, 4, 0, 3, 4, 3, 2, 3, 4, 3, 0, 0, 4, 3, 3, 2, 4, 0, 0, 4, 3, 4, 4, 0, 0, 0, 2, 0, 2, 2, 3, 4, 4, 3, 0, 0, 0, 2, 0, 4, 4, 2, 4, 4, 2, 0, 4, 2, 4, 3, 0, 3, 2, 3, 0, 2, 3, 0, 3, 4, 4, 3, 0, 4, 3, 0, 4, 0, 2, 2, 3, 0, 4, 0, 2, 4, 3, 0, 4, 4, 3, 3, 3, 4, 4, 4, 0, 0, 3, 3, 2, 0, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.96      0.72       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.72      0.80       100\n",
      "           3       0.76      0.96      0.85       100\n",
      "           4       0.71      0.91      0.79       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.63       500\n",
      "weighted avg       0.59      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1899927482008934, Val acc: 0.71\n",
      "Epoch 25/30\n",
      "Iteration 38800 - Batch 88/1613 - Train loss: 1.0423892301120115, Train acc: 0.8620084269662921\n",
      "Iteration 38900 - Batch 188/1613 - Train loss: 1.0393179973597249, Train acc: 0.8654100529100529\n",
      "Iteration 39000 - Batch 288/1613 - Train loss: 1.0347047301724708, Train acc: 0.8700259515570934\n",
      "Iteration 39100 - Batch 388/1613 - Train loss: 1.0372046134159314, Train acc: 0.8669665809768637\n",
      "Iteration 39200 - Batch 488/1613 - Train loss: 1.0368215864665182, Train acc: 0.8673312883435583\n",
      "Iteration 39300 - Batch 588/1613 - Train loss: 1.0371840537505157, Train acc: 0.8670415959252971\n",
      "Iteration 39400 - Batch 688/1613 - Train loss: 1.035312567463115, Train acc: 0.8689677068214804\n",
      "Iteration 39500 - Batch 788/1613 - Train loss: 1.03620964213167, Train acc: 0.867910329531052\n",
      "Iteration 39600 - Batch 888/1613 - Train loss: 1.036008827664855, Train acc: 0.8682156917885264\n",
      "Iteration 39700 - Batch 988/1613 - Train loss: 1.035382060659908, Train acc: 0.8688700707785642\n",
      "Iteration 39800 - Batch 1088/1613 - Train loss: 1.0341540586521474, Train acc: 0.8700929752066116\n",
      "Iteration 39900 - Batch 1188/1613 - Train loss: 1.0343955067950603, Train acc: 0.8698486122792263\n",
      "Iteration 40000 - Batch 1288/1613 - Train loss: 1.034694634406857, Train acc: 0.8694724592707526\n",
      "Iteration 40100 - Batch 1388/1613 - Train loss: 1.034919707014717, Train acc: 0.869150467962563\n",
      "Iteration 40200 - Batch 1488/1613 - Train loss: 1.035236923545699, Train acc: 0.8687667897918065\n",
      "Iteration 40300 - Batch 1588/1613 - Train loss: 1.0352596351003558, Train acc: 0.8687264002517306\n",
      "[4, 4, 0, 1, 2, 4, 2, 4, 4, 1, 4, 4, 3, 0, 1, 1, 0, 3, 0, 2, 4, 4, 1, 1, 1, 4, 0, 0, 1, 2, 3, 3, 2, 4, 1, 1, 1, 4, 0, 3, 2, 4, 1, 4, 2, 2, 1, 4, 2, 0, 1, 4, 4, 0, 0, 2, 4, 2, 0, 2, 0, 1, 3, 2, 2, 3, 0, 4, 3, 2, 3, 2, 0, 1, 1, 2, 2, 1, 0, 3, 1, 0, 0, 1, 1, 3, 2, 3, 1, 3, 3, 0, 1, 0, 2, 4, 3, 0, 2, 3, 3, 4, 3, 4, 4, 2, 1, 0, 1, 1, 3, 1, 2, 0, 0, 3, 0, 4, 2, 1, 4, 0, 0, 4, 1, 2, 4, 0, 3, 4, 1, 4, 2, 4, 1, 2, 3, 4, 2, 2, 1, 1, 1, 3, 1, 0, 3, 2, 0, 4, 3, 4, 4, 3, 0, 4, 1, 4, 1, 4, 0, 1, 3, 1, 1, 1, 4, 2, 4, 0, 1, 2, 2, 1, 3, 3, 0, 3, 2, 4, 0, 1, 4, 3, 3, 4, 1, 0, 0, 3, 2, 3, 2, 1, 0, 0, 0, 0, 0, 4, 2, 3, 0, 1, 4, 1, 1, 2, 1, 4, 3, 2, 1, 2, 4, 3, 3, 4, 2, 4, 3, 0, 2, 0, 1, 2, 4, 4, 3, 2, 0, 2, 4, 1, 1, 2, 4, 0, 3, 2, 3, 4, 0, 1, 1, 3, 1, 2, 3, 4, 2, 1, 3, 3, 4, 2, 2, 3, 2, 3, 1, 1, 0, 4, 4, 3, 0, 2, 1, 1, 3, 0, 3, 1, 4, 1, 1, 0, 2, 1, 2, 0, 0, 3, 3, 1, 4, 3, 4, 3, 3, 1, 2, 3, 2, 2, 4, 0, 0, 3, 1, 1, 4, 4, 1, 3, 3, 1, 1, 3, 1, 4, 2, 3, 0, 2, 0, 3, 3, 2, 4, 4, 1, 4, 0, 2, 4, 3, 3, 2, 4, 3, 0, 3, 4, 4, 4, 3, 0, 3, 0, 0, 0, 2, 1, 1, 0, 4, 3, 3, 4, 0, 3, 2, 3, 0, 2, 0, 4, 1, 1, 4, 3, 0, 2, 0, 4, 2, 2, 3, 4, 0, 2, 2, 3, 4, 1, 4, 0, 4, 1, 1, 1, 0, 2, 3, 2, 3, 2, 2, 3, 3, 0, 1, 1, 1, 4, 0, 4, 2, 2, 3, 4, 2, 4, 3, 0, 3, 0, 3, 0, 1, 0, 1, 1, 0, 2, 3, 2, 3, 2, 4, 2, 0, 3, 0, 0, 2, 4, 3, 4, 3, 0, 1, 3, 2, 2, 2, 0, 0, 1, 1, 0, 3, 2, 2, 2, 2, 2, 0, 4, 1, 4, 1, 3, 0, 3, 4, 2, 2, 1, 0, 4, 1, 0, 2, 2, 2, 0, 0, 0, 2, 2, 4, 1, 3, 3, 1, 3, 4, 1, 2, 0, 3, 0, 4, 0, 0, 4, 1, 0, 4, 0, 2, 3, 4, 4, 4, 0, 3]\n",
      "[4, 4, 0, 3, 2, 4, 2, 4, 3, 4, 4, 4, 3, 0, 4, 3, 0, 3, 0, 2, 4, 4, 4, 3, 3, 4, 0, 0, 3, 2, 3, 3, 2, 4, 4, 2, 3, 4, 0, 3, 2, 4, 4, 4, 2, 2, 0, 4, 2, 4, 4, 4, 4, 0, 2, 2, 4, 2, 0, 0, 0, 4, 3, 2, 2, 3, 0, 4, 3, 0, 3, 2, 0, 4, 3, 2, 2, 0, 0, 3, 3, 0, 0, 3, 4, 3, 0, 3, 4, 3, 3, 0, 4, 0, 2, 4, 3, 0, 2, 3, 3, 4, 3, 4, 4, 2, 2, 0, 2, 4, 3, 3, 2, 0, 0, 3, 0, 4, 0, 0, 4, 0, 0, 4, 4, 2, 4, 0, 3, 4, 4, 4, 0, 4, 3, 2, 3, 4, 2, 0, 0, 0, 4, 3, 3, 0, 4, 2, 0, 3, 3, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0, 4, 3, 0, 4, 4, 4, 0, 4, 4, 4, 0, 0, 0, 3, 3, 0, 3, 2, 4, 3, 4, 4, 3, 3, 4, 4, 0, 2, 3, 2, 3, 2, 0, 0, 4, 0, 0, 0, 4, 2, 3, 0, 4, 4, 4, 3, 2, 3, 4, 3, 0, 3, 2, 4, 3, 3, 4, 2, 4, 3, 0, 2, 0, 4, 2, 2, 4, 3, 2, 0, 2, 4, 4, 4, 2, 4, 0, 3, 2, 3, 4, 0, 0, 4, 3, 0, 2, 3, 4, 0, 4, 3, 3, 4, 2, 2, 3, 2, 3, 4, 4, 0, 4, 4, 0, 0, 2, 4, 4, 3, 0, 3, 4, 4, 2, 4, 0, 0, 4, 2, 0, 0, 3, 3, 4, 2, 3, 4, 4, 3, 0, 2, 3, 2, 2, 4, 0, 0, 3, 4, 0, 4, 4, 0, 3, 3, 0, 2, 3, 4, 4, 2, 3, 0, 2, 0, 3, 3, 2, 4, 4, 4, 4, 0, 2, 4, 3, 3, 2, 4, 3, 0, 3, 0, 4, 4, 3, 0, 3, 0, 4, 0, 2, 4, 3, 0, 4, 3, 3, 4, 4, 3, 2, 3, 0, 2, 0, 0, 4, 3, 4, 3, 0, 2, 0, 4, 2, 2, 4, 4, 0, 3, 2, 3, 4, 4, 4, 0, 4, 3, 0, 3, 0, 2, 3, 2, 3, 2, 2, 3, 3, 0, 4, 0, 3, 3, 0, 4, 2, 0, 3, 4, 2, 4, 4, 0, 3, 0, 3, 0, 4, 0, 0, 4, 0, 2, 3, 2, 3, 2, 4, 2, 0, 3, 0, 0, 0, 4, 3, 4, 3, 0, 4, 3, 0, 2, 2, 0, 0, 3, 3, 0, 3, 3, 0, 2, 2, 2, 0, 3, 4, 4, 0, 3, 0, 3, 4, 2, 2, 4, 0, 4, 4, 0, 2, 0, 2, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 4, 4, 2, 0, 3, 0, 4, 0, 0, 4, 4, 0, 4, 0, 2, 3, 4, 4, 4, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.79      0.84       100\n",
      "           3       0.75      0.94      0.83       100\n",
      "           4       0.59      0.91      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.185721978545189, Val acc: 0.712\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40400 - Batch 75/1613 - Train loss: 1.0311589272398698, Train acc: 0.8733552631578947\n",
      "Iteration 40500 - Batch 175/1613 - Train loss: 1.0270771756768227, Train acc: 0.8771306818181818\n",
      "Iteration 40600 - Batch 275/1613 - Train loss: 1.0236801073171091, Train acc: 0.8802083333333334\n",
      "Iteration 40700 - Batch 375/1613 - Train loss: 1.0240059994319652, Train acc: 0.8801529255319149\n",
      "Iteration 40800 - Batch 475/1613 - Train loss: 1.0295396420885534, Train acc: 0.8745404411764706\n",
      "Iteration 40900 - Batch 575/1613 - Train loss: 1.0307092724574938, Train acc: 0.8734266493055556\n",
      "Iteration 41000 - Batch 675/1613 - Train loss: 1.0325677674373932, Train acc: 0.8718102810650887\n",
      "Iteration 41100 - Batch 775/1613 - Train loss: 1.0331682245602314, Train acc: 0.8711340206185567\n",
      "Iteration 41200 - Batch 875/1613 - Train loss: 1.0335690247141607, Train acc: 0.8706121575342466\n",
      "Iteration 41300 - Batch 975/1613 - Train loss: 1.0339437897820942, Train acc: 0.8702292520491803\n",
      "Iteration 41400 - Batch 1075/1613 - Train loss: 1.0345716593323144, Train acc: 0.8696561338289963\n",
      "Iteration 41500 - Batch 1175/1613 - Train loss: 1.0345720154594402, Train acc: 0.8695790816326531\n",
      "Iteration 41600 - Batch 1275/1613 - Train loss: 1.0343409130659222, Train acc: 0.8697345219435737\n",
      "Iteration 41700 - Batch 1375/1613 - Train loss: 1.0339715964225835, Train acc: 0.8700717659883721\n",
      "Iteration 41800 - Batch 1475/1613 - Train loss: 1.0340912883601538, Train acc: 0.8699398712737128\n",
      "Iteration 41900 - Batch 1575/1613 - Train loss: 1.0338785391546748, Train acc: 0.870221288071066\n",
      "[0, 3, 3, 1, 3, 1, 1, 0, 2, 3, 0, 1, 1, 2, 0, 0, 0, 0, 0, 1, 4, 0, 3, 2, 4, 3, 2, 4, 4, 2, 4, 1, 2, 2, 0, 4, 4, 1, 0, 4, 4, 3, 4, 3, 4, 1, 4, 1, 1, 1, 1, 0, 1, 0, 3, 0, 4, 0, 0, 4, 3, 4, 0, 0, 4, 1, 4, 0, 1, 3, 1, 4, 0, 4, 3, 3, 4, 1, 1, 1, 4, 0, 3, 0, 1, 1, 3, 2, 0, 4, 3, 1, 1, 0, 4, 2, 3, 2, 3, 3, 3, 1, 0, 0, 2, 0, 0, 4, 1, 2, 2, 0, 0, 0, 1, 4, 1, 1, 3, 4, 3, 2, 2, 3, 1, 4, 0, 1, 2, 3, 1, 1, 1, 4, 3, 0, 4, 0, 4, 1, 3, 4, 3, 3, 1, 0, 4, 4, 2, 0, 2, 3, 3, 4, 0, 2, 0, 3, 3, 1, 1, 2, 4, 0, 1, 2, 2, 3, 2, 0, 2, 3, 1, 2, 2, 2, 0, 2, 2, 1, 4, 3, 0, 3, 1, 0, 2, 4, 3, 4, 3, 0, 1, 1, 0, 0, 0, 3, 2, 1, 4, 4, 0, 0, 2, 1, 4, 4, 2, 3, 1, 2, 2, 4, 2, 3, 1, 2, 4, 0, 3, 1, 4, 1, 3, 2, 0, 1, 0, 2, 3, 2, 3, 4, 3, 4, 4, 2, 1, 4, 3, 4, 2, 3, 2, 2, 1, 3, 4, 2, 0, 3, 1, 3, 4, 2, 1, 0, 4, 3, 3, 1, 4, 2, 0, 2, 4, 3, 4, 2, 3, 4, 1, 2, 1, 4, 2, 4, 0, 3, 2, 3, 0, 0, 0, 0, 3, 2, 4, 1, 3, 2, 4, 1, 2, 4, 3, 3, 2, 1, 0, 2, 0, 0, 0, 1, 4, 4, 4, 3, 0, 3, 0, 2, 3, 4, 2, 0, 1, 2, 2, 4, 3, 2, 4, 3, 0, 0, 0, 2, 1, 2, 1, 0, 4, 1, 2, 0, 2, 0, 3, 2, 0, 4, 2, 1, 3, 3, 0, 1, 2, 4, 0, 2, 3, 4, 1, 3, 1, 1, 1, 4, 1, 1, 4, 0, 0, 3, 1, 3, 4, 2, 1, 4, 1, 2, 0, 1, 1, 3, 2, 2, 4, 4, 0, 0, 2, 0, 1, 3, 2, 1, 3, 4, 1, 4, 4, 1, 0, 1, 2, 0, 0, 3, 0, 0, 2, 3, 3, 1, 3, 0, 3, 2, 1, 1, 4, 1, 2, 1, 4, 2, 0, 4, 3, 1, 2, 0, 3, 2, 2, 0, 4, 4, 3, 2, 2, 4, 1, 4, 2, 3, 2, 1, 4, 1, 2, 1, 1, 4, 4, 2, 3, 3, 3, 2, 4, 4, 1, 2, 3, 0, 0, 2, 4, 2, 3, 3, 0, 0, 4, 3, 0, 1, 2, 1, 2, 1, 4, 4, 2, 0, 0, 3, 1, 3, 0, 3, 3, 3, 3, 0, 2, 4, 4, 2, 3, 2, 4, 3]\n",
      "[2, 3, 4, 3, 3, 2, 4, 2, 2, 3, 0, 3, 2, 2, 2, 0, 0, 4, 0, 2, 4, 0, 3, 2, 4, 3, 0, 4, 4, 2, 4, 0, 2, 2, 2, 4, 4, 4, 0, 4, 4, 3, 4, 3, 4, 3, 3, 4, 4, 3, 3, 0, 0, 0, 3, 0, 4, 0, 0, 4, 3, 4, 0, 0, 4, 4, 4, 0, 4, 3, 0, 4, 0, 4, 3, 3, 4, 4, 4, 4, 4, 0, 3, 0, 3, 3, 3, 2, 0, 4, 3, 4, 3, 0, 4, 0, 4, 2, 3, 3, 3, 2, 2, 0, 2, 0, 0, 4, 3, 0, 0, 0, 2, 0, 3, 4, 3, 4, 3, 4, 3, 2, 2, 4, 4, 4, 4, 4, 2, 3, 4, 4, 4, 4, 3, 0, 4, 0, 4, 0, 3, 4, 3, 3, 3, 0, 4, 4, 2, 0, 2, 3, 3, 4, 0, 2, 0, 4, 3, 4, 0, 2, 4, 2, 4, 2, 2, 3, 3, 0, 2, 3, 2, 2, 2, 2, 0, 2, 2, 4, 4, 3, 0, 3, 3, 2, 2, 4, 3, 4, 3, 0, 3, 4, 0, 0, 0, 3, 2, 0, 2, 4, 0, 0, 2, 3, 4, 4, 2, 3, 3, 2, 2, 4, 2, 3, 2, 2, 4, 0, 3, 0, 4, 4, 3, 2, 0, 4, 0, 2, 3, 2, 4, 4, 3, 4, 4, 2, 3, 4, 3, 4, 2, 3, 2, 4, 0, 3, 4, 2, 0, 3, 4, 3, 4, 2, 3, 0, 4, 3, 3, 4, 4, 2, 0, 2, 4, 3, 4, 2, 3, 4, 4, 2, 4, 4, 2, 4, 0, 3, 2, 3, 0, 0, 2, 0, 3, 2, 4, 4, 3, 2, 4, 4, 2, 4, 3, 4, 2, 4, 0, 0, 3, 0, 2, 4, 4, 4, 4, 3, 0, 3, 0, 2, 3, 4, 0, 0, 2, 2, 2, 4, 3, 2, 4, 3, 0, 0, 0, 2, 4, 2, 0, 0, 4, 3, 2, 0, 2, 0, 3, 2, 0, 4, 2, 4, 3, 3, 0, 4, 2, 4, 0, 2, 3, 4, 0, 3, 3, 0, 4, 4, 0, 2, 4, 0, 0, 3, 4, 3, 4, 2, 0, 4, 0, 2, 0, 3, 0, 3, 2, 2, 4, 4, 0, 0, 2, 0, 4, 3, 2, 3, 3, 4, 4, 4, 4, 4, 0, 4, 2, 4, 2, 3, 0, 0, 2, 3, 4, 4, 2, 0, 3, 2, 4, 4, 4, 4, 2, 4, 3, 2, 0, 4, 3, 3, 0, 0, 3, 0, 2, 0, 4, 4, 4, 2, 2, 4, 4, 4, 2, 3, 2, 2, 4, 0, 2, 0, 4, 4, 4, 2, 3, 3, 3, 0, 4, 4, 3, 2, 3, 0, 0, 2, 4, 2, 3, 3, 0, 0, 4, 3, 0, 4, 0, 4, 2, 4, 4, 4, 2, 0, 0, 3, 0, 4, 0, 4, 3, 3, 3, 0, 2, 4, 4, 0, 3, 2, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.80      0.87      0.83       100\n",
      "           3       0.76      0.89      0.82       100\n",
      "           4       0.61      0.97      0.75       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.58      0.72      0.64       500\n",
      "weighted avg       0.58      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1845128759741783, Val acc: 0.716\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42000 - Batch 62/1613 - Train loss: 1.0320557053126986, Train acc: 0.8720238095238095\n",
      "Iteration 42100 - Batch 162/1613 - Train loss: 1.0316996980298516, Train acc: 0.8725076687116564\n",
      "Iteration 42200 - Batch 262/1613 - Train loss: 1.033643002065869, Train acc: 0.870365969581749\n",
      "Iteration 42300 - Batch 362/1613 - Train loss: 1.0339082471266923, Train acc: 0.8704373278236914\n",
      "Iteration 42400 - Batch 462/1613 - Train loss: 1.032493433478584, Train acc: 0.8719627429805615\n",
      "Iteration 42500 - Batch 562/1613 - Train loss: 1.0328513518319884, Train acc: 0.8714476021314387\n",
      "Iteration 42600 - Batch 662/1613 - Train loss: 1.0318648530167511, Train acc: 0.872407616892911\n",
      "Iteration 42700 - Batch 762/1613 - Train loss: 1.0330677109027127, Train acc: 0.8710271952817824\n",
      "Iteration 42800 - Batch 862/1613 - Train loss: 1.0332043136395557, Train acc: 0.8707995365005794\n",
      "Iteration 42900 - Batch 962/1613 - Train loss: 1.0338019428471044, Train acc: 0.8701973001038421\n",
      "Iteration 43000 - Batch 1062/1613 - Train loss: 1.0339238277495413, Train acc: 0.8700611476952023\n",
      "Iteration 43100 - Batch 1162/1613 - Train loss: 1.034057265863476, Train acc: 0.8698409286328461\n",
      "Iteration 43200 - Batch 1262/1613 - Train loss: 1.033472733089873, Train acc: 0.8703978622327792\n",
      "Iteration 43300 - Batch 1362/1613 - Train loss: 1.033966650791406, Train acc: 0.8699330520909758\n",
      "Iteration 43400 - Batch 1462/1613 - Train loss: 1.0344528727798696, Train acc: 0.8692968215994532\n",
      "Iteration 43500 - Batch 1562/1613 - Train loss: 1.0347569546711728, Train acc: 0.8690818937939859\n",
      "[0, 4, 1, 0, 1, 1, 1, 0, 3, 4, 1, 0, 0, 3, 2, 2, 1, 4, 3, 2, 0, 1, 1, 0, 1, 0, 4, 4, 1, 1, 1, 1, 0, 2, 4, 4, 4, 4, 2, 4, 1, 4, 1, 2, 2, 0, 1, 1, 0, 1, 0, 4, 4, 3, 4, 3, 3, 1, 4, 4, 4, 4, 0, 1, 2, 3, 4, 2, 3, 0, 1, 3, 4, 3, 3, 1, 0, 4, 4, 2, 4, 2, 2, 0, 3, 4, 0, 3, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 1, 3, 4, 3, 1, 2, 2, 3, 2, 0, 4, 3, 1, 1, 0, 2, 0, 1, 0, 2, 1, 3, 2, 2, 1, 2, 3, 0, 4, 3, 3, 2, 2, 4, 3, 2, 2, 0, 3, 4, 2, 1, 3, 2, 3, 4, 0, 2, 1, 2, 4, 1, 1, 1, 3, 3, 1, 2, 1, 4, 4, 1, 2, 0, 0, 2, 3, 4, 4, 3, 0, 3, 3, 0, 2, 0, 3, 4, 4, 2, 3, 0, 0, 1, 2, 3, 4, 2, 2, 4, 1, 3, 3, 1, 4, 0, 4, 4, 3, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0, 2, 3, 0, 0, 1, 3, 2, 1, 2, 2, 2, 3, 2, 4, 3, 0, 3, 4, 1, 2, 3, 1, 0, 4, 3, 2, 2, 2, 2, 0, 3, 4, 1, 2, 1, 0, 3, 4, 3, 1, 1, 3, 0, 4, 4, 0, 4, 3, 4, 0, 2, 0, 0, 0, 1, 4, 4, 2, 0, 3, 1, 0, 3, 2, 3, 0, 4, 4, 1, 3, 0, 2, 3, 0, 0, 0, 2, 1, 1, 1, 4, 4, 1, 4, 2, 3, 2, 1, 4, 3, 1, 0, 2, 4, 3, 3, 2, 1, 4, 0, 1, 4, 4, 1, 2, 0, 1, 3, 3, 3, 3, 3, 4, 3, 1, 3, 1, 3, 4, 4, 0, 3, 1, 3, 4, 2, 0, 4, 1, 1, 2, 0, 2, 2, 0, 3, 3, 2, 4, 1, 4, 4, 4, 3, 1, 2, 2, 1, 4, 3, 1, 1, 3, 1, 1, 0, 0, 3, 2, 1, 2, 1, 0, 4, 2, 1, 4, 3, 1, 0, 0, 3, 0, 3, 0, 1, 3, 2, 4, 2, 0, 0, 1, 0, 1, 3, 1, 1, 2, 0, 3, 3, 3, 3, 3, 1, 2, 0, 4, 4, 1, 2, 0, 2, 4, 2, 4, 1, 3, 0, 2, 0, 4, 0, 2, 0, 2, 2, 0, 1, 2, 3, 2, 0, 4, 1, 4, 1, 4, 0, 0, 0, 3, 0, 4, 3, 2, 4, 4, 1, 3, 0, 0, 1, 3, 1, 0, 1, 4, 2, 4, 3, 4, 2, 1, 4, 1, 0, 4, 0, 3, 3, 3, 1, 4, 2, 0, 2, 1, 4, 4, 4, 2, 0, 2, 3, 3, 0, 1, 4, 2, 0, 4, 4, 0, 3, 0, 2, 2, 4, 2, 0]\n",
      "[0, 4, 4, 0, 4, 0, 3, 0, 3, 4, 4, 0, 0, 3, 0, 2, 3, 4, 3, 2, 0, 4, 0, 0, 3, 4, 4, 3, 0, 0, 3, 0, 0, 0, 4, 4, 4, 3, 2, 4, 2, 4, 4, 0, 2, 0, 4, 4, 0, 4, 0, 4, 4, 3, 4, 3, 4, 3, 2, 4, 4, 4, 2, 4, 2, 3, 4, 0, 3, 0, 0, 2, 4, 3, 3, 2, 0, 4, 4, 2, 4, 2, 2, 0, 3, 4, 0, 4, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 0, 4, 4, 4, 3, 4, 2, 2, 3, 2, 0, 4, 3, 3, 3, 0, 2, 0, 2, 0, 2, 3, 3, 2, 2, 0, 2, 3, 0, 4, 3, 3, 2, 2, 4, 3, 0, 2, 0, 3, 0, 2, 4, 3, 2, 3, 4, 0, 2, 3, 2, 4, 4, 4, 0, 3, 3, 4, 2, 4, 4, 4, 4, 3, 0, 2, 2, 3, 2, 4, 3, 0, 3, 3, 0, 2, 0, 3, 4, 4, 3, 3, 0, 0, 2, 2, 3, 4, 2, 2, 4, 3, 3, 3, 3, 4, 0, 3, 4, 3, 3, 3, 0, 3, 2, 0, 2, 0, 4, 0, 0, 3, 0, 0, 0, 3, 2, 4, 2, 2, 2, 3, 2, 4, 3, 0, 3, 4, 4, 2, 3, 3, 0, 4, 3, 2, 2, 2, 3, 0, 3, 4, 2, 2, 2, 0, 3, 4, 3, 2, 4, 3, 0, 4, 4, 0, 4, 3, 4, 0, 0, 0, 0, 0, 3, 4, 4, 2, 0, 3, 4, 0, 3, 2, 3, 0, 4, 4, 4, 4, 0, 0, 3, 0, 0, 2, 2, 4, 3, 4, 4, 4, 0, 4, 2, 3, 2, 4, 4, 3, 3, 0, 2, 4, 3, 0, 2, 3, 4, 0, 4, 4, 4, 4, 2, 0, 0, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 4, 4, 0, 3, 4, 3, 4, 2, 2, 3, 4, 0, 2, 0, 2, 2, 0, 3, 3, 0, 4, 4, 2, 4, 0, 3, 4, 2, 2, 4, 4, 3, 4, 3, 3, 4, 3, 0, 0, 3, 2, 3, 2, 3, 0, 2, 2, 3, 4, 3, 4, 0, 0, 3, 0, 3, 0, 3, 3, 0, 4, 2, 0, 0, 3, 0, 4, 3, 4, 0, 2, 0, 3, 3, 3, 3, 3, 2, 2, 0, 4, 4, 2, 2, 0, 2, 4, 2, 4, 0, 2, 0, 2, 0, 4, 0, 0, 0, 2, 2, 0, 0, 2, 3, 2, 2, 4, 2, 4, 4, 4, 0, 0, 2, 3, 0, 4, 3, 2, 4, 4, 3, 3, 0, 0, 4, 3, 4, 0, 0, 4, 2, 4, 3, 4, 2, 4, 4, 3, 0, 4, 0, 3, 3, 3, 3, 4, 0, 0, 2, 3, 4, 4, 4, 0, 0, 2, 3, 3, 0, 2, 4, 2, 0, 4, 4, 0, 3, 0, 2, 2, 4, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.78      0.83      0.81       100\n",
      "           3       0.73      0.93      0.82       100\n",
      "           4       0.65      0.90      0.75       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.58      0.72      0.64       500\n",
      "weighted avg       0.58      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1812453716993332, Val acc: 0.718\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43600 - Batch 49/1613 - Train loss: 1.031974468231201, Train acc: 0.87375\n",
      "Iteration 43700 - Batch 149/1613 - Train loss: 1.0328973464171092, Train acc: 0.8704166666666666\n",
      "Iteration 43800 - Batch 249/1613 - Train loss: 1.0280605912208558, Train acc: 0.87575\n",
      "Iteration 43900 - Batch 349/1613 - Train loss: 1.0297317256246294, Train acc: 0.8739285714285714\n",
      "Iteration 44000 - Batch 449/1613 - Train loss: 1.0337312409612867, Train acc: 0.87\n",
      "Iteration 44100 - Batch 549/1613 - Train loss: 1.032183623747392, Train acc: 0.871875\n",
      "Iteration 44200 - Batch 649/1613 - Train loss: 1.0330546744970175, Train acc: 0.8708173076923077\n",
      "Iteration 44300 - Batch 749/1613 - Train loss: 1.033205331881841, Train acc: 0.8705416666666667\n",
      "Iteration 44400 - Batch 849/1613 - Train loss: 1.0331584008301005, Train acc: 0.8705514705882353\n",
      "Iteration 44500 - Batch 949/1613 - Train loss: 1.0325732491518322, Train acc: 0.8711842105263158\n",
      "Iteration 44600 - Batch 1049/1613 - Train loss: 1.032255778482982, Train acc: 0.8713690476190477\n",
      "Iteration 44700 - Batch 1149/1613 - Train loss: 1.0317714932690496, Train acc: 0.871875\n",
      "Iteration 44800 - Batch 1249/1613 - Train loss: 1.031119017791748, Train acc: 0.87265\n",
      "Iteration 44900 - Batch 1349/1613 - Train loss: 1.0312093043768848, Train acc: 0.8725925925925926\n",
      "Iteration 45000 - Batch 1449/1613 - Train loss: 1.0314184825995873, Train acc: 0.8723922413793104\n",
      "Iteration 45100 - Batch 1549/1613 - Train loss: 1.0321583971669597, Train acc: 0.8715927419354839\n",
      "[4, 3, 1, 2, 4, 3, 4, 3, 2, 0, 1, 0, 3, 4, 2, 2, 2, 4, 2, 4, 1, 2, 4, 2, 0, 2, 4, 3, 0, 0, 1, 0, 2, 4, 1, 1, 3, 1, 4, 4, 0, 2, 1, 2, 2, 4, 2, 3, 2, 4, 0, 0, 1, 2, 0, 0, 2, 4, 1, 3, 2, 2, 2, 1, 4, 2, 2, 1, 1, 2, 1, 0, 3, 1, 1, 1, 4, 4, 1, 0, 4, 3, 0, 4, 3, 2, 1, 3, 4, 0, 4, 4, 4, 0, 4, 1, 1, 4, 4, 3, 2, 0, 0, 0, 3, 0, 4, 2, 2, 2, 4, 1, 4, 3, 0, 3, 2, 1, 4, 0, 3, 4, 2, 3, 0, 0, 2, 2, 3, 0, 0, 3, 3, 2, 2, 0, 1, 0, 2, 3, 2, 3, 3, 2, 3, 0, 3, 0, 3, 0, 4, 2, 3, 0, 2, 2, 2, 4, 1, 0, 4, 0, 3, 3, 1, 0, 0, 1, 3, 0, 4, 2, 4, 1, 2, 3, 0, 3, 2, 3, 1, 4, 3, 2, 4, 1, 4, 0, 0, 2, 0, 1, 4, 2, 4, 1, 3, 3, 0, 1, 4, 3, 3, 1, 4, 2, 3, 3, 1, 0, 2, 0, 2, 2, 0, 3, 0, 4, 0, 2, 3, 2, 1, 1, 0, 1, 1, 1, 4, 4, 1, 4, 3, 2, 4, 3, 3, 0, 4, 1, 3, 2, 0, 1, 4, 3, 0, 0, 0, 1, 1, 3, 3, 4, 2, 0, 4, 3, 2, 2, 3, 0, 3, 3, 3, 0, 1, 0, 1, 3, 4, 0, 3, 2, 3, 1, 3, 0, 3, 3, 2, 2, 0, 0, 4, 1, 0, 1, 4, 1, 4, 0, 1, 3, 3, 1, 4, 0, 1, 2, 0, 0, 1, 2, 0, 0, 4, 4, 0, 3, 3, 0, 3, 0, 0, 1, 2, 4, 2, 3, 2, 3, 0, 1, 4, 2, 1, 4, 3, 2, 0, 0, 4, 0, 0, 0, 1, 4, 4, 0, 3, 3, 2, 3, 4, 2, 4, 1, 4, 0, 3, 3, 4, 4, 1, 0, 2, 2, 2, 3, 4, 1, 0, 2, 3, 2, 0, 4, 1, 3, 4, 1, 1, 4, 4, 1, 3, 4, 4, 1, 0, 3, 2, 4, 3, 1, 2, 0, 4, 1, 1, 1, 3, 3, 2, 0, 4, 2, 2, 2, 2, 2, 4, 3, 4, 3, 1, 1, 2, 1, 2, 0, 3, 3, 1, 1, 1, 0, 0, 0, 4, 3, 1, 1, 1, 1, 4, 4, 1, 4, 2, 4, 3, 0, 1, 2, 0, 3, 4, 1, 1, 1, 1, 0, 2, 3, 1, 3, 1, 4, 0, 4, 4, 4, 2, 2, 4, 1, 3, 2, 2, 3, 1, 0, 2, 3, 4, 3, 1, 0, 4, 2, 4, 2, 4, 3, 0, 3, 1, 1, 1, 2, 3, 0, 4, 2, 0, 1, 2, 1, 4, 2, 1, 1, 2, 3, 0, 4, 3, 1]\n",
      "[4, 3, 4, 2, 4, 3, 4, 3, 2, 0, 0, 0, 3, 4, 2, 2, 2, 4, 0, 4, 4, 0, 4, 2, 0, 2, 4, 3, 0, 0, 0, 0, 2, 4, 2, 3, 3, 4, 4, 4, 3, 2, 0, 2, 2, 4, 2, 3, 2, 4, 0, 0, 4, 2, 0, 0, 2, 4, 4, 3, 2, 2, 0, 3, 4, 2, 2, 4, 4, 2, 4, 0, 3, 3, 4, 3, 4, 4, 0, 2, 4, 3, 0, 4, 3, 2, 3, 3, 4, 0, 2, 4, 4, 0, 4, 0, 4, 4, 4, 3, 2, 0, 0, 0, 3, 0, 4, 2, 2, 2, 4, 2, 4, 3, 0, 3, 2, 0, 4, 0, 3, 4, 2, 3, 0, 0, 2, 2, 3, 0, 0, 3, 3, 2, 2, 0, 4, 0, 2, 3, 2, 3, 3, 0, 3, 0, 3, 0, 3, 0, 4, 2, 0, 0, 2, 0, 2, 4, 3, 0, 4, 0, 3, 3, 4, 0, 0, 4, 3, 0, 4, 0, 4, 3, 0, 3, 0, 3, 3, 3, 4, 4, 3, 2, 4, 3, 3, 0, 0, 2, 0, 0, 4, 2, 4, 2, 3, 3, 0, 2, 4, 3, 3, 3, 4, 2, 4, 4, 3, 0, 2, 0, 2, 2, 0, 3, 0, 4, 0, 2, 3, 0, 3, 0, 0, 3, 4, 4, 4, 3, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 2, 0, 4, 4, 3, 0, 0, 4, 0, 0, 3, 3, 4, 2, 2, 4, 3, 2, 2, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 4, 0, 3, 2, 3, 0, 3, 0, 3, 3, 2, 0, 0, 0, 4, 3, 0, 3, 4, 4, 4, 0, 4, 3, 3, 4, 4, 0, 3, 0, 0, 0, 2, 2, 0, 0, 4, 0, 0, 3, 3, 0, 3, 0, 0, 0, 2, 4, 0, 3, 2, 4, 0, 3, 4, 0, 0, 4, 3, 2, 0, 4, 4, 0, 0, 3, 4, 4, 4, 0, 3, 3, 2, 3, 4, 2, 4, 0, 4, 0, 3, 3, 4, 4, 0, 0, 2, 2, 2, 3, 4, 4, 0, 2, 3, 2, 0, 4, 3, 3, 4, 4, 0, 4, 4, 4, 3, 4, 4, 3, 0, 3, 2, 4, 3, 3, 2, 0, 4, 4, 4, 3, 3, 3, 0, 0, 4, 2, 2, 2, 2, 0, 4, 3, 4, 3, 3, 3, 2, 3, 2, 0, 3, 3, 3, 4, 4, 0, 0, 0, 4, 3, 4, 0, 4, 0, 4, 4, 3, 4, 0, 4, 3, 0, 4, 3, 0, 4, 4, 2, 4, 0, 3, 0, 2, 3, 3, 3, 2, 4, 0, 4, 4, 4, 2, 2, 4, 4, 3, 2, 2, 3, 4, 0, 2, 3, 4, 3, 4, 0, 4, 3, 4, 2, 3, 3, 0, 3, 3, 0, 4, 2, 3, 0, 4, 2, 0, 4, 2, 4, 4, 2, 4, 4, 2, 3, 0, 4, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.94      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.81      0.85       100\n",
      "           3       0.69      0.95      0.80       100\n",
      "           4       0.66      0.92      0.77       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.65       500\n",
      "weighted avg       0.59      0.72      0.65       500\n",
      "\n",
      "Val loss: 1.1825184300541878, Val acc: 0.724\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45200 - Batch 36/1613 - Train loss: 1.0068275654638135, Train acc: 0.8994932432432432\n",
      "Iteration 45300 - Batch 136/1613 - Train loss: 1.0253160417514995, Train acc: 0.8811587591240876\n",
      "Iteration 45400 - Batch 236/1613 - Train loss: 1.02640680824151, Train acc: 0.8785601265822784\n",
      "Iteration 45500 - Batch 336/1613 - Train loss: 1.0280864702134176, Train acc: 0.8765764094955489\n",
      "Iteration 45600 - Batch 436/1613 - Train loss: 1.0293102523554927, Train acc: 0.875429061784897\n",
      "Iteration 45700 - Batch 536/1613 - Train loss: 1.0308873526876865, Train acc: 0.8737779329608939\n",
      "Iteration 45800 - Batch 636/1613 - Train loss: 1.0315405404549005, Train acc: 0.8726452119309263\n",
      "Iteration 45900 - Batch 736/1613 - Train loss: 1.0318204623064484, Train acc: 0.8722438941655359\n",
      "Iteration 46000 - Batch 836/1613 - Train loss: 1.0320145332542656, Train acc: 0.8717891278375149\n",
      "Iteration 46100 - Batch 936/1613 - Train loss: 1.0316365495435456, Train acc: 0.872031750266809\n",
      "Iteration 46200 - Batch 1036/1613 - Train loss: 1.030068968105684, Train acc: 0.87349324975892\n",
      "Iteration 46300 - Batch 1136/1613 - Train loss: 1.0296764855544192, Train acc: 0.8740105540897097\n",
      "Iteration 46400 - Batch 1236/1613 - Train loss: 1.029816240337267, Train acc: 0.8738631770412287\n",
      "Iteration 46500 - Batch 1336/1613 - Train loss: 1.0306735120340347, Train acc: 0.8730366492146597\n",
      "Iteration 46600 - Batch 1436/1613 - Train loss: 1.0316251944400572, Train acc: 0.8721294363256785\n",
      "Iteration 46700 - Batch 1536/1613 - Train loss: 1.0314180449611114, Train acc: 0.8722552049446974\n",
      "[0, 2, 3, 4, 0, 2, 0, 1, 1, 1, 1, 4, 4, 4, 0, 2, 4, 0, 1, 3, 4, 0, 2, 3, 2, 2, 1, 0, 4, 3, 1, 3, 0, 4, 4, 0, 0, 3, 4, 3, 1, 3, 2, 2, 3, 0, 1, 1, 0, 2, 0, 4, 4, 1, 2, 0, 1, 4, 2, 0, 3, 0, 3, 0, 4, 1, 2, 4, 2, 1, 4, 2, 4, 1, 3, 3, 0, 4, 4, 1, 0, 2, 1, 3, 3, 2, 0, 1, 2, 3, 3, 0, 3, 1, 3, 3, 0, 1, 2, 2, 4, 2, 3, 3, 3, 4, 4, 1, 4, 2, 2, 0, 2, 4, 4, 0, 3, 3, 3, 3, 2, 4, 1, 0, 1, 1, 4, 4, 3, 2, 2, 2, 4, 0, 0, 4, 0, 4, 4, 1, 1, 2, 1, 1, 0, 1, 2, 0, 3, 2, 4, 0, 0, 1, 0, 1, 2, 2, 4, 0, 2, 4, 2, 4, 2, 3, 2, 3, 3, 1, 2, 4, 4, 2, 2, 0, 2, 0, 2, 3, 1, 3, 2, 0, 3, 3, 0, 2, 4, 4, 2, 1, 2, 4, 1, 1, 0, 4, 3, 1, 1, 2, 1, 3, 1, 4, 0, 2, 3, 1, 3, 4, 3, 2, 0, 0, 1, 2, 0, 4, 4, 3, 1, 4, 0, 2, 3, 0, 1, 1, 4, 2, 2, 0, 0, 1, 4, 2, 4, 3, 2, 3, 1, 2, 0, 4, 0, 1, 4, 4, 3, 4, 1, 3, 0, 0, 0, 1, 4, 4, 4, 4, 1, 1, 3, 4, 3, 2, 3, 1, 3, 1, 3, 1, 4, 1, 0, 4, 0, 2, 0, 4, 0, 3, 3, 1, 0, 2, 4, 1, 0, 2, 0, 2, 2, 3, 4, 1, 4, 3, 2, 2, 4, 0, 4, 4, 4, 0, 2, 0, 3, 0, 3, 3, 4, 3, 4, 1, 0, 2, 1, 4, 1, 3, 1, 0, 0, 2, 1, 3, 3, 0, 1, 3, 0, 1, 1, 2, 1, 3, 4, 1, 3, 0, 2, 2, 1, 0, 4, 4, 3, 1, 1, 3, 0, 3, 0, 2, 4, 2, 4, 3, 2, 2, 2, 4, 4, 3, 1, 1, 3, 0, 0, 1, 0, 0, 0, 3, 0, 1, 0, 0, 1, 1, 2, 2, 2, 3, 1, 4, 3, 1, 3, 4, 3, 3, 0, 0, 4, 2, 1, 2, 0, 4, 2, 2, 4, 4, 2, 2, 4, 3, 2, 3, 1, 2, 3, 3, 1, 2, 3, 3, 1, 1, 4, 2, 2, 3, 4, 4, 0, 0, 0, 2, 3, 1, 0, 0, 1, 2, 1, 1, 0, 1, 4, 3, 3, 1, 3, 4, 0, 3, 2, 4, 1, 1, 0, 0, 2, 4, 1, 1, 0, 3, 4, 0, 0, 3, 3, 3, 2, 3, 4, 0, 1, 2, 2, 1, 4, 1, 4, 3, 0, 3, 3, 0, 3, 2, 3, 2, 4, 2, 0, 2, 4, 1, 1, 2, 0, 4]\n",
      "[0, 2, 3, 4, 0, 0, 0, 4, 3, 4, 4, 4, 4, 4, 0, 2, 4, 0, 3, 3, 4, 0, 2, 3, 2, 2, 4, 0, 4, 3, 4, 3, 0, 4, 2, 0, 0, 3, 4, 3, 2, 3, 2, 2, 3, 0, 3, 4, 0, 2, 0, 4, 4, 3, 2, 0, 0, 4, 0, 0, 3, 0, 3, 0, 4, 4, 2, 4, 2, 3, 4, 2, 4, 4, 3, 3, 0, 4, 4, 4, 0, 2, 4, 3, 3, 2, 0, 4, 2, 3, 3, 0, 3, 4, 3, 3, 0, 4, 2, 0, 4, 2, 3, 3, 4, 2, 4, 3, 4, 0, 0, 0, 2, 4, 4, 0, 3, 3, 3, 3, 2, 4, 3, 0, 2, 4, 4, 4, 3, 2, 2, 2, 4, 0, 0, 4, 0, 3, 4, 3, 3, 2, 2, 3, 0, 0, 2, 0, 4, 2, 4, 0, 0, 4, 0, 3, 2, 0, 4, 0, 2, 4, 2, 4, 2, 3, 2, 3, 3, 3, 0, 4, 4, 2, 0, 0, 2, 0, 2, 3, 3, 3, 0, 0, 3, 3, 0, 0, 4, 4, 2, 0, 2, 3, 3, 4, 0, 4, 3, 3, 4, 2, 3, 3, 4, 3, 0, 2, 3, 4, 3, 4, 4, 2, 0, 0, 0, 2, 0, 4, 4, 3, 0, 4, 0, 2, 3, 0, 4, 0, 4, 2, 2, 0, 0, 2, 4, 2, 4, 3, 2, 3, 0, 0, 2, 4, 0, 3, 4, 4, 3, 4, 4, 3, 0, 0, 0, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 2, 3, 4, 3, 4, 3, 0, 4, 0, 0, 4, 0, 2, 0, 4, 0, 3, 4, 4, 0, 0, 4, 4, 0, 2, 0, 0, 2, 3, 4, 2, 4, 3, 2, 2, 4, 0, 4, 4, 4, 4, 2, 0, 3, 0, 3, 3, 4, 3, 4, 4, 0, 2, 4, 4, 4, 3, 0, 0, 0, 2, 4, 3, 3, 0, 4, 3, 0, 0, 4, 2, 0, 3, 4, 0, 3, 0, 2, 2, 4, 0, 4, 4, 3, 0, 0, 3, 2, 3, 0, 2, 4, 2, 4, 4, 2, 2, 2, 4, 4, 3, 0, 4, 3, 0, 0, 0, 0, 0, 0, 4, 0, 3, 0, 0, 0, 4, 2, 0, 0, 4, 0, 4, 3, 0, 3, 4, 3, 0, 0, 0, 4, 2, 3, 2, 0, 4, 2, 2, 4, 4, 0, 2, 4, 3, 0, 3, 4, 2, 3, 3, 3, 2, 3, 3, 0, 4, 4, 2, 4, 3, 4, 4, 0, 0, 0, 2, 3, 4, 0, 0, 3, 2, 4, 0, 0, 0, 4, 3, 3, 4, 3, 4, 4, 3, 2, 4, 3, 0, 0, 0, 2, 4, 3, 3, 0, 3, 4, 0, 0, 3, 4, 4, 0, 3, 4, 0, 3, 2, 0, 4, 4, 4, 4, 3, 0, 3, 3, 0, 3, 2, 3, 3, 4, 2, 4, 0, 4, 3, 3, 2, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.78      0.83       100\n",
      "           3       0.74      0.89      0.81       100\n",
      "           4       0.62      0.95      0.75       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1883836165070534, Val acc: 0.714\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46800 - Batch 23/1613 - Train loss: 1.0327029377222061, Train acc: 0.8723958333333334\n",
      "Iteration 46900 - Batch 123/1613 - Train loss: 1.0359100411015172, Train acc: 0.868195564516129\n",
      "Iteration 47000 - Batch 223/1613 - Train loss: 1.034463765365737, Train acc: 0.8698381696428571\n",
      "Iteration 47100 - Batch 323/1613 - Train loss: 1.034423440326879, Train acc: 0.869116512345679\n",
      "Iteration 47200 - Batch 423/1613 - Train loss: 1.0358366654166635, Train acc: 0.8679982311320755\n",
      "Iteration 47300 - Batch 523/1613 - Train loss: 1.0354098761809691, Train acc: 0.8684398854961832\n",
      "Iteration 47400 - Batch 623/1613 - Train loss: 1.0343658237312086, Train acc: 0.8694411057692307\n",
      "Iteration 47500 - Batch 723/1613 - Train loss: 1.0344843567240962, Train acc: 0.8693024861878453\n",
      "Iteration 47600 - Batch 823/1613 - Train loss: 1.0318834032971882, Train acc: 0.8721177184466019\n",
      "Iteration 47700 - Batch 923/1613 - Train loss: 1.0311670367851917, Train acc: 0.8728693181818182\n",
      "Iteration 47800 - Batch 1023/1613 - Train loss: 1.0306483734748326, Train acc: 0.873565673828125\n",
      "Iteration 47900 - Batch 1123/1613 - Train loss: 1.0315161715941072, Train acc: 0.872803603202847\n",
      "Iteration 48000 - Batch 1223/1613 - Train loss: 1.031893586752072, Train acc: 0.8724468954248366\n",
      "Iteration 48100 - Batch 1323/1613 - Train loss: 1.0318397916965973, Train acc: 0.8725453172205438\n",
      "Iteration 48200 - Batch 1423/1613 - Train loss: 1.0323168014207582, Train acc: 0.8721032303370787\n",
      "Iteration 48300 - Batch 1523/1613 - Train loss: 1.0328565516418673, Train acc: 0.8716166338582677\n",
      "[2, 0, 1, 3, 1, 4, 1, 3, 3, 2, 4, 1, 1, 0, 0, 3, 0, 1, 1, 0, 1, 0, 4, 3, 4, 4, 1, 1, 4, 1, 2, 4, 4, 4, 3, 0, 1, 3, 0, 4, 0, 2, 4, 3, 1, 3, 0, 4, 3, 3, 2, 4, 4, 1, 2, 4, 0, 1, 0, 4, 4, 2, 4, 3, 3, 4, 3, 3, 4, 0, 1, 2, 1, 2, 0, 1, 4, 2, 4, 3, 3, 4, 2, 2, 0, 0, 3, 3, 0, 4, 1, 4, 1, 2, 1, 2, 0, 1, 1, 0, 1, 3, 1, 3, 4, 0, 2, 2, 0, 3, 2, 2, 3, 1, 3, 1, 3, 1, 0, 4, 3, 3, 0, 3, 2, 3, 4, 0, 3, 3, 2, 2, 4, 3, 4, 4, 1, 4, 3, 4, 1, 2, 0, 1, 0, 3, 4, 1, 2, 1, 4, 3, 3, 2, 0, 4, 0, 1, 2, 2, 0, 3, 2, 0, 2, 1, 0, 3, 3, 4, 0, 4, 3, 4, 4, 4, 0, 3, 3, 0, 1, 1, 2, 0, 2, 1, 0, 0, 4, 1, 0, 4, 0, 1, 4, 4, 0, 2, 0, 3, 0, 1, 2, 1, 3, 1, 1, 2, 4, 2, 2, 4, 1, 3, 4, 4, 0, 1, 4, 4, 2, 3, 2, 2, 4, 3, 2, 0, 1, 4, 1, 4, 4, 0, 1, 1, 2, 1, 0, 0, 2, 4, 3, 1, 0, 0, 3, 1, 2, 4, 0, 3, 2, 3, 1, 1, 1, 4, 3, 3, 1, 0, 4, 4, 1, 1, 2, 2, 0, 2, 1, 0, 0, 4, 1, 2, 4, 4, 0, 2, 0, 3, 0, 4, 0, 0, 4, 4, 0, 0, 3, 3, 3, 2, 4, 3, 3, 3, 2, 0, 2, 3, 4, 2, 2, 3, 4, 3, 4, 4, 1, 2, 0, 3, 3, 2, 0, 0, 4, 3, 3, 2, 4, 1, 2, 4, 0, 4, 0, 2, 1, 2, 3, 1, 1, 1, 3, 0, 1, 1, 1, 1, 1, 3, 4, 4, 1, 1, 0, 3, 1, 0, 4, 0, 1, 4, 3, 2, 2, 0, 3, 2, 0, 0, 0, 2, 2, 0, 2, 3, 2, 0, 3, 0, 2, 2, 3, 0, 0, 3, 1, 4, 1, 1, 0, 2, 1, 2, 4, 3, 4, 3, 2, 4, 3, 4, 1, 0, 2, 3, 0, 2, 1, 3, 4, 1, 2, 4, 0, 1, 3, 2, 0, 4, 2, 1, 3, 3, 1, 1, 3, 4, 4, 2, 2, 0, 4, 1, 2, 2, 3, 1, 0, 1, 2, 4, 0, 4, 4, 3, 0, 0, 0, 1, 3, 0, 1, 2, 2, 0, 2, 1, 0, 4, 1, 2, 3, 2, 2, 4, 2, 4, 2, 1, 2, 4, 4, 2, 3, 2, 2, 3, 0, 2, 3, 0, 3, 1, 3, 3, 0, 1, 4, 2, 1, 3, 2, 2, 2, 3, 2, 1, 0, 2, 4, 0, 3, 1, 0, 3]\n",
      "[2, 0, 4, 3, 0, 4, 4, 4, 3, 2, 4, 4, 4, 0, 0, 3, 0, 4, 0, 0, 4, 0, 4, 3, 3, 4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 0, 4, 3, 0, 4, 0, 2, 4, 3, 4, 3, 0, 2, 3, 3, 2, 4, 3, 4, 2, 4, 0, 4, 0, 4, 4, 2, 4, 3, 3, 4, 3, 3, 4, 0, 0, 2, 3, 2, 0, 4, 4, 2, 4, 3, 3, 4, 2, 2, 0, 0, 3, 4, 0, 4, 4, 4, 2, 2, 3, 2, 0, 0, 3, 0, 3, 3, 4, 3, 4, 0, 2, 0, 0, 3, 2, 2, 3, 3, 4, 3, 3, 3, 0, 4, 3, 3, 0, 3, 2, 3, 4, 0, 3, 3, 2, 0, 4, 3, 4, 4, 4, 4, 4, 4, 4, 2, 0, 4, 0, 3, 4, 0, 2, 3, 4, 3, 3, 2, 0, 4, 0, 4, 2, 2, 0, 3, 2, 0, 2, 4, 4, 3, 3, 4, 0, 4, 3, 4, 4, 4, 0, 3, 3, 0, 0, 3, 2, 0, 2, 4, 0, 0, 4, 4, 0, 4, 2, 4, 4, 4, 0, 0, 0, 3, 4, 3, 2, 4, 3, 3, 2, 2, 4, 2, 2, 4, 3, 3, 4, 4, 0, 0, 4, 4, 2, 3, 0, 3, 4, 3, 2, 0, 4, 0, 0, 4, 4, 0, 0, 3, 2, 3, 0, 4, 2, 4, 3, 4, 4, 0, 3, 3, 2, 4, 0, 3, 2, 3, 4, 4, 4, 4, 3, 3, 4, 0, 3, 4, 4, 4, 2, 0, 0, 2, 3, 0, 0, 4, 3, 0, 4, 4, 0, 2, 0, 3, 0, 4, 0, 0, 4, 4, 0, 0, 3, 3, 3, 2, 4, 3, 3, 3, 2, 4, 2, 3, 4, 0, 2, 3, 4, 3, 4, 4, 0, 2, 0, 3, 3, 2, 2, 0, 4, 3, 3, 2, 4, 4, 0, 4, 0, 4, 0, 0, 4, 0, 3, 3, 2, 4, 4, 0, 3, 3, 4, 4, 0, 3, 4, 4, 4, 4, 0, 3, 4, 0, 4, 0, 4, 4, 3, 2, 2, 0, 3, 2, 0, 0, 0, 2, 2, 0, 2, 3, 2, 0, 3, 0, 2, 2, 3, 0, 0, 3, 4, 4, 3, 3, 4, 2, 4, 2, 4, 3, 4, 3, 2, 4, 3, 4, 4, 0, 2, 3, 0, 2, 3, 3, 4, 4, 2, 4, 0, 4, 3, 2, 0, 4, 2, 0, 3, 3, 3, 4, 3, 4, 4, 2, 0, 0, 4, 4, 0, 2, 3, 3, 0, 3, 0, 4, 0, 4, 4, 4, 0, 0, 0, 3, 3, 0, 3, 0, 2, 0, 4, 0, 0, 4, 2, 0, 3, 0, 2, 4, 2, 4, 2, 4, 0, 4, 4, 2, 4, 0, 2, 3, 0, 2, 3, 0, 3, 3, 3, 3, 0, 4, 4, 2, 4, 3, 2, 2, 2, 3, 2, 3, 0, 2, 3, 0, 3, 2, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.79      0.84       100\n",
      "           3       0.72      0.93      0.81       100\n",
      "           4       0.59      0.94      0.73       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1869138032197952, Val acc: 0.716\n",
      "Tiempo total de entrenamiento: 644.4335 [s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "curves=trainer(train_loader,val_loader,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14542,  2396, 14523,  9599, 10534])\n",
      "Epoch 1/30\n",
      "Iteration 0 - Batch 0/1613 - Train loss: 1.620602011680603, Train acc: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 - Batch 100/1613 - Train loss: 1.4700292348861694, Train acc: 0.4993811881188119\n",
      "Iteration 200 - Batch 200/1613 - Train loss: 1.4162680361401383, Train acc: 0.5359141791044776\n",
      "Iteration 300 - Batch 300/1613 - Train loss: 1.3887432469085998, Train acc: 0.5527408637873754\n",
      "Iteration 400 - Batch 400/1613 - Train loss: 1.3573202316897766, Train acc: 0.578319825436409\n",
      "Iteration 500 - Batch 500/1613 - Train loss: 1.3346198768672828, Train acc: 0.5968063872255489\n",
      "Iteration 600 - Batch 600/1613 - Train loss: 1.3147404096685908, Train acc: 0.6135607321131448\n",
      "Iteration 700 - Batch 700/1613 - Train loss: 1.3000452623897885, Train acc: 0.6251783166904422\n",
      "Iteration 800 - Batch 800/1613 - Train loss: 1.2882488893063626, Train acc: 0.6345583645443196\n",
      "Iteration 900 - Batch 900/1613 - Train loss: 1.2794136447991171, Train acc: 0.6415094339622641\n",
      "Iteration 1000 - Batch 1000/1613 - Train loss: 1.2686824450840601, Train acc: 0.6506618381618382\n",
      "Iteration 1100 - Batch 1100/1613 - Train loss: 1.25946965383249, Train acc: 0.6586058128973661\n",
      "Iteration 1200 - Batch 1200/1613 - Train loss: 1.2507260112242338, Train acc: 0.6662676935886761\n",
      "Iteration 1300 - Batch 1300/1613 - Train loss: 1.2429642825287914, Train acc: 0.6732081091468102\n",
      "Iteration 1400 - Batch 1400/1613 - Train loss: 1.2360682060767887, Train acc: 0.6791354389721628\n",
      "Iteration 1500 - Batch 1500/1613 - Train loss: 1.2292631476978553, Train acc: 0.6853555962691539\n",
      "Iteration 1600 - Batch 1600/1613 - Train loss: 1.2230770890225775, Train acc: 0.690896314803248\n",
      "[3, 0, 3, 3, 1, 3, 3, 2, 1, 4, 3, 0, 1, 0, 4, 3, 3, 0, 1, 0, 3, 4, 1, 3, 0, 4, 2, 1, 0, 3, 1, 2, 0, 1, 1, 3, 3, 2, 3, 4, 2, 4, 1, 1, 2, 0, 1, 2, 3, 2, 4, 0, 1, 3, 1, 0, 1, 0, 4, 4, 4, 1, 3, 0, 2, 1, 3, 2, 3, 2, 3, 4, 4, 2, 4, 1, 0, 3, 1, 3, 2, 0, 1, 4, 1, 0, 2, 1, 0, 0, 4, 2, 0, 4, 4, 2, 0, 3, 4, 2, 1, 2, 4, 0, 3, 0, 1, 3, 0, 3, 4, 2, 4, 2, 2, 2, 0, 4, 4, 2, 4, 0, 0, 2, 0, 2, 4, 4, 1, 2, 4, 1, 3, 1, 2, 2, 0, 4, 3, 2, 4, 2, 4, 2, 3, 2, 0, 0, 3, 2, 0, 4, 1, 0, 0, 0, 0, 4, 4, 0, 1, 1, 2, 1, 4, 1, 4, 0, 2, 3, 2, 3, 0, 2, 2, 1, 1, 3, 3, 3, 4, 1, 2, 2, 3, 2, 0, 2, 4, 0, 4, 3, 3, 3, 0, 0, 4, 3, 4, 4, 3, 3, 1, 4, 0, 1, 2, 1, 1, 2, 4, 3, 2, 3, 4, 2, 3, 4, 1, 0, 3, 3, 4, 1, 1, 1, 2, 1, 3, 4, 2, 3, 3, 3, 1, 3, 1, 3, 4, 4, 2, 2, 4, 1, 1, 4, 4, 3, 3, 0, 3, 4, 4, 4, 1, 0, 0, 0, 0, 4, 2, 2, 3, 0, 2, 1, 0, 4, 2, 2, 2, 3, 1, 1, 1, 0, 1, 0, 0, 4, 0, 4, 1, 2, 4, 0, 1, 3, 3, 0, 1, 2, 1, 3, 3, 1, 1, 1, 0, 3, 2, 2, 1, 0, 2, 2, 1, 2, 4, 3, 2, 2, 4, 3, 0, 0, 2, 0, 4, 1, 2, 4, 0, 4, 0, 4, 0, 1, 1, 2, 1, 3, 1, 4, 4, 2, 3, 0, 4, 1, 2, 3, 3, 1, 0, 3, 2, 4, 1, 3, 2, 2, 1, 2, 0, 2, 2, 4, 0, 4, 3, 0, 0, 1, 0, 2, 1, 0, 4, 1, 2, 2, 3, 1, 3, 0, 1, 4, 3, 3, 1, 1, 2, 1, 0, 3, 1, 0, 1, 3, 0, 4, 0, 4, 0, 4, 1, 4, 1, 2, 1, 0, 2, 1, 4, 3, 0, 1, 4, 3, 3, 0, 0, 1, 0, 2, 0, 3, 0, 0, 1, 0, 0, 2, 3, 1, 2, 4, 4, 0, 3, 2, 4, 2, 4, 4, 2, 4, 3, 4, 2, 4, 3, 0, 3, 2, 2, 4, 0, 4, 3, 4, 3, 0, 1, 4, 0, 3, 3, 3, 0, 4, 1, 3, 3, 3, 3, 4, 0, 0, 3, 2, 4, 3, 2, 1, 1, 0, 4, 1, 3, 2, 2, 4, 1, 4, 2, 4, 2, 2, 0, 3, 1, 1, 2, 4, 0, 1, 1, 2]\n",
      "[4, 0, 3, 3, 4, 3, 3, 2, 4, 4, 3, 0, 4, 2, 4, 3, 3, 4, 3, 0, 3, 4, 3, 3, 0, 4, 2, 4, 0, 3, 4, 2, 0, 4, 3, 4, 2, 2, 4, 4, 3, 4, 4, 0, 2, 0, 4, 3, 3, 2, 4, 0, 4, 3, 4, 0, 4, 0, 4, 4, 4, 4, 3, 0, 2, 4, 3, 2, 3, 2, 3, 4, 4, 2, 4, 2, 0, 3, 0, 4, 0, 0, 4, 4, 4, 0, 2, 4, 0, 0, 4, 2, 0, 4, 4, 2, 0, 3, 4, 2, 4, 4, 2, 2, 3, 0, 0, 3, 0, 3, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 0, 0, 2, 2, 2, 4, 4, 4, 2, 4, 4, 3, 0, 2, 2, 0, 4, 3, 2, 2, 2, 4, 2, 3, 2, 4, 2, 3, 2, 0, 4, 4, 0, 2, 2, 0, 4, 4, 0, 4, 4, 2, 3, 4, 3, 4, 0, 2, 3, 2, 3, 2, 0, 2, 4, 3, 3, 3, 3, 4, 4, 2, 2, 3, 2, 2, 2, 4, 0, 4, 3, 4, 3, 0, 0, 4, 3, 4, 4, 3, 3, 4, 4, 0, 4, 2, 4, 0, 2, 4, 4, 2, 3, 4, 2, 3, 4, 2, 2, 3, 3, 4, 3, 4, 3, 2, 4, 4, 4, 2, 3, 3, 3, 3, 3, 4, 3, 4, 4, 2, 2, 4, 3, 3, 4, 4, 3, 4, 0, 3, 4, 4, 4, 4, 0, 0, 0, 4, 4, 2, 4, 3, 0, 0, 2, 0, 4, 2, 2, 2, 4, 0, 0, 0, 0, 0, 2, 0, 4, 0, 4, 4, 2, 4, 0, 3, 3, 4, 0, 0, 4, 4, 3, 3, 2, 3, 4, 0, 3, 2, 2, 4, 0, 2, 2, 4, 2, 4, 3, 4, 2, 4, 4, 0, 0, 2, 0, 4, 4, 2, 4, 0, 4, 0, 4, 0, 2, 0, 2, 0, 4, 0, 4, 4, 2, 3, 0, 4, 4, 2, 3, 4, 4, 0, 3, 2, 4, 4, 3, 2, 3, 4, 2, 0, 2, 2, 4, 0, 4, 3, 2, 0, 0, 0, 0, 0, 0, 4, 4, 2, 0, 3, 4, 4, 0, 3, 4, 3, 3, 0, 4, 2, 4, 0, 3, 4, 4, 4, 3, 0, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 0, 2, 4, 4, 3, 0, 4, 4, 3, 3, 0, 0, 4, 0, 2, 0, 4, 4, 0, 3, 4, 0, 2, 4, 3, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 3, 4, 0, 4, 4, 2, 4, 2, 2, 4, 0, 3, 4, 4, 3, 0, 4, 4, 0, 3, 3, 3, 2, 4, 3, 3, 0, 3, 3, 4, 2, 4, 4, 4, 4, 3, 2, 4, 4, 0, 4, 0, 3, 2, 0, 4, 4, 4, 2, 4, 2, 2, 0, 3, 0, 4, 2, 4, 0, 3, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.78      0.85      0.81       100\n",
      "           3       0.78      0.77      0.77       100\n",
      "           4       0.50      0.96      0.66       100\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.56      0.67      0.60       500\n",
      "weighted avg       0.56      0.67      0.60       500\n",
      "\n",
      "Val loss: 1.2383409589529037, Val acc: 0.666\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1700 - Batch 87/1613 - Train loss: 1.1317224014889111, Train acc: 0.7716619318181818\n",
      "Iteration 1800 - Batch 187/1613 - Train loss: 1.1271060657628038, Train acc: 0.7774268617021277\n",
      "Iteration 1900 - Batch 287/1613 - Train loss: 1.1206637093176444, Train acc: 0.7836371527777778\n",
      "Iteration 2000 - Batch 387/1613 - Train loss: 1.1201619141802346, Train acc: 0.7843105670103093\n",
      "Iteration 2100 - Batch 487/1613 - Train loss: 1.1184316979812794, Train acc: 0.7863729508196722\n",
      "Iteration 2200 - Batch 587/1613 - Train loss: 1.116504858647074, Train acc: 0.7884247448979592\n",
      "Iteration 2300 - Batch 687/1613 - Train loss: 1.1146939509483271, Train acc: 0.790061773255814\n",
      "Iteration 2400 - Batch 787/1613 - Train loss: 1.1138834622759504, Train acc: 0.7906487944162437\n",
      "Iteration 2500 - Batch 887/1613 - Train loss: 1.1135235606013119, Train acc: 0.7912443693693694\n",
      "Iteration 2600 - Batch 987/1613 - Train loss: 1.1145933743430536, Train acc: 0.7900113866396761\n",
      "Iteration 2700 - Batch 1087/1613 - Train loss: 1.1140753435628379, Train acc: 0.7904698988970589\n",
      "Iteration 2800 - Batch 1187/1613 - Train loss: 1.1133957850913005, Train acc: 0.7909301346801347\n",
      "Iteration 2900 - Batch 1287/1613 - Train loss: 1.11189060963644, Train acc: 0.7923379270186336\n",
      "Iteration 3000 - Batch 1387/1613 - Train loss: 1.112730573980884, Train acc: 0.7913814841498559\n",
      "Iteration 3100 - Batch 1487/1613 - Train loss: 1.1123849979091076, Train acc: 0.7916666666666666\n",
      "Iteration 3200 - Batch 1587/1613 - Train loss: 1.1112340268695384, Train acc: 0.7928211586901763\n",
      "[0, 4, 2, 4, 2, 1, 2, 0, 1, 2, 2, 2, 1, 4, 4, 0, 0, 4, 1, 4, 1, 0, 3, 0, 2, 3, 2, 1, 4, 4, 3, 0, 3, 1, 4, 4, 2, 1, 2, 0, 0, 1, 2, 4, 0, 2, 1, 1, 4, 1, 3, 2, 0, 4, 2, 2, 4, 3, 4, 3, 3, 4, 4, 2, 3, 1, 1, 0, 3, 0, 0, 1, 1, 3, 3, 3, 4, 3, 0, 1, 4, 0, 4, 0, 3, 3, 0, 3, 3, 0, 3, 0, 2, 2, 4, 3, 0, 4, 3, 3, 1, 0, 2, 2, 1, 3, 3, 1, 4, 3, 2, 1, 1, 2, 0, 1, 2, 3, 0, 2, 4, 3, 2, 3, 0, 1, 4, 4, 4, 4, 1, 3, 0, 4, 3, 1, 2, 3, 3, 3, 1, 1, 4, 0, 3, 3, 1, 4, 1, 2, 4, 3, 1, 2, 1, 4, 1, 2, 0, 1, 4, 3, 3, 0, 3, 1, 3, 3, 4, 2, 4, 1, 2, 1, 0, 2, 3, 4, 1, 3, 1, 0, 4, 1, 4, 2, 4, 0, 1, 4, 4, 1, 0, 2, 2, 3, 3, 4, 3, 3, 2, 2, 1, 2, 0, 0, 1, 3, 4, 2, 1, 4, 4, 0, 0, 2, 4, 4, 3, 1, 2, 2, 1, 3, 0, 2, 0, 3, 4, 0, 3, 2, 2, 0, 2, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 3, 1, 1, 0, 0, 1, 2, 4, 0, 0, 0, 3, 4, 2, 4, 1, 3, 3, 2, 2, 0, 4, 4, 3, 2, 2, 1, 3, 2, 2, 3, 2, 0, 3, 4, 0, 2, 1, 0, 4, 0, 3, 0, 2, 3, 4, 2, 1, 1, 1, 0, 4, 1, 4, 1, 2, 3, 3, 1, 2, 1, 0, 2, 0, 1, 4, 3, 3, 0, 2, 1, 0, 2, 0, 4, 3, 3, 2, 3, 2, 2, 4, 2, 3, 4, 3, 4, 3, 3, 3, 2, 2, 2, 4, 2, 3, 3, 3, 2, 2, 3, 3, 4, 1, 1, 1, 2, 1, 0, 2, 4, 0, 2, 0, 2, 3, 4, 1, 0, 3, 0, 0, 1, 4, 3, 2, 4, 2, 4, 4, 4, 0, 3, 4, 1, 2, 2, 0, 4, 1, 0, 4, 4, 3, 1, 4, 4, 3, 2, 2, 2, 1, 1, 4, 4, 4, 0, 0, 4, 1, 3, 3, 3, 4, 1, 4, 0, 1, 2, 4, 2, 1, 2, 2, 2, 1, 1, 1, 0, 3, 2, 3, 0, 2, 0, 1, 2, 0, 1, 4, 0, 4, 3, 0, 1, 4, 1, 2, 1, 3, 1, 1, 0, 1, 3, 2, 1, 2, 4, 1, 0, 3, 0, 4, 4, 0, 0, 1, 1, 0, 4, 2, 1, 3, 4, 4, 2, 0, 1, 4, 0, 0, 0, 3, 3, 4, 0, 0, 0, 3, 3, 1, 1, 0, 4, 0, 4, 0, 2, 0, 2, 2, 4, 3, 0]\n",
      "[0, 4, 2, 4, 2, 4, 0, 0, 4, 2, 2, 2, 3, 4, 4, 0, 0, 2, 0, 4, 3, 0, 3, 0, 3, 3, 2, 4, 4, 4, 3, 2, 3, 3, 4, 4, 0, 4, 2, 0, 2, 3, 2, 4, 0, 2, 3, 4, 4, 0, 3, 2, 0, 4, 2, 2, 0, 3, 4, 3, 3, 4, 4, 2, 3, 4, 0, 2, 3, 0, 0, 4, 2, 3, 3, 3, 4, 3, 0, 4, 4, 0, 3, 3, 4, 3, 0, 3, 3, 0, 3, 0, 2, 2, 2, 3, 0, 4, 3, 4, 4, 0, 0, 2, 3, 3, 3, 0, 2, 3, 2, 3, 0, 3, 0, 2, 2, 3, 0, 0, 4, 3, 2, 2, 0, 0, 4, 4, 4, 4, 0, 3, 0, 4, 3, 4, 2, 3, 3, 3, 0, 4, 3, 0, 3, 3, 0, 4, 4, 2, 4, 3, 2, 2, 3, 4, 4, 0, 0, 0, 3, 3, 3, 0, 3, 2, 3, 3, 4, 2, 4, 0, 2, 0, 0, 3, 3, 2, 3, 3, 2, 0, 4, 4, 4, 3, 4, 0, 3, 4, 3, 4, 0, 2, 2, 3, 3, 4, 2, 3, 0, 2, 3, 2, 0, 0, 4, 3, 4, 2, 4, 4, 4, 0, 0, 2, 4, 4, 3, 2, 2, 2, 0, 3, 0, 2, 0, 3, 4, 4, 3, 2, 2, 0, 2, 0, 0, 3, 0, 2, 3, 3, 3, 0, 0, 3, 2, 3, 0, 0, 3, 2, 4, 0, 0, 0, 3, 4, 2, 4, 4, 3, 3, 2, 0, 0, 4, 4, 3, 0, 0, 3, 3, 2, 2, 4, 2, 0, 3, 0, 0, 2, 0, 4, 4, 0, 3, 0, 2, 3, 2, 0, 3, 0, 3, 0, 3, 0, 4, 4, 2, 3, 3, 0, 2, 4, 0, 2, 0, 4, 4, 3, 3, 0, 2, 3, 0, 2, 0, 4, 3, 3, 0, 3, 2, 0, 4, 2, 4, 4, 3, 3, 3, 3, 3, 2, 2, 2, 4, 2, 3, 3, 3, 0, 2, 3, 3, 4, 0, 4, 4, 2, 3, 0, 2, 4, 0, 2, 0, 2, 3, 2, 4, 0, 3, 0, 3, 3, 4, 3, 0, 4, 2, 4, 4, 4, 0, 3, 4, 0, 2, 2, 0, 4, 0, 0, 4, 4, 3, 3, 4, 4, 3, 2, 0, 2, 3, 4, 4, 4, 4, 0, 0, 3, 3, 3, 2, 3, 4, 3, 4, 0, 0, 2, 4, 2, 3, 2, 2, 2, 4, 4, 2, 0, 4, 2, 3, 0, 2, 0, 3, 2, 4, 0, 4, 0, 4, 3, 0, 0, 4, 4, 2, 3, 3, 3, 0, 0, 4, 3, 0, 0, 2, 4, 4, 0, 3, 0, 2, 4, 0, 0, 4, 3, 0, 4, 2, 4, 3, 4, 4, 2, 0, 0, 4, 0, 0, 0, 3, 4, 4, 0, 0, 0, 3, 3, 4, 3, 0, 4, 0, 4, 0, 2, 0, 2, 2, 4, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.78      0.80      0.79       100\n",
      "           3       0.66      0.91      0.77       100\n",
      "           4       0.67      0.84      0.74       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.56      0.69      0.62       500\n",
      "weighted avg       0.56      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.205539509654045, Val acc: 0.692\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3300 - Batch 74/1613 - Train loss: 1.0804235911369324, Train acc: 0.8233333333333334\n",
      "Iteration 3400 - Batch 174/1613 - Train loss: 1.0878251729692732, Train acc: 0.8160714285714286\n",
      "Iteration 3500 - Batch 274/1613 - Train loss: 1.0904270967570218, Train acc: 0.8139772727272727\n",
      "Iteration 3600 - Batch 374/1613 - Train loss: 1.0939980765978494, Train acc: 0.81075\n",
      "Iteration 3700 - Batch 474/1613 - Train loss: 1.0947315837207594, Train acc: 0.8097368421052632\n",
      "Iteration 3800 - Batch 574/1613 - Train loss: 1.0945650145281915, Train acc: 0.8097826086956522\n",
      "Iteration 3900 - Batch 674/1613 - Train loss: 1.0949425180753072, Train acc: 0.809212962962963\n",
      "Iteration 4000 - Batch 774/1613 - Train loss: 1.095365885765322, Train acc: 0.8087096774193548\n",
      "Iteration 4100 - Batch 874/1613 - Train loss: 1.0950863387244087, Train acc: 0.8090357142857143\n",
      "Iteration 4200 - Batch 974/1613 - Train loss: 1.0933120233584672, Train acc: 0.8109615384615385\n",
      "Iteration 4300 - Batch 1074/1613 - Train loss: 1.0938576613470565, Train acc: 0.8102906976744186\n",
      "Iteration 4400 - Batch 1174/1613 - Train loss: 1.0935652823143818, Train acc: 0.8105851063829788\n",
      "Iteration 4500 - Batch 1274/1613 - Train loss: 1.0930396849033879, Train acc: 0.8111274509803922\n",
      "Iteration 4600 - Batch 1374/1613 - Train loss: 1.092670662576502, Train acc: 0.8115681818181818\n",
      "Iteration 4700 - Batch 1474/1613 - Train loss: 1.0928967286772646, Train acc: 0.811271186440678\n",
      "Iteration 4800 - Batch 1574/1613 - Train loss: 1.0925884375496515, Train acc: 0.8115277777777777\n",
      "[2, 4, 0, 4, 0, 0, 4, 2, 3, 1, 2, 1, 3, 2, 2, 1, 1, 4, 0, 1, 2, 0, 4, 3, 1, 3, 3, 2, 2, 0, 0, 3, 1, 4, 0, 2, 4, 1, 2, 4, 4, 2, 2, 4, 1, 0, 2, 2, 2, 1, 4, 4, 1, 2, 4, 3, 0, 3, 1, 2, 3, 4, 0, 1, 3, 2, 4, 2, 1, 3, 2, 4, 0, 4, 4, 3, 1, 0, 0, 1, 2, 2, 4, 0, 0, 3, 1, 0, 1, 3, 4, 0, 1, 1, 1, 1, 1, 4, 0, 2, 4, 1, 0, 3, 3, 4, 2, 2, 1, 4, 0, 4, 0, 1, 2, 1, 3, 3, 2, 3, 4, 1, 3, 3, 1, 1, 4, 4, 2, 1, 1, 2, 1, 4, 4, 1, 3, 1, 3, 3, 0, 2, 3, 0, 0, 2, 4, 0, 3, 0, 0, 1, 1, 4, 2, 1, 1, 3, 3, 1, 0, 2, 0, 0, 3, 4, 1, 3, 1, 3, 1, 2, 4, 4, 3, 3, 2, 1, 1, 4, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 1, 1, 3, 3, 1, 3, 2, 1, 4, 2, 3, 0, 2, 4, 4, 0, 4, 0, 2, 3, 0, 2, 3, 2, 3, 0, 4, 1, 2, 3, 0, 4, 3, 4, 2, 1, 0, 4, 4, 4, 0, 4, 2, 3, 2, 3, 3, 2, 2, 2, 1, 1, 4, 0, 0, 1, 3, 2, 3, 0, 3, 3, 3, 2, 4, 0, 2, 4, 2, 3, 2, 3, 4, 3, 2, 4, 0, 0, 4, 4, 0, 0, 4, 0, 0, 1, 0, 2, 0, 1, 0, 0, 3, 3, 0, 0, 4, 0, 0, 1, 2, 2, 3, 3, 1, 1, 1, 1, 0, 0, 3, 3, 0, 2, 0, 0, 3, 3, 2, 4, 0, 1, 1, 4, 3, 0, 2, 4, 2, 1, 1, 3, 2, 2, 3, 3, 1, 1, 2, 3, 4, 2, 1, 4, 0, 2, 3, 3, 3, 4, 0, 1, 4, 0, 0, 2, 4, 3, 2, 1, 4, 4, 3, 2, 2, 2, 4, 4, 4, 3, 3, 2, 1, 2, 4, 3, 3, 1, 0, 1, 1, 2, 1, 1, 4, 3, 0, 4, 2, 3, 0, 1, 0, 2, 0, 4, 3, 1, 0, 2, 4, 3, 3, 0, 3, 4, 3, 1, 1, 4, 4, 1, 0, 4, 2, 0, 0, 1, 2, 1, 3, 4, 1, 4, 1, 4, 3, 0, 2, 0, 0, 4, 3, 4, 1, 4, 1, 4, 4, 2, 0, 1, 2, 2, 3, 2, 3, 1, 0, 1, 3, 3, 3, 0, 2, 0, 0, 2, 3, 4, 0, 0, 0, 4, 3, 3, 4, 1, 0, 1, 2, 4, 3, 1, 1, 4, 1, 1, 3, 2, 4, 0, 4, 0, 1, 0, 2, 4, 2, 1, 3, 3, 3, 0, 3, 4, 2, 4, 4, 2, 0, 4, 1, 0, 0, 4, 4]\n",
      "[2, 4, 2, 4, 0, 0, 4, 2, 3, 3, 2, 4, 3, 2, 2, 0, 3, 4, 0, 4, 2, 0, 4, 3, 4, 3, 3, 0, 2, 0, 0, 3, 2, 4, 0, 2, 4, 3, 0, 4, 4, 2, 2, 4, 0, 4, 2, 2, 2, 3, 4, 4, 3, 2, 4, 3, 0, 3, 4, 2, 3, 4, 0, 0, 3, 0, 4, 0, 4, 3, 2, 4, 0, 4, 4, 3, 0, 0, 4, 3, 3, 3, 4, 0, 0, 3, 3, 0, 0, 3, 2, 0, 3, 4, 4, 4, 3, 4, 0, 2, 4, 4, 0, 3, 4, 4, 2, 2, 0, 4, 0, 4, 0, 3, 2, 4, 3, 3, 2, 3, 4, 4, 3, 3, 2, 4, 4, 4, 0, 3, 4, 2, 4, 4, 4, 0, 3, 4, 3, 3, 0, 0, 3, 0, 0, 2, 4, 0, 3, 0, 2, 3, 3, 4, 0, 3, 3, 3, 4, 3, 0, 2, 0, 0, 3, 4, 4, 3, 2, 3, 4, 0, 4, 4, 3, 3, 2, 3, 2, 4, 0, 2, 4, 0, 0, 2, 2, 3, 2, 0, 0, 2, 0, 4, 3, 3, 3, 4, 3, 0, 0, 4, 2, 3, 0, 2, 4, 4, 0, 4, 4, 0, 3, 0, 2, 3, 2, 3, 0, 4, 3, 2, 4, 4, 4, 3, 4, 2, 4, 0, 4, 4, 4, 4, 4, 2, 3, 0, 3, 4, 2, 2, 2, 3, 4, 4, 0, 0, 0, 3, 2, 3, 0, 3, 3, 3, 0, 4, 0, 2, 4, 2, 3, 2, 2, 4, 3, 2, 4, 0, 0, 4, 4, 0, 0, 4, 2, 0, 4, 0, 2, 0, 0, 0, 0, 3, 3, 2, 0, 4, 0, 0, 4, 3, 2, 3, 3, 2, 0, 4, 4, 0, 0, 3, 4, 0, 2, 0, 0, 3, 3, 2, 4, 0, 4, 3, 4, 3, 0, 0, 4, 2, 4, 4, 3, 2, 2, 3, 3, 3, 4, 2, 3, 4, 2, 3, 4, 0, 2, 3, 3, 3, 4, 0, 4, 2, 0, 0, 2, 4, 3, 2, 4, 4, 4, 3, 0, 2, 2, 4, 3, 4, 3, 3, 2, 4, 2, 4, 2, 3, 4, 0, 4, 4, 0, 4, 4, 4, 3, 0, 4, 2, 3, 0, 3, 4, 2, 0, 4, 3, 4, 0, 2, 4, 3, 3, 2, 3, 4, 3, 4, 4, 3, 4, 4, 0, 4, 2, 2, 0, 4, 2, 4, 3, 4, 3, 4, 4, 4, 4, 0, 2, 0, 0, 4, 4, 4, 0, 4, 2, 4, 4, 2, 0, 3, 3, 0, 3, 2, 3, 4, 0, 3, 3, 3, 3, 0, 0, 0, 0, 2, 3, 4, 4, 0, 0, 4, 3, 3, 4, 4, 0, 3, 2, 3, 3, 0, 0, 4, 2, 3, 3, 2, 4, 0, 3, 0, 4, 0, 2, 4, 2, 4, 3, 3, 4, 0, 3, 4, 0, 4, 4, 2, 0, 4, 3, 0, 3, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.80      0.74      0.77       100\n",
      "           3       0.69      0.89      0.78       100\n",
      "           4       0.59      0.94      0.73       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.56      0.68      0.61       500\n",
      "weighted avg       0.56      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2158431485295296, Val acc: 0.684\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4900 - Batch 61/1613 - Train loss: 1.0875956089265886, Train acc: 0.8190524193548387\n",
      "Iteration 5000 - Batch 161/1613 - Train loss: 1.0923386620886533, Train acc: 0.8125\n",
      "Iteration 5100 - Batch 261/1613 - Train loss: 1.0920233892575475, Train acc: 0.8121421755725191\n",
      "Iteration 5200 - Batch 361/1613 - Train loss: 1.0909361444125518, Train acc: 0.8131042817679558\n",
      "Iteration 5300 - Batch 461/1613 - Train loss: 1.0882560782360309, Train acc: 0.8154761904761905\n",
      "Iteration 5400 - Batch 561/1613 - Train loss: 1.0875028441809251, Train acc: 0.8162811387900356\n",
      "Iteration 5500 - Batch 661/1613 - Train loss: 1.0874134788340313, Train acc: 0.815851586102719\n",
      "Iteration 5600 - Batch 761/1613 - Train loss: 1.0866204858452004, Train acc: 0.8166830708661418\n",
      "Iteration 5700 - Batch 861/1613 - Train loss: 1.0860478794353468, Train acc: 0.8171766241299304\n",
      "Iteration 5800 - Batch 961/1613 - Train loss: 1.0862146793185055, Train acc: 0.8170803014553014\n",
      "Iteration 5900 - Batch 1061/1613 - Train loss: 1.0852369089696816, Train acc: 0.8181202919020716\n",
      "Iteration 6000 - Batch 1161/1613 - Train loss: 1.0842476380466388, Train acc: 0.819223321858864\n",
      "Iteration 6100 - Batch 1261/1613 - Train loss: 1.083658181024618, Train acc: 0.8197801109350238\n",
      "Iteration 6200 - Batch 1361/1613 - Train loss: 1.0842042021814422, Train acc: 0.8192455947136564\n",
      "Iteration 6300 - Batch 1461/1613 - Train loss: 1.083399225479927, Train acc: 0.8202376880984952\n",
      "Iteration 6400 - Batch 1561/1613 - Train loss: 1.082888027197573, Train acc: 0.8208226632522407\n",
      "[0, 1, 0, 2, 0, 2, 2, 4, 0, 1, 2, 2, 3, 0, 0, 0, 1, 4, 3, 0, 3, 3, 4, 0, 1, 1, 4, 2, 2, 1, 0, 2, 3, 3, 4, 3, 3, 4, 0, 4, 2, 2, 2, 3, 4, 0, 0, 0, 2, 3, 1, 2, 1, 1, 1, 4, 4, 2, 2, 2, 4, 1, 2, 1, 2, 4, 4, 1, 2, 4, 3, 3, 0, 4, 4, 2, 0, 3, 1, 4, 4, 2, 4, 2, 1, 2, 3, 0, 2, 2, 1, 0, 4, 0, 4, 2, 1, 1, 3, 3, 2, 0, 1, 1, 4, 2, 4, 1, 4, 3, 0, 0, 3, 0, 1, 0, 2, 0, 0, 1, 1, 2, 4, 0, 1, 0, 0, 3, 4, 2, 0, 2, 0, 4, 1, 3, 3, 3, 1, 1, 3, 3, 3, 2, 1, 4, 0, 2, 2, 1, 4, 2, 3, 3, 3, 2, 4, 2, 3, 1, 3, 0, 2, 2, 4, 4, 4, 2, 0, 0, 1, 2, 2, 2, 3, 3, 1, 4, 1, 3, 0, 3, 0, 4, 4, 0, 2, 1, 1, 4, 4, 2, 3, 4, 3, 3, 4, 0, 0, 1, 4, 3, 4, 1, 0, 2, 0, 1, 0, 4, 3, 4, 0, 2, 4, 1, 4, 2, 0, 3, 0, 2, 3, 1, 1, 2, 3, 2, 1, 1, 0, 2, 4, 2, 3, 2, 3, 1, 2, 1, 0, 1, 1, 4, 1, 0, 4, 0, 2, 2, 4, 4, 2, 1, 4, 0, 1, 2, 0, 0, 4, 3, 1, 2, 4, 1, 4, 2, 3, 1, 1, 4, 1, 4, 0, 1, 3, 1, 4, 3, 1, 2, 3, 2, 4, 0, 1, 2, 3, 0, 2, 4, 3, 2, 1, 3, 0, 4, 2, 3, 1, 3, 1, 1, 1, 3, 3, 3, 3, 2, 1, 4, 3, 4, 3, 4, 4, 0, 2, 0, 0, 2, 0, 2, 0, 3, 1, 3, 2, 1, 2, 2, 2, 1, 1, 4, 2, 1, 0, 4, 3, 4, 1, 3, 3, 4, 0, 3, 3, 2, 0, 3, 2, 2, 0, 3, 0, 2, 0, 0, 1, 2, 1, 4, 2, 0, 0, 0, 4, 2, 3, 1, 3, 2, 4, 0, 3, 0, 0, 4, 0, 4, 1, 3, 3, 4, 1, 3, 1, 1, 0, 1, 1, 0, 0, 4, 3, 1, 2, 1, 1, 0, 4, 3, 3, 2, 3, 3, 4, 3, 4, 1, 4, 2, 3, 2, 3, 3, 1, 0, 0, 1, 0, 3, 4, 4, 0, 4, 0, 0, 2, 1, 0, 4, 1, 4, 2, 4, 4, 2, 1, 3, 3, 2, 1, 2, 4, 4, 1, 3, 2, 0, 4, 3, 4, 3, 4, 3, 3, 0, 2, 3, 2, 0, 4, 4, 4, 2, 4, 3, 3, 4, 1, 0, 0, 0, 0, 0, 1, 1, 3, 1, 4, 3, 1, 4, 4, 0, 2, 3, 0, 3, 0, 1, 1, 2, 0, 1, 3, 0]\n",
      "[0, 4, 0, 2, 0, 2, 2, 4, 0, 4, 2, 0, 3, 0, 0, 0, 4, 4, 3, 0, 3, 3, 4, 0, 0, 4, 4, 2, 0, 2, 0, 2, 3, 3, 4, 3, 3, 4, 2, 4, 2, 2, 2, 4, 4, 0, 0, 0, 2, 3, 4, 2, 0, 4, 0, 4, 4, 0, 3, 2, 4, 0, 2, 4, 2, 4, 4, 3, 2, 4, 3, 3, 0, 4, 4, 2, 0, 3, 0, 4, 4, 3, 4, 2, 4, 2, 4, 0, 2, 2, 4, 0, 4, 0, 4, 2, 4, 3, 3, 3, 2, 2, 4, 4, 4, 2, 4, 3, 4, 3, 0, 0, 3, 0, 4, 0, 2, 0, 0, 4, 0, 2, 3, 4, 3, 0, 0, 3, 3, 0, 0, 2, 0, 4, 4, 3, 3, 4, 4, 4, 4, 3, 3, 2, 0, 4, 0, 2, 0, 3, 4, 2, 3, 3, 3, 2, 4, 2, 3, 2, 3, 0, 2, 2, 4, 4, 4, 2, 2, 0, 3, 2, 2, 2, 3, 3, 0, 4, 4, 4, 0, 3, 0, 4, 4, 0, 0, 4, 3, 4, 4, 2, 3, 4, 3, 3, 4, 0, 0, 4, 4, 3, 4, 4, 0, 2, 0, 3, 0, 4, 3, 4, 0, 2, 4, 4, 4, 2, 0, 3, 0, 2, 3, 4, 4, 0, 3, 2, 2, 0, 0, 2, 4, 2, 3, 2, 3, 4, 2, 4, 0, 3, 4, 4, 4, 0, 4, 0, 4, 2, 4, 4, 2, 4, 4, 0, 2, 2, 0, 0, 4, 3, 4, 2, 4, 4, 4, 2, 3, 3, 3, 4, 3, 4, 0, 0, 3, 3, 4, 3, 3, 2, 3, 2, 4, 0, 4, 2, 3, 0, 2, 4, 3, 2, 3, 4, 0, 4, 0, 3, 0, 3, 4, 3, 4, 3, 3, 4, 4, 2, 3, 4, 3, 4, 3, 4, 4, 0, 2, 4, 0, 2, 0, 2, 0, 3, 0, 3, 0, 0, 2, 2, 2, 4, 3, 4, 2, 0, 0, 4, 3, 4, 4, 3, 0, 4, 4, 4, 3, 0, 2, 3, 2, 0, 0, 3, 0, 2, 0, 0, 3, 2, 2, 4, 2, 0, 0, 0, 4, 2, 3, 2, 4, 0, 4, 0, 3, 0, 0, 4, 0, 4, 4, 3, 4, 2, 4, 4, 4, 4, 0, 0, 4, 0, 0, 4, 3, 3, 2, 4, 2, 0, 4, 4, 3, 2, 3, 3, 4, 3, 4, 4, 4, 0, 3, 2, 3, 3, 2, 0, 2, 4, 2, 3, 4, 4, 0, 4, 0, 0, 2, 4, 0, 4, 3, 4, 2, 4, 4, 0, 3, 3, 3, 2, 0, 2, 4, 4, 3, 3, 0, 0, 4, 3, 4, 3, 2, 4, 3, 0, 3, 3, 2, 4, 4, 4, 4, 2, 4, 3, 3, 4, 0, 2, 0, 0, 0, 0, 4, 2, 2, 3, 4, 3, 4, 4, 4, 0, 2, 3, 0, 3, 0, 4, 0, 2, 0, 3, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.81      0.81      0.81       100\n",
      "           3       0.74      0.84      0.79       100\n",
      "           4       0.59      0.96      0.73       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.206844612956047, Val acc: 0.7\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6500 - Batch 48/1613 - Train loss: 1.0669399864819584, Train acc: 0.8360969387755102\n",
      "Iteration 6600 - Batch 148/1613 - Train loss: 1.0620136837031218, Train acc: 0.84123322147651\n",
      "Iteration 6700 - Batch 248/1613 - Train loss: 1.0641065206393658, Train acc: 0.8401104417670683\n",
      "Iteration 6800 - Batch 348/1613 - Train loss: 1.0673158894637254, Train acc: 0.8369448424068768\n",
      "Iteration 6900 - Batch 448/1613 - Train loss: 1.0668441705024057, Train acc: 0.8377644766146993\n",
      "Iteration 7000 - Batch 548/1613 - Train loss: 1.0700909474725497, Train acc: 0.8344717668488161\n",
      "Iteration 7100 - Batch 648/1613 - Train loss: 1.0694910466946512, Train acc: 0.8350828197226502\n",
      "Iteration 7200 - Batch 748/1613 - Train loss: 1.069278700329433, Train acc: 0.8352386515353805\n",
      "Iteration 7300 - Batch 848/1613 - Train loss: 1.0696556544977869, Train acc: 0.8347320376914017\n",
      "Iteration 7400 - Batch 948/1613 - Train loss: 1.0703382677348572, Train acc: 0.8338382507903056\n",
      "Iteration 7500 - Batch 1048/1613 - Train loss: 1.070095460908088, Train acc: 0.8341277407054337\n",
      "Iteration 7600 - Batch 1148/1613 - Train loss: 1.071126689331961, Train acc: 0.8329525674499565\n",
      "Iteration 7700 - Batch 1248/1613 - Train loss: 1.0714615962331633, Train acc: 0.8326160928742994\n",
      "Iteration 7800 - Batch 1348/1613 - Train loss: 1.0714544704262638, Train acc: 0.8325379911045219\n",
      "Iteration 7900 - Batch 1448/1613 - Train loss: 1.0726008227646475, Train acc: 0.8313060731538993\n",
      "Iteration 8000 - Batch 1548/1613 - Train loss: 1.0720668425861677, Train acc: 0.8317866365397031\n",
      "[3, 3, 4, 0, 0, 3, 0, 4, 1, 4, 2, 0, 3, 1, 3, 2, 0, 1, 3, 1, 2, 1, 2, 3, 4, 3, 1, 1, 0, 4, 2, 1, 0, 3, 2, 4, 3, 0, 2, 4, 1, 1, 0, 4, 3, 1, 2, 2, 2, 1, 0, 4, 0, 0, 0, 0, 4, 0, 1, 4, 0, 0, 1, 3, 4, 2, 1, 0, 3, 3, 2, 4, 1, 0, 2, 0, 3, 1, 3, 1, 4, 1, 2, 1, 3, 3, 4, 4, 3, 3, 1, 4, 4, 4, 3, 0, 4, 2, 4, 4, 0, 1, 0, 0, 3, 4, 0, 0, 1, 1, 0, 4, 1, 2, 4, 2, 4, 1, 2, 2, 1, 4, 4, 0, 4, 2, 0, 2, 3, 3, 1, 4, 1, 0, 3, 2, 3, 3, 2, 3, 4, 3, 0, 1, 1, 0, 3, 3, 2, 3, 2, 1, 1, 1, 1, 1, 3, 4, 3, 2, 3, 2, 3, 1, 4, 3, 2, 4, 3, 1, 1, 2, 0, 2, 1, 0, 0, 2, 3, 0, 0, 2, 0, 4, 3, 3, 2, 1, 4, 1, 1, 4, 2, 4, 2, 3, 0, 4, 2, 3, 1, 4, 1, 4, 2, 1, 4, 0, 2, 0, 3, 2, 0, 0, 4, 3, 2, 2, 3, 3, 2, 4, 4, 2, 0, 2, 3, 0, 2, 4, 1, 1, 1, 1, 0, 0, 1, 4, 3, 1, 2, 4, 0, 3, 1, 2, 2, 1, 3, 1, 3, 1, 1, 0, 4, 2, 0, 3, 2, 2, 2, 0, 4, 3, 4, 4, 0, 0, 3, 3, 3, 0, 2, 4, 0, 4, 1, 2, 4, 1, 0, 2, 3, 1, 0, 2, 4, 0, 4, 4, 0, 2, 4, 0, 0, 0, 2, 1, 1, 2, 2, 1, 0, 0, 3, 1, 4, 1, 3, 2, 2, 2, 4, 3, 1, 4, 3, 2, 2, 3, 4, 4, 1, 4, 1, 2, 1, 1, 1, 3, 1, 4, 0, 2, 4, 3, 3, 3, 2, 1, 0, 3, 4, 0, 1, 4, 0, 2, 0, 2, 2, 3, 3, 2, 0, 1, 4, 1, 4, 4, 3, 4, 1, 4, 0, 4, 1, 1, 2, 1, 3, 0, 3, 3, 1, 0, 0, 0, 4, 2, 4, 2, 0, 2, 1, 0, 2, 3, 0, 3, 4, 2, 0, 1, 3, 4, 2, 3, 1, 0, 1, 3, 2, 1, 4, 1, 0, 2, 4, 4, 3, 2, 0, 0, 3, 4, 1, 2, 2, 4, 2, 4, 3, 2, 2, 3, 1, 3, 2, 4, 4, 3, 4, 0, 1, 3, 0, 2, 4, 1, 1, 3, 0, 3, 0, 3, 4, 0, 2, 2, 0, 0, 3, 2, 4, 2, 0, 3, 4, 0, 4, 3, 1, 3, 1, 2, 1, 1, 3, 0, 0, 0, 3, 4, 2, 4, 4, 1, 1, 3, 2, 4, 0, 3, 2, 2, 3, 0, 3, 3, 4, 4, 0, 4, 0, 2, 1, 0, 2, 1]\n",
      "[3, 3, 2, 0, 0, 3, 0, 4, 3, 4, 2, 0, 3, 0, 0, 2, 0, 4, 3, 0, 2, 4, 2, 3, 4, 3, 4, 4, 4, 4, 2, 4, 0, 3, 2, 4, 3, 2, 2, 4, 2, 4, 0, 4, 3, 4, 2, 2, 0, 4, 0, 0, 0, 0, 0, 2, 4, 2, 4, 4, 0, 0, 4, 4, 4, 2, 0, 0, 3, 4, 2, 4, 4, 0, 3, 0, 3, 3, 3, 4, 4, 3, 3, 4, 4, 3, 4, 4, 3, 3, 4, 4, 4, 4, 3, 2, 4, 3, 4, 4, 0, 4, 0, 0, 4, 4, 0, 0, 3, 0, 0, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 0, 2, 3, 3, 3, 4, 3, 0, 3, 0, 3, 3, 2, 3, 4, 3, 0, 2, 4, 0, 3, 3, 2, 3, 2, 4, 0, 4, 4, 3, 3, 3, 3, 0, 3, 0, 3, 3, 4, 3, 2, 4, 3, 4, 3, 2, 0, 2, 4, 2, 0, 2, 3, 2, 0, 2, 0, 4, 3, 3, 2, 4, 4, 4, 3, 4, 2, 4, 2, 4, 0, 4, 2, 3, 4, 2, 3, 4, 0, 4, 4, 0, 2, 2, 3, 2, 0, 0, 3, 3, 2, 2, 3, 3, 2, 0, 4, 2, 0, 0, 3, 2, 2, 4, 3, 3, 0, 4, 0, 0, 4, 4, 3, 4, 2, 4, 2, 3, 3, 2, 2, 3, 3, 2, 3, 4, 4, 0, 4, 2, 0, 3, 2, 2, 2, 2, 4, 3, 4, 4, 0, 2, 3, 3, 4, 0, 0, 4, 0, 2, 2, 2, 4, 0, 0, 2, 3, 4, 0, 2, 4, 0, 4, 4, 0, 2, 4, 3, 2, 0, 2, 0, 4, 2, 0, 4, 0, 0, 3, 3, 4, 4, 3, 2, 2, 2, 4, 4, 4, 4, 3, 2, 2, 3, 4, 4, 3, 4, 0, 2, 4, 4, 4, 3, 2, 4, 0, 0, 4, 3, 3, 3, 2, 3, 0, 3, 4, 0, 3, 4, 2, 2, 0, 2, 2, 3, 3, 2, 0, 4, 4, 4, 4, 3, 3, 4, 3, 4, 0, 4, 4, 4, 2, 4, 3, 0, 3, 3, 3, 4, 0, 2, 4, 2, 4, 0, 0, 0, 3, 0, 2, 3, 0, 3, 4, 2, 0, 4, 3, 4, 2, 4, 4, 0, 0, 3, 2, 4, 4, 4, 0, 2, 4, 4, 3, 2, 0, 0, 3, 4, 0, 2, 2, 4, 2, 4, 3, 2, 2, 4, 0, 3, 2, 4, 4, 3, 4, 2, 4, 3, 0, 2, 4, 4, 0, 3, 0, 3, 0, 3, 4, 2, 2, 2, 0, 0, 3, 2, 4, 2, 0, 3, 4, 0, 4, 3, 3, 3, 4, 2, 4, 4, 3, 0, 0, 0, 3, 4, 2, 4, 4, 4, 4, 4, 0, 4, 2, 3, 0, 0, 3, 0, 4, 3, 4, 4, 0, 4, 0, 2, 0, 0, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.75      0.82      0.78       100\n",
      "           3       0.74      0.88      0.80       100\n",
      "           4       0.57      0.92      0.70       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.55      0.68      0.61       500\n",
      "weighted avg       0.55      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2240194901823997, Val acc: 0.682\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8100 - Batch 35/1613 - Train loss: 1.0520104302300348, Train acc: 0.8567708333333334\n",
      "Iteration 8200 - Batch 135/1613 - Train loss: 1.0631370693445206, Train acc: 0.8432904411764706\n",
      "Iteration 8300 - Batch 235/1613 - Train loss: 1.0685616112866645, Train acc: 0.8365995762711864\n",
      "Iteration 8400 - Batch 335/1613 - Train loss: 1.0733710758033252, Train acc: 0.8314732142857143\n",
      "Iteration 8500 - Batch 435/1613 - Train loss: 1.0733857257377117, Train acc: 0.8310636467889908\n",
      "Iteration 8600 - Batch 535/1613 - Train loss: 1.0729402104642853, Train acc: 0.8311567164179104\n",
      "Iteration 8700 - Batch 635/1613 - Train loss: 1.0727328454735894, Train acc: 0.8313187893081762\n",
      "Iteration 8800 - Batch 735/1613 - Train loss: 1.0726241104142822, Train acc: 0.8314792798913043\n",
      "Iteration 8900 - Batch 835/1613 - Train loss: 1.0715669112627586, Train acc: 0.8323863636363636\n",
      "Iteration 9000 - Batch 935/1613 - Train loss: 1.0710093843249173, Train acc: 0.8327991452991453\n",
      "Iteration 9100 - Batch 1035/1613 - Train loss: 1.0711609573322833, Train acc: 0.8325289575289575\n",
      "Iteration 9200 - Batch 1135/1613 - Train loss: 1.0723480877637024, Train acc: 0.831178477112676\n",
      "Iteration 9300 - Batch 1235/1613 - Train loss: 1.0717343195163702, Train acc: 0.8317910598705501\n",
      "Iteration 9400 - Batch 1335/1613 - Train loss: 1.072171020115207, Train acc: 0.8314230913173652\n",
      "Iteration 9500 - Batch 1435/1613 - Train loss: 1.0719022129903597, Train acc: 0.8316939415041783\n",
      "Iteration 9600 - Batch 1535/1613 - Train loss: 1.0722836341786508, Train acc: 0.8313395182291666\n",
      "[4, 1, 1, 3, 4, 2, 0, 4, 1, 2, 1, 0, 0, 0, 4, 3, 3, 1, 3, 2, 3, 1, 2, 2, 1, 4, 0, 3, 3, 0, 3, 1, 2, 4, 1, 3, 3, 0, 2, 4, 3, 3, 3, 4, 4, 4, 2, 3, 3, 0, 0, 4, 0, 1, 4, 1, 3, 4, 4, 4, 2, 2, 2, 0, 3, 2, 1, 1, 3, 4, 4, 1, 2, 4, 0, 0, 0, 4, 1, 3, 3, 2, 4, 2, 1, 3, 0, 0, 2, 1, 4, 2, 4, 1, 2, 1, 1, 3, 3, 2, 3, 2, 1, 2, 0, 1, 3, 3, 2, 0, 3, 3, 0, 2, 3, 0, 4, 4, 0, 3, 2, 1, 3, 3, 0, 0, 2, 0, 4, 1, 4, 2, 2, 0, 2, 1, 1, 0, 1, 3, 1, 0, 0, 2, 2, 2, 1, 1, 4, 4, 3, 4, 3, 2, 3, 0, 1, 4, 2, 4, 3, 0, 3, 4, 0, 2, 1, 1, 3, 3, 0, 3, 3, 3, 2, 0, 0, 1, 0, 1, 1, 3, 2, 1, 2, 1, 4, 1, 0, 1, 1, 3, 4, 1, 1, 0, 3, 1, 0, 3, 2, 2, 2, 1, 2, 0, 3, 1, 1, 1, 0, 0, 2, 2, 0, 2, 0, 4, 1, 3, 3, 2, 2, 3, 2, 3, 3, 0, 1, 0, 4, 1, 2, 4, 4, 3, 4, 3, 4, 2, 3, 2, 2, 1, 4, 1, 4, 2, 3, 0, 3, 4, 2, 2, 3, 4, 4, 3, 4, 2, 0, 1, 0, 4, 3, 0, 2, 4, 4, 0, 4, 4, 0, 4, 3, 1, 4, 1, 0, 2, 4, 4, 3, 0, 1, 2, 3, 1, 2, 4, 1, 4, 3, 4, 1, 0, 1, 3, 4, 2, 2, 4, 1, 4, 2, 1, 3, 0, 2, 0, 3, 4, 4, 3, 0, 4, 2, 1, 1, 2, 4, 0, 4, 4, 0, 0, 3, 0, 0, 0, 4, 1, 2, 1, 0, 2, 1, 1, 0, 4, 0, 1, 2, 1, 3, 3, 3, 1, 3, 4, 4, 1, 0, 2, 0, 4, 2, 2, 2, 2, 4, 3, 2, 3, 1, 1, 1, 1, 4, 4, 3, 2, 2, 0, 2, 2, 2, 0, 3, 3, 2, 1, 1, 2, 4, 3, 2, 4, 2, 4, 2, 4, 0, 0, 2, 4, 4, 0, 4, 1, 2, 1, 0, 4, 1, 2, 1, 0, 4, 3, 0, 0, 0, 3, 1, 3, 1, 1, 0, 3, 3, 0, 2, 0, 3, 4, 3, 3, 3, 1, 3, 3, 0, 0, 0, 1, 0, 4, 3, 0, 1, 0, 4, 0, 3, 2, 0, 1, 4, 1, 4, 2, 3, 0, 1, 0, 0, 3, 2, 4, 3, 2, 2, 2, 3, 4, 4, 2, 2, 0, 1, 4, 2, 4, 4, 1, 0, 3, 3, 4, 3, 1, 0, 0, 2, 4, 1, 1, 4, 1, 1, 1, 2, 4, 0, 0, 0, 2, 0, 4]\n",
      "[4, 0, 3, 3, 4, 2, 0, 4, 4, 2, 3, 0, 0, 0, 0, 3, 4, 3, 3, 0, 3, 4, 2, 0, 3, 4, 0, 3, 3, 0, 3, 4, 2, 2, 4, 3, 3, 0, 2, 4, 3, 3, 3, 4, 4, 4, 2, 3, 3, 0, 0, 4, 0, 3, 4, 0, 4, 4, 4, 4, 2, 2, 0, 0, 3, 0, 3, 4, 3, 3, 4, 4, 2, 4, 0, 0, 0, 4, 4, 2, 3, 2, 4, 2, 4, 3, 0, 0, 2, 4, 4, 2, 4, 4, 0, 3, 4, 3, 4, 2, 3, 0, 3, 2, 0, 0, 3, 3, 2, 0, 3, 3, 0, 2, 3, 0, 4, 4, 0, 3, 2, 0, 4, 3, 0, 4, 0, 0, 4, 0, 4, 2, 2, 0, 2, 3, 2, 0, 3, 3, 4, 0, 0, 3, 2, 2, 0, 3, 4, 4, 3, 4, 3, 2, 3, 0, 3, 4, 2, 4, 3, 0, 3, 4, 0, 2, 3, 0, 3, 3, 0, 3, 3, 3, 2, 0, 0, 4, 0, 4, 4, 3, 2, 4, 2, 3, 3, 4, 0, 4, 4, 3, 4, 3, 4, 0, 3, 0, 0, 3, 0, 2, 2, 3, 2, 0, 3, 3, 2, 3, 0, 0, 2, 2, 0, 2, 0, 4, 0, 3, 3, 2, 2, 3, 0, 3, 3, 0, 0, 0, 4, 3, 2, 4, 4, 3, 4, 3, 4, 0, 3, 0, 0, 4, 4, 4, 4, 2, 3, 0, 3, 4, 2, 2, 3, 4, 4, 3, 2, 0, 0, 4, 0, 4, 3, 0, 0, 4, 4, 4, 4, 4, 0, 4, 3, 0, 4, 3, 3, 2, 4, 4, 3, 0, 4, 2, 3, 4, 2, 4, 3, 4, 3, 4, 3, 0, 0, 3, 4, 2, 2, 3, 4, 4, 3, 0, 4, 2, 2, 0, 3, 4, 4, 3, 0, 4, 2, 0, 0, 0, 4, 0, 4, 4, 0, 0, 3, 0, 0, 0, 4, 0, 0, 2, 0, 2, 0, 4, 0, 4, 0, 0, 2, 0, 3, 3, 4, 4, 3, 4, 3, 0, 0, 2, 0, 4, 2, 2, 2, 2, 4, 3, 2, 3, 4, 4, 4, 2, 4, 3, 3, 2, 2, 0, 2, 2, 3, 0, 3, 3, 2, 4, 3, 2, 4, 3, 2, 4, 2, 4, 2, 4, 0, 0, 2, 4, 4, 0, 3, 4, 2, 4, 0, 4, 0, 2, 0, 0, 4, 3, 0, 0, 0, 3, 4, 3, 4, 4, 0, 4, 3, 0, 2, 4, 3, 4, 3, 3, 3, 3, 3, 3, 0, 0, 0, 4, 0, 4, 3, 0, 2, 0, 4, 0, 3, 2, 0, 4, 4, 4, 4, 2, 0, 4, 0, 0, 0, 3, 2, 4, 3, 0, 2, 2, 3, 4, 3, 3, 2, 2, 4, 4, 0, 4, 4, 4, 0, 4, 3, 4, 3, 3, 0, 0, 2, 4, 4, 3, 4, 3, 2, 4, 2, 4, 0, 0, 0, 0, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.77      0.82       100\n",
      "           3       0.70      0.90      0.79       100\n",
      "           4       0.62      0.90      0.73       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2036525309085846, Val acc: 0.7\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9700 - Batch 22/1613 - Train loss: 1.0746741683586785, Train acc: 0.8288043478260869\n",
      "Iteration 9800 - Batch 122/1613 - Train loss: 1.072147854459964, Train acc: 0.8310467479674797\n",
      "Iteration 9900 - Batch 222/1613 - Train loss: 1.0668358613022775, Train acc: 0.8370235426008968\n",
      "Iteration 10000 - Batch 322/1613 - Train loss: 1.0648766040063864, Train acc: 0.8390092879256966\n",
      "Iteration 10100 - Batch 422/1613 - Train loss: 1.064473434824752, Train acc: 0.8390218676122931\n",
      "Iteration 10200 - Batch 522/1613 - Train loss: 1.0635894990559973, Train acc: 0.8400454110898662\n",
      "Iteration 10300 - Batch 622/1613 - Train loss: 1.0643351343049283, Train acc: 0.8392355537720706\n",
      "Iteration 10400 - Batch 722/1613 - Train loss: 1.0634295743365836, Train acc: 0.8402489626556017\n",
      "Iteration 10500 - Batch 822/1613 - Train loss: 1.0638629983146455, Train acc: 0.8399529161603888\n",
      "Iteration 10600 - Batch 922/1613 - Train loss: 1.064153527193183, Train acc: 0.8396533044420368\n",
      "Iteration 10700 - Batch 1022/1613 - Train loss: 1.0645136654318719, Train acc: 0.8391984359726296\n",
      "Iteration 10800 - Batch 1122/1613 - Train loss: 1.06429523229599, Train acc: 0.8394367764915405\n",
      "Iteration 10900 - Batch 1222/1613 - Train loss: 1.064533105709469, Train acc: 0.839176206050695\n",
      "Iteration 11000 - Batch 1322/1613 - Train loss: 1.0642215001339814, Train acc: 0.8394038170823885\n",
      "Iteration 11100 - Batch 1422/1613 - Train loss: 1.0648589282913772, Train acc: 0.8388308151791989\n",
      "Iteration 11200 - Batch 1522/1613 - Train loss: 1.0658100383186215, Train acc: 0.8379226854891662\n",
      "[2, 3, 2, 3, 0, 1, 4, 3, 3, 2, 4, 0, 2, 2, 3, 1, 0, 3, 1, 4, 4, 4, 4, 0, 3, 4, 3, 4, 4, 2, 1, 1, 4, 2, 1, 2, 0, 2, 2, 3, 2, 0, 3, 0, 2, 1, 4, 0, 3, 1, 2, 0, 2, 2, 0, 2, 0, 3, 0, 0, 3, 3, 1, 1, 2, 0, 3, 3, 0, 1, 1, 0, 1, 4, 4, 2, 4, 1, 1, 3, 0, 2, 2, 3, 0, 4, 0, 3, 2, 0, 3, 2, 3, 3, 1, 0, 0, 3, 1, 3, 2, 1, 2, 1, 3, 2, 3, 3, 2, 0, 3, 2, 3, 1, 1, 3, 0, 0, 0, 2, 1, 3, 3, 4, 0, 4, 0, 4, 0, 4, 1, 1, 3, 4, 3, 0, 1, 4, 4, 4, 3, 3, 2, 2, 0, 4, 1, 3, 3, 3, 3, 0, 1, 3, 1, 4, 0, 4, 1, 1, 4, 3, 0, 0, 3, 2, 3, 4, 4, 3, 4, 4, 2, 4, 1, 0, 0, 3, 1, 1, 2, 0, 2, 2, 3, 2, 1, 3, 0, 3, 3, 2, 4, 4, 1, 2, 2, 1, 1, 0, 2, 2, 1, 1, 4, 1, 2, 2, 4, 1, 4, 1, 0, 4, 2, 3, 3, 0, 3, 0, 3, 0, 3, 2, 3, 4, 3, 1, 0, 0, 2, 0, 3, 2, 0, 0, 2, 2, 3, 3, 2, 4, 0, 0, 0, 0, 3, 2, 2, 4, 1, 4, 1, 0, 3, 3, 0, 4, 3, 2, 3, 1, 4, 4, 1, 2, 0, 4, 2, 2, 2, 4, 1, 4, 4, 3, 2, 0, 1, 4, 0, 2, 3, 0, 2, 2, 2, 4, 0, 3, 4, 4, 4, 4, 1, 3, 3, 1, 4, 1, 0, 0, 1, 1, 2, 4, 2, 1, 3, 4, 3, 2, 4, 0, 2, 1, 2, 4, 2, 1, 1, 4, 1, 3, 4, 1, 2, 3, 4, 0, 0, 0, 3, 1, 1, 3, 3, 4, 1, 3, 4, 1, 1, 0, 4, 4, 0, 1, 3, 3, 2, 4, 1, 3, 1, 1, 2, 1, 2, 3, 4, 0, 1, 0, 4, 4, 2, 2, 1, 4, 4, 0, 0, 2, 3, 1, 4, 1, 0, 1, 1, 0, 1, 4, 1, 2, 3, 0, 0, 4, 2, 4, 0, 0, 1, 1, 4, 3, 1, 1, 1, 4, 0, 1, 1, 4, 2, 1, 2, 0, 2, 1, 4, 2, 2, 4, 4, 3, 2, 0, 4, 2, 2, 0, 1, 1, 3, 4, 1, 3, 2, 3, 0, 0, 2, 1, 0, 2, 4, 3, 4, 0, 3, 4, 2, 3, 4, 1, 0, 2, 1, 0, 0, 0, 4, 0, 0, 1, 4, 3, 2, 1, 4, 1, 1, 2, 2, 4, 1, 4, 4, 4, 4, 3, 4, 2, 0, 4, 0, 1, 2, 2, 0, 0, 3, 2, 3, 3, 2, 3, 0, 1, 2, 3, 0, 2, 3, 4, 0, 0]\n",
      "[2, 3, 2, 3, 0, 3, 4, 3, 3, 2, 4, 0, 2, 2, 4, 4, 0, 3, 2, 2, 4, 4, 4, 0, 3, 4, 3, 4, 4, 2, 4, 4, 4, 0, 3, 2, 2, 2, 2, 3, 2, 0, 3, 0, 2, 4, 4, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 3, 3, 4, 4, 2, 0, 3, 3, 0, 4, 4, 0, 4, 4, 4, 2, 4, 0, 4, 3, 0, 0, 0, 3, 0, 4, 0, 3, 2, 0, 3, 2, 3, 3, 0, 0, 0, 3, 3, 3, 4, 2, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2, 3, 4, 4, 3, 0, 0, 0, 2, 4, 3, 3, 4, 0, 4, 0, 4, 0, 2, 4, 3, 4, 4, 3, 0, 4, 4, 4, 4, 3, 3, 2, 2, 0, 4, 2, 3, 3, 3, 3, 0, 3, 2, 0, 4, 2, 4, 4, 4, 4, 4, 0, 2, 3, 2, 3, 4, 0, 3, 4, 3, 2, 4, 4, 0, 0, 4, 4, 0, 2, 0, 2, 0, 4, 0, 2, 3, 0, 3, 3, 2, 4, 4, 4, 2, 0, 3, 4, 0, 2, 2, 4, 4, 4, 2, 2, 2, 4, 3, 4, 3, 0, 4, 4, 3, 3, 0, 0, 0, 4, 0, 4, 2, 2, 4, 4, 0, 0, 0, 2, 0, 3, 2, 0, 0, 2, 2, 3, 3, 2, 4, 4, 2, 0, 0, 3, 2, 2, 4, 2, 4, 4, 0, 3, 3, 0, 4, 3, 2, 3, 4, 4, 4, 0, 2, 0, 4, 2, 2, 2, 4, 4, 4, 4, 3, 2, 0, 4, 4, 0, 2, 3, 0, 2, 2, 2, 4, 0, 3, 4, 4, 4, 4, 0, 3, 3, 0, 4, 3, 0, 0, 4, 4, 2, 2, 0, 3, 3, 4, 3, 3, 4, 0, 2, 0, 0, 4, 0, 3, 4, 4, 4, 3, 3, 4, 0, 3, 4, 2, 0, 0, 3, 0, 0, 3, 4, 4, 4, 3, 4, 4, 4, 0, 4, 4, 0, 4, 3, 3, 0, 4, 4, 3, 4, 4, 2, 4, 2, 3, 4, 0, 4, 0, 4, 4, 2, 2, 4, 4, 4, 0, 0, 2, 3, 0, 4, 3, 0, 3, 4, 0, 4, 4, 4, 2, 3, 0, 0, 4, 0, 4, 0, 4, 0, 3, 4, 3, 2, 4, 3, 4, 0, 0, 3, 4, 0, 0, 2, 0, 2, 0, 4, 2, 2, 4, 4, 4, 2, 2, 4, 2, 2, 0, 4, 4, 3, 4, 3, 3, 2, 3, 0, 0, 2, 0, 0, 2, 4, 3, 4, 4, 3, 3, 0, 3, 4, 4, 4, 0, 4, 0, 0, 0, 4, 0, 0, 3, 3, 3, 2, 4, 4, 2, 3, 2, 2, 4, 0, 4, 4, 4, 4, 3, 4, 2, 0, 4, 0, 4, 2, 2, 0, 0, 3, 2, 3, 3, 2, 3, 2, 4, 2, 3, 0, 2, 3, 4, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.88      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.80      0.79      0.79       100\n",
      "           3       0.78      0.86      0.82       100\n",
      "           4       0.56      0.92      0.70       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2061364725232124, Val acc: 0.69\n",
      "Epoch 8/30\n",
      "Iteration 11300 - Batch 9/1613 - Train loss: 1.09454243183136, Train acc: 0.803125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11400 - Batch 109/1613 - Train loss: 1.0697422043843703, Train acc: 0.83125\n",
      "Iteration 11500 - Batch 209/1613 - Train loss: 1.0697161992390951, Train acc: 0.8328869047619047\n",
      "Iteration 11600 - Batch 309/1613 - Train loss: 1.0651124763873316, Train acc: 0.8379032258064516\n",
      "Iteration 11700 - Batch 409/1613 - Train loss: 1.0661441688130542, Train acc: 0.8368140243902439\n",
      "Iteration 11800 - Batch 509/1613 - Train loss: 1.0661691971853668, Train acc: 0.8368872549019608\n",
      "Iteration 11900 - Batch 609/1613 - Train loss: 1.066871889301988, Train acc: 0.8359631147540983\n",
      "Iteration 12000 - Batch 709/1613 - Train loss: 1.0672590051738309, Train acc: 0.8356514084507042\n",
      "Iteration 12100 - Batch 809/1613 - Train loss: 1.0652021368344624, Train acc: 0.8379243827160494\n",
      "Iteration 12200 - Batch 909/1613 - Train loss: 1.0637694098137238, Train acc: 0.8393887362637362\n",
      "Iteration 12300 - Batch 1009/1613 - Train loss: 1.063665119551196, Train acc: 0.8396039603960396\n",
      "Iteration 12400 - Batch 1109/1613 - Train loss: 1.0638868086509876, Train acc: 0.8394144144144144\n",
      "Iteration 12500 - Batch 1209/1613 - Train loss: 1.063005321823861, Train acc: 0.8401859504132232\n",
      "Iteration 12600 - Batch 1309/1613 - Train loss: 1.0629831686729694, Train acc: 0.8400286259541985\n",
      "Iteration 12700 - Batch 1409/1613 - Train loss: 1.0627663286019724, Train acc: 0.8401595744680851\n",
      "Iteration 12800 - Batch 1509/1613 - Train loss: 1.0621499286976872, Train acc: 0.8408940397350994\n",
      "Iteration 12900 - Batch 1609/1613 - Train loss: 1.061796570416563, Train acc: 0.841304347826087\n",
      "[1, 0, 2, 0, 4, 1, 4, 1, 2, 3, 1, 1, 3, 0, 3, 2, 3, 2, 0, 2, 2, 3, 3, 2, 1, 0, 0, 1, 4, 1, 3, 4, 4, 4, 2, 4, 0, 2, 3, 0, 0, 0, 2, 1, 3, 3, 3, 0, 2, 4, 1, 3, 4, 2, 1, 1, 2, 3, 0, 0, 0, 0, 3, 0, 2, 2, 0, 4, 0, 4, 2, 4, 0, 0, 1, 4, 3, 4, 2, 3, 1, 1, 2, 0, 0, 2, 4, 3, 0, 3, 0, 4, 2, 2, 1, 3, 0, 1, 0, 4, 3, 2, 3, 0, 2, 2, 2, 0, 4, 0, 2, 1, 0, 3, 3, 3, 2, 4, 1, 1, 1, 4, 2, 0, 3, 3, 3, 0, 1, 2, 4, 1, 3, 1, 4, 0, 1, 0, 2, 3, 4, 4, 0, 4, 4, 4, 0, 4, 3, 1, 3, 1, 4, 0, 0, 2, 3, 0, 3, 2, 2, 2, 2, 3, 1, 3, 2, 3, 0, 2, 2, 1, 1, 0, 4, 2, 4, 3, 4, 1, 4, 4, 0, 2, 1, 1, 2, 3, 4, 0, 0, 0, 4, 1, 1, 2, 4, 3, 4, 4, 3, 3, 2, 2, 1, 3, 3, 4, 3, 2, 2, 3, 3, 4, 4, 2, 3, 3, 1, 2, 0, 4, 4, 0, 3, 2, 1, 0, 1, 2, 3, 2, 0, 3, 0, 4, 2, 1, 3, 1, 0, 0, 4, 0, 1, 2, 4, 0, 3, 2, 3, 3, 0, 4, 1, 3, 4, 3, 4, 2, 1, 1, 0, 0, 1, 4, 4, 1, 2, 1, 1, 0, 1, 2, 0, 2, 1, 2, 4, 3, 0, 4, 3, 2, 3, 1, 1, 0, 4, 3, 1, 4, 1, 4, 2, 1, 3, 1, 0, 1, 2, 1, 4, 3, 1, 4, 2, 2, 4, 0, 2, 1, 3, 1, 4, 1, 0, 3, 2, 1, 1, 4, 4, 1, 3, 4, 2, 1, 2, 2, 3, 2, 0, 4, 2, 1, 4, 3, 4, 3, 0, 2, 4, 2, 0, 2, 4, 1, 2, 2, 2, 0, 4, 0, 4, 0, 3, 1, 4, 0, 4, 0, 4, 0, 2, 3, 1, 1, 4, 0, 0, 1, 1, 4, 2, 1, 1, 0, 3, 1, 0, 4, 0, 3, 0, 4, 4, 0, 1, 2, 2, 3, 0, 3, 3, 2, 0, 2, 1, 3, 1, 2, 4, 0, 2, 3, 3, 3, 0, 2, 4, 4, 1, 4, 3, 3, 3, 0, 4, 4, 0, 0, 1, 3, 2, 1, 1, 1, 4, 3, 3, 0, 4, 4, 4, 4, 1, 3, 3, 1, 2, 2, 4, 3, 4, 2, 0, 2, 1, 2, 1, 4, 0, 3, 1, 3, 0, 0, 3, 3, 1, 2, 4, 3, 4, 0, 0, 2, 1, 3, 1, 1, 0, 1, 0, 0, 4, 3, 1, 3, 0, 2, 4, 3, 1, 2, 2, 4, 2, 0, 1, 3, 2, 4, 2, 1, 0, 3, 4, 1]\n",
      "[4, 0, 2, 0, 4, 4, 4, 2, 2, 3, 4, 3, 3, 2, 4, 2, 3, 2, 0, 2, 2, 2, 3, 2, 2, 0, 0, 3, 4, 3, 3, 4, 4, 4, 2, 2, 0, 3, 3, 0, 0, 4, 2, 4, 3, 3, 3, 0, 2, 4, 4, 3, 4, 2, 4, 4, 2, 3, 0, 0, 4, 0, 3, 0, 2, 2, 0, 2, 0, 4, 2, 3, 0, 0, 0, 4, 3, 4, 2, 3, 2, 4, 2, 0, 0, 2, 4, 3, 0, 3, 0, 4, 2, 2, 4, 3, 2, 4, 0, 3, 3, 2, 3, 0, 2, 0, 2, 4, 4, 0, 2, 4, 0, 3, 3, 3, 2, 4, 0, 4, 3, 3, 2, 0, 3, 3, 3, 3, 4, 2, 4, 4, 2, 2, 3, 0, 4, 0, 2, 3, 4, 4, 0, 4, 4, 4, 2, 2, 3, 4, 3, 2, 4, 0, 0, 2, 3, 0, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 4, 2, 0, 3, 2, 4, 3, 3, 4, 4, 4, 2, 2, 3, 4, 2, 3, 4, 0, 0, 0, 4, 3, 3, 2, 4, 3, 4, 4, 3, 3, 2, 2, 3, 3, 3, 4, 3, 2, 2, 3, 3, 4, 4, 2, 3, 3, 4, 2, 4, 4, 4, 0, 3, 2, 4, 0, 3, 2, 3, 2, 0, 3, 0, 0, 0, 0, 3, 4, 0, 2, 4, 0, 3, 2, 4, 2, 3, 2, 3, 3, 0, 4, 2, 3, 4, 3, 4, 2, 0, 4, 0, 0, 2, 3, 4, 4, 2, 4, 4, 0, 0, 2, 0, 2, 4, 2, 4, 3, 4, 4, 3, 2, 3, 0, 4, 2, 4, 3, 2, 4, 0, 4, 2, 4, 3, 0, 0, 0, 2, 0, 4, 3, 3, 4, 3, 0, 3, 0, 2, 2, 3, 4, 4, 4, 0, 3, 2, 3, 3, 4, 4, 4, 3, 4, 2, 0, 2, 0, 3, 2, 0, 2, 3, 4, 3, 4, 4, 3, 0, 2, 4, 2, 0, 2, 4, 0, 2, 2, 2, 0, 4, 0, 4, 0, 3, 3, 4, 0, 4, 0, 4, 0, 2, 3, 3, 3, 4, 2, 0, 4, 4, 4, 2, 4, 3, 0, 3, 4, 0, 4, 4, 4, 0, 4, 4, 2, 0, 2, 2, 4, 0, 3, 4, 0, 0, 2, 3, 3, 2, 2, 4, 0, 2, 3, 3, 3, 0, 0, 4, 4, 0, 4, 4, 4, 3, 2, 4, 4, 0, 2, 4, 3, 2, 4, 3, 2, 4, 3, 3, 0, 4, 4, 4, 2, 3, 3, 3, 0, 2, 2, 4, 3, 4, 2, 0, 2, 4, 2, 3, 4, 0, 3, 4, 3, 0, 2, 3, 3, 0, 0, 4, 3, 4, 0, 2, 2, 3, 3, 4, 4, 0, 3, 0, 0, 4, 3, 4, 3, 0, 0, 0, 3, 0, 2, 0, 4, 2, 2, 4, 3, 2, 4, 2, 4, 0, 3, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.72      0.88      0.79       100\n",
      "           3       0.71      0.91      0.80       100\n",
      "           4       0.59      0.84      0.69       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.55      0.68      0.61       500\n",
      "weighted avg       0.55      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2205940634012222, Val acc: 0.682\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13000 - Batch 96/1613 - Train loss: 1.0587668683111053, Train acc: 0.8431056701030928\n",
      "Iteration 13100 - Batch 196/1613 - Train loss: 1.0573125569348407, Train acc: 0.8454949238578681\n",
      "Iteration 13200 - Batch 296/1613 - Train loss: 1.058422868701344, Train acc: 0.8445917508417509\n",
      "Iteration 13300 - Batch 396/1613 - Train loss: 1.057929158811305, Train acc: 0.8451668765743073\n",
      "Iteration 13400 - Batch 496/1613 - Train loss: 1.057162949856618, Train acc: 0.8458878269617707\n",
      "Iteration 13500 - Batch 596/1613 - Train loss: 1.0576572475121848, Train acc: 0.8454773869346733\n",
      "Iteration 13600 - Batch 696/1613 - Train loss: 1.056745229270229, Train acc: 0.8463055954088953\n",
      "Iteration 13700 - Batch 796/1613 - Train loss: 1.0584223348941826, Train acc: 0.8443773525721455\n",
      "Iteration 13800 - Batch 896/1613 - Train loss: 1.0598371719968491, Train acc: 0.8427745261984393\n",
      "Iteration 13900 - Batch 996/1613 - Train loss: 1.0588257883711827, Train acc: 0.8440320962888666\n",
      "Iteration 14000 - Batch 1096/1613 - Train loss: 1.0587147236848378, Train acc: 0.8443197356426618\n",
      "Iteration 14100 - Batch 1196/1613 - Train loss: 1.0580672818915289, Train acc: 0.8448464912280702\n",
      "Iteration 14200 - Batch 1296/1613 - Train loss: 1.057259334815679, Train acc: 0.8457016191210486\n",
      "Iteration 14300 - Batch 1396/1613 - Train loss: 1.0581328684974758, Train acc: 0.8449579455977094\n",
      "Iteration 14400 - Batch 1496/1613 - Train loss: 1.0577347357430773, Train acc: 0.8453156312625251\n",
      "Iteration 14500 - Batch 1596/1613 - Train loss: 1.05821736435929, Train acc: 0.8448849405134627\n",
      "[4, 1, 4, 0, 4, 4, 4, 4, 2, 2, 0, 1, 1, 2, 1, 2, 4, 2, 3, 3, 2, 1, 1, 4, 3, 3, 3, 0, 1, 0, 1, 2, 0, 3, 2, 4, 3, 3, 0, 1, 2, 2, 2, 2, 1, 3, 1, 2, 2, 4, 4, 1, 1, 3, 4, 1, 0, 1, 0, 3, 2, 4, 1, 3, 3, 1, 0, 0, 2, 0, 1, 0, 0, 0, 2, 3, 1, 0, 4, 3, 2, 3, 1, 0, 0, 4, 0, 0, 0, 3, 1, 1, 4, 3, 1, 1, 3, 1, 0, 3, 2, 2, 4, 0, 4, 4, 4, 0, 0, 0, 4, 4, 2, 2, 4, 4, 0, 4, 1, 3, 0, 0, 2, 3, 1, 3, 3, 0, 3, 2, 2, 1, 0, 4, 4, 1, 3, 2, 0, 0, 3, 1, 3, 4, 4, 2, 2, 3, 3, 0, 4, 0, 4, 0, 3, 2, 4, 3, 4, 4, 2, 0, 4, 4, 1, 3, 1, 4, 3, 1, 0, 1, 3, 3, 4, 4, 0, 3, 4, 2, 4, 2, 2, 4, 1, 3, 4, 1, 4, 4, 3, 4, 0, 1, 3, 1, 4, 1, 2, 1, 0, 0, 2, 2, 2, 0, 1, 2, 3, 3, 3, 1, 0, 1, 0, 4, 2, 3, 1, 2, 0, 4, 3, 0, 0, 3, 2, 3, 4, 4, 2, 3, 3, 4, 2, 3, 4, 1, 2, 3, 0, 0, 2, 3, 2, 2, 2, 1, 2, 0, 3, 1, 4, 1, 2, 2, 2, 0, 0, 3, 1, 2, 2, 1, 0, 2, 2, 0, 3, 2, 4, 1, 0, 3, 2, 3, 2, 0, 3, 3, 1, 3, 4, 0, 3, 1, 3, 0, 1, 1, 2, 1, 1, 1, 4, 4, 2, 2, 4, 0, 1, 3, 0, 3, 1, 3, 3, 4, 3, 0, 3, 0, 0, 4, 2, 2, 1, 1, 3, 2, 2, 4, 4, 4, 2, 0, 0, 0, 1, 4, 0, 4, 0, 3, 1, 2, 4, 4, 4, 1, 3, 2, 4, 0, 2, 0, 3, 4, 4, 4, 2, 4, 2, 0, 3, 0, 2, 2, 1, 3, 2, 0, 4, 0, 2, 2, 4, 2, 1, 1, 3, 1, 0, 2, 1, 2, 1, 2, 0, 4, 2, 1, 1, 4, 1, 0, 2, 1, 3, 2, 3, 4, 1, 4, 3, 2, 2, 1, 4, 1, 2, 0, 2, 3, 4, 3, 4, 3, 4, 2, 0, 3, 3, 0, 4, 0, 0, 3, 4, 4, 4, 4, 3, 4, 1, 4, 1, 3, 0, 3, 2, 4, 1, 0, 3, 1, 4, 0, 1, 3, 3, 2, 1, 0, 4, 3, 4, 3, 1, 3, 0, 2, 1, 0, 3, 0, 3, 1, 2, 2, 0, 4, 1, 3, 0, 2, 1, 1, 2, 2, 3, 1, 1, 3, 0, 2, 4, 1, 4, 0, 2, 0, 1, 4, 1, 1, 0, 2, 0, 1, 0, 0, 1, 0, 0, 3, 4, 1, 1, 3]\n",
      "[4, 4, 4, 0, 4, 4, 4, 4, 2, 2, 0, 4, 2, 3, 3, 0, 4, 0, 3, 3, 2, 4, 3, 4, 3, 3, 3, 0, 2, 0, 4, 2, 0, 3, 2, 4, 3, 2, 0, 3, 2, 2, 0, 2, 4, 3, 4, 2, 2, 2, 4, 3, 3, 3, 4, 4, 0, 4, 0, 4, 2, 4, 3, 3, 3, 2, 0, 0, 2, 0, 4, 0, 0, 0, 3, 3, 4, 0, 4, 3, 2, 3, 2, 4, 0, 4, 0, 0, 2, 4, 4, 4, 4, 3, 4, 4, 3, 0, 0, 3, 0, 2, 4, 0, 4, 4, 4, 0, 0, 0, 2, 4, 0, 2, 4, 4, 0, 4, 4, 3, 0, 0, 2, 3, 3, 3, 3, 0, 3, 2, 2, 3, 0, 4, 4, 0, 0, 2, 0, 0, 3, 4, 3, 4, 4, 2, 2, 3, 3, 0, 4, 0, 4, 0, 3, 2, 2, 4, 4, 4, 2, 0, 4, 4, 4, 3, 4, 4, 3, 0, 0, 3, 4, 4, 4, 4, 0, 3, 4, 2, 4, 2, 2, 4, 4, 3, 4, 4, 4, 4, 3, 4, 0, 4, 3, 4, 4, 4, 2, 4, 0, 0, 2, 2, 2, 0, 4, 2, 3, 3, 3, 0, 0, 4, 0, 4, 2, 3, 4, 2, 0, 4, 3, 0, 2, 3, 2, 3, 4, 4, 2, 3, 3, 4, 2, 3, 4, 0, 0, 4, 0, 0, 2, 3, 2, 2, 2, 3, 2, 0, 3, 0, 4, 0, 2, 2, 2, 0, 0, 3, 2, 2, 0, 3, 0, 2, 2, 0, 3, 0, 4, 4, 4, 3, 2, 3, 2, 0, 3, 3, 0, 3, 4, 0, 4, 4, 3, 0, 4, 2, 2, 0, 4, 0, 4, 4, 2, 2, 4, 0, 4, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 0, 0, 4, 2, 2, 4, 3, 3, 2, 2, 4, 4, 2, 2, 0, 0, 0, 4, 4, 0, 4, 0, 3, 4, 2, 4, 4, 4, 4, 3, 0, 4, 0, 3, 0, 3, 4, 3, 4, 0, 4, 0, 4, 3, 0, 2, 2, 3, 3, 2, 0, 4, 0, 2, 2, 4, 2, 3, 4, 2, 4, 0, 2, 4, 2, 4, 2, 0, 0, 2, 4, 4, 4, 2, 0, 0, 4, 3, 2, 3, 4, 4, 4, 4, 2, 2, 0, 4, 2, 2, 3, 0, 3, 4, 3, 4, 3, 4, 0, 0, 4, 3, 0, 3, 0, 0, 4, 4, 4, 4, 0, 3, 4, 2, 4, 4, 3, 0, 3, 2, 4, 2, 0, 3, 0, 4, 0, 4, 3, 3, 2, 0, 0, 4, 3, 4, 3, 3, 3, 0, 0, 3, 0, 3, 0, 3, 4, 2, 2, 4, 4, 3, 3, 0, 2, 4, 0, 2, 2, 3, 4, 4, 3, 0, 2, 4, 4, 4, 2, 2, 0, 4, 4, 0, 3, 0, 2, 2, 4, 0, 0, 4, 0, 0, 3, 4, 0, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.80      0.82      0.81       100\n",
      "           3       0.78      0.87      0.82       100\n",
      "           4       0.57      0.91      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2031259462237358, Val acc: 0.702\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14600 - Batch 83/1613 - Train loss: 1.03889437800362, Train acc: 0.8653273809523809\n",
      "Iteration 14700 - Batch 183/1613 - Train loss: 1.0492829392137735, Train acc: 0.85546875\n",
      "Iteration 14800 - Batch 283/1613 - Train loss: 1.0514876405957718, Train acc: 0.8528829225352113\n",
      "Iteration 14900 - Batch 383/1613 - Train loss: 1.0522321940710146, Train acc: 0.85205078125\n",
      "Iteration 15000 - Batch 483/1613 - Train loss: 1.0542832111770457, Train acc: 0.8500774793388429\n",
      "Iteration 15100 - Batch 583/1613 - Train loss: 1.0560246136498779, Train acc: 0.8483518835616438\n",
      "Iteration 15200 - Batch 683/1613 - Train loss: 1.055449433058326, Train acc: 0.8490040204678363\n",
      "Iteration 15300 - Batch 783/1613 - Train loss: 1.0556187667712873, Train acc: 0.8488121811224489\n",
      "Iteration 15400 - Batch 883/1613 - Train loss: 1.0554755491234058, Train acc: 0.8488758484162896\n",
      "Iteration 15500 - Batch 983/1613 - Train loss: 1.0552468597283209, Train acc: 0.8490218495934959\n",
      "Iteration 15600 - Batch 1083/1613 - Train loss: 1.0553541019064034, Train acc: 0.848967942804428\n",
      "Iteration 15700 - Batch 1183/1613 - Train loss: 1.0555557517485845, Train acc: 0.848659206081081\n",
      "Iteration 15800 - Batch 1283/1613 - Train loss: 1.0562098137686187, Train acc: 0.8480091510903427\n",
      "Iteration 15900 - Batch 1383/1613 - Train loss: 1.0565361431826745, Train acc: 0.8476336705202312\n",
      "Iteration 16000 - Batch 1483/1613 - Train loss: 1.056575026071939, Train acc: 0.8474772574123989\n",
      "Iteration 16100 - Batch 1583/1613 - Train loss: 1.0565618488824728, Train acc: 0.8475181502525253\n",
      "[1, 3, 2, 0, 4, 2, 0, 1, 0, 0, 0, 3, 1, 1, 1, 4, 2, 4, 2, 3, 3, 4, 1, 1, 4, 3, 4, 2, 1, 3, 4, 1, 1, 2, 0, 0, 0, 2, 2, 0, 3, 1, 3, 0, 0, 1, 1, 4, 1, 3, 4, 4, 4, 2, 2, 3, 1, 4, 4, 4, 0, 4, 1, 4, 1, 2, 1, 4, 3, 0, 0, 0, 3, 2, 3, 0, 3, 0, 4, 1, 0, 2, 4, 3, 0, 0, 0, 3, 2, 2, 3, 3, 0, 3, 2, 4, 3, 4, 4, 2, 2, 2, 1, 0, 1, 2, 1, 3, 2, 1, 3, 1, 0, 3, 1, 4, 2, 0, 0, 4, 0, 0, 3, 0, 1, 1, 1, 0, 0, 3, 2, 3, 3, 0, 1, 1, 2, 0, 2, 4, 3, 2, 0, 2, 0, 2, 1, 4, 3, 3, 0, 1, 0, 4, 1, 2, 1, 1, 2, 3, 1, 3, 0, 4, 2, 4, 4, 4, 4, 4, 0, 2, 0, 4, 4, 4, 0, 0, 3, 4, 0, 1, 3, 4, 3, 2, 4, 0, 1, 2, 3, 3, 0, 2, 3, 0, 0, 2, 0, 3, 1, 3, 0, 0, 3, 3, 4, 0, 2, 1, 2, 3, 1, 0, 4, 1, 4, 3, 3, 1, 1, 0, 4, 2, 3, 0, 1, 0, 0, 3, 1, 0, 4, 4, 2, 3, 4, 1, 3, 3, 0, 1, 4, 3, 4, 4, 1, 3, 2, 4, 4, 4, 3, 0, 2, 0, 4, 1, 2, 1, 0, 2, 2, 4, 4, 4, 0, 4, 1, 2, 3, 4, 3, 4, 3, 4, 3, 4, 0, 2, 2, 1, 2, 1, 0, 1, 2, 3, 2, 3, 3, 1, 2, 4, 4, 0, 4, 4, 3, 4, 1, 2, 0, 2, 1, 3, 1, 1, 0, 1, 2, 1, 3, 0, 1, 3, 2, 4, 2, 4, 2, 1, 3, 2, 0, 1, 0, 3, 2, 2, 1, 2, 4, 0, 4, 4, 2, 3, 1, 1, 2, 3, 0, 1, 1, 2, 2, 0, 4, 2, 4, 0, 3, 2, 3, 0, 2, 4, 0, 3, 1, 1, 0, 0, 2, 4, 4, 2, 1, 0, 3, 4, 2, 2, 4, 3, 3, 4, 3, 2, 4, 0, 1, 4, 3, 3, 4, 4, 2, 4, 2, 2, 2, 1, 1, 4, 2, 3, 4, 4, 4, 0, 3, 1, 1, 3, 3, 1, 2, 2, 1, 3, 4, 1, 4, 1, 1, 3, 0, 0, 2, 4, 2, 2, 4, 3, 0, 1, 3, 2, 0, 4, 0, 2, 3, 4, 0, 2, 4, 0, 0, 1, 3, 2, 2, 1, 0, 1, 2, 4, 3, 0, 3, 3, 1, 1, 1, 0, 0, 3, 2, 0, 0, 2, 1, 2, 3, 0, 0, 3, 3, 2, 3, 4, 1, 1, 2, 2, 0, 3, 1, 3, 1, 1, 4, 2, 0, 3, 3, 1, 4, 2, 1, 1, 4, 0, 1, 2, 3, 2]\n",
      "[3, 3, 2, 0, 4, 0, 0, 3, 0, 0, 0, 3, 2, 2, 4, 4, 2, 4, 0, 3, 3, 4, 3, 2, 4, 3, 0, 2, 4, 3, 4, 4, 4, 2, 4, 0, 0, 2, 0, 0, 3, 4, 3, 0, 0, 2, 2, 4, 0, 3, 4, 4, 4, 2, 2, 3, 4, 4, 4, 3, 0, 4, 4, 4, 4, 2, 4, 4, 3, 4, 2, 0, 3, 2, 3, 0, 3, 0, 4, 4, 0, 2, 4, 4, 0, 0, 0, 3, 2, 2, 3, 3, 0, 3, 2, 4, 3, 4, 4, 0, 2, 0, 3, 0, 4, 2, 4, 0, 2, 4, 3, 3, 0, 3, 4, 4, 2, 0, 0, 4, 0, 4, 3, 0, 0, 3, 4, 0, 0, 3, 2, 3, 3, 0, 4, 2, 2, 0, 4, 4, 3, 2, 0, 2, 0, 2, 4, 3, 3, 3, 0, 0, 0, 4, 3, 2, 4, 4, 2, 3, 3, 3, 0, 4, 2, 4, 2, 4, 2, 4, 0, 2, 0, 2, 4, 4, 0, 2, 3, 4, 0, 3, 3, 4, 3, 0, 4, 0, 0, 2, 3, 3, 0, 2, 3, 4, 0, 2, 0, 3, 0, 3, 0, 0, 4, 3, 4, 0, 0, 3, 2, 3, 3, 0, 4, 3, 4, 3, 3, 4, 3, 0, 4, 2, 3, 4, 4, 0, 0, 3, 4, 4, 4, 4, 2, 3, 4, 4, 3, 3, 0, 3, 4, 3, 4, 4, 4, 3, 2, 4, 4, 4, 3, 0, 0, 0, 4, 4, 2, 4, 0, 2, 2, 4, 0, 4, 2, 4, 4, 2, 3, 4, 4, 4, 3, 3, 3, 4, 0, 2, 2, 3, 2, 4, 0, 4, 2, 3, 2, 3, 3, 4, 2, 4, 4, 4, 3, 4, 2, 4, 3, 2, 4, 2, 4, 3, 4, 4, 0, 4, 2, 4, 3, 0, 4, 3, 2, 4, 2, 4, 2, 3, 3, 2, 0, 4, 0, 3, 2, 2, 3, 0, 4, 2, 3, 4, 2, 4, 0, 4, 2, 3, 0, 3, 2, 2, 2, 0, 4, 2, 2, 0, 3, 2, 3, 0, 2, 4, 0, 3, 3, 3, 0, 0, 2, 4, 4, 2, 2, 0, 3, 4, 3, 2, 4, 3, 3, 3, 3, 2, 4, 4, 4, 4, 3, 3, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 0, 3, 3, 4, 3, 3, 4, 2, 0, 4, 3, 4, 2, 4, 4, 3, 3, 0, 0, 2, 4, 2, 2, 4, 3, 0, 0, 3, 2, 0, 4, 0, 2, 3, 4, 0, 2, 4, 2, 0, 4, 3, 2, 2, 0, 0, 4, 2, 4, 3, 0, 3, 3, 4, 0, 4, 4, 0, 3, 2, 0, 3, 0, 4, 2, 4, 0, 0, 3, 4, 2, 3, 4, 4, 4, 2, 2, 0, 3, 3, 3, 3, 4, 4, 3, 0, 3, 3, 3, 4, 2, 4, 4, 3, 0, 4, 4, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.80      0.84      0.82       100\n",
      "           3       0.72      0.91      0.80       100\n",
      "           4       0.54      0.87      0.67       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2174370139837265, Val acc: 0.692\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16200 - Batch 70/1613 - Train loss: 1.0565112031681436, Train acc: 0.8455105633802817\n",
      "Iteration 16300 - Batch 170/1613 - Train loss: 1.0519171562808298, Train acc: 0.8508771929824561\n",
      "Iteration 16400 - Batch 270/1613 - Train loss: 1.0565489315018883, Train acc: 0.8467481549815498\n",
      "Iteration 16500 - Batch 370/1613 - Train loss: 1.056923820484038, Train acc: 0.8464454177897575\n",
      "Iteration 16600 - Batch 470/1613 - Train loss: 1.0549823249474706, Train acc: 0.8484607218683652\n",
      "Iteration 16700 - Batch 570/1613 - Train loss: 1.053909203530193, Train acc: 0.8496059544658494\n",
      "Iteration 16800 - Batch 670/1613 - Train loss: 1.0538665763312054, Train acc: 0.8499441132637854\n",
      "Iteration 16900 - Batch 770/1613 - Train loss: 1.0537405283070724, Train acc: 0.8501540207522698\n",
      "Iteration 17000 - Batch 870/1613 - Train loss: 1.0537738797995855, Train acc: 0.8501722158438576\n",
      "Iteration 17100 - Batch 970/1613 - Train loss: 1.0547959859167388, Train acc: 0.849124613800206\n",
      "Iteration 17200 - Batch 1070/1613 - Train loss: 1.0545773314717326, Train acc: 0.8492938842203548\n",
      "Iteration 17300 - Batch 1170/1613 - Train loss: 1.0543152046549737, Train acc: 0.8497011101622545\n",
      "Iteration 17400 - Batch 1270/1613 - Train loss: 1.0543918685590443, Train acc: 0.8496508654602675\n",
      "Iteration 17500 - Batch 1370/1613 - Train loss: 1.0549993767606178, Train acc: 0.8491292851932896\n",
      "Iteration 17600 - Batch 1470/1613 - Train loss: 1.0551346483318114, Train acc: 0.8489547926580557\n",
      "Iteration 17700 - Batch 1570/1613 - Train loss: 1.0556692844132267, Train acc: 0.8484046785486951\n",
      "[2, 3, 1, 4, 4, 2, 4, 4, 4, 3, 3, 2, 4, 1, 0, 3, 4, 2, 3, 3, 1, 2, 0, 3, 1, 2, 3, 4, 3, 1, 3, 1, 3, 0, 3, 4, 0, 0, 0, 3, 4, 2, 0, 1, 2, 0, 1, 2, 3, 0, 1, 1, 3, 4, 0, 4, 1, 3, 0, 0, 2, 2, 3, 1, 4, 0, 4, 3, 4, 1, 3, 2, 1, 1, 4, 3, 4, 2, 1, 0, 2, 3, 0, 2, 0, 4, 2, 0, 4, 1, 2, 2, 4, 2, 2, 1, 4, 0, 3, 4, 0, 4, 0, 2, 2, 1, 2, 3, 0, 1, 4, 3, 4, 0, 2, 2, 2, 3, 1, 3, 1, 1, 1, 1, 3, 2, 0, 2, 1, 4, 1, 3, 1, 3, 4, 2, 2, 2, 2, 1, 3, 3, 0, 0, 2, 0, 1, 2, 3, 1, 3, 1, 0, 1, 2, 3, 2, 0, 1, 3, 3, 2, 4, 4, 3, 1, 3, 0, 1, 3, 3, 1, 0, 1, 1, 3, 1, 0, 1, 1, 3, 4, 4, 2, 0, 4, 4, 3, 4, 2, 3, 4, 4, 3, 1, 3, 1, 2, 0, 0, 4, 1, 3, 1, 1, 4, 1, 4, 0, 1, 0, 0, 1, 3, 4, 4, 2, 1, 4, 3, 0, 2, 0, 4, 4, 3, 2, 3, 0, 4, 2, 2, 0, 4, 2, 4, 1, 3, 1, 0, 1, 1, 2, 4, 3, 1, 2, 1, 2, 4, 3, 4, 2, 3, 1, 1, 2, 0, 3, 0, 2, 2, 4, 4, 4, 1, 4, 3, 4, 0, 1, 0, 2, 2, 3, 0, 3, 0, 3, 0, 2, 1, 4, 3, 3, 2, 1, 3, 0, 0, 0, 0, 4, 2, 4, 2, 4, 3, 4, 0, 4, 2, 4, 1, 0, 3, 1, 1, 2, 2, 4, 2, 1, 3, 3, 2, 4, 0, 1, 1, 3, 4, 4, 3, 2, 0, 1, 4, 4, 0, 1, 0, 2, 4, 2, 1, 0, 2, 3, 1, 0, 3, 0, 4, 3, 1, 0, 2, 1, 3, 1, 2, 3, 2, 1, 1, 0, 4, 4, 0, 4, 2, 2, 1, 0, 0, 0, 4, 3, 3, 0, 4, 4, 0, 4, 0, 1, 4, 2, 0, 3, 3, 4, 2, 4, 3, 0, 4, 4, 3, 4, 3, 4, 2, 0, 0, 4, 3, 0, 3, 2, 2, 4, 4, 3, 3, 3, 0, 3, 2, 2, 4, 2, 3, 2, 0, 3, 0, 0, 2, 2, 0, 4, 1, 1, 4, 3, 1, 1, 4, 2, 3, 3, 1, 0, 2, 0, 0, 4, 2, 3, 2, 0, 2, 2, 0, 1, 4, 2, 0, 1, 1, 0, 0, 0, 1, 2, 3, 0, 4, 4, 3, 0, 3, 2, 2, 2, 1, 1, 1, 0, 2, 1, 1, 2, 2, 2, 0, 1, 1, 0, 2, 3, 0, 1, 3, 1, 4, 0, 4, 4, 3, 1, 0, 0, 0, 1, 3, 4, 4]\n",
      "[2, 3, 3, 4, 4, 2, 4, 4, 4, 3, 4, 0, 2, 3, 0, 3, 4, 2, 3, 3, 0, 2, 0, 3, 0, 0, 3, 4, 3, 4, 3, 4, 3, 0, 3, 4, 0, 4, 0, 3, 4, 2, 0, 3, 2, 0, 3, 2, 3, 0, 3, 4, 3, 4, 0, 4, 4, 3, 0, 0, 2, 2, 3, 0, 4, 0, 0, 3, 4, 4, 3, 2, 0, 4, 4, 0, 4, 2, 4, 0, 0, 3, 0, 2, 0, 4, 0, 0, 2, 3, 0, 0, 4, 0, 2, 4, 4, 0, 3, 4, 0, 4, 0, 2, 0, 4, 2, 3, 4, 4, 4, 3, 4, 0, 0, 2, 2, 4, 4, 3, 3, 0, 4, 0, 3, 2, 0, 2, 2, 4, 4, 3, 0, 3, 4, 0, 2, 2, 0, 4, 3, 3, 3, 0, 2, 0, 4, 0, 3, 4, 3, 4, 0, 3, 2, 3, 0, 0, 3, 3, 3, 2, 4, 4, 3, 0, 3, 0, 0, 3, 3, 4, 0, 4, 4, 3, 3, 4, 3, 4, 3, 4, 4, 0, 0, 4, 4, 3, 4, 0, 4, 4, 4, 3, 4, 4, 0, 0, 0, 0, 4, 0, 3, 4, 4, 4, 4, 4, 0, 3, 0, 0, 0, 4, 4, 4, 2, 2, 4, 3, 0, 2, 0, 4, 4, 3, 2, 3, 0, 4, 2, 2, 0, 4, 2, 4, 4, 3, 3, 0, 4, 3, 3, 4, 3, 3, 2, 3, 2, 4, 3, 4, 2, 3, 3, 0, 2, 0, 4, 0, 2, 0, 4, 4, 4, 4, 4, 3, 4, 0, 0, 0, 0, 2, 3, 0, 3, 0, 3, 0, 2, 3, 4, 3, 4, 2, 4, 4, 0, 0, 0, 0, 4, 2, 4, 2, 4, 3, 4, 0, 4, 2, 4, 3, 0, 3, 4, 0, 0, 2, 4, 2, 4, 3, 3, 2, 0, 0, 0, 4, 4, 4, 4, 3, 3, 0, 4, 4, 4, 0, 3, 0, 2, 4, 2, 4, 0, 2, 3, 3, 0, 3, 0, 4, 3, 4, 0, 2, 4, 3, 0, 2, 3, 2, 4, 4, 0, 4, 4, 0, 4, 2, 0, 4, 0, 0, 0, 4, 3, 3, 0, 4, 4, 0, 4, 0, 3, 3, 0, 0, 3, 2, 3, 2, 4, 3, 0, 4, 4, 3, 4, 3, 4, 2, 0, 0, 0, 4, 0, 3, 2, 0, 4, 4, 3, 3, 3, 0, 4, 2, 2, 4, 2, 3, 2, 0, 4, 0, 0, 2, 2, 0, 4, 2, 3, 4, 3, 4, 0, 4, 0, 3, 4, 4, 4, 2, 0, 0, 4, 2, 3, 2, 0, 2, 2, 0, 4, 4, 2, 0, 4, 4, 0, 0, 0, 4, 2, 3, 0, 4, 4, 3, 0, 4, 3, 2, 3, 4, 3, 3, 4, 2, 4, 3, 2, 2, 2, 0, 0, 4, 0, 2, 3, 4, 0, 3, 4, 4, 0, 4, 4, 4, 4, 0, 2, 4, 2, 3, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.91      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.73      0.81       100\n",
      "           3       0.72      0.83      0.77       100\n",
      "           4       0.56      0.93      0.70       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.57      0.68      0.61       500\n",
      "weighted avg       0.57      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.221981629729271, Val acc: 0.68\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17800 - Batch 57/1613 - Train loss: 1.0612378634255508, Train acc: 0.8426724137931034\n",
      "Iteration 17900 - Batch 157/1613 - Train loss: 1.0569108479385134, Train acc: 0.8469145569620253\n",
      "Iteration 18000 - Batch 257/1613 - Train loss: 1.0547233161538145, Train acc: 0.8490794573643411\n",
      "Iteration 18100 - Batch 357/1613 - Train loss: 1.0556766578938042, Train acc: 0.848463687150838\n",
      "Iteration 18200 - Batch 457/1613 - Train loss: 1.055691995995534, Train acc: 0.8484579694323144\n",
      "Iteration 18300 - Batch 557/1613 - Train loss: 1.055607951029227, Train acc: 0.848622311827957\n",
      "Iteration 18400 - Batch 657/1613 - Train loss: 1.05512470686327, Train acc: 0.8490216565349544\n",
      "Iteration 18500 - Batch 757/1613 - Train loss: 1.0559945336117909, Train acc: 0.8481200527704486\n",
      "Iteration 18600 - Batch 857/1613 - Train loss: 1.0562146751336006, Train acc: 0.8479385198135199\n",
      "Iteration 18700 - Batch 957/1613 - Train loss: 1.0566165931911708, Train acc: 0.8475339248434238\n",
      "Iteration 18800 - Batch 1057/1613 - Train loss: 1.0575268846603783, Train acc: 0.8465560018903592\n",
      "Iteration 18900 - Batch 1157/1613 - Train loss: 1.057433524794735, Train acc: 0.8467184801381693\n",
      "Iteration 19000 - Batch 1257/1613 - Train loss: 1.0569774869041715, Train acc: 0.8471532193958664\n",
      "Iteration 19100 - Batch 1357/1613 - Train loss: 1.0566434210635425, Train acc: 0.8474318851251841\n",
      "Iteration 19200 - Batch 1457/1613 - Train loss: 1.056556492471564, Train acc: 0.8475222908093278\n",
      "Iteration 19300 - Batch 1557/1613 - Train loss: 1.0564126381136487, Train acc: 0.8476612644415917\n",
      "[3, 3, 4, 0, 2, 0, 4, 4, 2, 3, 1, 3, 0, 1, 4, 0, 0, 3, 0, 4, 3, 2, 0, 0, 1, 4, 4, 4, 4, 0, 0, 2, 1, 4, 2, 0, 4, 3, 0, 1, 1, 3, 2, 3, 4, 2, 3, 3, 3, 1, 2, 4, 4, 0, 3, 0, 3, 1, 3, 3, 0, 3, 0, 4, 3, 2, 0, 1, 1, 3, 2, 1, 3, 0, 1, 3, 4, 1, 1, 2, 0, 0, 4, 3, 1, 0, 3, 4, 1, 0, 2, 1, 2, 3, 3, 1, 3, 4, 4, 1, 3, 1, 0, 1, 1, 3, 0, 0, 4, 4, 0, 4, 1, 4, 1, 0, 4, 0, 1, 4, 3, 4, 3, 1, 4, 3, 4, 2, 0, 0, 0, 1, 2, 1, 2, 1, 2, 3, 0, 3, 2, 1, 2, 1, 0, 4, 4, 2, 1, 1, 2, 1, 2, 1, 2, 4, 3, 4, 4, 1, 1, 3, 3, 1, 4, 1, 2, 3, 4, 4, 3, 4, 4, 4, 0, 3, 4, 2, 1, 1, 0, 0, 3, 1, 0, 0, 1, 4, 4, 1, 3, 1, 1, 1, 2, 1, 2, 2, 2, 3, 3, 3, 3, 2, 2, 4, 4, 4, 0, 4, 4, 1, 1, 1, 3, 3, 3, 0, 3, 1, 1, 4, 2, 2, 1, 1, 0, 0, 2, 4, 0, 1, 2, 4, 4, 4, 0, 4, 0, 1, 3, 2, 2, 1, 2, 3, 2, 3, 1, 4, 3, 1, 3, 0, 1, 4, 1, 4, 3, 2, 4, 4, 0, 0, 0, 0, 1, 1, 4, 1, 2, 4, 2, 4, 4, 1, 3, 0, 0, 2, 0, 4, 3, 2, 2, 3, 1, 2, 2, 3, 2, 2, 2, 0, 2, 2, 3, 0, 3, 2, 3, 1, 3, 2, 3, 4, 1, 1, 3, 0, 2, 2, 0, 3, 3, 1, 0, 0, 3, 2, 0, 3, 2, 1, 3, 1, 4, 2, 2, 0, 0, 2, 1, 3, 0, 4, 0, 2, 0, 4, 3, 0, 4, 2, 1, 2, 3, 0, 0, 1, 0, 2, 2, 1, 0, 0, 4, 2, 2, 3, 1, 4, 0, 4, 0, 0, 2, 3, 0, 3, 2, 2, 2, 4, 0, 0, 4, 0, 0, 4, 4, 2, 0, 0, 1, 0, 3, 3, 0, 3, 2, 2, 2, 3, 2, 0, 2, 4, 2, 4, 1, 3, 0, 0, 1, 2, 1, 4, 4, 1, 4, 1, 0, 1, 3, 0, 2, 3, 2, 0, 1, 3, 4, 4, 1, 1, 4, 4, 0, 0, 3, 0, 0, 0, 4, 4, 3, 3, 3, 2, 1, 1, 2, 4, 0, 2, 3, 4, 2, 2, 1, 2, 1, 0, 4, 3, 2, 2, 3, 0, 1, 4, 4, 1, 4, 0, 4, 3, 4, 0, 3, 2, 3, 2, 4, 3, 2, 2, 1, 4, 3, 3, 1, 2, 2, 0, 3, 1, 2, 4, 4, 3, 3, 1, 4, 1, 2, 2, 2, 1]\n",
      "[3, 3, 4, 0, 2, 2, 4, 4, 2, 3, 2, 3, 0, 3, 0, 0, 0, 3, 0, 4, 3, 2, 0, 0, 4, 4, 4, 4, 4, 0, 0, 0, 0, 4, 2, 0, 4, 4, 0, 0, 2, 2, 2, 3, 4, 0, 3, 4, 3, 2, 2, 4, 4, 0, 3, 0, 3, 2, 3, 3, 0, 3, 0, 4, 3, 0, 0, 0, 4, 4, 2, 0, 3, 0, 4, 3, 4, 3, 0, 2, 0, 0, 4, 3, 4, 0, 3, 4, 0, 0, 2, 4, 2, 3, 3, 3, 3, 2, 4, 4, 3, 0, 0, 4, 4, 3, 0, 4, 4, 4, 0, 4, 4, 4, 3, 0, 4, 0, 2, 3, 3, 4, 3, 0, 4, 3, 4, 2, 0, 0, 0, 3, 2, 0, 2, 0, 2, 3, 0, 3, 2, 2, 0, 0, 0, 2, 4, 2, 2, 3, 2, 3, 2, 4, 2, 2, 3, 4, 4, 0, 3, 3, 3, 4, 4, 4, 2, 4, 4, 4, 3, 2, 4, 4, 0, 3, 4, 2, 0, 4, 0, 0, 3, 4, 0, 0, 3, 4, 4, 4, 3, 3, 4, 2, 2, 4, 0, 0, 2, 4, 3, 3, 3, 0, 2, 4, 2, 4, 0, 4, 4, 4, 0, 4, 3, 3, 3, 0, 3, 0, 2, 4, 2, 0, 0, 4, 0, 0, 2, 4, 0, 0, 2, 4, 4, 4, 0, 4, 0, 3, 3, 2, 2, 2, 2, 3, 2, 3, 3, 4, 3, 3, 3, 0, 3, 3, 2, 4, 3, 2, 4, 4, 0, 0, 2, 0, 3, 0, 4, 0, 2, 4, 2, 4, 4, 3, 3, 2, 0, 2, 0, 3, 3, 2, 2, 3, 4, 2, 0, 3, 2, 2, 2, 0, 2, 0, 3, 0, 3, 2, 3, 3, 3, 2, 3, 4, 3, 4, 3, 0, 2, 2, 3, 3, 3, 3, 0, 0, 3, 2, 2, 3, 0, 4, 3, 3, 4, 2, 2, 0, 0, 2, 4, 3, 0, 4, 0, 2, 0, 4, 3, 0, 4, 2, 3, 2, 4, 0, 0, 2, 0, 3, 2, 0, 0, 2, 4, 2, 0, 3, 3, 4, 0, 4, 0, 0, 2, 3, 0, 2, 2, 2, 2, 4, 0, 0, 4, 0, 0, 3, 0, 2, 0, 0, 0, 0, 4, 3, 0, 3, 0, 2, 2, 3, 2, 0, 2, 4, 2, 4, 4, 0, 0, 0, 0, 2, 3, 4, 4, 3, 4, 4, 0, 3, 3, 0, 2, 3, 2, 0, 2, 4, 4, 4, 2, 4, 4, 4, 0, 0, 3, 0, 0, 0, 4, 4, 3, 3, 3, 2, 4, 4, 3, 4, 0, 2, 3, 4, 2, 2, 0, 2, 4, 2, 4, 3, 2, 2, 3, 0, 0, 4, 4, 0, 3, 0, 0, 3, 4, 0, 3, 2, 3, 2, 4, 3, 2, 2, 4, 4, 3, 3, 0, 2, 2, 0, 3, 4, 2, 4, 4, 3, 3, 0, 4, 0, 2, 2, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.76      0.85      0.80       100\n",
      "           3       0.73      0.89      0.80       100\n",
      "           4       0.67      0.87      0.76       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1953995302319527, Val acc: 0.706\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19400 - Batch 44/1613 - Train loss: 1.0722584538989597, Train acc: 0.8333333333333334\n",
      "Iteration 19500 - Batch 144/1613 - Train loss: 1.0556238347086413, Train acc: 0.8487068965517242\n",
      "Iteration 19600 - Batch 244/1613 - Train loss: 1.052086031193636, Train acc: 0.8517857142857143\n",
      "Iteration 19700 - Batch 344/1613 - Train loss: 1.050525639022606, Train acc: 0.8539855072463768\n",
      "Iteration 19800 - Batch 444/1613 - Train loss: 1.049490023730846, Train acc: 0.8549157303370787\n",
      "Iteration 19900 - Batch 544/1613 - Train loss: 1.048714408743272, Train acc: 0.855848623853211\n",
      "Iteration 20000 - Batch 644/1613 - Train loss: 1.0508862452913625, Train acc: 0.8534399224806202\n",
      "Iteration 20100 - Batch 744/1613 - Train loss: 1.0506744157547918, Train acc: 0.8534395973154363\n",
      "Iteration 20200 - Batch 844/1613 - Train loss: 1.0498396094734146, Train acc: 0.8542529585798817\n",
      "Iteration 20300 - Batch 944/1613 - Train loss: 1.0497130711242635, Train acc: 0.8544642857142857\n",
      "Iteration 20400 - Batch 1044/1613 - Train loss: 1.0504611033571964, Train acc: 0.8537081339712919\n",
      "Iteration 20500 - Batch 1144/1613 - Train loss: 1.0508542483550491, Train acc: 0.8532478165938865\n",
      "Iteration 20600 - Batch 1244/1613 - Train loss: 1.0513997110497042, Train acc: 0.8526857429718876\n",
      "Iteration 20700 - Batch 1344/1613 - Train loss: 1.0514930138800667, Train acc: 0.8525092936802974\n",
      "Iteration 20800 - Batch 1444/1613 - Train loss: 1.0524574302884535, Train acc: 0.8514489619377162\n",
      "Iteration 20900 - Batch 1544/1613 - Train loss: 1.0522248596049435, Train acc: 0.8516181229773463\n",
      "[4, 3, 2, 3, 0, 3, 4, 1, 3, 3, 4, 4, 0, 1, 1, 1, 3, 4, 0, 3, 2, 1, 1, 2, 3, 0, 1, 1, 3, 1, 3, 3, 1, 4, 0, 2, 3, 3, 2, 4, 1, 0, 3, 0, 0, 2, 3, 2, 2, 4, 2, 0, 2, 2, 3, 1, 4, 2, 3, 1, 1, 0, 4, 0, 1, 1, 3, 0, 4, 4, 0, 0, 4, 0, 0, 3, 3, 1, 3, 0, 1, 4, 0, 3, 2, 1, 3, 0, 2, 3, 3, 1, 0, 2, 4, 0, 3, 0, 4, 2, 0, 1, 3, 2, 3, 3, 2, 2, 1, 1, 4, 1, 3, 1, 1, 4, 3, 0, 0, 2, 4, 2, 0, 0, 0, 3, 0, 0, 2, 3, 0, 2, 4, 3, 4, 3, 4, 1, 4, 2, 0, 0, 2, 3, 2, 0, 4, 2, 0, 3, 0, 0, 0, 3, 1, 4, 4, 4, 2, 4, 1, 2, 3, 1, 2, 0, 0, 4, 1, 4, 0, 1, 4, 3, 0, 3, 1, 2, 0, 1, 4, 1, 3, 3, 3, 3, 2, 1, 2, 0, 1, 3, 4, 1, 4, 1, 2, 1, 2, 2, 2, 3, 1, 2, 3, 0, 4, 1, 0, 3, 3, 3, 2, 1, 4, 2, 0, 2, 3, 4, 4, 3, 4, 0, 2, 4, 4, 3, 4, 4, 0, 0, 2, 4, 0, 0, 2, 0, 0, 2, 3, 2, 0, 2, 1, 2, 0, 4, 0, 3, 2, 4, 2, 2, 3, 1, 2, 1, 1, 4, 3, 2, 2, 0, 3, 0, 1, 4, 3, 0, 1, 2, 2, 1, 4, 1, 1, 4, 0, 0, 2, 0, 1, 2, 3, 0, 3, 4, 2, 3, 4, 0, 1, 3, 1, 4, 1, 4, 1, 1, 2, 3, 4, 4, 4, 3, 1, 4, 3, 3, 4, 1, 2, 1, 2, 2, 1, 1, 0, 4, 3, 2, 4, 3, 4, 0, 3, 0, 3, 0, 3, 4, 0, 3, 0, 4, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, 0, 4, 3, 1, 4, 0, 4, 2, 3, 4, 0, 1, 4, 2, 2, 2, 0, 0, 1, 2, 0, 3, 2, 4, 4, 4, 2, 2, 0, 1, 4, 1, 3, 4, 2, 0, 1, 4, 0, 0, 3, 3, 4, 1, 3, 4, 2, 0, 4, 0, 0, 3, 1, 1, 4, 4, 4, 2, 2, 1, 1, 2, 1, 4, 4, 3, 4, 2, 4, 1, 3, 4, 2, 3, 4, 2, 2, 1, 1, 1, 2, 3, 4, 0, 1, 0, 2, 4, 1, 1, 1, 0, 3, 1, 1, 4, 0, 3, 1, 0, 2, 4, 4, 0, 2, 4, 1, 3, 0, 4, 2, 4, 0, 3, 2, 4, 1, 0, 1, 2, 3, 1, 1, 2, 2, 1, 3, 4, 2, 4, 0, 3, 2, 1, 0, 4, 2, 3, 2, 3, 1, 2, 0, 0, 0, 3, 1, 0, 0, 3, 3, 4, 2, 3]\n",
      "[4, 3, 2, 3, 0, 3, 4, 3, 3, 3, 4, 4, 0, 4, 4, 4, 3, 3, 0, 3, 2, 4, 0, 2, 3, 0, 4, 4, 3, 4, 3, 3, 4, 4, 0, 0, 3, 3, 0, 3, 4, 0, 3, 0, 4, 2, 3, 2, 0, 4, 2, 0, 2, 3, 3, 3, 4, 2, 3, 3, 4, 0, 4, 0, 3, 2, 3, 0, 4, 4, 0, 0, 4, 0, 4, 3, 3, 4, 3, 0, 0, 4, 0, 3, 2, 4, 3, 0, 2, 3, 3, 4, 0, 2, 2, 0, 4, 0, 4, 2, 0, 3, 4, 2, 3, 3, 2, 2, 0, 3, 4, 4, 3, 0, 4, 4, 3, 0, 0, 2, 4, 2, 0, 0, 4, 3, 0, 3, 2, 3, 0, 0, 4, 0, 4, 3, 4, 0, 4, 2, 0, 0, 2, 3, 2, 0, 4, 0, 0, 3, 0, 0, 2, 3, 3, 4, 2, 4, 2, 4, 4, 4, 3, 4, 2, 0, 0, 4, 4, 4, 0, 4, 4, 3, 0, 3, 4, 2, 0, 0, 4, 4, 3, 3, 3, 3, 2, 0, 2, 0, 4, 4, 4, 4, 4, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 0, 4, 4, 0, 3, 3, 3, 2, 4, 4, 2, 0, 3, 3, 4, 4, 3, 4, 0, 2, 4, 4, 3, 4, 3, 0, 0, 2, 4, 0, 0, 2, 0, 0, 2, 3, 0, 0, 2, 4, 2, 0, 4, 0, 3, 2, 4, 2, 0, 3, 4, 2, 4, 4, 4, 3, 2, 2, 0, 3, 0, 4, 4, 2, 0, 0, 0, 2, 4, 4, 3, 4, 4, 0, 0, 2, 0, 4, 2, 3, 0, 3, 4, 2, 3, 3, 0, 4, 3, 0, 3, 4, 4, 2, 0, 2, 4, 4, 4, 4, 3, 4, 2, 3, 3, 4, 3, 0, 0, 2, 2, 4, 0, 0, 4, 3, 0, 4, 3, 4, 0, 3, 0, 3, 0, 3, 4, 0, 3, 0, 3, 0, 0, 2, 2, 4, 3, 0, 3, 3, 4, 0, 4, 3, 3, 4, 0, 2, 2, 3, 4, 0, 4, 0, 2, 2, 2, 0, 0, 3, 2, 0, 3, 2, 4, 0, 3, 2, 2, 0, 0, 4, 4, 3, 4, 2, 0, 2, 4, 0, 0, 3, 3, 4, 3, 3, 4, 2, 0, 4, 0, 0, 3, 3, 0, 4, 4, 4, 0, 2, 0, 3, 2, 4, 4, 4, 3, 4, 2, 3, 3, 3, 4, 2, 3, 4, 0, 2, 3, 4, 3, 2, 3, 4, 0, 4, 0, 0, 4, 4, 4, 0, 0, 3, 3, 2, 4, 0, 3, 4, 0, 2, 4, 4, 0, 2, 4, 0, 3, 0, 4, 2, 4, 0, 3, 2, 4, 4, 0, 3, 2, 3, 3, 0, 0, 2, 4, 3, 4, 0, 4, 0, 3, 2, 2, 0, 4, 2, 3, 2, 4, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 4, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.78      0.82       100\n",
      "           3       0.72      0.93      0.81       100\n",
      "           4       0.60      0.86      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1967771425843239, Val acc: 0.704\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21000 - Batch 31/1613 - Train loss: 1.0496199019253254, Train acc: 0.8544921875\n",
      "Iteration 21100 - Batch 131/1613 - Train loss: 1.0501783950762316, Train acc: 0.8544034090909091\n",
      "Iteration 21200 - Batch 231/1613 - Train loss: 1.0546427497576023, Train acc: 0.849676724137931\n",
      "Iteration 21300 - Batch 331/1613 - Train loss: 1.0532432485775776, Train acc: 0.8509036144578314\n",
      "Iteration 21400 - Batch 431/1613 - Train loss: 1.0506942058327022, Train acc: 0.8531539351851852\n",
      "Iteration 21500 - Batch 531/1613 - Train loss: 1.0511507099508344, Train acc: 0.852796052631579\n",
      "Iteration 21600 - Batch 631/1613 - Train loss: 1.0501638061449499, Train acc: 0.8535897943037974\n",
      "Iteration 21700 - Batch 731/1613 - Train loss: 1.051045621190566, Train acc: 0.8527578551912568\n",
      "Iteration 21800 - Batch 831/1613 - Train loss: 1.0521818243970091, Train acc: 0.8516376201923077\n",
      "Iteration 21900 - Batch 931/1613 - Train loss: 1.051503593381894, Train acc: 0.8525013412017167\n",
      "Iteration 22000 - Batch 1031/1613 - Train loss: 1.0520165108086528, Train acc: 0.852046996124031\n",
      "Iteration 22100 - Batch 1131/1613 - Train loss: 1.0502063842628533, Train acc: 0.8539366166077739\n",
      "Iteration 22200 - Batch 1231/1613 - Train loss: 1.0496438127736767, Train acc: 0.8545302353896104\n",
      "Iteration 22300 - Batch 1331/1613 - Train loss: 1.049252548912266, Train acc: 0.8549643393393394\n",
      "Iteration 22400 - Batch 1431/1613 - Train loss: 1.0487727394650102, Train acc: 0.8554905726256983\n",
      "Iteration 22500 - Batch 1531/1613 - Train loss: 1.048558854986731, Train acc: 0.8557033289817232\n",
      "[1, 3, 4, 1, 3, 4, 3, 1, 1, 2, 0, 2, 3, 1, 0, 3, 4, 1, 3, 2, 4, 2, 2, 0, 3, 4, 3, 3, 4, 3, 2, 1, 4, 4, 3, 3, 3, 4, 4, 2, 0, 1, 3, 4, 4, 4, 3, 3, 1, 0, 1, 1, 0, 3, 4, 0, 2, 2, 2, 0, 2, 1, 2, 4, 1, 1, 3, 1, 0, 4, 3, 2, 1, 4, 1, 2, 0, 2, 1, 3, 1, 2, 0, 4, 0, 4, 4, 2, 1, 4, 1, 2, 1, 2, 3, 0, 3, 0, 4, 1, 3, 0, 2, 0, 4, 3, 0, 3, 3, 3, 0, 3, 4, 2, 1, 2, 4, 1, 1, 0, 0, 3, 3, 0, 1, 3, 1, 3, 4, 4, 3, 2, 0, 2, 3, 4, 0, 4, 2, 4, 0, 0, 3, 4, 3, 0, 3, 0, 1, 0, 3, 0, 0, 2, 4, 1, 0, 1, 4, 4, 3, 3, 0, 0, 4, 1, 1, 2, 2, 0, 2, 2, 4, 4, 0, 4, 3, 1, 0, 2, 2, 4, 3, 2, 3, 1, 2, 0, 4, 2, 3, 4, 2, 0, 1, 1, 1, 2, 0, 1, 4, 2, 2, 0, 2, 4, 2, 3, 2, 2, 3, 0, 3, 0, 3, 4, 0, 0, 0, 4, 2, 1, 1, 2, 3, 2, 0, 0, 1, 4, 2, 2, 1, 4, 2, 1, 4, 2, 4, 2, 1, 2, 1, 2, 0, 0, 0, 4, 4, 4, 3, 1, 1, 3, 2, 4, 3, 4, 2, 4, 2, 0, 4, 4, 2, 4, 4, 2, 2, 0, 4, 0, 3, 3, 1, 1, 0, 3, 2, 3, 0, 4, 0, 0, 1, 1, 3, 2, 3, 4, 0, 3, 1, 4, 0, 4, 1, 0, 4, 4, 4, 2, 3, 4, 4, 1, 4, 3, 2, 0, 0, 3, 1, 1, 1, 4, 1, 0, 2, 3, 2, 2, 2, 0, 1, 3, 0, 0, 3, 4, 0, 0, 2, 1, 4, 3, 2, 0, 4, 1, 1, 1, 0, 2, 0, 2, 0, 3, 0, 4, 1, 4, 1, 3, 2, 1, 4, 0, 1, 1, 2, 1, 4, 2, 0, 0, 1, 4, 2, 4, 0, 3, 0, 1, 1, 0, 1, 4, 1, 0, 1, 1, 3, 3, 0, 0, 1, 3, 2, 2, 3, 3, 2, 3, 3, 0, 1, 1, 1, 0, 2, 1, 2, 0, 4, 0, 4, 2, 3, 2, 3, 1, 3, 4, 2, 0, 2, 0, 4, 4, 1, 1, 4, 3, 1, 4, 4, 4, 4, 2, 3, 0, 4, 1, 4, 2, 0, 3, 1, 2, 2, 1, 3, 2, 3, 4, 0, 3, 2, 3, 2, 0, 3, 3, 1, 0, 2, 4, 3, 1, 3, 3, 3, 2, 3, 3, 1, 3, 1, 1, 1, 4, 2, 1, 2, 0, 2, 0, 2, 1, 1, 4, 1, 0, 3, 4, 2, 0, 0, 4, 3, 1, 2, 3, 2, 0, 3, 0, 4, 3]\n",
      "[4, 3, 4, 4, 3, 4, 3, 3, 0, 0, 0, 2, 3, 4, 0, 3, 4, 4, 3, 2, 4, 2, 2, 0, 3, 4, 3, 3, 4, 3, 2, 4, 4, 3, 3, 3, 3, 4, 4, 2, 0, 0, 3, 4, 4, 4, 3, 3, 3, 0, 2, 3, 0, 3, 4, 4, 2, 2, 2, 0, 2, 2, 2, 4, 0, 0, 3, 3, 0, 4, 3, 2, 3, 4, 3, 2, 0, 2, 3, 3, 4, 2, 0, 4, 0, 4, 4, 2, 0, 4, 0, 2, 4, 0, 3, 0, 4, 0, 4, 4, 3, 0, 2, 0, 4, 3, 0, 4, 3, 3, 0, 3, 4, 3, 4, 0, 4, 3, 4, 0, 0, 3, 3, 0, 3, 3, 3, 3, 4, 4, 3, 2, 3, 2, 3, 4, 0, 4, 2, 2, 0, 0, 4, 2, 3, 0, 3, 0, 4, 0, 3, 0, 0, 3, 4, 4, 0, 4, 2, 4, 3, 3, 0, 0, 4, 3, 4, 2, 0, 0, 2, 2, 4, 4, 0, 4, 3, 4, 0, 2, 2, 4, 3, 2, 3, 4, 2, 0, 4, 2, 4, 4, 0, 4, 3, 3, 4, 2, 4, 3, 4, 2, 2, 2, 2, 4, 2, 3, 2, 0, 3, 0, 3, 0, 3, 4, 0, 0, 0, 4, 0, 3, 4, 2, 3, 2, 0, 0, 0, 4, 2, 2, 4, 4, 2, 0, 4, 0, 3, 2, 3, 2, 2, 2, 0, 0, 0, 4, 4, 4, 4, 4, 4, 3, 2, 4, 3, 4, 0, 3, 2, 0, 4, 4, 2, 4, 4, 2, 2, 0, 4, 4, 3, 3, 4, 4, 0, 3, 2, 3, 0, 3, 0, 0, 0, 4, 3, 2, 3, 4, 0, 4, 4, 2, 0, 4, 4, 0, 4, 4, 4, 2, 3, 4, 4, 4, 4, 3, 2, 0, 0, 3, 4, 3, 2, 4, 4, 0, 2, 3, 0, 2, 2, 0, 2, 3, 0, 0, 4, 4, 0, 0, 2, 0, 4, 3, 0, 0, 4, 3, 4, 4, 4, 2, 4, 0, 0, 3, 0, 4, 4, 4, 4, 3, 2, 4, 4, 0, 3, 4, 0, 4, 4, 2, 0, 2, 4, 4, 2, 4, 0, 3, 0, 4, 2, 0, 3, 4, 4, 2, 3, 4, 3, 3, 2, 0, 3, 4, 2, 0, 3, 3, 2, 3, 3, 0, 4, 0, 4, 0, 2, 4, 2, 0, 4, 0, 4, 2, 3, 2, 3, 4, 3, 4, 3, 0, 2, 0, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 2, 3, 0, 4, 0, 4, 2, 2, 3, 4, 2, 2, 4, 3, 2, 0, 4, 0, 3, 2, 3, 2, 0, 3, 3, 4, 0, 2, 4, 3, 0, 3, 3, 3, 2, 3, 3, 3, 4, 3, 3, 4, 4, 2, 4, 3, 0, 2, 0, 2, 4, 4, 0, 3, 0, 4, 4, 2, 0, 0, 4, 3, 4, 2, 3, 2, 0, 3, 0, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.82      0.83       100\n",
      "           3       0.72      0.89      0.79       100\n",
      "           4       0.56      0.91      0.69       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2002559676766396, Val acc: 0.7\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22600 - Batch 18/1613 - Train loss: 1.0658470831419293, Train acc: 0.837171052631579\n",
      "Iteration 22700 - Batch 118/1613 - Train loss: 1.0546123415482145, Train acc: 0.8471638655462185\n",
      "Iteration 22800 - Batch 218/1613 - Train loss: 1.0526011667839468, Train acc: 0.8503139269406392\n",
      "Iteration 22900 - Batch 318/1613 - Train loss: 1.049122839325274, Train acc: 0.8544278996865203\n",
      "Iteration 23000 - Batch 418/1613 - Train loss: 1.0476701438853735, Train acc: 0.8556085918854416\n",
      "Iteration 23100 - Batch 518/1613 - Train loss: 1.0470368213276873, Train acc: 0.8564547206165704\n",
      "Iteration 23200 - Batch 618/1613 - Train loss: 1.0469961548660414, Train acc: 0.8565226171243941\n",
      "Iteration 23300 - Batch 718/1613 - Train loss: 1.0466650736845915, Train acc: 0.8570062586926287\n",
      "Iteration 23400 - Batch 818/1613 - Train loss: 1.045371535496834, Train acc: 0.8582112332112332\n",
      "Iteration 23500 - Batch 918/1613 - Train loss: 1.0457502511432304, Train acc: 0.8577597932535365\n",
      "Iteration 23600 - Batch 1018/1613 - Train loss: 1.0462360188467346, Train acc: 0.8573356231599607\n",
      "Iteration 23700 - Batch 1118/1613 - Train loss: 1.047257500583301, Train acc: 0.8564845844504021\n",
      "Iteration 23800 - Batch 1218/1613 - Train loss: 1.047601273355179, Train acc: 0.8561320754716981\n",
      "Iteration 23900 - Batch 1318/1613 - Train loss: 1.0478279070930105, Train acc: 0.855927786201668\n",
      "Iteration 24000 - Batch 1418/1613 - Train loss: 1.0483278492708454, Train acc: 0.8554219520789288\n",
      "Iteration 24100 - Batch 1518/1613 - Train loss: 1.0478940679494921, Train acc: 0.855949637919684\n",
      "[1, 1, 3, 2, 0, 0, 0, 1, 2, 1, 1, 2, 2, 3, 1, 0, 3, 2, 3, 2, 2, 4, 1, 0, 3, 2, 4, 3, 2, 2, 3, 2, 3, 2, 1, 4, 1, 1, 4, 1, 1, 1, 4, 2, 0, 0, 2, 3, 3, 2, 3, 4, 3, 3, 1, 3, 4, 2, 0, 2, 0, 3, 0, 3, 4, 0, 4, 2, 2, 1, 0, 2, 0, 3, 2, 3, 4, 2, 2, 0, 0, 3, 3, 2, 4, 2, 1, 2, 4, 0, 4, 1, 3, 2, 1, 1, 3, 3, 3, 2, 3, 4, 3, 4, 3, 0, 3, 4, 2, 4, 2, 1, 0, 2, 2, 1, 1, 0, 1, 0, 2, 2, 3, 0, 4, 1, 4, 0, 0, 3, 4, 3, 3, 3, 0, 2, 2, 2, 3, 1, 4, 3, 4, 4, 0, 4, 1, 1, 2, 0, 0, 2, 4, 1, 1, 0, 0, 1, 4, 1, 3, 3, 4, 1, 2, 2, 4, 0, 0, 1, 4, 0, 1, 1, 3, 2, 3, 3, 2, 1, 2, 3, 2, 1, 3, 1, 4, 3, 1, 0, 1, 2, 3, 4, 0, 4, 1, 4, 0, 0, 0, 1, 2, 0, 4, 4, 2, 0, 0, 1, 0, 2, 4, 4, 0, 2, 2, 2, 0, 0, 3, 1, 1, 1, 2, 4, 0, 3, 0, 3, 4, 2, 4, 0, 0, 0, 2, 4, 3, 3, 3, 0, 0, 0, 0, 0, 4, 3, 0, 1, 1, 4, 4, 2, 0, 1, 4, 0, 4, 4, 2, 2, 4, 1, 4, 0, 3, 4, 1, 1, 1, 3, 0, 0, 4, 0, 0, 1, 0, 3, 1, 1, 3, 0, 3, 2, 2, 4, 3, 2, 2, 0, 2, 0, 0, 1, 0, 4, 0, 4, 0, 1, 1, 1, 0, 3, 1, 4, 2, 4, 2, 4, 0, 0, 1, 3, 1, 0, 1, 0, 3, 3, 1, 0, 3, 3, 0, 1, 3, 3, 4, 0, 4, 1, 2, 4, 3, 0, 4, 2, 4, 2, 2, 0, 3, 1, 1, 3, 4, 4, 4, 2, 4, 1, 3, 4, 4, 2, 2, 1, 1, 0, 3, 2, 3, 0, 0, 4, 3, 4, 2, 3, 3, 1, 4, 0, 2, 4, 1, 4, 3, 3, 0, 1, 3, 3, 2, 2, 4, 4, 4, 0, 2, 2, 4, 1, 0, 3, 4, 0, 0, 0, 4, 4, 2, 4, 3, 0, 2, 1, 1, 0, 1, 4, 0, 4, 3, 1, 4, 3, 4, 4, 1, 0, 2, 1, 3, 4, 1, 3, 4, 3, 3, 2, 0, 1, 2, 4, 1, 2, 4, 1, 1, 3, 3, 0, 4, 1, 4, 1, 1, 2, 2, 3, 3, 2, 2, 1, 2, 1, 3, 2, 4, 1, 1, 3, 0, 3, 2, 4, 2, 3, 2, 2, 2, 3, 1, 3, 3, 1, 0, 2, 4, 4, 3, 1, 4, 2, 4, 1, 3, 2, 3, 2, 1, 1, 4, 4, 0, 0]\n",
      "[3, 4, 3, 2, 4, 0, 0, 3, 2, 4, 3, 2, 0, 3, 0, 0, 3, 2, 3, 2, 3, 4, 3, 2, 3, 2, 4, 3, 2, 2, 3, 2, 3, 2, 2, 4, 4, 2, 4, 2, 3, 3, 4, 2, 2, 0, 2, 4, 3, 3, 3, 4, 3, 3, 4, 3, 4, 2, 0, 2, 0, 3, 0, 2, 3, 0, 4, 2, 2, 3, 0, 2, 0, 3, 2, 3, 4, 2, 2, 0, 0, 3, 3, 2, 4, 2, 3, 0, 4, 0, 4, 4, 3, 2, 4, 4, 3, 3, 3, 4, 3, 4, 3, 4, 3, 0, 3, 4, 2, 2, 0, 4, 3, 0, 2, 4, 4, 0, 3, 0, 2, 2, 3, 0, 4, 4, 4, 0, 0, 3, 4, 3, 3, 3, 0, 2, 2, 2, 3, 4, 4, 3, 4, 4, 0, 4, 3, 4, 2, 0, 0, 2, 3, 0, 4, 0, 2, 4, 4, 2, 3, 3, 4, 3, 2, 2, 4, 0, 2, 4, 4, 0, 4, 2, 3, 2, 3, 3, 0, 4, 2, 3, 2, 4, 3, 4, 4, 3, 4, 0, 2, 0, 3, 4, 0, 4, 4, 4, 0, 0, 0, 4, 2, 2, 4, 4, 2, 0, 0, 4, 0, 2, 4, 3, 0, 2, 2, 2, 0, 0, 3, 3, 0, 3, 2, 4, 0, 3, 0, 3, 4, 2, 4, 0, 0, 0, 2, 4, 3, 3, 3, 0, 2, 0, 2, 0, 4, 3, 0, 0, 2, 4, 4, 2, 0, 4, 4, 2, 4, 4, 2, 2, 4, 0, 4, 0, 3, 4, 0, 2, 4, 3, 0, 0, 4, 0, 0, 4, 0, 3, 4, 4, 3, 2, 3, 2, 2, 4, 3, 2, 2, 4, 2, 0, 0, 3, 0, 4, 0, 4, 4, 4, 3, 4, 0, 4, 2, 3, 2, 2, 2, 4, 0, 0, 2, 3, 3, 4, 4, 0, 3, 3, 3, 0, 3, 3, 0, 4, 3, 3, 4, 2, 4, 4, 2, 4, 3, 0, 4, 0, 4, 2, 2, 0, 3, 2, 3, 3, 4, 4, 4, 0, 4, 3, 3, 4, 4, 2, 2, 4, 4, 0, 3, 2, 3, 0, 0, 4, 3, 4, 2, 3, 3, 4, 4, 4, 2, 4, 0, 4, 3, 3, 0, 4, 3, 3, 2, 2, 4, 0, 3, 0, 2, 0, 4, 4, 0, 3, 4, 0, 2, 2, 4, 4, 2, 2, 3, 4, 2, 4, 4, 0, 0, 4, 0, 4, 3, 2, 4, 3, 2, 4, 4, 0, 2, 3, 3, 4, 4, 3, 0, 3, 3, 2, 0, 4, 2, 4, 2, 2, 4, 4, 4, 4, 3, 0, 4, 4, 4, 4, 4, 2, 2, 3, 3, 2, 2, 0, 2, 2, 3, 3, 4, 4, 0, 3, 0, 3, 2, 4, 2, 3, 2, 2, 2, 4, 4, 3, 3, 3, 0, 0, 4, 4, 3, 4, 4, 0, 4, 4, 3, 2, 3, 2, 3, 3, 4, 4, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.73      0.85      0.79       100\n",
      "           3       0.75      0.95      0.84       100\n",
      "           4       0.58      0.89      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.200627751648426, Val acc: 0.7\n",
      "Epoch 16/30\n",
      "Iteration 24200 - Batch 5/1613 - Train loss: 1.074157178401947, Train acc: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24300 - Batch 105/1613 - Train loss: 1.0497392556577358, Train acc: 0.8549528301886793\n",
      "Iteration 24400 - Batch 205/1613 - Train loss: 1.0496320958855083, Train acc: 0.8542172330097088\n",
      "Iteration 24500 - Batch 305/1613 - Train loss: 1.0468039526269326, Train acc: 0.8574346405228758\n",
      "Iteration 24600 - Batch 405/1613 - Train loss: 1.0466797108133439, Train acc: 0.8574507389162561\n",
      "Iteration 24700 - Batch 505/1613 - Train loss: 1.04413951185381, Train acc: 0.8597455533596838\n",
      "Iteration 24800 - Batch 605/1613 - Train loss: 1.0433275575685028, Train acc: 0.860664191419142\n",
      "Iteration 24900 - Batch 705/1613 - Train loss: 1.0432364386809785, Train acc: 0.8605701133144475\n",
      "Iteration 25000 - Batch 805/1613 - Train loss: 1.0441715792006359, Train acc: 0.859568858560794\n",
      "Iteration 25100 - Batch 905/1613 - Train loss: 1.0445333396230576, Train acc: 0.8592370309050773\n",
      "Iteration 25200 - Batch 1005/1613 - Train loss: 1.044553285801624, Train acc: 0.8592196819085487\n",
      "Iteration 25300 - Batch 1105/1613 - Train loss: 1.044930940133538, Train acc: 0.8589229204339964\n",
      "Iteration 25400 - Batch 1205/1613 - Train loss: 1.0461002379705262, Train acc: 0.8577943615257048\n",
      "Iteration 25500 - Batch 1305/1613 - Train loss: 1.0471174534849514, Train acc: 0.8567907733537519\n",
      "Iteration 25600 - Batch 1405/1613 - Train loss: 1.0467053565327846, Train acc: 0.8572190611664295\n",
      "Iteration 25700 - Batch 1505/1613 - Train loss: 1.0469782105875838, Train acc: 0.8568642098273572\n",
      "Iteration 25800 - Batch 1605/1613 - Train loss: 1.0480999701272506, Train acc: 0.8557557596513076\n",
      "[4, 4, 3, 3, 2, 0, 1, 3, 0, 0, 0, 3, 0, 3, 4, 2, 3, 3, 0, 4, 2, 1, 4, 4, 3, 0, 4, 0, 2, 2, 4, 0, 0, 2, 4, 3, 0, 1, 0, 4, 2, 0, 3, 4, 2, 0, 2, 2, 3, 0, 1, 2, 2, 2, 1, 0, 3, 4, 0, 3, 0, 0, 2, 3, 1, 1, 0, 3, 4, 2, 4, 1, 3, 1, 1, 3, 0, 0, 0, 3, 1, 3, 3, 2, 1, 4, 3, 3, 2, 2, 1, 1, 3, 3, 2, 2, 2, 0, 3, 3, 4, 0, 2, 1, 1, 4, 2, 4, 1, 0, 2, 2, 3, 0, 3, 1, 1, 4, 3, 2, 1, 3, 2, 1, 3, 2, 3, 0, 2, 3, 0, 1, 2, 2, 2, 3, 4, 4, 0, 0, 2, 0, 4, 3, 4, 1, 1, 3, 0, 0, 0, 2, 4, 1, 0, 4, 4, 2, 1, 4, 2, 4, 1, 1, 1, 1, 3, 4, 1, 3, 4, 2, 0, 4, 2, 1, 4, 2, 3, 4, 0, 4, 0, 4, 3, 2, 0, 4, 2, 1, 0, 1, 0, 1, 1, 2, 2, 1, 2, 4, 2, 4, 4, 4, 1, 1, 2, 3, 4, 4, 0, 3, 3, 2, 4, 4, 1, 3, 0, 1, 2, 4, 2, 3, 3, 0, 4, 2, 3, 2, 4, 3, 4, 1, 2, 0, 4, 2, 1, 1, 2, 4, 3, 4, 2, 0, 0, 1, 0, 1, 1, 0, 0, 1, 3, 2, 0, 1, 3, 3, 4, 1, 1, 4, 4, 0, 1, 0, 1, 3, 0, 1, 0, 1, 1, 0, 3, 2, 2, 0, 1, 2, 3, 0, 4, 0, 0, 2, 2, 3, 3, 0, 2, 0, 1, 2, 2, 4, 2, 2, 4, 3, 4, 3, 1, 0, 0, 4, 3, 1, 4, 1, 0, 2, 3, 0, 1, 1, 0, 4, 4, 1, 3, 2, 4, 1, 3, 2, 1, 3, 4, 4, 2, 3, 2, 0, 2, 2, 2, 1, 4, 4, 0, 0, 3, 1, 4, 2, 2, 1, 0, 4, 2, 4, 1, 0, 4, 1, 1, 0, 1, 4, 4, 3, 2, 0, 3, 3, 3, 1, 3, 0, 1, 3, 1, 2, 0, 2, 4, 0, 3, 3, 2, 4, 3, 2, 3, 3, 0, 0, 1, 0, 0, 0, 2, 4, 4, 0, 0, 3, 1, 4, 0, 2, 4, 0, 3, 1, 3, 4, 1, 4, 1, 4, 1, 0, 4, 0, 1, 0, 4, 3, 3, 3, 1, 1, 1, 1, 3, 4, 4, 3, 2, 4, 2, 2, 1, 1, 4, 4, 4, 4, 1, 3, 1, 1, 2, 3, 0, 3, 3, 3, 3, 3, 0, 3, 4, 4, 0, 0, 2, 1, 4, 2, 0, 0, 1, 2, 4, 2, 1, 3, 2, 2, 4, 1, 0, 3, 1, 0, 0, 1, 1, 3, 3, 4, 1, 2, 3, 4, 4, 3, 2, 0, 2, 4, 3, 2, 2, 2]\n",
      "[2, 4, 3, 3, 2, 0, 3, 3, 0, 0, 0, 3, 0, 3, 4, 3, 3, 4, 4, 4, 0, 4, 4, 4, 3, 0, 4, 0, 0, 2, 4, 0, 0, 2, 4, 3, 0, 0, 0, 4, 0, 0, 3, 2, 0, 0, 2, 2, 3, 0, 0, 2, 0, 2, 4, 0, 3, 4, 0, 3, 0, 0, 2, 3, 4, 2, 4, 3, 4, 0, 0, 4, 3, 4, 3, 3, 0, 0, 2, 3, 4, 3, 3, 2, 0, 4, 3, 3, 2, 2, 4, 0, 3, 3, 2, 2, 2, 0, 3, 3, 3, 0, 2, 4, 0, 3, 2, 4, 2, 0, 2, 2, 3, 0, 3, 4, 3, 4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 0, 2, 3, 0, 0, 2, 3, 2, 3, 3, 4, 0, 0, 2, 0, 4, 4, 4, 2, 0, 4, 0, 0, 0, 2, 4, 3, 0, 4, 4, 2, 3, 4, 2, 2, 4, 2, 3, 0, 3, 4, 3, 3, 4, 2, 0, 4, 2, 2, 4, 2, 3, 4, 0, 4, 0, 4, 3, 2, 0, 4, 2, 2, 0, 3, 0, 4, 2, 2, 2, 2, 2, 4, 0, 4, 4, 3, 3, 0, 0, 3, 4, 4, 2, 3, 3, 0, 4, 4, 3, 3, 0, 4, 2, 4, 2, 3, 3, 0, 4, 2, 3, 2, 4, 3, 4, 3, 2, 0, 4, 2, 3, 4, 3, 4, 3, 4, 2, 0, 0, 0, 0, 4, 0, 0, 0, 4, 3, 2, 0, 4, 3, 3, 4, 3, 4, 4, 4, 0, 4, 0, 3, 4, 0, 4, 0, 4, 4, 0, 3, 2, 2, 0, 3, 2, 3, 0, 2, 0, 0, 2, 2, 3, 4, 4, 2, 4, 0, 2, 2, 4, 0, 2, 4, 3, 4, 3, 4, 0, 2, 4, 3, 4, 4, 2, 0, 2, 3, 0, 2, 0, 0, 4, 4, 4, 3, 2, 4, 3, 3, 0, 4, 3, 4, 4, 0, 3, 2, 0, 2, 2, 2, 4, 4, 4, 0, 0, 3, 4, 4, 2, 0, 4, 0, 4, 2, 4, 4, 0, 4, 4, 2, 0, 4, 4, 4, 3, 2, 0, 3, 3, 2, 0, 4, 0, 3, 3, 4, 2, 0, 2, 3, 0, 3, 3, 2, 4, 3, 2, 3, 3, 0, 2, 4, 0, 0, 0, 2, 4, 4, 0, 0, 3, 4, 4, 0, 2, 4, 0, 3, 3, 3, 4, 3, 4, 4, 4, 4, 0, 4, 0, 4, 0, 4, 3, 3, 3, 4, 3, 4, 3, 3, 4, 4, 3, 2, 4, 2, 2, 3, 4, 4, 4, 3, 4, 2, 3, 2, 0, 2, 3, 0, 3, 3, 3, 3, 3, 0, 3, 4, 4, 0, 0, 2, 0, 4, 2, 0, 0, 4, 0, 4, 2, 4, 3, 2, 2, 4, 0, 0, 3, 3, 0, 0, 4, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 2, 0, 2, 4, 3, 2, 2, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.82      0.80       100\n",
      "           3       0.73      0.92      0.81       100\n",
      "           4       0.61      0.89      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1925323531031609, Val acc: 0.71\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25900 - Batch 92/1613 - Train loss: 1.0623931000309605, Train acc: 0.8387096774193549\n",
      "Iteration 26000 - Batch 192/1613 - Train loss: 1.0531961766549343, Train acc: 0.8490932642487047\n",
      "Iteration 26100 - Batch 292/1613 - Train loss: 1.0504276595831732, Train acc: 0.8526023890784983\n",
      "Iteration 26200 - Batch 392/1613 - Train loss: 1.0465283354426764, Train acc: 0.856631679389313\n",
      "Iteration 26300 - Batch 492/1613 - Train loss: 1.0484170011767993, Train acc: 0.8547794117647058\n",
      "Iteration 26400 - Batch 592/1613 - Train loss: 1.0467947437027454, Train acc: 0.8566610455311973\n",
      "Iteration 26500 - Batch 692/1613 - Train loss: 1.0464965884303634, Train acc: 0.8572781385281385\n",
      "Iteration 26600 - Batch 792/1613 - Train loss: 1.0475739375189004, Train acc: 0.8562421185372006\n",
      "Iteration 26700 - Batch 892/1613 - Train loss: 1.0468368007648166, Train acc: 0.8571528555431132\n",
      "Iteration 26800 - Batch 992/1613 - Train loss: 1.0462992082669775, Train acc: 0.857754279959718\n",
      "Iteration 26900 - Batch 1092/1613 - Train loss: 1.0455768362492024, Train acc: 0.858445791399817\n",
      "Iteration 27000 - Batch 1192/1613 - Train loss: 1.0459616252682535, Train acc: 0.8579474015088013\n",
      "Iteration 27100 - Batch 1292/1613 - Train loss: 1.0456621866768308, Train acc: 0.8582994972931168\n",
      "Iteration 27200 - Batch 1392/1613 - Train loss: 1.0458034729666617, Train acc: 0.8581748025843503\n",
      "Iteration 27300 - Batch 1492/1613 - Train loss: 1.045682132842951, Train acc: 0.8582551908908238\n",
      "Iteration 27400 - Batch 1592/1613 - Train loss: 1.0455381489742948, Train acc: 0.8583843377275581\n",
      "[3, 4, 4, 0, 1, 2, 0, 2, 2, 4, 0, 2, 0, 1, 2, 2, 4, 4, 4, 3, 4, 2, 2, 0, 3, 4, 2, 0, 1, 3, 3, 0, 0, 1, 0, 3, 0, 3, 2, 0, 4, 4, 1, 0, 2, 3, 1, 3, 0, 0, 4, 4, 1, 3, 3, 0, 3, 4, 1, 2, 2, 3, 2, 0, 2, 4, 1, 3, 3, 3, 4, 2, 3, 0, 0, 1, 3, 3, 4, 2, 0, 2, 1, 3, 2, 1, 4, 4, 2, 4, 4, 0, 3, 1, 4, 0, 1, 1, 0, 0, 4, 1, 2, 2, 0, 3, 0, 0, 4, 1, 1, 2, 0, 2, 4, 0, 2, 1, 3, 4, 2, 0, 2, 2, 1, 0, 3, 0, 1, 3, 2, 4, 1, 3, 2, 3, 1, 3, 4, 0, 3, 1, 0, 4, 2, 4, 0, 2, 1, 3, 3, 2, 2, 0, 2, 2, 0, 0, 3, 2, 0, 1, 1, 1, 0, 4, 1, 2, 2, 4, 1, 1, 4, 4, 1, 1, 1, 3, 1, 2, 3, 2, 0, 0, 1, 1, 1, 0, 3, 3, 4, 3, 4, 0, 3, 3, 0, 3, 1, 1, 2, 4, 3, 4, 1, 4, 2, 3, 0, 0, 1, 4, 1, 1, 1, 2, 4, 2, 2, 0, 2, 0, 4, 4, 2, 1, 0, 1, 4, 0, 3, 0, 3, 4, 1, 0, 4, 4, 2, 2, 4, 3, 1, 2, 2, 3, 4, 0, 3, 0, 2, 0, 3, 1, 1, 2, 3, 1, 4, 2, 1, 2, 1, 4, 0, 0, 1, 1, 1, 3, 1, 2, 1, 3, 0, 4, 2, 3, 2, 2, 1, 3, 4, 4, 0, 1, 4, 4, 0, 2, 4, 2, 1, 4, 2, 1, 4, 2, 4, 0, 2, 4, 4, 3, 3, 3, 1, 0, 0, 2, 2, 4, 3, 2, 0, 4, 0, 3, 3, 1, 2, 3, 1, 0, 2, 1, 1, 3, 0, 2, 4, 2, 4, 1, 1, 1, 2, 2, 4, 1, 1, 0, 3, 0, 3, 3, 1, 2, 3, 4, 3, 0, 1, 0, 3, 4, 0, 0, 4, 4, 3, 1, 1, 0, 2, 4, 0, 1, 4, 3, 4, 1, 1, 4, 0, 1, 1, 4, 2, 2, 3, 4, 0, 3, 4, 4, 3, 0, 3, 4, 3, 3, 2, 3, 3, 1, 1, 2, 4, 4, 3, 0, 1, 3, 2, 1, 4, 4, 2, 4, 3, 1, 0, 4, 2, 4, 3, 3, 1, 3, 1, 0, 3, 1, 0, 2, 0, 2, 0, 3, 3, 3, 4, 0, 2, 2, 2, 3, 1, 4, 4, 2, 0, 1, 1, 4, 2, 3, 0, 3, 0, 4, 2, 1, 2, 4, 4, 3, 2, 2, 3, 2, 0, 1, 3, 4, 0, 3, 0, 4, 0, 0, 1, 0, 3, 1, 2, 3, 2, 2, 0, 0, 4, 4, 4, 0, 0, 4, 4, 3, 2, 1, 1, 3, 1, 0, 2, 0, 3, 3]\n",
      "[3, 4, 4, 0, 4, 2, 0, 2, 2, 4, 0, 2, 0, 4, 2, 2, 4, 4, 4, 3, 4, 2, 2, 0, 3, 4, 2, 0, 4, 3, 3, 0, 2, 4, 0, 3, 0, 3, 2, 0, 4, 4, 4, 2, 2, 2, 4, 3, 0, 2, 4, 4, 4, 3, 3, 0, 3, 4, 0, 2, 2, 3, 2, 0, 2, 4, 4, 4, 3, 2, 4, 0, 3, 0, 2, 4, 3, 3, 4, 2, 0, 0, 4, 3, 2, 4, 4, 4, 2, 4, 4, 0, 3, 0, 2, 0, 4, 3, 0, 0, 4, 4, 2, 2, 0, 3, 0, 0, 4, 4, 4, 2, 0, 2, 4, 0, 2, 4, 3, 4, 2, 0, 2, 0, 0, 0, 4, 0, 2, 3, 2, 4, 2, 3, 2, 3, 4, 3, 4, 0, 3, 3, 0, 4, 2, 4, 0, 2, 4, 3, 3, 2, 2, 0, 2, 2, 0, 0, 3, 2, 0, 4, 4, 2, 0, 4, 4, 2, 2, 4, 2, 4, 4, 4, 3, 2, 4, 3, 4, 0, 3, 2, 2, 0, 4, 4, 0, 0, 3, 3, 4, 4, 4, 0, 3, 4, 0, 3, 0, 4, 3, 4, 3, 4, 4, 4, 2, 3, 0, 4, 2, 4, 4, 3, 0, 2, 4, 0, 2, 2, 2, 0, 4, 4, 2, 4, 0, 4, 4, 0, 3, 0, 3, 4, 4, 2, 4, 4, 2, 2, 4, 0, 4, 2, 2, 3, 4, 0, 4, 0, 2, 0, 3, 4, 0, 2, 4, 3, 4, 2, 4, 2, 0, 4, 0, 0, 0, 4, 4, 3, 4, 2, 3, 4, 0, 4, 2, 3, 2, 2, 2, 3, 4, 4, 0, 2, 4, 4, 0, 2, 4, 0, 4, 4, 0, 4, 4, 2, 4, 2, 2, 4, 4, 3, 3, 3, 3, 0, 0, 2, 2, 2, 3, 0, 0, 4, 0, 3, 3, 0, 2, 3, 0, 0, 2, 3, 4, 3, 0, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 0, 3, 0, 3, 3, 3, 2, 3, 4, 4, 0, 4, 0, 3, 4, 0, 0, 4, 4, 3, 3, 0, 2, 2, 4, 0, 0, 4, 3, 4, 4, 4, 4, 0, 4, 4, 4, 0, 4, 3, 4, 0, 3, 4, 4, 4, 0, 3, 4, 3, 3, 0, 4, 3, 4, 4, 2, 4, 4, 3, 0, 0, 3, 2, 0, 4, 4, 2, 4, 3, 4, 0, 4, 2, 4, 3, 3, 3, 3, 4, 0, 4, 3, 0, 2, 0, 2, 0, 3, 3, 3, 4, 0, 2, 2, 2, 3, 3, 4, 4, 2, 0, 0, 4, 4, 2, 3, 0, 4, 4, 4, 2, 4, 0, 4, 4, 3, 2, 2, 3, 2, 0, 3, 3, 3, 0, 3, 0, 4, 0, 4, 4, 0, 3, 4, 0, 3, 2, 0, 0, 0, 4, 4, 3, 0, 0, 4, 4, 3, 2, 2, 3, 3, 4, 4, 2, 0, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.87      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.85      0.82       100\n",
      "           3       0.83      0.85      0.84       100\n",
      "           4       0.55      0.96      0.70       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.193898867815733, Val acc: 0.706\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27500 - Batch 79/1613 - Train loss: 1.038287865370512, Train acc: 0.866015625\n",
      "Iteration 27600 - Batch 179/1613 - Train loss: 1.0448068900240792, Train acc: 0.8590277777777777\n",
      "Iteration 27700 - Batch 279/1613 - Train loss: 1.0461473356400217, Train acc: 0.8579241071428572\n",
      "Iteration 27800 - Batch 379/1613 - Train loss: 1.04509887930594, Train acc: 0.8585526315789473\n",
      "Iteration 27900 - Batch 479/1613 - Train loss: 1.0428715118517478, Train acc: 0.8607421875\n",
      "Iteration 28000 - Batch 579/1613 - Train loss: 1.0436542777151896, Train acc: 0.8600754310344828\n",
      "Iteration 28100 - Batch 679/1613 - Train loss: 1.0431231428595151, Train acc: 0.8605238970588235\n",
      "Iteration 28200 - Batch 779/1613 - Train loss: 1.0430880488493504, Train acc: 0.8606971153846154\n",
      "Iteration 28300 - Batch 879/1613 - Train loss: 1.0429144675758752, Train acc: 0.8609730113636364\n",
      "Iteration 28400 - Batch 979/1613 - Train loss: 1.0429045243530857, Train acc: 0.8608737244897959\n",
      "Iteration 28500 - Batch 1079/1613 - Train loss: 1.043089036753884, Train acc: 0.8607060185185185\n",
      "Iteration 28600 - Batch 1179/1613 - Train loss: 1.0430851389796048, Train acc: 0.8606726694915254\n",
      "Iteration 28700 - Batch 1279/1613 - Train loss: 1.0434896322432905, Train acc: 0.8604248046875\n",
      "Iteration 28800 - Batch 1379/1613 - Train loss: 1.0435603762018508, Train acc: 0.8603034420289855\n",
      "Iteration 28900 - Batch 1479/1613 - Train loss: 1.0443129588623306, Train acc: 0.859522804054054\n",
      "Iteration 29000 - Batch 1579/1613 - Train loss: 1.0437248477830163, Train acc: 0.8601463607594937\n",
      "[3, 1, 0, 1, 4, 3, 3, 4, 3, 1, 0, 2, 3, 3, 2, 4, 1, 2, 2, 1, 2, 1, 0, 4, 0, 4, 0, 4, 3, 4, 1, 2, 4, 3, 0, 4, 4, 0, 2, 2, 1, 3, 0, 0, 4, 2, 4, 4, 4, 0, 0, 4, 2, 2, 1, 3, 4, 0, 2, 1, 1, 0, 3, 0, 2, 2, 4, 1, 1, 4, 4, 4, 2, 1, 2, 0, 0, 4, 1, 2, 3, 4, 0, 1, 0, 2, 0, 2, 3, 2, 4, 1, 3, 1, 2, 2, 0, 1, 2, 3, 0, 0, 0, 1, 0, 2, 2, 0, 1, 1, 4, 1, 1, 0, 3, 2, 4, 4, 3, 3, 3, 3, 1, 4, 4, 3, 0, 0, 0, 3, 1, 2, 2, 3, 3, 1, 0, 0, 2, 4, 3, 2, 1, 3, 1, 0, 4, 2, 3, 3, 4, 2, 3, 1, 4, 0, 2, 3, 2, 0, 1, 2, 0, 2, 1, 3, 4, 0, 3, 3, 2, 3, 4, 3, 4, 1, 1, 4, 0, 2, 3, 4, 3, 3, 4, 1, 0, 2, 1, 3, 3, 2, 3, 2, 0, 3, 3, 0, 0, 3, 1, 4, 1, 1, 1, 0, 2, 4, 1, 0, 0, 4, 1, 1, 2, 3, 3, 0, 3, 2, 0, 1, 3, 1, 2, 0, 1, 1, 3, 4, 3, 3, 4, 2, 3, 2, 1, 0, 2, 2, 2, 4, 2, 2, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 0, 2, 1, 0, 4, 3, 1, 3, 3, 2, 3, 0, 3, 3, 3, 0, 4, 1, 0, 0, 3, 4, 4, 3, 1, 0, 0, 1, 0, 2, 4, 4, 4, 2, 3, 0, 2, 0, 1, 0, 2, 1, 1, 3, 4, 4, 0, 2, 1, 2, 4, 4, 2, 0, 0, 3, 3, 2, 1, 0, 4, 1, 1, 3, 0, 1, 2, 2, 1, 1, 1, 3, 1, 4, 3, 3, 0, 3, 1, 4, 3, 0, 0, 4, 3, 4, 0, 1, 2, 3, 0, 1, 0, 3, 2, 4, 1, 4, 1, 1, 4, 0, 1, 2, 1, 1, 1, 0, 0, 1, 3, 4, 2, 2, 3, 2, 2, 2, 4, 3, 3, 3, 3, 0, 2, 4, 2, 2, 0, 1, 4, 0, 1, 3, 1, 3, 2, 4, 0, 3, 4, 2, 4, 4, 1, 2, 1, 2, 1, 4, 4, 4, 2, 2, 4, 0, 1, 0, 4, 4, 4, 2, 2, 3, 3, 4, 2, 4, 2, 3, 0, 1, 2, 1, 2, 0, 1, 2, 2, 1, 0, 2, 2, 3, 0, 3, 2, 2, 3, 0, 2, 0, 3, 0, 3, 4, 4, 0, 1, 2, 1, 4, 1, 0, 4, 0, 3, 4, 0, 2, 3, 1, 1, 1, 3, 1, 1, 4, 4, 4, 2, 0, 1, 3, 3, 2, 1, 4, 4, 3, 4, 0, 4, 1, 1, 3, 4, 1, 0, 3, 0, 0, 2, 2, 4, 3]\n",
      "[3, 4, 0, 4, 4, 3, 3, 4, 3, 0, 0, 2, 3, 3, 2, 4, 4, 2, 2, 4, 2, 4, 0, 4, 0, 4, 0, 3, 3, 4, 3, 2, 4, 3, 0, 4, 4, 0, 2, 2, 4, 3, 0, 4, 4, 0, 4, 4, 4, 0, 0, 4, 2, 0, 3, 3, 4, 0, 2, 3, 4, 0, 4, 0, 2, 2, 3, 3, 4, 4, 4, 4, 0, 4, 4, 0, 0, 4, 4, 0, 3, 4, 0, 0, 0, 2, 0, 2, 3, 2, 4, 4, 3, 3, 2, 2, 0, 4, 2, 4, 0, 4, 0, 4, 0, 0, 2, 0, 3, 3, 4, 0, 3, 0, 3, 2, 4, 4, 3, 3, 3, 3, 2, 4, 4, 3, 4, 0, 0, 3, 3, 0, 2, 3, 3, 0, 0, 3, 2, 4, 3, 0, 4, 3, 4, 0, 4, 3, 3, 4, 4, 2, 3, 0, 4, 0, 0, 3, 2, 4, 4, 2, 0, 2, 4, 3, 4, 0, 3, 3, 2, 3, 4, 3, 4, 4, 4, 4, 0, 0, 3, 3, 3, 3, 4, 3, 0, 0, 4, 3, 3, 0, 3, 2, 0, 3, 3, 0, 0, 3, 4, 4, 3, 4, 0, 0, 2, 4, 4, 0, 0, 4, 3, 2, 0, 3, 4, 0, 3, 2, 0, 0, 3, 0, 2, 0, 4, 4, 3, 4, 3, 3, 4, 2, 3, 2, 4, 0, 2, 2, 2, 4, 3, 2, 4, 0, 0, 4, 4, 0, 4, 4, 0, 4, 0, 2, 3, 0, 4, 3, 4, 0, 3, 2, 3, 2, 3, 3, 3, 0, 4, 3, 0, 0, 3, 4, 4, 2, 3, 0, 4, 4, 2, 2, 4, 4, 4, 2, 3, 0, 2, 0, 3, 2, 2, 3, 4, 3, 4, 4, 0, 2, 0, 2, 4, 4, 2, 0, 0, 3, 3, 2, 0, 2, 4, 0, 4, 3, 0, 0, 2, 2, 4, 4, 3, 3, 3, 3, 3, 3, 0, 3, 4, 4, 3, 0, 0, 4, 3, 4, 0, 2, 2, 3, 0, 3, 0, 3, 2, 4, 4, 4, 4, 0, 4, 0, 0, 0, 0, 0, 3, 0, 0, 4, 3, 4, 2, 2, 3, 2, 2, 2, 4, 3, 3, 3, 3, 0, 0, 4, 2, 4, 0, 4, 4, 0, 2, 3, 3, 3, 2, 0, 0, 3, 4, 2, 4, 4, 0, 0, 0, 2, 4, 4, 4, 4, 2, 2, 4, 0, 4, 0, 4, 4, 3, 0, 2, 3, 3, 4, 2, 4, 0, 3, 0, 3, 2, 2, 2, 0, 4, 2, 2, 0, 0, 0, 0, 3, 0, 3, 2, 2, 4, 0, 2, 0, 3, 0, 3, 4, 4, 0, 4, 0, 4, 4, 3, 0, 4, 0, 3, 4, 0, 2, 3, 3, 3, 0, 3, 0, 4, 3, 4, 2, 0, 0, 3, 3, 3, 2, 4, 4, 4, 4, 4, 0, 4, 4, 4, 3, 4, 4, 0, 4, 2, 0, 2, 2, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.75      0.80       100\n",
      "           3       0.72      0.91      0.80       100\n",
      "           4       0.60      0.92      0.73       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.62       500\n",
      "weighted avg       0.57      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2071420699357986, Val acc: 0.694\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29100 - Batch 66/1613 - Train loss: 1.0432259529384214, Train acc: 0.8600746268656716\n",
      "Iteration 29200 - Batch 166/1613 - Train loss: 1.0403707502130977, Train acc: 0.8635853293413174\n",
      "Iteration 29300 - Batch 266/1613 - Train loss: 1.0399510349227248, Train acc: 0.8637640449438202\n",
      "Iteration 29400 - Batch 366/1613 - Train loss: 1.0413640211323627, Train acc: 0.8620572207084468\n",
      "Iteration 29500 - Batch 466/1613 - Train loss: 1.0417422204252484, Train acc: 0.8619512847965739\n",
      "Iteration 29600 - Batch 566/1613 - Train loss: 1.0426263924839214, Train acc: 0.861166225749559\n",
      "Iteration 29700 - Batch 666/1613 - Train loss: 1.0417850255251289, Train acc: 0.8623032233883059\n",
      "Iteration 29800 - Batch 766/1613 - Train loss: 1.0429052225613997, Train acc: 0.8610250977835724\n",
      "Iteration 29900 - Batch 866/1613 - Train loss: 1.0422326888042612, Train acc: 0.861663783160323\n",
      "Iteration 30000 - Batch 966/1613 - Train loss: 1.0419203476304228, Train acc: 0.8617825749741469\n",
      "Iteration 30100 - Batch 1066/1613 - Train loss: 1.0421153775083762, Train acc: 0.861703373945642\n",
      "Iteration 30200 - Batch 1166/1613 - Train loss: 1.0418831188145516, Train acc: 0.8620394173093402\n",
      "Iteration 30300 - Batch 1266/1613 - Train loss: 1.041712681797422, Train acc: 0.8621744277821626\n",
      "Iteration 30400 - Batch 1366/1613 - Train loss: 1.0434917808887116, Train acc: 0.8603465618141917\n",
      "Iteration 30500 - Batch 1466/1613 - Train loss: 1.0438456222486074, Train acc: 0.8600034083162917\n",
      "Iteration 30600 - Batch 1566/1613 - Train loss: 1.0437522238047927, Train acc: 0.8600829610721124\n",
      "[4, 0, 4, 3, 4, 2, 0, 1, 1, 0, 4, 2, 3, 2, 2, 0, 1, 3, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 4, 4, 3, 0, 1, 4, 0, 4, 1, 4, 0, 2, 2, 3, 0, 0, 0, 0, 3, 4, 4, 2, 1, 2, 2, 4, 2, 1, 4, 0, 3, 4, 1, 2, 3, 3, 1, 1, 3, 1, 1, 1, 0, 4, 3, 4, 0, 0, 3, 0, 4, 2, 2, 4, 2, 4, 2, 4, 0, 1, 3, 0, 1, 3, 3, 2, 1, 4, 0, 2, 3, 1, 3, 1, 3, 4, 4, 3, 4, 4, 1, 0, 0, 1, 3, 0, 3, 3, 4, 0, 1, 4, 4, 1, 1, 2, 4, 0, 2, 1, 1, 1, 4, 1, 1, 2, 2, 1, 3, 2, 4, 1, 2, 0, 4, 1, 2, 3, 2, 3, 4, 2, 3, 1, 3, 1, 3, 2, 2, 2, 4, 2, 0, 3, 3, 3, 2, 0, 2, 3, 0, 0, 4, 2, 2, 1, 1, 1, 1, 3, 2, 4, 0, 3, 0, 0, 3, 4, 2, 2, 0, 1, 1, 4, 0, 3, 4, 3, 4, 3, 2, 1, 3, 4, 2, 4, 1, 3, 2, 2, 0, 4, 3, 1, 3, 0, 4, 4, 1, 0, 1, 1, 1, 4, 1, 2, 4, 4, 0, 4, 1, 2, 0, 0, 3, 4, 2, 1, 0, 4, 1, 3, 3, 2, 3, 0, 4, 2, 2, 2, 0, 4, 0, 3, 1, 1, 0, 0, 1, 3, 0, 3, 2, 1, 1, 3, 1, 0, 4, 2, 2, 0, 0, 2, 2, 1, 3, 2, 0, 3, 1, 3, 2, 2, 1, 2, 1, 1, 0, 2, 0, 0, 1, 1, 4, 3, 1, 1, 0, 4, 1, 4, 4, 4, 3, 1, 4, 0, 2, 4, 2, 3, 0, 2, 4, 1, 0, 4, 4, 1, 1, 0, 0, 2, 3, 1, 0, 2, 2, 4, 4, 3, 3, 1, 0, 4, 4, 3, 4, 0, 0, 3, 3, 2, 4, 3, 1, 1, 4, 2, 3, 0, 1, 3, 3, 1, 4, 2, 2, 3, 2, 4, 4, 1, 1, 1, 3, 1, 0, 0, 0, 0, 3, 3, 4, 4, 4, 0, 3, 3, 1, 0, 4, 4, 1, 2, 2, 4, 0, 0, 3, 2, 2, 0, 2, 3, 0, 1, 3, 3, 3, 2, 4, 2, 1, 2, 0, 0, 1, 4, 0, 4, 0, 3, 3, 0, 4, 4, 3, 2, 0, 3, 3, 4, 1, 3, 3, 1, 4, 0, 2, 4, 4, 0, 2, 2, 1, 2, 2, 2, 4, 3, 3, 0, 4, 4, 2, 0, 3, 1, 3, 0, 0, 1, 2, 2, 2, 3, 3, 0, 3, 2, 3, 1, 0, 2, 1, 3, 1, 4, 3, 3, 1, 3, 2, 4, 3, 1, 0, 2, 2, 2, 0, 0, 1, 0, 0, 4, 4, 3, 0, 4, 1, 2, 3, 4, 4, 2, 4, 1, 3]\n",
      "[4, 4, 4, 3, 4, 2, 0, 0, 4, 0, 4, 2, 3, 2, 2, 0, 2, 3, 2, 2, 3, 3, 0, 0, 2, 0, 0, 4, 2, 4, 4, 3, 0, 3, 4, 0, 4, 3, 4, 4, 2, 2, 3, 0, 0, 0, 0, 3, 4, 4, 2, 0, 2, 3, 4, 2, 4, 4, 0, 3, 2, 3, 0, 3, 3, 4, 0, 3, 2, 4, 4, 0, 4, 3, 4, 0, 0, 3, 0, 4, 2, 0, 4, 0, 4, 2, 4, 0, 3, 3, 0, 3, 3, 3, 2, 4, 4, 0, 2, 3, 3, 3, 3, 4, 4, 4, 3, 4, 3, 4, 4, 0, 3, 3, 0, 3, 3, 4, 3, 0, 4, 4, 3, 3, 0, 4, 0, 2, 4, 4, 4, 4, 4, 3, 2, 2, 4, 3, 2, 3, 4, 2, 0, 4, 4, 0, 3, 2, 3, 3, 2, 3, 4, 3, 4, 3, 2, 2, 2, 4, 2, 0, 3, 3, 3, 0, 0, 2, 3, 0, 0, 4, 2, 2, 4, 4, 4, 0, 3, 2, 4, 0, 4, 0, 0, 3, 4, 2, 2, 0, 4, 4, 4, 4, 3, 4, 3, 4, 3, 2, 4, 4, 4, 2, 4, 4, 3, 0, 2, 0, 4, 3, 3, 3, 0, 4, 4, 3, 0, 2, 3, 4, 4, 3, 2, 4, 4, 0, 3, 4, 0, 0, 0, 3, 4, 2, 3, 0, 4, 4, 3, 3, 2, 3, 0, 4, 0, 2, 2, 0, 4, 0, 3, 4, 3, 0, 0, 4, 3, 0, 3, 2, 4, 4, 3, 3, 0, 4, 2, 2, 0, 0, 2, 2, 4, 3, 2, 0, 3, 3, 3, 4, 2, 4, 0, 4, 4, 4, 2, 0, 2, 0, 4, 4, 3, 3, 4, 0, 4, 4, 4, 4, 4, 3, 2, 4, 3, 2, 4, 0, 3, 0, 2, 4, 2, 2, 4, 4, 4, 3, 0, 0, 0, 4, 4, 0, 2, 0, 4, 4, 3, 3, 3, 4, 4, 4, 3, 4, 0, 0, 3, 3, 2, 4, 3, 0, 4, 4, 2, 3, 0, 0, 3, 3, 4, 4, 2, 2, 3, 0, 4, 4, 4, 3, 4, 3, 0, 0, 0, 0, 0, 3, 3, 4, 4, 4, 0, 4, 3, 4, 0, 4, 4, 3, 2, 2, 4, 0, 4, 0, 2, 2, 0, 2, 3, 0, 4, 4, 3, 3, 2, 4, 2, 0, 2, 0, 0, 4, 4, 0, 4, 0, 3, 4, 0, 4, 0, 4, 0, 0, 3, 3, 4, 2, 3, 3, 4, 4, 0, 2, 4, 4, 2, 2, 2, 3, 2, 2, 2, 4, 3, 3, 0, 4, 4, 2, 0, 3, 3, 3, 0, 0, 3, 2, 2, 3, 3, 3, 0, 3, 2, 3, 4, 0, 2, 4, 3, 4, 4, 4, 3, 0, 3, 2, 4, 3, 0, 0, 2, 2, 2, 2, 0, 4, 0, 0, 4, 4, 3, 0, 4, 4, 2, 3, 4, 4, 0, 4, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.81      0.84       100\n",
      "           3       0.71      0.90      0.79       100\n",
      "           4       0.57      0.94      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1998054385185242, Val acc: 0.702\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30700 - Batch 53/1613 - Train loss: 1.0589007139205933, Train acc: 0.8466435185185185\n",
      "Iteration 30800 - Batch 153/1613 - Train loss: 1.0450572719821682, Train acc: 0.859577922077922\n",
      "Iteration 30900 - Batch 253/1613 - Train loss: 1.045083714047755, Train acc: 0.858882874015748\n",
      "Iteration 31000 - Batch 353/1613 - Train loss: 1.0450772201947574, Train acc: 0.858933615819209\n",
      "Iteration 31100 - Batch 453/1613 - Train loss: 1.0445707444314916, Train acc: 0.8595814977973568\n",
      "Iteration 31200 - Batch 553/1613 - Train loss: 1.0448508313201395, Train acc: 0.8593185920577617\n",
      "Iteration 31300 - Batch 653/1613 - Train loss: 1.0441703092796721, Train acc: 0.8599006116207951\n",
      "Iteration 31400 - Batch 753/1613 - Train loss: 1.0428816539381165, Train acc: 0.8611571618037135\n",
      "Iteration 31500 - Batch 853/1613 - Train loss: 1.0428181865734574, Train acc: 0.8612412177985949\n",
      "Iteration 31600 - Batch 953/1613 - Train loss: 1.0423729596522868, Train acc: 0.8617990041928721\n",
      "Iteration 31700 - Batch 1053/1613 - Train loss: 1.041879149213914, Train acc: 0.8622212998102466\n",
      "Iteration 31800 - Batch 1153/1613 - Train loss: 1.0416534037379293, Train acc: 0.8624891681109186\n",
      "Iteration 31900 - Batch 1253/1613 - Train loss: 1.041941627028266, Train acc: 0.8622408293460925\n",
      "Iteration 32000 - Batch 1353/1613 - Train loss: 1.0417921531675838, Train acc: 0.8622599704579025\n",
      "Iteration 32100 - Batch 1453/1613 - Train loss: 1.042427050362263, Train acc: 0.8615887207702888\n",
      "Iteration 32200 - Batch 1553/1613 - Train loss: 1.042715424659783, Train acc: 0.8614663770913771\n",
      "[0, 1, 0, 3, 4, 1, 3, 3, 0, 2, 2, 4, 1, 1, 2, 4, 0, 4, 1, 1, 3, 2, 3, 2, 1, 4, 4, 4, 2, 3, 2, 0, 0, 3, 2, 4, 2, 0, 4, 3, 3, 4, 1, 3, 1, 4, 3, 4, 0, 2, 4, 2, 1, 4, 1, 4, 1, 0, 0, 2, 4, 3, 2, 3, 0, 3, 0, 0, 1, 2, 2, 1, 1, 3, 1, 2, 0, 4, 2, 1, 0, 0, 1, 3, 3, 4, 3, 3, 3, 0, 4, 2, 1, 4, 3, 0, 0, 3, 0, 0, 2, 1, 2, 3, 2, 1, 1, 1, 3, 1, 2, 2, 4, 4, 0, 1, 1, 3, 0, 1, 4, 2, 3, 0, 0, 2, 4, 1, 2, 2, 0, 1, 3, 4, 4, 3, 2, 3, 3, 4, 2, 3, 2, 1, 0, 0, 2, 3, 0, 2, 3, 3, 0, 1, 0, 1, 0, 4, 4, 2, 4, 2, 2, 3, 2, 0, 4, 1, 3, 4, 3, 1, 1, 4, 0, 2, 1, 0, 2, 3, 0, 3, 1, 0, 0, 3, 0, 1, 3, 4, 3, 3, 3, 1, 4, 1, 1, 4, 1, 1, 2, 1, 3, 2, 4, 2, 0, 4, 2, 2, 2, 3, 1, 0, 4, 4, 3, 2, 4, 3, 2, 1, 4, 2, 1, 2, 2, 3, 1, 1, 3, 4, 2, 4, 3, 2, 0, 0, 2, 2, 2, 3, 4, 4, 1, 4, 2, 2, 1, 4, 4, 0, 3, 3, 4, 0, 0, 4, 4, 0, 0, 4, 3, 4, 2, 2, 3, 2, 3, 0, 2, 1, 3, 0, 3, 0, 4, 2, 4, 3, 2, 4, 2, 4, 2, 2, 1, 0, 4, 1, 0, 4, 0, 0, 4, 3, 0, 2, 1, 4, 2, 2, 2, 4, 0, 0, 2, 1, 3, 4, 3, 4, 0, 3, 0, 3, 0, 0, 3, 1, 1, 0, 4, 4, 4, 0, 3, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 4, 4, 3, 1, 3, 0, 2, 3, 1, 2, 0, 1, 4, 4, 1, 0, 3, 4, 4, 1, 0, 1, 4, 1, 4, 2, 1, 1, 2, 4, 4, 1, 1, 2, 3, 0, 1, 0, 2, 4, 0, 1, 3, 3, 3, 0, 4, 3, 1, 2, 3, 4, 0, 1, 2, 1, 4, 2, 4, 3, 1, 4, 0, 2, 0, 4, 3, 1, 3, 1, 1, 2, 1, 4, 2, 2, 2, 3, 3, 0, 4, 0, 3, 3, 3, 1, 1, 3, 3, 2, 3, 2, 4, 0, 0, 2, 3, 0, 3, 1, 1, 1, 0, 4, 0, 1, 3, 2, 3, 0, 0, 1, 3, 0, 3, 1, 4, 2, 0, 2, 2, 4, 3, 0, 0, 3, 3, 4, 4, 3, 2, 0, 4, 0, 1, 4, 3, 4, 3, 2, 4, 2, 2, 4, 1, 2, 0, 4, 2, 0, 2, 0, 0, 0, 1, 1, 0, 2, 4]\n",
      "[0, 3, 0, 3, 4, 4, 3, 3, 0, 2, 2, 4, 3, 4, 2, 4, 0, 4, 3, 4, 3, 2, 3, 2, 0, 4, 4, 4, 2, 3, 2, 0, 2, 3, 0, 4, 2, 0, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 0, 2, 3, 0, 3, 4, 4, 4, 3, 0, 0, 2, 4, 3, 2, 4, 0, 3, 0, 0, 4, 2, 2, 4, 4, 3, 0, 0, 4, 4, 2, 4, 0, 0, 3, 3, 3, 4, 3, 3, 3, 0, 4, 2, 0, 4, 3, 0, 0, 3, 0, 3, 2, 0, 2, 4, 0, 4, 3, 4, 4, 2, 2, 2, 4, 4, 0, 4, 4, 3, 0, 4, 4, 2, 3, 0, 0, 2, 4, 4, 2, 2, 0, 3, 3, 4, 4, 3, 2, 3, 3, 4, 0, 3, 2, 4, 0, 0, 2, 3, 0, 2, 3, 3, 0, 2, 0, 2, 0, 4, 4, 2, 4, 2, 2, 3, 2, 2, 4, 0, 3, 4, 3, 4, 0, 4, 0, 2, 3, 0, 2, 3, 0, 3, 0, 0, 0, 3, 0, 4, 3, 4, 3, 3, 3, 4, 2, 2, 3, 4, 0, 4, 2, 4, 3, 2, 4, 2, 2, 4, 2, 2, 2, 3, 4, 0, 4, 3, 3, 2, 4, 3, 3, 4, 4, 2, 4, 2, 2, 3, 4, 3, 4, 4, 2, 4, 3, 2, 0, 2, 2, 2, 2, 3, 4, 4, 4, 4, 2, 2, 2, 3, 4, 4, 3, 3, 4, 0, 0, 3, 4, 0, 0, 4, 3, 3, 2, 0, 3, 2, 3, 0, 4, 4, 3, 0, 2, 0, 2, 2, 4, 3, 2, 4, 2, 4, 2, 2, 0, 0, 4, 4, 4, 4, 0, 0, 4, 3, 0, 2, 4, 3, 2, 2, 2, 4, 0, 0, 2, 3, 3, 4, 3, 4, 0, 3, 0, 2, 0, 0, 3, 4, 4, 2, 4, 4, 4, 0, 3, 0, 4, 4, 4, 0, 0, 4, 4, 4, 0, 0, 2, 4, 3, 4, 4, 3, 0, 3, 0, 2, 3, 3, 2, 2, 4, 4, 4, 4, 0, 3, 4, 4, 3, 2, 4, 4, 3, 4, 2, 4, 2, 2, 4, 4, 3, 2, 2, 3, 0, 4, 0, 2, 4, 0, 2, 4, 3, 3, 0, 4, 3, 3, 2, 4, 4, 0, 0, 2, 3, 3, 2, 4, 3, 4, 4, 0, 2, 0, 4, 3, 4, 3, 2, 4, 2, 4, 4, 2, 2, 0, 4, 3, 0, 4, 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 2, 4, 0, 0, 2, 3, 0, 3, 4, 2, 4, 0, 4, 0, 2, 3, 2, 3, 0, 0, 0, 3, 4, 3, 4, 4, 3, 0, 0, 0, 4, 3, 0, 0, 3, 3, 4, 4, 3, 2, 0, 4, 0, 3, 4, 4, 4, 3, 2, 4, 2, 2, 4, 4, 0, 0, 4, 2, 0, 2, 0, 0, 0, 4, 4, 0, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.78      0.86      0.82       100\n",
      "           3       0.74      0.88      0.80       100\n",
      "           4       0.57      0.91      0.70       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1986924782395363, Val acc: 0.706\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32300 - Batch 40/1613 - Train loss: 1.0554458789709138, Train acc: 0.8483231707317073\n",
      "Iteration 32400 - Batch 140/1613 - Train loss: 1.042301965520737, Train acc: 0.862145390070922\n",
      "Iteration 32500 - Batch 240/1613 - Train loss: 1.0408411424189683, Train acc: 0.8637188796680498\n",
      "Iteration 32600 - Batch 340/1613 - Train loss: 1.039077265696092, Train acc: 0.8651942815249267\n",
      "Iteration 32700 - Batch 440/1613 - Train loss: 1.0385396135907594, Train acc: 0.8656462585034014\n",
      "Iteration 32800 - Batch 540/1613 - Train loss: 1.040674398214231, Train acc: 0.8630429759704251\n",
      "Iteration 32900 - Batch 640/1613 - Train loss: 1.0399853134304053, Train acc: 0.8636895475819033\n",
      "Iteration 33000 - Batch 740/1613 - Train loss: 1.040525463750327, Train acc: 0.8630651147098516\n",
      "Iteration 33100 - Batch 840/1613 - Train loss: 1.0409380103971955, Train acc: 0.8627378121284186\n",
      "Iteration 33200 - Batch 940/1613 - Train loss: 1.0415236993626504, Train acc: 0.8621811902231669\n",
      "Iteration 33300 - Batch 1040/1613 - Train loss: 1.042128724277764, Train acc: 0.861671469740634\n",
      "Iteration 33400 - Batch 1140/1613 - Train loss: 1.0414188889220135, Train acc: 0.8622918492550394\n",
      "Iteration 33500 - Batch 1240/1613 - Train loss: 1.041302650950783, Train acc: 0.8623841659951652\n",
      "Iteration 33600 - Batch 1340/1613 - Train loss: 1.040906885192965, Train acc: 0.8626724459358688\n",
      "Iteration 33700 - Batch 1440/1613 - Train loss: 1.0414349653504111, Train acc: 0.8620315752949341\n",
      "Iteration 33800 - Batch 1540/1613 - Train loss: 1.0414831683590844, Train acc: 0.8620619727449708\n",
      "[3, 2, 3, 4, 3, 0, 0, 2, 0, 3, 0, 2, 3, 0, 0, 3, 1, 0, 1, 0, 1, 4, 2, 2, 4, 0, 4, 3, 0, 2, 2, 2, 3, 4, 3, 2, 0, 3, 3, 3, 0, 3, 2, 0, 3, 4, 1, 0, 3, 2, 1, 4, 3, 0, 4, 0, 4, 3, 4, 3, 0, 0, 2, 2, 2, 1, 3, 1, 0, 2, 1, 4, 1, 2, 2, 4, 2, 0, 2, 1, 2, 1, 3, 2, 4, 2, 4, 0, 1, 4, 3, 4, 0, 0, 2, 0, 2, 3, 1, 1, 3, 3, 3, 1, 4, 4, 0, 1, 3, 1, 1, 4, 1, 4, 2, 3, 3, 1, 0, 0, 3, 4, 1, 0, 1, 2, 3, 1, 1, 2, 1, 4, 2, 4, 4, 2, 1, 0, 4, 0, 3, 4, 3, 2, 0, 3, 2, 2, 1, 0, 3, 2, 2, 1, 1, 4, 3, 3, 0, 4, 0, 1, 2, 0, 4, 0, 2, 3, 4, 2, 4, 0, 0, 0, 0, 3, 2, 3, 1, 0, 2, 2, 0, 2, 4, 2, 2, 3, 2, 3, 2, 4, 0, 4, 2, 2, 0, 4, 4, 2, 1, 4, 4, 1, 3, 2, 1, 0, 4, 3, 4, 4, 4, 3, 3, 3, 2, 4, 4, 0, 1, 3, 2, 3, 2, 2, 1, 2, 3, 3, 4, 1, 1, 4, 0, 1, 1, 4, 1, 0, 0, 3, 2, 2, 3, 1, 4, 3, 3, 3, 2, 4, 3, 0, 1, 3, 1, 2, 1, 1, 3, 1, 2, 3, 4, 4, 0, 3, 3, 1, 4, 2, 1, 1, 0, 4, 4, 1, 2, 3, 0, 4, 3, 1, 2, 3, 3, 4, 0, 3, 1, 2, 1, 3, 0, 0, 2, 3, 1, 0, 4, 0, 4, 1, 0, 4, 0, 3, 3, 0, 2, 0, 2, 2, 1, 3, 2, 4, 1, 1, 1, 3, 0, 4, 4, 0, 1, 4, 0, 2, 3, 0, 4, 2, 3, 2, 1, 4, 1, 4, 2, 2, 3, 0, 0, 4, 0, 0, 1, 0, 4, 3, 4, 1, 4, 2, 4, 4, 1, 0, 4, 1, 0, 1, 1, 1, 1, 0, 4, 3, 4, 0, 2, 4, 1, 4, 3, 3, 2, 3, 0, 2, 1, 3, 1, 2, 1, 2, 4, 2, 0, 1, 0, 2, 1, 4, 0, 3, 3, 4, 2, 2, 3, 4, 3, 3, 2, 3, 4, 1, 4, 4, 1, 3, 3, 2, 4, 1, 4, 3, 4, 1, 1, 0, 0, 4, 0, 1, 1, 0, 4, 1, 0, 0, 2, 2, 3, 1, 0, 2, 1, 2, 4, 0, 3, 2, 1, 4, 3, 4, 3, 0, 2, 3, 1, 4, 3, 3, 1, 0, 3, 1, 2, 2, 1, 0, 4, 1, 4, 0, 2, 1, 0, 2, 0, 1, 3, 0, 0, 0, 4, 4, 2, 4, 0, 2, 0, 3, 2, 1, 1, 1, 2, 0, 0, 2, 4, 4, 1, 1]\n",
      "[3, 2, 4, 4, 3, 0, 0, 2, 0, 3, 0, 2, 3, 0, 0, 4, 4, 4, 4, 0, 3, 4, 2, 2, 4, 0, 4, 3, 0, 2, 2, 2, 3, 4, 3, 2, 0, 3, 3, 3, 0, 3, 2, 0, 4, 4, 4, 0, 3, 2, 0, 4, 3, 0, 4, 0, 4, 3, 4, 3, 0, 0, 2, 2, 0, 4, 4, 4, 0, 0, 4, 2, 3, 2, 0, 4, 2, 0, 2, 4, 2, 4, 3, 2, 4, 2, 3, 0, 4, 4, 3, 4, 0, 0, 2, 0, 2, 3, 3, 4, 3, 3, 3, 4, 4, 3, 0, 4, 3, 0, 4, 4, 4, 4, 0, 2, 3, 0, 0, 0, 3, 4, 0, 0, 4, 2, 3, 0, 4, 2, 2, 4, 0, 3, 4, 0, 3, 0, 4, 0, 3, 4, 3, 2, 2, 3, 0, 2, 4, 0, 3, 0, 2, 3, 3, 4, 2, 3, 0, 4, 0, 3, 2, 0, 4, 0, 0, 3, 3, 2, 3, 0, 0, 0, 0, 3, 2, 4, 0, 0, 2, 0, 0, 2, 4, 2, 2, 3, 0, 3, 2, 4, 0, 4, 2, 2, 0, 4, 4, 2, 4, 3, 4, 4, 3, 2, 0, 0, 4, 3, 4, 4, 4, 3, 3, 3, 2, 3, 4, 0, 4, 3, 0, 3, 2, 2, 0, 2, 3, 3, 4, 0, 0, 4, 0, 4, 4, 4, 4, 0, 0, 3, 2, 2, 3, 0, 4, 3, 3, 3, 0, 4, 3, 0, 3, 3, 3, 2, 3, 2, 3, 4, 2, 4, 4, 4, 0, 3, 3, 2, 4, 4, 4, 3, 0, 4, 4, 4, 0, 3, 0, 4, 3, 3, 2, 3, 3, 4, 0, 3, 0, 0, 3, 3, 0, 0, 2, 3, 4, 4, 4, 0, 4, 3, 0, 4, 0, 3, 2, 0, 2, 0, 0, 0, 0, 3, 2, 4, 0, 0, 4, 3, 0, 4, 4, 0, 3, 4, 0, 2, 3, 0, 4, 2, 3, 2, 0, 3, 0, 4, 2, 2, 3, 0, 0, 4, 0, 0, 0, 0, 4, 3, 4, 4, 4, 2, 4, 3, 2, 0, 4, 3, 0, 4, 4, 3, 0, 0, 4, 3, 4, 0, 2, 4, 4, 4, 3, 3, 3, 3, 0, 2, 0, 3, 4, 2, 3, 2, 4, 0, 0, 4, 0, 0, 0, 4, 0, 3, 3, 4, 0, 2, 3, 4, 3, 3, 2, 3, 4, 3, 4, 4, 3, 3, 3, 0, 4, 3, 4, 3, 4, 4, 4, 0, 0, 4, 0, 0, 2, 0, 4, 4, 0, 0, 2, 0, 3, 2, 0, 2, 4, 0, 4, 0, 3, 2, 3, 4, 3, 4, 4, 0, 2, 3, 3, 4, 3, 3, 3, 0, 3, 4, 2, 2, 0, 0, 2, 4, 4, 0, 2, 4, 0, 2, 0, 3, 3, 0, 4, 0, 4, 4, 2, 4, 0, 2, 2, 3, 2, 4, 4, 4, 0, 0, 0, 2, 4, 4, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.95      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.74      0.79       100\n",
      "           3       0.71      0.90      0.80       100\n",
      "           4       0.62      0.89      0.73       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2099339962005615, Val acc: 0.696\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33900 - Batch 27/1613 - Train loss: 1.0430183091333933, Train acc: 0.8604910714285714\n",
      "Iteration 34000 - Batch 127/1613 - Train loss: 1.0430987114086747, Train acc: 0.860107421875\n",
      "Iteration 34100 - Batch 227/1613 - Train loss: 1.03813656850865, Train acc: 0.8651315789473685\n",
      "Iteration 34200 - Batch 327/1613 - Train loss: 1.0325121347133706, Train acc: 0.87109375\n",
      "Iteration 34300 - Batch 427/1613 - Train loss: 1.035486318379919, Train acc: 0.8683557242990654\n",
      "Iteration 34400 - Batch 527/1613 - Train loss: 1.0375948565250093, Train acc: 0.8661813446969697\n",
      "Iteration 34500 - Batch 627/1613 - Train loss: 1.0377682606885388, Train acc: 0.8661425159235668\n",
      "Iteration 34600 - Batch 727/1613 - Train loss: 1.038340843477092, Train acc: 0.8654275412087912\n",
      "Iteration 34700 - Batch 827/1613 - Train loss: 1.039463267594144, Train acc: 0.8643568840579711\n",
      "Iteration 34800 - Batch 927/1613 - Train loss: 1.0379667295592612, Train acc: 0.8659752155172413\n",
      "Iteration 34900 - Batch 1027/1613 - Train loss: 1.0383707000239815, Train acc: 0.8656675583657587\n",
      "Iteration 35000 - Batch 1127/1613 - Train loss: 1.0391653148417777, Train acc: 0.8648603723404256\n",
      "Iteration 35100 - Batch 1227/1613 - Train loss: 1.0396568623738491, Train acc: 0.8641083061889251\n",
      "Iteration 35200 - Batch 1327/1613 - Train loss: 1.0392763258283397, Train acc: 0.8645284262048193\n",
      "Iteration 35300 - Batch 1427/1613 - Train loss: 1.0394146745027948, Train acc: 0.8643426120448179\n",
      "Iteration 35400 - Batch 1527/1613 - Train loss: 1.039254234489346, Train acc: 0.8644674410994765\n",
      "[1, 3, 2, 4, 3, 4, 4, 3, 4, 0, 4, 4, 0, 4, 0, 3, 3, 4, 4, 0, 1, 4, 1, 0, 3, 2, 0, 0, 2, 1, 4, 1, 2, 2, 3, 4, 2, 1, 1, 0, 3, 2, 1, 4, 1, 2, 0, 1, 0, 1, 1, 2, 1, 0, 1, 4, 4, 1, 1, 2, 0, 1, 3, 1, 3, 1, 2, 0, 4, 0, 1, 0, 3, 0, 4, 3, 3, 2, 4, 0, 2, 4, 2, 1, 3, 0, 2, 2, 0, 2, 2, 1, 4, 3, 3, 4, 1, 2, 2, 0, 4, 4, 3, 4, 2, 0, 1, 2, 2, 1, 1, 2, 0, 3, 4, 2, 3, 1, 2, 0, 0, 0, 4, 4, 2, 1, 2, 0, 3, 4, 3, 2, 3, 2, 2, 1, 4, 0, 1, 3, 4, 0, 3, 1, 2, 3, 4, 3, 4, 3, 3, 0, 3, 3, 0, 0, 4, 3, 0, 1, 1, 2, 4, 1, 3, 3, 2, 0, 0, 3, 1, 1, 4, 2, 0, 0, 2, 3, 4, 3, 0, 0, 2, 2, 2, 1, 0, 2, 1, 2, 2, 4, 3, 3, 2, 0, 0, 4, 2, 4, 2, 2, 3, 1, 4, 0, 0, 3, 0, 1, 2, 0, 2, 1, 4, 4, 3, 3, 3, 0, 2, 0, 1, 2, 0, 2, 4, 3, 0, 1, 4, 1, 2, 3, 4, 2, 4, 3, 4, 0, 4, 2, 3, 0, 1, 3, 3, 3, 3, 1, 2, 3, 0, 3, 1, 2, 2, 4, 1, 0, 4, 4, 0, 4, 4, 4, 4, 2, 1, 1, 2, 1, 4, 2, 0, 1, 0, 3, 2, 3, 0, 3, 4, 4, 4, 1, 2, 3, 4, 3, 1, 0, 1, 3, 0, 3, 4, 0, 3, 2, 1, 3, 1, 3, 2, 0, 2, 4, 4, 1, 0, 0, 2, 2, 3, 0, 3, 4, 1, 2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 3, 4, 1, 4, 0, 3, 1, 4, 1, 3, 1, 0, 0, 2, 3, 3, 3, 3, 3, 3, 4, 3, 4, 0, 3, 0, 1, 0, 3, 4, 2, 2, 4, 1, 1, 4, 0, 3, 1, 2, 2, 0, 2, 3, 1, 4, 0, 3, 2, 1, 3, 4, 2, 1, 0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 4, 3, 0, 2, 3, 0, 3, 2, 0, 2, 3, 2, 1, 3, 0, 2, 1, 4, 2, 1, 3, 4, 3, 4, 4, 0, 4, 1, 0, 0, 0, 1, 4, 3, 0, 0, 0, 1, 1, 0, 4, 4, 4, 2, 1, 4, 4, 2, 4, 1, 4, 0, 0, 2, 4, 0, 1, 0, 1, 4, 3, 2, 3, 4, 0, 2, 2, 1, 4, 1, 2, 3, 3, 4, 4, 2, 3, 2, 0, 4, 0, 2, 0, 0, 3, 2, 4, 3, 0, 1, 1, 4, 1, 1, 3, 0, 3, 0, 3, 4, 1, 3, 1, 4, 4, 1]\n",
      "[4, 3, 2, 3, 3, 4, 4, 3, 4, 0, 4, 4, 0, 3, 0, 3, 3, 4, 4, 0, 4, 4, 4, 0, 3, 2, 0, 4, 2, 4, 4, 4, 2, 2, 3, 4, 2, 4, 4, 0, 3, 2, 0, 3, 4, 2, 2, 0, 0, 4, 4, 2, 4, 0, 0, 4, 4, 4, 0, 2, 0, 2, 4, 4, 3, 4, 2, 0, 4, 0, 4, 0, 3, 0, 4, 3, 3, 2, 4, 0, 2, 4, 2, 4, 3, 0, 0, 2, 0, 2, 2, 3, 4, 3, 3, 4, 3, 2, 2, 0, 4, 4, 3, 4, 0, 0, 4, 2, 2, 4, 4, 2, 0, 3, 4, 2, 3, 0, 2, 0, 0, 0, 4, 4, 2, 4, 2, 2, 3, 4, 3, 4, 3, 2, 2, 4, 4, 0, 4, 3, 4, 0, 3, 3, 2, 2, 4, 3, 4, 3, 3, 0, 3, 3, 0, 0, 4, 3, 0, 3, 3, 2, 3, 3, 3, 3, 0, 0, 2, 3, 4, 3, 4, 2, 0, 0, 2, 3, 4, 4, 0, 0, 2, 2, 2, 0, 0, 2, 3, 2, 0, 4, 4, 3, 0, 0, 0, 4, 2, 4, 2, 0, 3, 3, 4, 0, 0, 3, 0, 4, 0, 0, 0, 4, 4, 4, 3, 3, 3, 2, 2, 4, 4, 0, 0, 2, 4, 3, 0, 4, 4, 3, 2, 3, 3, 2, 4, 2, 2, 0, 4, 0, 3, 0, 2, 3, 3, 3, 3, 2, 2, 3, 0, 3, 3, 2, 2, 4, 2, 0, 4, 4, 0, 4, 0, 4, 4, 2, 4, 4, 0, 0, 4, 2, 0, 4, 0, 3, 2, 3, 0, 3, 4, 4, 4, 3, 2, 3, 4, 3, 4, 0, 0, 3, 0, 3, 4, 0, 3, 2, 3, 3, 0, 3, 2, 0, 0, 4, 4, 2, 0, 2, 2, 2, 3, 0, 3, 4, 0, 2, 4, 2, 0, 2, 2, 3, 4, 4, 2, 2, 3, 4, 3, 4, 0, 3, 4, 4, 4, 3, 4, 0, 0, 2, 4, 3, 3, 3, 3, 3, 4, 3, 4, 0, 3, 0, 4, 0, 3, 4, 2, 2, 4, 3, 4, 4, 0, 3, 0, 2, 2, 0, 2, 3, 4, 4, 0, 3, 4, 3, 3, 4, 2, 3, 0, 2, 3, 2, 0, 4, 0, 3, 2, 0, 4, 3, 0, 2, 3, 0, 3, 0, 0, 2, 3, 2, 4, 3, 0, 0, 3, 4, 2, 4, 3, 4, 3, 4, 4, 0, 4, 4, 0, 0, 0, 3, 4, 3, 2, 0, 0, 2, 4, 0, 4, 4, 4, 2, 3, 4, 2, 0, 4, 0, 4, 0, 0, 3, 4, 0, 0, 0, 0, 2, 4, 2, 3, 4, 0, 2, 2, 3, 3, 4, 2, 2, 3, 4, 4, 2, 3, 2, 0, 4, 0, 2, 0, 0, 3, 2, 4, 3, 0, 4, 2, 4, 4, 4, 3, 0, 3, 0, 3, 4, 0, 3, 2, 4, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.80      0.82      0.81       100\n",
      "           3       0.75      0.92      0.83       100\n",
      "           4       0.61      0.90      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1901419907808304, Val acc: 0.712\n",
      "Epoch 23/30\n",
      "Iteration 35500 - Batch 14/1613 - Train loss: 1.0229538957277933, Train acc: 0.88125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35600 - Batch 114/1613 - Train loss: 1.0382754813069883, Train acc: 0.8654891304347826\n",
      "Iteration 35700 - Batch 214/1613 - Train loss: 1.0397905474485354, Train acc: 0.8636627906976744\n",
      "Iteration 35800 - Batch 314/1613 - Train loss: 1.0387930820858668, Train acc: 0.8645833333333334\n",
      "Iteration 35900 - Batch 414/1613 - Train loss: 1.0377803299800459, Train acc: 0.8659638554216867\n",
      "Iteration 36000 - Batch 514/1613 - Train loss: 1.0362789924862315, Train acc: 0.8672330097087378\n",
      "Iteration 36100 - Batch 614/1613 - Train loss: 1.0355124553044637, Train acc: 0.8682418699186992\n",
      "Iteration 36200 - Batch 714/1613 - Train loss: 1.0351139538771623, Train acc: 0.8686625874125874\n",
      "Iteration 36300 - Batch 814/1613 - Train loss: 1.0348667375149172, Train acc: 0.8689800613496933\n",
      "Iteration 36400 - Batch 914/1613 - Train loss: 1.0360274770872189, Train acc: 0.8678620218579235\n",
      "Iteration 36500 - Batch 1014/1613 - Train loss: 1.0368678230957444, Train acc: 0.867179802955665\n",
      "Iteration 36600 - Batch 1114/1613 - Train loss: 1.0379164018438536, Train acc: 0.8660033632286995\n",
      "Iteration 36700 - Batch 1214/1613 - Train loss: 1.0379937834209867, Train acc: 0.8660751028806585\n",
      "Iteration 36800 - Batch 1314/1613 - Train loss: 1.0374845779893969, Train acc: 0.8666349809885932\n",
      "Iteration 36900 - Batch 1414/1613 - Train loss: 1.0376290096411014, Train acc: 0.8664090106007067\n",
      "Iteration 37000 - Batch 1514/1613 - Train loss: 1.037700389478073, Train acc: 0.8663366336633663\n",
      "[0, 4, 2, 1, 1, 4, 2, 3, 3, 2, 2, 1, 2, 3, 3, 3, 4, 3, 2, 4, 1, 1, 0, 4, 4, 2, 1, 4, 2, 0, 4, 0, 3, 0, 0, 3, 0, 3, 0, 3, 1, 0, 3, 2, 1, 4, 2, 0, 4, 1, 3, 0, 4, 1, 2, 4, 0, 4, 0, 1, 2, 0, 4, 4, 0, 4, 3, 0, 0, 0, 1, 3, 1, 1, 4, 3, 0, 4, 1, 4, 2, 2, 2, 0, 4, 2, 3, 4, 0, 4, 1, 3, 1, 4, 3, 3, 1, 0, 3, 1, 1, 0, 0, 3, 4, 1, 1, 2, 4, 3, 2, 1, 4, 4, 4, 4, 1, 3, 0, 4, 2, 4, 0, 1, 3, 2, 3, 4, 1, 3, 0, 4, 0, 4, 2, 3, 0, 1, 2, 1, 3, 1, 1, 0, 4, 0, 3, 1, 3, 2, 4, 4, 4, 2, 3, 0, 4, 0, 1, 3, 4, 1, 4, 2, 3, 0, 4, 3, 1, 2, 0, 3, 1, 2, 1, 3, 0, 3, 1, 0, 1, 3, 2, 2, 2, 3, 3, 0, 2, 0, 4, 2, 0, 2, 1, 1, 0, 0, 2, 3, 3, 2, 2, 2, 4, 2, 2, 2, 1, 3, 1, 3, 3, 2, 2, 1, 0, 0, 1, 0, 2, 0, 1, 0, 3, 3, 1, 2, 3, 3, 4, 4, 1, 2, 1, 3, 0, 4, 3, 0, 1, 1, 4, 0, 3, 0, 3, 4, 3, 1, 0, 3, 2, 1, 4, 3, 1, 4, 2, 4, 0, 3, 0, 0, 1, 2, 1, 4, 1, 4, 2, 3, 1, 2, 4, 1, 0, 3, 2, 3, 0, 3, 2, 2, 0, 4, 4, 3, 0, 4, 0, 4, 4, 2, 4, 1, 0, 0, 1, 3, 2, 0, 1, 2, 1, 0, 3, 4, 3, 3, 2, 0, 4, 2, 4, 0, 3, 3, 4, 3, 4, 1, 2, 3, 3, 2, 4, 4, 1, 1, 2, 0, 0, 3, 0, 4, 4, 2, 2, 0, 1, 1, 3, 2, 2, 2, 0, 1, 4, 1, 0, 2, 3, 1, 1, 3, 1, 3, 3, 2, 1, 0, 3, 3, 1, 0, 1, 2, 3, 4, 0, 0, 1, 0, 2, 4, 3, 0, 4, 0, 0, 3, 2, 0, 4, 1, 3, 3, 0, 2, 3, 0, 1, 1, 0, 0, 1, 0, 3, 3, 0, 4, 4, 1, 4, 4, 0, 3, 3, 1, 1, 2, 1, 3, 4, 0, 2, 1, 1, 2, 2, 1, 3, 0, 1, 3, 3, 0, 2, 2, 1, 1, 2, 4, 4, 0, 2, 2, 2, 2, 2, 4, 2, 3, 0, 2, 4, 1, 1, 3, 0, 4, 3, 4, 3, 4, 1, 0, 2, 4, 1, 4, 2, 4, 2, 4, 1, 4, 0, 0, 4, 4, 0, 2, 2, 4, 1, 1, 4, 2, 3, 2, 2, 2, 4, 1, 0, 1, 2, 4, 3, 4, 1, 0, 2, 2, 2, 3, 2, 4]\n",
      "[0, 4, 2, 3, 4, 4, 2, 3, 3, 2, 2, 4, 2, 3, 3, 3, 4, 4, 0, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 0, 3, 0, 3, 0, 0, 3, 0, 3, 0, 3, 4, 0, 3, 2, 0, 4, 2, 0, 4, 4, 3, 0, 4, 0, 2, 4, 0, 4, 0, 3, 2, 0, 4, 4, 0, 4, 3, 0, 0, 2, 4, 2, 4, 4, 4, 3, 0, 4, 4, 4, 2, 2, 0, 0, 4, 2, 3, 4, 0, 4, 4, 3, 0, 4, 3, 3, 3, 0, 3, 3, 3, 0, 0, 3, 0, 0, 4, 2, 4, 3, 2, 3, 4, 4, 4, 4, 4, 3, 0, 4, 2, 4, 0, 3, 3, 2, 3, 4, 3, 3, 0, 4, 0, 4, 2, 4, 4, 0, 2, 4, 3, 4, 2, 0, 4, 0, 3, 0, 2, 2, 4, 4, 4, 2, 4, 0, 3, 0, 4, 3, 4, 3, 4, 2, 3, 0, 4, 3, 0, 2, 0, 3, 4, 2, 4, 3, 0, 3, 3, 0, 4, 3, 2, 2, 2, 3, 3, 0, 0, 0, 4, 2, 0, 2, 2, 4, 0, 0, 0, 3, 3, 2, 2, 2, 4, 0, 2, 0, 0, 4, 4, 3, 3, 2, 2, 4, 0, 0, 4, 0, 2, 3, 4, 0, 3, 3, 4, 2, 3, 3, 4, 4, 4, 2, 4, 3, 0, 4, 3, 2, 0, 3, 4, 0, 3, 0, 3, 4, 3, 0, 0, 3, 2, 4, 4, 3, 0, 4, 2, 4, 0, 3, 0, 0, 4, 2, 4, 4, 0, 2, 0, 3, 0, 2, 4, 0, 0, 0, 2, 3, 0, 3, 2, 2, 0, 2, 3, 3, 0, 4, 0, 4, 4, 2, 4, 4, 0, 0, 0, 3, 2, 0, 0, 2, 4, 0, 3, 4, 3, 3, 2, 0, 4, 0, 3, 0, 3, 3, 4, 3, 4, 4, 0, 3, 3, 2, 4, 4, 4, 3, 2, 0, 0, 3, 0, 4, 4, 2, 2, 0, 4, 3, 3, 0, 2, 2, 0, 4, 4, 3, 0, 2, 3, 3, 3, 3, 4, 3, 3, 0, 4, 0, 3, 4, 4, 0, 4, 0, 3, 4, 0, 0, 4, 0, 2, 4, 3, 0, 4, 0, 0, 3, 2, 0, 4, 2, 3, 3, 0, 2, 3, 0, 4, 3, 0, 0, 3, 0, 4, 3, 0, 4, 4, 4, 4, 4, 0, 3, 3, 4, 4, 2, 3, 3, 4, 0, 2, 3, 3, 2, 2, 3, 3, 0, 0, 3, 3, 0, 2, 2, 3, 4, 2, 4, 4, 0, 2, 2, 2, 2, 2, 4, 2, 3, 0, 2, 4, 4, 3, 3, 0, 4, 3, 4, 3, 3, 2, 0, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 0, 0, 4, 4, 0, 0, 2, 4, 3, 0, 3, 0, 3, 2, 2, 2, 4, 4, 0, 4, 2, 4, 3, 4, 4, 0, 2, 0, 2, 3, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.84      0.86       100\n",
      "           3       0.74      0.91      0.82       100\n",
      "           4       0.60      0.90      0.72       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.65       500\n",
      "weighted avg       0.59      0.72      0.65       500\n",
      "\n",
      "Val loss: 1.182951308786869, Val acc: 0.722\n",
      "Epoch 24/30\n",
      "Iteration 37100 - Batch 1/1613 - Train loss: 1.0323706269264221, Train acc: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37200 - Batch 101/1613 - Train loss: 1.0468471909270567, Train acc: 0.8572303921568627\n",
      "Iteration 37300 - Batch 201/1613 - Train loss: 1.0399536449130218, Train acc: 0.8638613861386139\n",
      "Iteration 37400 - Batch 301/1613 - Train loss: 1.0384804300519803, Train acc: 0.8652731788079471\n",
      "Iteration 37500 - Batch 401/1613 - Train loss: 1.0373071261602849, Train acc: 0.8666044776119403\n",
      "Iteration 37600 - Batch 501/1613 - Train loss: 1.0376615766510071, Train acc: 0.866222609561753\n",
      "Iteration 37700 - Batch 601/1613 - Train loss: 1.0385294572459502, Train acc: 0.8651889534883721\n",
      "Iteration 37800 - Batch 701/1613 - Train loss: 1.040045862948453, Train acc: 0.8637820512820513\n",
      "Iteration 37900 - Batch 801/1613 - Train loss: 1.039810510050329, Train acc: 0.8641677057356608\n",
      "Iteration 38000 - Batch 901/1613 - Train loss: 1.0406674687191018, Train acc: 0.8632206208425721\n",
      "Iteration 38100 - Batch 1001/1613 - Train loss: 1.0394723232753738, Train acc: 0.8645209580838323\n",
      "Iteration 38200 - Batch 1101/1613 - Train loss: 1.0386370972150467, Train acc: 0.8655002268602541\n",
      "Iteration 38300 - Batch 1201/1613 - Train loss: 1.0384099525639698, Train acc: 0.8656405990016639\n",
      "Iteration 38400 - Batch 1301/1613 - Train loss: 1.0384728437927644, Train acc: 0.8656153993855606\n",
      "Iteration 38500 - Batch 1401/1613 - Train loss: 1.0390694651981223, Train acc: 0.864902817403709\n",
      "Iteration 38600 - Batch 1501/1613 - Train loss: 1.038623981405987, Train acc: 0.8653462050599201\n",
      "Iteration 38700 - Batch 1601/1613 - Train loss: 1.0380399283696053, Train acc: 0.8659878277153558\n",
      "[3, 3, 2, 1, 3, 0, 3, 0, 0, 2, 0, 3, 4, 4, 3, 2, 0, 3, 4, 3, 2, 1, 2, 1, 2, 0, 2, 3, 1, 4, 2, 3, 3, 2, 0, 3, 0, 2, 2, 0, 3, 3, 0, 1, 1, 1, 3, 0, 3, 1, 0, 2, 0, 3, 1, 2, 4, 1, 2, 2, 4, 2, 2, 4, 3, 1, 0, 0, 1, 2, 1, 2, 1, 4, 2, 3, 2, 2, 0, 2, 0, 1, 1, 0, 3, 4, 0, 1, 2, 1, 4, 0, 3, 1, 2, 3, 1, 0, 4, 0, 0, 3, 4, 4, 1, 0, 3, 2, 0, 1, 3, 1, 4, 1, 3, 0, 3, 3, 4, 2, 4, 3, 0, 1, 0, 0, 4, 4, 4, 1, 2, 1, 0, 4, 0, 3, 1, 4, 2, 2, 3, 3, 4, 2, 4, 2, 0, 3, 0, 3, 1, 3, 1, 1, 0, 2, 1, 2, 4, 0, 0, 2, 3, 4, 2, 0, 0, 1, 0, 1, 0, 3, 1, 2, 2, 3, 4, 0, 0, 1, 4, 2, 4, 1, 1, 4, 3, 4, 3, 3, 3, 0, 3, 3, 3, 1, 0, 3, 1, 3, 0, 4, 0, 2, 1, 1, 2, 0, 4, 1, 1, 2, 3, 2, 2, 0, 0, 4, 1, 0, 3, 0, 4, 3, 3, 1, 0, 4, 4, 4, 3, 3, 2, 4, 4, 4, 2, 2, 1, 3, 3, 4, 4, 0, 4, 2, 4, 4, 1, 1, 1, 0, 4, 0, 1, 4, 0, 4, 4, 2, 0, 2, 4, 4, 3, 3, 0, 1, 3, 2, 3, 4, 0, 0, 1, 0, 1, 3, 4, 1, 2, 1, 4, 0, 2, 1, 2, 3, 1, 0, 4, 1, 3, 4, 0, 4, 4, 3, 2, 4, 4, 3, 0, 3, 1, 4, 3, 1, 4, 0, 0, 2, 2, 1, 4, 2, 1, 4, 1, 1, 0, 2, 4, 3, 1, 2, 0, 3, 4, 1, 1, 0, 4, 0, 0, 2, 3, 1, 2, 2, 4, 3, 0, 2, 3, 1, 4, 3, 2, 1, 2, 1, 2, 1, 3, 3, 3, 0, 4, 2, 0, 0, 2, 2, 4, 0, 3, 2, 4, 4, 3, 3, 2, 1, 0, 1, 3, 1, 2, 1, 4, 1, 3, 2, 1, 4, 3, 2, 3, 1, 3, 0, 0, 2, 2, 2, 1, 4, 4, 3, 2, 3, 3, 3, 4, 4, 1, 0, 3, 1, 4, 2, 0, 1, 3, 1, 1, 2, 4, 0, 4, 4, 0, 1, 4, 1, 4, 1, 2, 4, 2, 4, 4, 3, 0, 1, 2, 0, 0, 2, 1, 3, 2, 0, 2, 0, 3, 4, 1, 2, 0, 3, 4, 2, 2, 0, 0, 0, 0, 0, 2, 4, 1, 2, 4, 3, 2, 3, 0, 0, 4, 1, 1, 4, 0, 4, 4, 3, 3, 1, 2, 1, 4, 3, 2, 0, 2, 4, 4, 2, 2, 1, 0, 2, 1, 2, 4, 3, 1, 3]\n",
      "[3, 3, 2, 0, 3, 0, 3, 0, 0, 0, 0, 3, 2, 4, 3, 2, 0, 3, 4, 3, 2, 4, 0, 3, 2, 0, 2, 3, 0, 4, 2, 3, 3, 2, 0, 4, 0, 0, 2, 0, 3, 3, 0, 4, 3, 4, 3, 0, 3, 3, 0, 0, 0, 3, 3, 2, 4, 4, 2, 0, 3, 2, 2, 3, 3, 0, 0, 0, 4, 2, 4, 0, 4, 4, 2, 3, 0, 2, 0, 2, 0, 3, 3, 0, 3, 0, 4, 0, 2, 4, 4, 0, 3, 3, 2, 3, 4, 4, 4, 0, 0, 3, 4, 4, 4, 0, 3, 2, 0, 4, 3, 4, 4, 4, 3, 0, 3, 3, 4, 4, 4, 4, 0, 0, 0, 0, 4, 4, 3, 4, 2, 0, 0, 4, 0, 3, 3, 4, 2, 0, 4, 3, 4, 2, 2, 2, 3, 3, 0, 3, 4, 3, 4, 2, 0, 2, 0, 2, 0, 0, 0, 2, 3, 4, 2, 0, 0, 3, 0, 0, 2, 3, 0, 2, 0, 3, 4, 0, 0, 0, 4, 2, 4, 3, 4, 4, 3, 4, 3, 3, 2, 0, 3, 3, 3, 0, 0, 3, 4, 3, 0, 4, 0, 2, 4, 2, 2, 0, 4, 4, 0, 2, 3, 2, 2, 0, 0, 4, 4, 0, 3, 0, 4, 4, 3, 3, 0, 4, 4, 4, 3, 3, 2, 4, 4, 4, 2, 2, 4, 3, 3, 4, 4, 0, 4, 0, 4, 4, 4, 3, 4, 0, 4, 0, 4, 4, 0, 4, 4, 2, 0, 2, 4, 4, 3, 3, 0, 4, 3, 2, 3, 4, 0, 0, 4, 0, 0, 3, 4, 4, 0, 4, 4, 0, 2, 3, 2, 3, 4, 0, 4, 3, 3, 3, 0, 4, 4, 3, 2, 4, 4, 3, 4, 3, 4, 4, 3, 0, 4, 0, 3, 2, 2, 3, 4, 0, 3, 4, 2, 4, 0, 0, 4, 3, 0, 2, 0, 0, 4, 3, 3, 0, 4, 0, 0, 2, 3, 4, 0, 2, 4, 3, 0, 2, 4, 4, 4, 3, 2, 4, 2, 4, 2, 2, 3, 3, 3, 0, 4, 2, 0, 0, 2, 2, 4, 0, 3, 2, 4, 4, 3, 3, 2, 3, 0, 3, 3, 4, 2, 4, 4, 4, 3, 2, 0, 4, 0, 0, 3, 4, 3, 0, 0, 0, 2, 2, 0, 4, 4, 4, 2, 3, 3, 3, 4, 4, 4, 0, 3, 0, 4, 2, 0, 0, 4, 4, 4, 0, 4, 0, 4, 4, 0, 3, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 0, 4, 2, 0, 0, 2, 3, 3, 2, 0, 2, 0, 3, 4, 0, 0, 0, 3, 4, 2, 2, 0, 0, 0, 0, 0, 0, 3, 3, 2, 4, 3, 2, 3, 0, 0, 4, 3, 4, 4, 0, 4, 4, 3, 3, 2, 2, 4, 3, 4, 2, 0, 2, 4, 4, 2, 0, 0, 0, 0, 3, 2, 4, 3, 4, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.94      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.78      0.83       100\n",
      "           3       0.73      0.88      0.80       100\n",
      "           4       0.59      0.90      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2045245990157127, Val acc: 0.7\n",
      "Epoch 25/30\n",
      "Iteration 38800 - Batch 88/1613 - Train loss: 1.0290203837866194, Train acc: 0.875\n",
      "Iteration 38900 - Batch 188/1613 - Train loss: 1.026400574931392, Train acc: 0.8781415343915344\n",
      "Iteration 39000 - Batch 288/1613 - Train loss: 1.0302267544822297, Train acc: 0.8740268166089965\n",
      "Iteration 39100 - Batch 388/1613 - Train loss: 1.031566593058618, Train acc: 0.8724293059125964\n",
      "Iteration 39200 - Batch 488/1613 - Train loss: 1.0319835091417309, Train acc: 0.8721881390593047\n",
      "Iteration 39300 - Batch 588/1613 - Train loss: 1.032023367938445, Train acc: 0.8721880305602716\n",
      "Iteration 39400 - Batch 688/1613 - Train loss: 1.0338329025726707, Train acc: 0.8703737300435413\n",
      "Iteration 39500 - Batch 788/1613 - Train loss: 1.0338575455474612, Train acc: 0.8702867553865653\n",
      "Iteration 39600 - Batch 888/1613 - Train loss: 1.0334469089357872, Train acc: 0.8706411698537683\n",
      "Iteration 39700 - Batch 988/1613 - Train loss: 1.033401517884917, Train acc: 0.8707659251769464\n",
      "Iteration 39800 - Batch 1088/1613 - Train loss: 1.0338398513167795, Train acc: 0.8703799357208448\n",
      "Iteration 39900 - Batch 1188/1613 - Train loss: 1.034388716026351, Train acc: 0.8697697645079899\n",
      "Iteration 40000 - Batch 1288/1613 - Train loss: 1.035030821018944, Train acc: 0.869133048875097\n",
      "Iteration 40100 - Batch 1388/1613 - Train loss: 1.0357809271891396, Train acc: 0.8683180345572354\n",
      "Iteration 40200 - Batch 1488/1613 - Train loss: 1.035761771544744, Train acc: 0.8682211215580927\n",
      "Iteration 40300 - Batch 1588/1613 - Train loss: 1.03592994087068, Train acc: 0.8680577407174324\n",
      "[4, 3, 4, 4, 4, 0, 0, 4, 4, 3, 2, 0, 3, 4, 0, 3, 3, 0, 4, 2, 4, 4, 2, 2, 4, 1, 2, 1, 1, 2, 2, 4, 2, 3, 4, 2, 0, 0, 1, 3, 4, 1, 3, 2, 2, 0, 0, 1, 1, 1, 4, 0, 3, 4, 1, 1, 3, 3, 2, 3, 4, 2, 4, 4, 1, 3, 3, 0, 0, 2, 3, 0, 0, 2, 0, 0, 1, 4, 2, 3, 3, 1, 0, 1, 3, 0, 1, 0, 3, 3, 2, 4, 2, 1, 3, 4, 1, 1, 1, 4, 4, 4, 4, 4, 0, 2, 4, 2, 0, 3, 2, 2, 2, 2, 1, 4, 3, 3, 2, 0, 2, 1, 0, 4, 3, 3, 2, 4, 2, 0, 2, 1, 1, 1, 4, 3, 0, 0, 4, 1, 1, 1, 3, 0, 3, 1, 4, 0, 1, 4, 4, 0, 3, 0, 4, 1, 1, 0, 4, 3, 0, 4, 1, 4, 1, 1, 2, 3, 2, 3, 3, 3, 3, 2, 0, 3, 2, 0, 3, 2, 0, 0, 4, 4, 3, 2, 2, 3, 1, 2, 4, 3, 1, 3, 3, 1, 0, 3, 0, 3, 0, 0, 4, 2, 1, 2, 1, 3, 1, 1, 4, 3, 4, 4, 2, 0, 3, 4, 4, 4, 4, 1, 4, 1, 0, 0, 2, 3, 2, 1, 1, 1, 4, 0, 2, 1, 3, 2, 3, 2, 4, 1, 2, 2, 2, 2, 0, 0, 0, 1, 1, 3, 0, 1, 3, 2, 3, 1, 3, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 4, 2, 4, 3, 4, 4, 0, 4, 0, 4, 0, 0, 2, 1, 3, 3, 4, 1, 0, 1, 0, 3, 0, 0, 3, 3, 3, 2, 2, 2, 0, 1, 2, 2, 1, 1, 0, 3, 0, 0, 2, 0, 0, 1, 1, 3, 1, 3, 0, 1, 4, 2, 3, 4, 4, 3, 2, 3, 1, 3, 0, 0, 0, 1, 0, 4, 2, 3, 1, 3, 0, 3, 0, 3, 3, 0, 4, 1, 3, 3, 2, 3, 3, 4, 1, 3, 2, 0, 3, 2, 3, 2, 2, 3, 1, 2, 1, 0, 4, 2, 4, 3, 3, 0, 0, 2, 2, 3, 2, 1, 0, 2, 4, 4, 3, 2, 1, 4, 2, 1, 3, 1, 4, 2, 0, 4, 4, 1, 0, 2, 3, 1, 4, 4, 4, 0, 4, 2, 2, 3, 2, 2, 2, 2, 1, 3, 4, 1, 4, 1, 0, 3, 1, 2, 4, 4, 1, 4, 2, 0, 0, 4, 1, 4, 2, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 0, 0, 4, 2, 1, 3, 0, 4, 2, 3, 0, 1, 1, 0, 4, 2, 0, 3, 4, 0, 1, 4, 4, 0, 0, 4, 3, 0, 2, 2, 4, 1, 2, 3, 0, 4, 0, 0, 2, 3, 4, 3, 4, 0, 1, 4, 1, 1, 1, 1, 3, 4, 0, 3, 0, 4]\n",
      "[4, 3, 4, 4, 4, 0, 3, 4, 4, 3, 0, 0, 3, 4, 0, 4, 3, 0, 4, 2, 4, 4, 2, 2, 4, 3, 2, 4, 4, 2, 0, 4, 2, 3, 4, 2, 0, 0, 0, 3, 4, 4, 3, 2, 3, 0, 0, 0, 3, 2, 4, 0, 3, 3, 0, 2, 3, 3, 0, 3, 4, 2, 4, 4, 4, 4, 3, 0, 0, 2, 3, 0, 0, 2, 0, 0, 4, 4, 2, 0, 3, 3, 0, 4, 3, 0, 4, 0, 3, 4, 0, 4, 2, 4, 3, 4, 4, 3, 2, 4, 4, 4, 4, 4, 0, 2, 4, 2, 0, 3, 0, 2, 2, 3, 0, 4, 3, 3, 2, 0, 2, 4, 4, 4, 3, 3, 2, 4, 2, 0, 2, 4, 4, 4, 4, 3, 0, 0, 4, 4, 0, 0, 3, 0, 3, 4, 4, 0, 4, 4, 4, 2, 2, 0, 4, 3, 3, 0, 0, 3, 0, 4, 0, 4, 3, 4, 2, 3, 2, 3, 3, 3, 3, 2, 0, 3, 2, 0, 3, 2, 0, 0, 4, 4, 3, 2, 2, 3, 0, 2, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 0, 0, 4, 2, 0, 2, 4, 3, 3, 4, 4, 3, 0, 4, 2, 0, 3, 4, 4, 4, 4, 3, 4, 4, 0, 0, 2, 3, 2, 4, 4, 4, 4, 0, 2, 3, 3, 2, 3, 0, 4, 3, 2, 2, 2, 2, 0, 0, 0, 4, 4, 3, 0, 3, 3, 2, 3, 4, 4, 0, 4, 0, 3, 2, 2, 0, 4, 0, 2, 3, 2, 4, 3, 4, 4, 2, 4, 0, 4, 0, 0, 2, 0, 3, 3, 4, 3, 0, 4, 4, 3, 0, 0, 4, 3, 3, 2, 2, 2, 0, 4, 0, 2, 4, 4, 0, 3, 0, 0, 2, 0, 0, 3, 4, 3, 4, 3, 2, 4, 0, 2, 3, 4, 4, 3, 2, 3, 4, 3, 0, 0, 0, 0, 0, 4, 0, 3, 4, 3, 0, 3, 0, 3, 3, 0, 4, 3, 3, 3, 0, 3, 3, 3, 0, 3, 2, 0, 3, 2, 3, 0, 2, 3, 4, 2, 4, 2, 4, 2, 4, 3, 3, 0, 0, 2, 2, 3, 2, 4, 0, 2, 4, 4, 4, 2, 0, 4, 2, 3, 3, 4, 4, 0, 0, 4, 4, 3, 0, 2, 3, 4, 4, 4, 4, 0, 4, 2, 2, 3, 2, 2, 2, 2, 4, 3, 2, 4, 4, 3, 0, 3, 4, 2, 4, 4, 0, 3, 2, 0, 0, 4, 3, 4, 2, 2, 2, 2, 3, 2, 4, 4, 0, 0, 2, 0, 0, 4, 2, 2, 3, 0, 4, 2, 3, 0, 3, 0, 0, 4, 2, 0, 3, 4, 0, 4, 4, 4, 0, 0, 4, 3, 0, 0, 2, 4, 4, 0, 3, 0, 2, 0, 0, 2, 4, 4, 3, 4, 0, 4, 4, 0, 4, 0, 4, 3, 4, 0, 4, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.84      0.86       100\n",
      "           3       0.74      0.90      0.81       100\n",
      "           4       0.59      0.90      0.71       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.64       500\n",
      "weighted avg       0.58      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1919203028082848, Val acc: 0.714\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40400 - Batch 75/1613 - Train loss: 1.027662799546593, Train acc: 0.8758223684210527\n",
      "Iteration 40500 - Batch 175/1613 - Train loss: 1.0315243422307752, Train acc: 0.8718039772727273\n",
      "Iteration 40600 - Batch 275/1613 - Train loss: 1.0360937638991121, Train acc: 0.8673007246376812\n",
      "Iteration 40700 - Batch 375/1613 - Train loss: 1.0336367755811264, Train acc: 0.8700132978723404\n",
      "Iteration 40800 - Batch 475/1613 - Train loss: 1.0354211177645611, Train acc: 0.8684348739495799\n",
      "Iteration 40900 - Batch 575/1613 - Train loss: 1.0362228038203385, Train acc: 0.86767578125\n",
      "Iteration 41000 - Batch 675/1613 - Train loss: 1.0360400538296388, Train acc: 0.8679271449704142\n",
      "Iteration 41100 - Batch 775/1613 - Train loss: 1.0356254841095394, Train acc: 0.8685567010309279\n",
      "Iteration 41200 - Batch 875/1613 - Train loss: 1.0349585507830528, Train acc: 0.8692922374429224\n",
      "Iteration 41300 - Batch 975/1613 - Train loss: 1.0348021336754814, Train acc: 0.8694928278688525\n",
      "Iteration 41400 - Batch 1075/1613 - Train loss: 1.0346679811584019, Train acc: 0.8695690055762082\n",
      "Iteration 41500 - Batch 1175/1613 - Train loss: 1.034068909074579, Train acc: 0.8701636904761905\n",
      "Iteration 41600 - Batch 1275/1613 - Train loss: 1.0335655961197372, Train acc: 0.8706161833855799\n",
      "Iteration 41700 - Batch 1375/1613 - Train loss: 1.03394487495859, Train acc: 0.8701626090116279\n",
      "Iteration 41800 - Batch 1475/1613 - Train loss: 1.0340582438843038, Train acc: 0.8699610433604336\n",
      "Iteration 41900 - Batch 1575/1613 - Train loss: 1.0347672289019914, Train acc: 0.8691901967005076\n",
      "[1, 3, 2, 1, 3, 2, 0, 2, 3, 3, 2, 1, 4, 4, 1, 4, 0, 1, 3, 2, 3, 3, 3, 1, 2, 1, 1, 2, 4, 0, 4, 1, 2, 4, 0, 2, 1, 2, 3, 0, 3, 3, 0, 2, 0, 4, 1, 2, 2, 2, 1, 0, 4, 4, 1, 0, 1, 1, 2, 3, 3, 4, 1, 0, 3, 0, 0, 4, 0, 4, 1, 0, 1, 0, 3, 0, 0, 2, 0, 2, 4, 1, 4, 4, 4, 0, 2, 0, 2, 2, 0, 1, 0, 0, 3, 0, 0, 2, 1, 4, 4, 4, 0, 0, 4, 3, 0, 1, 1, 4, 0, 2, 2, 1, 2, 2, 4, 3, 4, 4, 1, 0, 3, 0, 0, 4, 0, 3, 3, 0, 3, 1, 2, 3, 1, 1, 3, 0, 2, 0, 1, 0, 2, 2, 2, 4, 2, 4, 3, 4, 4, 1, 4, 1, 3, 0, 4, 3, 2, 1, 1, 0, 0, 3, 2, 3, 1, 0, 4, 3, 4, 0, 3, 1, 1, 2, 1, 3, 0, 4, 2, 3, 0, 4, 3, 1, 3, 0, 3, 3, 4, 0, 4, 4, 4, 2, 3, 0, 0, 0, 3, 0, 1, 1, 2, 1, 0, 0, 3, 0, 4, 1, 4, 3, 1, 3, 4, 4, 2, 0, 3, 0, 2, 2, 4, 0, 1, 0, 3, 4, 2, 1, 3, 4, 4, 3, 1, 1, 0, 1, 4, 4, 1, 1, 0, 1, 4, 2, 2, 3, 1, 2, 4, 2, 3, 1, 0, 1, 2, 0, 2, 4, 4, 0, 4, 2, 0, 3, 2, 2, 2, 2, 1, 2, 1, 2, 3, 2, 4, 1, 3, 3, 0, 3, 0, 0, 0, 2, 3, 4, 4, 2, 2, 1, 3, 1, 2, 3, 3, 2, 1, 2, 4, 3, 3, 0, 1, 2, 2, 3, 4, 3, 0, 4, 2, 1, 4, 2, 0, 1, 0, 4, 0, 2, 3, 3, 4, 1, 2, 2, 4, 4, 2, 1, 4, 4, 4, 2, 0, 4, 3, 1, 2, 0, 0, 3, 3, 2, 0, 1, 0, 0, 0, 2, 1, 2, 1, 1, 4, 2, 0, 3, 0, 1, 0, 3, 4, 4, 4, 1, 4, 3, 1, 0, 2, 4, 2, 4, 3, 3, 4, 3, 1, 0, 4, 1, 1, 1, 4, 0, 0, 4, 3, 1, 1, 0, 3, 2, 0, 4, 1, 1, 2, 4, 4, 4, 2, 3, 1, 2, 2, 3, 0, 4, 4, 3, 1, 2, 0, 3, 4, 3, 2, 3, 1, 1, 0, 0, 2, 3, 3, 2, 4, 1, 2, 4, 4, 1, 2, 3, 3, 2, 4, 0, 4, 3, 0, 2, 4, 2, 0, 3, 3, 1, 2, 1, 4, 3, 1, 3, 0, 4, 1, 3, 3, 1, 3, 4, 3, 1, 0, 3, 3, 1, 3, 1, 2, 0, 3, 2, 3, 2, 4, 2, 3, 0, 2, 4, 2, 1, 1, 3, 4, 1, 1, 2, 0, 4, 2, 1]\n",
      "[4, 3, 2, 4, 3, 0, 0, 2, 3, 3, 2, 4, 4, 4, 0, 4, 0, 4, 3, 2, 3, 3, 3, 3, 0, 4, 4, 2, 4, 0, 3, 0, 2, 4, 0, 2, 4, 2, 3, 2, 3, 3, 0, 0, 0, 4, 0, 2, 2, 0, 4, 0, 4, 4, 2, 0, 4, 4, 2, 3, 3, 4, 0, 0, 3, 0, 0, 4, 2, 4, 4, 0, 4, 0, 3, 0, 0, 2, 0, 2, 4, 4, 4, 4, 4, 0, 2, 0, 2, 2, 0, 4, 0, 0, 3, 2, 0, 2, 3, 4, 4, 4, 0, 0, 4, 3, 0, 4, 4, 4, 0, 2, 2, 3, 2, 2, 4, 3, 4, 4, 4, 0, 3, 0, 0, 3, 0, 3, 3, 0, 3, 4, 2, 3, 3, 4, 4, 0, 2, 0, 3, 2, 2, 0, 2, 4, 0, 4, 3, 4, 4, 0, 4, 4, 3, 0, 4, 3, 2, 4, 0, 0, 0, 3, 0, 3, 3, 0, 4, 4, 4, 0, 3, 0, 4, 2, 3, 3, 0, 4, 0, 3, 0, 4, 3, 4, 3, 0, 3, 3, 3, 0, 4, 4, 4, 0, 3, 3, 0, 0, 3, 0, 4, 3, 2, 4, 0, 0, 3, 0, 4, 3, 4, 3, 3, 3, 4, 4, 2, 0, 3, 0, 2, 0, 4, 0, 4, 0, 4, 4, 2, 0, 3, 2, 4, 3, 2, 3, 2, 3, 4, 4, 3, 4, 0, 4, 4, 2, 2, 3, 4, 2, 4, 2, 3, 3, 0, 0, 3, 0, 4, 4, 2, 0, 4, 2, 0, 3, 2, 2, 2, 0, 3, 2, 0, 2, 3, 2, 4, 4, 3, 3, 4, 3, 0, 0, 0, 0, 3, 3, 4, 2, 2, 4, 3, 4, 2, 3, 4, 2, 2, 2, 4, 3, 3, 2, 0, 2, 2, 3, 4, 3, 0, 4, 2, 3, 4, 2, 0, 4, 0, 4, 0, 2, 3, 3, 4, 3, 2, 2, 4, 4, 2, 4, 4, 4, 4, 2, 0, 4, 3, 2, 2, 0, 0, 3, 3, 2, 0, 3, 0, 2, 0, 2, 4, 2, 4, 4, 4, 2, 0, 3, 0, 4, 0, 3, 4, 4, 4, 3, 4, 3, 3, 0, 2, 4, 2, 4, 3, 3, 4, 3, 0, 2, 4, 0, 4, 4, 4, 0, 0, 4, 3, 3, 4, 0, 3, 2, 0, 4, 0, 3, 2, 4, 4, 4, 2, 0, 2, 0, 2, 3, 0, 4, 4, 3, 4, 2, 0, 3, 4, 3, 2, 3, 0, 3, 0, 0, 2, 3, 3, 2, 4, 0, 2, 4, 4, 3, 2, 3, 3, 2, 4, 0, 4, 3, 0, 2, 4, 2, 0, 3, 3, 4, 2, 3, 4, 3, 3, 4, 0, 4, 4, 3, 3, 4, 3, 4, 3, 0, 0, 3, 3, 3, 3, 4, 0, 0, 3, 2, 3, 2, 0, 2, 3, 0, 2, 4, 2, 3, 4, 3, 4, 3, 4, 0, 0, 4, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.90      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.83      0.84       100\n",
      "           3       0.73      0.94      0.82       100\n",
      "           4       0.62      0.93      0.75       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1822258085012436, Val acc: 0.72\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42000 - Batch 62/1613 - Train loss: 1.0496972581696888, Train acc: 0.8536706349206349\n",
      "Iteration 42100 - Batch 162/1613 - Train loss: 1.0391040685718045, Train acc: 0.8656058282208589\n",
      "Iteration 42200 - Batch 262/1613 - Train loss: 1.0340914139276223, Train acc: 0.870365969581749\n",
      "Iteration 42300 - Batch 362/1613 - Train loss: 1.0334815790173764, Train acc: 0.8712121212121212\n",
      "Iteration 42400 - Batch 462/1613 - Train loss: 1.0336900104971736, Train acc: 0.8712877969762419\n",
      "Iteration 42500 - Batch 562/1613 - Train loss: 1.031645292393056, Train acc: 0.8732238010657194\n",
      "Iteration 42600 - Batch 662/1613 - Train loss: 1.0309295118484383, Train acc: 0.8739159125188537\n",
      "Iteration 42700 - Batch 762/1613 - Train loss: 1.0318061153198133, Train acc: 0.872870249017038\n",
      "Iteration 42800 - Batch 862/1613 - Train loss: 1.0327620430313145, Train acc: 0.8717410196987254\n",
      "Iteration 42900 - Batch 962/1613 - Train loss: 1.0322726770601045, Train acc: 0.8720145379023884\n",
      "Iteration 43000 - Batch 1062/1613 - Train loss: 1.033295059080743, Train acc: 0.8710312793979303\n",
      "Iteration 43100 - Batch 1162/1613 - Train loss: 1.0330189976421595, Train acc: 0.8711844368013758\n",
      "Iteration 43200 - Batch 1262/1613 - Train loss: 1.0332085185832478, Train acc: 0.8709422011084719\n",
      "Iteration 43300 - Batch 1362/1613 - Train loss: 1.0332064285754108, Train acc: 0.870964783565664\n",
      "Iteration 43400 - Batch 1462/1613 - Train loss: 1.0336269691474456, Train acc: 0.870557074504443\n",
      "Iteration 43500 - Batch 1562/1613 - Train loss: 1.033461374345683, Train acc: 0.8706813819577736\n",
      "[0, 2, 0, 0, 4, 3, 0, 0, 1, 0, 1, 4, 4, 4, 0, 4, 1, 1, 1, 0, 1, 4, 1, 1, 4, 1, 3, 0, 3, 4, 0, 0, 1, 2, 4, 4, 2, 2, 1, 1, 2, 3, 3, 0, 2, 3, 1, 4, 3, 2, 2, 2, 0, 2, 1, 4, 4, 2, 0, 3, 0, 3, 0, 0, 3, 2, 2, 2, 2, 1, 0, 1, 4, 1, 0, 3, 2, 4, 3, 3, 1, 3, 0, 4, 3, 3, 2, 1, 4, 4, 0, 4, 2, 2, 0, 0, 1, 4, 3, 4, 1, 2, 4, 1, 4, 2, 0, 4, 2, 3, 3, 0, 3, 4, 2, 2, 0, 1, 1, 0, 1, 2, 2, 2, 0, 2, 3, 0, 2, 3, 0, 2, 3, 4, 2, 4, 2, 3, 4, 3, 3, 2, 0, 4, 1, 3, 1, 2, 1, 4, 2, 2, 1, 1, 0, 2, 3, 0, 1, 1, 1, 0, 1, 2, 3, 0, 1, 3, 4, 0, 3, 3, 0, 4, 4, 1, 0, 4, 1, 2, 4, 2, 2, 1, 3, 4, 0, 0, 3, 1, 0, 0, 2, 0, 3, 3, 3, 3, 1, 2, 4, 4, 1, 3, 3, 2, 0, 1, 0, 3, 1, 3, 0, 4, 0, 4, 4, 0, 4, 1, 0, 1, 2, 0, 0, 0, 3, 0, 1, 2, 3, 1, 1, 2, 3, 3, 3, 2, 4, 1, 2, 1, 0, 4, 1, 0, 0, 2, 3, 0, 0, 2, 0, 3, 3, 3, 0, 3, 1, 3, 4, 2, 3, 0, 1, 3, 2, 3, 1, 4, 1, 0, 2, 1, 0, 3, 3, 4, 1, 3, 2, 1, 4, 0, 0, 2, 4, 2, 1, 2, 3, 4, 0, 0, 2, 1, 2, 2, 1, 3, 3, 3, 4, 3, 2, 0, 2, 3, 4, 2, 1, 3, 0, 0, 1, 2, 1, 0, 4, 2, 0, 4, 2, 4, 0, 1, 4, 4, 1, 2, 4, 1, 4, 1, 1, 3, 4, 2, 4, 0, 0, 4, 2, 2, 4, 4, 3, 0, 0, 3, 3, 1, 3, 3, 4, 2, 0, 4, 1, 2, 3, 1, 0, 0, 0, 4, 2, 3, 4, 2, 2, 0, 4, 3, 4, 1, 0, 3, 3, 1, 3, 2, 0, 1, 4, 3, 1, 1, 1, 3, 2, 1, 4, 1, 4, 3, 4, 1, 1, 1, 3, 1, 4, 2, 4, 1, 3, 3, 3, 2, 3, 0, 0, 4, 4, 2, 0, 1, 4, 3, 1, 1, 2, 2, 2, 3, 4, 0, 4, 3, 3, 3, 3, 4, 1, 0, 3, 4, 2, 2, 2, 2, 2, 2, 3, 4, 3, 4, 1, 0, 2, 3, 2, 4, 3, 2, 1, 2, 1, 4, 0, 4, 0, 4, 1, 2, 4, 4, 0, 1, 1, 0, 4, 1, 1, 0, 0, 2, 3, 4, 2, 0, 2, 4, 4, 0, 4, 2, 2, 4, 4, 4, 1, 1, 4, 3, 0, 3, 1, 0]\n",
      "[0, 2, 0, 0, 4, 3, 0, 0, 4, 0, 4, 4, 3, 4, 0, 4, 0, 4, 4, 0, 3, 4, 0, 4, 4, 0, 3, 0, 3, 4, 0, 0, 2, 2, 2, 4, 0, 2, 4, 0, 2, 3, 3, 0, 2, 3, 3, 4, 3, 2, 0, 2, 0, 2, 0, 4, 4, 2, 4, 4, 0, 3, 0, 0, 4, 2, 2, 0, 2, 0, 0, 3, 4, 4, 0, 3, 2, 4, 3, 3, 4, 3, 0, 4, 3, 3, 2, 3, 4, 4, 0, 4, 0, 2, 4, 0, 4, 4, 3, 4, 4, 2, 4, 4, 4, 2, 0, 4, 2, 3, 3, 0, 3, 4, 2, 2, 0, 0, 4, 0, 2, 2, 2, 2, 0, 2, 3, 0, 2, 3, 0, 2, 3, 3, 2, 4, 0, 3, 4, 3, 3, 2, 0, 4, 4, 3, 0, 2, 4, 4, 2, 2, 3, 0, 0, 2, 3, 0, 4, 0, 4, 0, 4, 2, 3, 0, 3, 3, 3, 0, 3, 3, 0, 4, 4, 0, 0, 4, 4, 2, 4, 0, 2, 3, 3, 4, 0, 0, 3, 4, 0, 0, 2, 0, 3, 3, 3, 3, 4, 0, 4, 4, 4, 3, 3, 2, 0, 4, 0, 3, 4, 3, 0, 4, 0, 4, 4, 0, 4, 0, 0, 4, 2, 0, 0, 0, 3, 0, 4, 2, 4, 4, 3, 2, 3, 3, 4, 0, 4, 4, 2, 4, 0, 4, 3, 0, 0, 2, 3, 0, 0, 2, 4, 4, 3, 3, 0, 3, 4, 3, 4, 2, 3, 0, 3, 3, 2, 3, 4, 4, 4, 0, 2, 0, 0, 4, 3, 4, 3, 3, 3, 0, 4, 0, 0, 2, 4, 2, 3, 2, 3, 4, 2, 0, 2, 4, 2, 2, 4, 3, 3, 3, 4, 3, 0, 0, 2, 3, 4, 2, 3, 3, 0, 0, 4, 0, 3, 0, 4, 2, 0, 4, 2, 4, 0, 0, 4, 4, 4, 0, 4, 4, 4, 0, 3, 3, 0, 2, 4, 0, 0, 4, 2, 2, 4, 4, 3, 0, 0, 3, 3, 4, 0, 3, 4, 2, 0, 4, 4, 2, 3, 3, 0, 4, 0, 3, 0, 3, 4, 2, 2, 0, 4, 3, 4, 3, 0, 3, 3, 0, 3, 2, 0, 4, 2, 3, 4, 0, 4, 3, 0, 0, 4, 4, 4, 3, 4, 0, 0, 3, 3, 3, 4, 0, 4, 0, 3, 3, 3, 2, 3, 0, 0, 4, 4, 2, 0, 4, 4, 3, 3, 4, 2, 0, 0, 3, 4, 0, 4, 3, 3, 3, 3, 3, 4, 0, 3, 4, 2, 0, 2, 2, 2, 2, 3, 4, 3, 4, 4, 0, 2, 3, 2, 4, 3, 2, 0, 2, 4, 4, 0, 4, 2, 4, 4, 2, 4, 4, 0, 4, 4, 0, 4, 4, 4, 0, 0, 2, 3, 4, 2, 0, 2, 4, 4, 0, 4, 2, 0, 4, 4, 4, 3, 4, 4, 3, 0, 3, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.93      0.81      0.87       100\n",
      "           3       0.78      0.93      0.85       100\n",
      "           4       0.59      0.92      0.72       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.60      0.72      0.64       500\n",
      "weighted avg       0.60      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.181566134095192, Val acc: 0.72\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43600 - Batch 49/1613 - Train loss: 1.03631831407547, Train acc: 0.865625\n",
      "Iteration 43700 - Batch 149/1613 - Train loss: 1.033773980140686, Train acc: 0.869375\n",
      "Iteration 43800 - Batch 249/1613 - Train loss: 1.0359885370731354, Train acc: 0.868\n",
      "Iteration 43900 - Batch 349/1613 - Train loss: 1.0356742671557835, Train acc: 0.8683928571428572\n",
      "Iteration 44000 - Batch 449/1613 - Train loss: 1.0344473368591733, Train acc: 0.8697222222222222\n",
      "Iteration 44100 - Batch 549/1613 - Train loss: 1.0351424605196173, Train acc: 0.8692613636363636\n",
      "Iteration 44200 - Batch 649/1613 - Train loss: 1.0338650244932908, Train acc: 0.8704807692307692\n",
      "Iteration 44300 - Batch 749/1613 - Train loss: 1.0327742189566294, Train acc: 0.8714583333333333\n",
      "Iteration 44400 - Batch 849/1613 - Train loss: 1.0313272410981795, Train acc: 0.8729779411764705\n",
      "Iteration 44500 - Batch 949/1613 - Train loss: 1.0316553463433917, Train acc: 0.8725\n",
      "Iteration 44600 - Batch 1049/1613 - Train loss: 1.0326719927220118, Train acc: 0.8714583333333333\n",
      "Iteration 44700 - Batch 1149/1613 - Train loss: 1.0333580047151316, Train acc: 0.8707608695652174\n",
      "Iteration 44800 - Batch 1249/1613 - Train loss: 1.0332371180057525, Train acc: 0.8709\n",
      "Iteration 44900 - Batch 1349/1613 - Train loss: 1.0332644507178554, Train acc: 0.8709722222222223\n",
      "Iteration 45000 - Batch 1449/1613 - Train loss: 1.0332456555037663, Train acc: 0.8708836206896552\n",
      "Iteration 45100 - Batch 1549/1613 - Train loss: 1.0330399808960575, Train acc: 0.8710282258064516\n",
      "[1, 2, 3, 2, 0, 3, 4, 4, 2, 0, 2, 3, 3, 2, 2, 0, 4, 1, 3, 1, 1, 4, 4, 1, 3, 3, 2, 2, 3, 3, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, 3, 1, 3, 1, 0, 2, 1, 0, 4, 1, 1, 1, 0, 1, 4, 4, 0, 3, 1, 3, 0, 2, 1, 3, 0, 1, 4, 3, 3, 1, 4, 4, 2, 3, 4, 3, 4, 4, 0, 4, 2, 3, 1, 2, 3, 2, 1, 2, 1, 0, 0, 1, 2, 1, 3, 1, 4, 2, 0, 3, 3, 3, 2, 1, 3, 4, 4, 1, 0, 2, 2, 1, 0, 2, 2, 4, 1, 2, 0, 4, 2, 1, 1, 1, 3, 3, 1, 4, 0, 1, 3, 4, 0, 1, 3, 0, 0, 2, 2, 0, 0, 1, 4, 2, 1, 1, 4, 4, 1, 1, 3, 2, 3, 3, 2, 0, 4, 2, 1, 4, 3, 3, 1, 1, 1, 4, 3, 4, 4, 4, 1, 2, 4, 2, 4, 3, 1, 1, 1, 2, 2, 0, 1, 0, 3, 3, 0, 4, 2, 0, 4, 1, 0, 1, 1, 1, 4, 2, 0, 0, 1, 4, 1, 1, 2, 3, 0, 1, 0, 2, 3, 3, 1, 0, 1, 3, 2, 4, 4, 2, 0, 0, 2, 1, 3, 2, 4, 1, 3, 1, 3, 0, 0, 0, 2, 1, 4, 1, 3, 4, 2, 2, 0, 0, 3, 2, 4, 0, 0, 4, 3, 0, 0, 3, 4, 0, 3, 1, 3, 3, 0, 2, 0, 1, 3, 0, 0, 2, 3, 4, 2, 2, 3, 3, 2, 1, 3, 2, 2, 1, 0, 2, 1, 3, 1, 0, 4, 3, 3, 0, 4, 4, 3, 1, 3, 2, 0, 0, 0, 0, 2, 2, 3, 3, 4, 0, 4, 4, 2, 3, 2, 1, 0, 2, 2, 3, 0, 1, 3, 0, 4, 0, 4, 1, 1, 3, 1, 4, 1, 0, 2, 1, 4, 3, 2, 4, 3, 2, 0, 0, 1, 4, 0, 2, 4, 2, 3, 4, 4, 2, 0, 1, 2, 3, 0, 4, 4, 2, 4, 2, 2, 4, 1, 3, 4, 4, 0, 3, 4, 0, 0, 1, 4, 4, 1, 0, 3, 0, 4, 1, 4, 1, 0, 2, 1, 4, 4, 3, 1, 0, 2, 3, 4, 2, 0, 4, 3, 2, 4, 4, 3, 0, 0, 4, 3, 3, 2, 2, 2, 3, 4, 2, 2, 0, 3, 1, 4, 2, 2, 0, 0, 2, 4, 4, 0, 0, 0, 2, 4, 0, 4, 2, 2, 0, 4, 4, 4, 4, 2, 0, 3, 3, 3, 2, 1, 0, 0, 1, 2, 4, 3, 1, 2, 0, 1, 3, 0, 1, 0, 4, 2, 3, 1, 1, 0, 2, 0, 3, 0, 2, 3, 4, 2, 0, 4, 3, 1, 4, 0, 1, 0, 3, 1, 4, 1, 3, 2, 3, 1, 4, 1, 3, 4, 0, 1, 2, 4, 4, 0, 0]\n",
      "[4, 2, 3, 2, 2, 3, 4, 4, 2, 0, 0, 3, 3, 2, 0, 0, 4, 3, 3, 3, 3, 4, 4, 2, 3, 3, 2, 2, 3, 3, 2, 3, 0, 2, 2, 3, 0, 3, 3, 4, 3, 2, 3, 2, 0, 0, 4, 0, 4, 4, 4, 4, 0, 3, 4, 4, 0, 3, 4, 3, 0, 2, 4, 3, 0, 0, 4, 3, 3, 4, 4, 4, 2, 3, 4, 3, 4, 4, 0, 4, 2, 3, 3, 0, 3, 2, 4, 2, 3, 2, 0, 0, 2, 3, 4, 0, 3, 2, 0, 3, 3, 3, 2, 0, 3, 3, 4, 4, 0, 2, 2, 0, 0, 2, 2, 4, 0, 2, 2, 4, 2, 4, 3, 3, 3, 3, 2, 4, 0, 4, 3, 4, 0, 3, 3, 0, 2, 2, 0, 4, 0, 3, 4, 0, 4, 4, 4, 4, 4, 2, 3, 2, 3, 3, 2, 0, 4, 2, 4, 4, 4, 3, 4, 0, 4, 4, 4, 4, 4, 4, 0, 2, 4, 0, 3, 2, 0, 3, 3, 2, 0, 0, 4, 2, 3, 3, 0, 4, 2, 0, 4, 3, 0, 0, 3, 3, 4, 2, 0, 2, 4, 4, 4, 3, 2, 3, 0, 2, 0, 2, 4, 3, 4, 0, 4, 3, 2, 4, 4, 2, 0, 0, 2, 3, 3, 0, 4, 0, 3, 4, 3, 0, 0, 0, 2, 4, 3, 3, 3, 4, 2, 2, 0, 0, 3, 2, 4, 0, 0, 4, 3, 0, 0, 3, 4, 0, 3, 3, 3, 3, 0, 2, 0, 4, 3, 0, 0, 2, 3, 4, 2, 2, 3, 3, 2, 3, 3, 2, 0, 4, 0, 2, 4, 3, 3, 0, 3, 3, 3, 0, 4, 4, 3, 4, 3, 2, 0, 0, 0, 0, 2, 2, 3, 3, 4, 0, 4, 4, 2, 4, 2, 2, 0, 2, 2, 3, 0, 0, 0, 0, 4, 0, 4, 3, 0, 3, 0, 3, 3, 0, 2, 4, 4, 3, 0, 4, 3, 2, 0, 0, 3, 4, 0, 2, 4, 2, 3, 4, 4, 2, 4, 4, 2, 3, 0, 4, 4, 2, 4, 2, 2, 4, 0, 3, 4, 4, 2, 3, 4, 0, 0, 0, 0, 4, 3, 0, 3, 0, 4, 4, 4, 0, 2, 0, 3, 4, 4, 3, 4, 0, 2, 3, 4, 2, 0, 4, 3, 2, 0, 4, 3, 0, 0, 4, 3, 3, 2, 2, 2, 3, 4, 2, 2, 0, 4, 0, 4, 2, 2, 0, 0, 2, 4, 4, 0, 0, 0, 2, 4, 0, 4, 2, 0, 0, 4, 4, 3, 3, 2, 0, 3, 3, 3, 0, 4, 4, 0, 0, 2, 4, 3, 0, 2, 0, 3, 0, 0, 3, 0, 4, 2, 3, 3, 0, 0, 2, 0, 3, 0, 2, 3, 4, 3, 2, 2, 3, 0, 4, 0, 4, 0, 3, 0, 4, 4, 3, 2, 3, 4, 4, 3, 3, 4, 0, 2, 2, 4, 4, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.82      0.84      0.83       100\n",
      "           3       0.69      0.91      0.79       100\n",
      "           4       0.66      0.89      0.76       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1963849440217018, Val acc: 0.704\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45200 - Batch 36/1613 - Train loss: 1.02053454598865, Train acc: 0.8834459459459459\n",
      "Iteration 45300 - Batch 136/1613 - Train loss: 1.0274065363146092, Train acc: 0.8761405109489051\n",
      "Iteration 45400 - Batch 236/1613 - Train loss: 1.0357308128715064, Train acc: 0.8677478902953587\n",
      "Iteration 45500 - Batch 336/1613 - Train loss: 1.0302357100591462, Train acc: 0.8738872403560831\n",
      "Iteration 45600 - Batch 436/1613 - Train loss: 1.030224136684252, Train acc: 0.8738558352402745\n",
      "Iteration 45700 - Batch 536/1613 - Train loss: 1.028875179907907, Train acc: 0.8750581936685289\n",
      "Iteration 45800 - Batch 636/1613 - Train loss: 1.0301229354912296, Train acc: 0.873675431711146\n",
      "Iteration 45900 - Batch 736/1613 - Train loss: 1.0290795772499437, Train acc: 0.874915196743555\n",
      "Iteration 46000 - Batch 836/1613 - Train loss: 1.030925608023093, Train acc: 0.8730212066905615\n",
      "Iteration 46100 - Batch 936/1613 - Train loss: 1.0318508040052594, Train acc: 0.8721985058697972\n",
      "Iteration 46200 - Batch 1036/1613 - Train loss: 1.0313859595167258, Train acc: 0.8724987945998072\n",
      "Iteration 46300 - Batch 1136/1613 - Train loss: 1.0317747971942368, Train acc: 0.8719492084432717\n",
      "Iteration 46400 - Batch 1236/1613 - Train loss: 1.0325114328531653, Train acc: 0.871336903799515\n",
      "Iteration 46500 - Batch 1336/1613 - Train loss: 1.0326584730472865, Train acc: 0.8712135377711294\n",
      "Iteration 46600 - Batch 1436/1613 - Train loss: 1.032761756670334, Train acc: 0.8710638482950591\n",
      "Iteration 46700 - Batch 1536/1613 - Train loss: 1.0332391994993797, Train acc: 0.870608327911516\n",
      "[4, 1, 2, 2, 1, 0, 4, 0, 1, 4, 3, 0, 3, 0, 1, 3, 0, 2, 4, 4, 0, 0, 0, 2, 0, 4, 1, 0, 4, 4, 3, 4, 1, 2, 1, 3, 1, 1, 2, 4, 0, 4, 0, 0, 3, 0, 4, 2, 2, 3, 4, 2, 3, 0, 4, 0, 2, 4, 1, 0, 4, 0, 0, 3, 4, 4, 2, 1, 2, 4, 4, 0, 0, 2, 3, 4, 0, 3, 1, 4, 1, 1, 2, 3, 3, 0, 0, 1, 3, 4, 4, 0, 1, 0, 4, 0, 4, 3, 4, 3, 2, 2, 2, 4, 3, 4, 4, 1, 4, 4, 1, 3, 1, 3, 2, 4, 4, 1, 2, 0, 4, 0, 0, 1, 3, 2, 3, 3, 4, 3, 2, 0, 0, 0, 3, 0, 3, 1, 4, 4, 2, 3, 4, 1, 2, 1, 0, 3, 0, 3, 0, 3, 4, 2, 2, 4, 1, 3, 4, 1, 1, 3, 4, 4, 1, 4, 1, 0, 1, 1, 1, 3, 2, 0, 4, 3, 1, 4, 1, 1, 0, 3, 3, 3, 4, 2, 2, 1, 4, 4, 4, 1, 1, 0, 4, 0, 2, 2, 3, 0, 1, 3, 3, 4, 0, 3, 2, 2, 1, 3, 3, 2, 1, 0, 2, 3, 4, 3, 1, 0, 1, 0, 3, 0, 1, 2, 3, 0, 2, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 3, 4, 4, 1, 1, 3, 2, 0, 2, 0, 1, 1, 3, 0, 3, 0, 3, 2, 4, 2, 1, 0, 0, 0, 1, 1, 4, 2, 3, 1, 4, 3, 0, 3, 3, 2, 3, 2, 4, 2, 3, 0, 2, 3, 0, 4, 1, 2, 0, 1, 2, 1, 0, 2, 0, 3, 4, 3, 4, 4, 4, 3, 2, 2, 3, 0, 3, 0, 2, 2, 2, 0, 0, 4, 2, 1, 1, 1, 2, 1, 2, 0, 2, 3, 3, 3, 3, 4, 4, 4, 3, 3, 4, 4, 1, 1, 0, 0, 3, 4, 4, 0, 2, 3, 2, 0, 3, 2, 0, 2, 3, 1, 2, 4, 2, 4, 4, 2, 1, 1, 3, 4, 0, 4, 0, 1, 0, 3, 3, 2, 1, 1, 3, 2, 2, 1, 3, 2, 4, 3, 0, 3, 1, 0, 2, 1, 4, 4, 0, 2, 1, 4, 0, 4, 4, 3, 0, 3, 4, 3, 4, 2, 1, 2, 0, 2, 4, 2, 0, 4, 3, 0, 1, 0, 3, 3, 4, 0, 1, 3, 1, 3, 0, 2, 0, 4, 0, 4, 1, 1, 2, 2, 3, 1, 1, 3, 4, 2, 1, 2, 2, 2, 1, 2, 0, 1, 4, 0, 1, 1, 3, 0, 3, 2, 2, 1, 3, 1, 2, 0, 3, 4, 0, 4, 4, 2, 3, 4, 3, 2, 0, 0, 4, 2, 1, 1, 3, 2, 3, 1, 2, 0, 2, 1, 2, 0, 0, 4, 2, 3, 3, 2, 1, 0, 2, 2, 1, 4, 2, 1, 1]\n",
      "[4, 4, 2, 2, 4, 0, 4, 4, 4, 4, 3, 0, 3, 4, 4, 3, 0, 2, 4, 4, 0, 0, 0, 2, 0, 3, 3, 0, 4, 4, 3, 3, 0, 2, 4, 3, 4, 4, 2, 4, 0, 4, 0, 0, 3, 4, 4, 2, 2, 3, 4, 2, 3, 0, 4, 0, 2, 4, 0, 0, 4, 0, 0, 3, 4, 2, 2, 4, 2, 4, 3, 0, 0, 3, 3, 4, 0, 3, 0, 4, 4, 4, 2, 3, 3, 0, 0, 4, 3, 4, 4, 2, 4, 0, 4, 0, 4, 3, 4, 3, 2, 2, 2, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 3, 2, 4, 4, 3, 2, 4, 4, 0, 0, 4, 3, 0, 3, 3, 4, 0, 0, 0, 0, 0, 3, 0, 3, 4, 0, 4, 2, 3, 4, 4, 0, 3, 0, 3, 4, 3, 0, 3, 4, 2, 2, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 2, 0, 4, 3, 4, 4, 0, 4, 0, 3, 3, 3, 4, 2, 2, 3, 4, 4, 4, 0, 3, 0, 4, 2, 2, 0, 3, 0, 2, 4, 4, 4, 0, 3, 0, 2, 4, 3, 4, 2, 3, 0, 2, 3, 3, 3, 4, 0, 2, 0, 3, 0, 3, 2, 3, 0, 2, 4, 4, 2, 0, 2, 0, 2, 4, 0, 0, 3, 4, 4, 4, 4, 3, 2, 0, 2, 0, 4, 4, 3, 2, 3, 0, 3, 2, 4, 2, 0, 0, 0, 0, 4, 2, 4, 2, 4, 4, 4, 3, 0, 3, 3, 2, 3, 0, 4, 0, 3, 0, 2, 3, 0, 3, 3, 2, 0, 4, 2, 2, 0, 2, 0, 3, 4, 4, 2, 4, 4, 3, 2, 2, 3, 0, 3, 0, 0, 0, 2, 0, 0, 4, 2, 0, 0, 4, 2, 0, 2, 0, 2, 3, 3, 3, 3, 4, 4, 3, 3, 3, 4, 4, 0, 4, 0, 0, 3, 4, 4, 0, 2, 3, 2, 0, 3, 0, 0, 2, 3, 4, 2, 4, 2, 4, 4, 4, 3, 3, 3, 4, 0, 4, 0, 3, 0, 3, 3, 2, 3, 4, 3, 2, 0, 3, 3, 2, 4, 3, 0, 3, 3, 0, 2, 4, 4, 4, 0, 2, 3, 4, 0, 2, 4, 3, 0, 4, 4, 3, 4, 0, 3, 2, 0, 2, 4, 2, 2, 3, 3, 0, 4, 0, 3, 3, 4, 0, 4, 3, 0, 3, 0, 2, 0, 4, 0, 4, 4, 3, 2, 0, 3, 4, 4, 3, 4, 2, 3, 2, 2, 2, 0, 2, 0, 3, 4, 0, 4, 4, 4, 0, 3, 2, 2, 4, 3, 4, 4, 0, 3, 4, 0, 4, 4, 2, 3, 4, 3, 2, 0, 0, 4, 2, 4, 3, 4, 2, 3, 3, 2, 0, 0, 4, 2, 0, 0, 4, 2, 3, 3, 2, 4, 0, 2, 2, 4, 4, 2, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.82      0.84       100\n",
      "           3       0.74      0.90      0.81       100\n",
      "           4       0.55      0.89      0.68       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2019007727503777, Val acc: 0.702\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46800 - Batch 23/1613 - Train loss: 1.0467230528593063, Train acc: 0.8567708333333334\n",
      "Iteration 46900 - Batch 123/1613 - Train loss: 1.0309828726514694, Train acc: 0.873991935483871\n",
      "Iteration 47000 - Batch 223/1613 - Train loss: 1.0324755630322866, Train acc: 0.8717912946428571\n",
      "Iteration 47100 - Batch 323/1613 - Train loss: 1.0310160747648758, Train acc: 0.8733603395061729\n",
      "Iteration 47200 - Batch 423/1613 - Train loss: 1.0304646347210091, Train acc: 0.8738207547169812\n",
      "Iteration 47300 - Batch 523/1613 - Train loss: 1.0304411110532192, Train acc: 0.8737476145038168\n",
      "Iteration 47400 - Batch 623/1613 - Train loss: 1.0311084599831166, Train acc: 0.8731971153846154\n",
      "Iteration 47500 - Batch 723/1613 - Train loss: 1.0320149236127159, Train acc: 0.8721512430939227\n",
      "Iteration 47600 - Batch 823/1613 - Train loss: 1.0324196065369162, Train acc: 0.8716246966019418\n",
      "Iteration 47700 - Batch 923/1613 - Train loss: 1.032382347108998, Train acc: 0.8716856060606061\n",
      "Iteration 47800 - Batch 1023/1613 - Train loss: 1.033119332685601, Train acc: 0.8709716796875\n",
      "Iteration 47900 - Batch 1123/1613 - Train loss: 1.033149473448665, Train acc: 0.8709686387900356\n",
      "Iteration 48000 - Batch 1223/1613 - Train loss: 1.0331028971114968, Train acc: 0.8709660947712419\n",
      "Iteration 48100 - Batch 1323/1613 - Train loss: 1.0329258447327283, Train acc: 0.8710819486404834\n",
      "Iteration 48200 - Batch 1423/1613 - Train loss: 1.0336204722439974, Train acc: 0.8703037219101124\n",
      "Iteration 48300 - Batch 1523/1613 - Train loss: 1.0336346576220095, Train acc: 0.8703248031496063\n",
      "[2, 3, 0, 1, 0, 3, 3, 3, 3, 0, 0, 3, 0, 2, 2, 4, 3, 1, 1, 3, 0, 1, 4, 4, 1, 0, 0, 4, 1, 2, 3, 3, 0, 0, 0, 1, 2, 2, 0, 1, 0, 3, 0, 4, 0, 3, 1, 3, 1, 4, 1, 2, 0, 2, 3, 3, 1, 2, 0, 3, 3, 4, 1, 0, 2, 4, 0, 4, 3, 0, 3, 2, 1, 3, 1, 2, 4, 3, 4, 0, 0, 2, 0, 3, 2, 2, 3, 4, 3, 4, 3, 0, 1, 1, 1, 2, 3, 4, 4, 1, 4, 2, 3, 0, 2, 3, 3, 3, 1, 4, 2, 4, 2, 2, 4, 2, 4, 1, 4, 3, 1, 4, 3, 2, 3, 4, 2, 2, 0, 0, 2, 0, 1, 3, 4, 2, 0, 2, 1, 1, 3, 1, 3, 3, 0, 3, 0, 0, 0, 4, 1, 3, 4, 4, 1, 2, 1, 3, 1, 2, 4, 1, 2, 3, 2, 0, 0, 3, 1, 3, 1, 2, 2, 3, 1, 0, 2, 4, 2, 2, 4, 4, 0, 1, 4, 0, 0, 3, 2, 4, 4, 2, 0, 1, 3, 3, 0, 0, 4, 1, 4, 4, 4, 3, 1, 2, 2, 4, 4, 4, 1, 2, 1, 0, 0, 0, 1, 4, 1, 4, 3, 4, 1, 4, 1, 0, 4, 4, 0, 1, 3, 4, 1, 3, 4, 2, 4, 4, 2, 2, 3, 3, 2, 1, 1, 3, 1, 3, 4, 3, 1, 3, 1, 0, 2, 1, 4, 0, 4, 2, 1, 2, 4, 0, 0, 2, 0, 4, 3, 3, 0, 0, 0, 0, 2, 4, 4, 0, 2, 3, 4, 4, 1, 2, 1, 0, 2, 2, 1, 1, 4, 1, 2, 1, 4, 4, 4, 4, 4, 4, 0, 1, 1, 0, 0, 2, 1, 3, 1, 1, 1, 1, 1, 3, 0, 3, 4, 2, 4, 0, 0, 0, 0, 3, 2, 3, 1, 1, 3, 2, 3, 0, 1, 4, 0, 3, 2, 1, 1, 1, 4, 1, 2, 0, 0, 1, 4, 1, 3, 4, 0, 2, 0, 1, 3, 4, 2, 2, 3, 0, 2, 2, 4, 2, 4, 2, 4, 2, 1, 2, 3, 3, 0, 4, 4, 0, 4, 0, 2, 0, 4, 1, 3, 2, 1, 2, 2, 2, 3, 0, 1, 0, 0, 0, 1, 0, 2, 3, 4, 2, 3, 1, 4, 4, 4, 3, 1, 2, 4, 2, 1, 1, 2, 2, 1, 2, 4, 0, 1, 1, 2, 3, 0, 1, 2, 3, 0, 4, 3, 0, 0, 0, 3, 2, 2, 4, 3, 0, 4, 3, 3, 3, 0, 2, 4, 1, 4, 1, 2, 4, 2, 4, 0, 3, 1, 3, 0, 3, 3, 2, 1, 2, 3, 3, 1, 0, 3, 2, 4, 0, 3, 4, 4, 4, 3, 1, 2, 3, 2, 4, 3, 2, 0, 0, 1, 3, 2, 1, 4, 2, 3, 0, 0, 3, 0, 1, 2, 0, 1, 2]\n",
      "[2, 3, 2, 4, 0, 3, 3, 3, 3, 0, 0, 3, 0, 2, 2, 4, 3, 4, 0, 3, 0, 3, 4, 3, 0, 4, 0, 4, 3, 2, 3, 3, 0, 0, 0, 4, 2, 2, 0, 3, 0, 3, 4, 4, 0, 3, 0, 3, 4, 4, 4, 2, 0, 2, 3, 3, 4, 2, 0, 3, 3, 4, 4, 0, 2, 4, 0, 4, 3, 0, 3, 2, 4, 3, 4, 2, 4, 3, 2, 0, 0, 2, 0, 3, 2, 2, 3, 4, 3, 4, 3, 0, 4, 4, 4, 2, 3, 2, 4, 4, 4, 2, 3, 0, 0, 3, 3, 3, 0, 4, 2, 4, 2, 2, 3, 2, 0, 4, 4, 3, 3, 3, 3, 0, 3, 4, 2, 2, 0, 0, 2, 2, 3, 3, 4, 2, 0, 2, 4, 3, 3, 4, 3, 3, 0, 3, 0, 2, 0, 4, 3, 3, 4, 4, 2, 2, 4, 3, 4, 2, 4, 2, 2, 3, 2, 0, 0, 3, 4, 3, 3, 2, 2, 3, 4, 0, 2, 4, 2, 2, 4, 4, 0, 0, 4, 0, 2, 3, 2, 4, 4, 2, 0, 3, 4, 3, 0, 0, 4, 4, 4, 4, 4, 4, 0, 2, 2, 4, 4, 4, 0, 2, 0, 0, 0, 0, 2, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 4, 2, 4, 3, 4, 2, 3, 4, 2, 4, 4, 2, 2, 4, 3, 2, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 0, 0, 0, 4, 0, 4, 2, 3, 0, 4, 0, 0, 2, 0, 4, 4, 3, 0, 0, 0, 0, 2, 4, 4, 2, 2, 3, 4, 4, 4, 2, 3, 0, 2, 2, 0, 3, 4, 4, 2, 0, 4, 4, 4, 4, 4, 4, 0, 4, 0, 0, 0, 2, 0, 3, 0, 4, 4, 4, 2, 3, 0, 3, 4, 0, 4, 4, 0, 0, 0, 3, 2, 2, 4, 0, 3, 2, 4, 0, 4, 0, 0, 3, 2, 4, 4, 4, 3, 4, 2, 0, 0, 4, 4, 4, 3, 4, 0, 2, 0, 4, 3, 4, 2, 2, 2, 0, 2, 0, 4, 2, 4, 0, 4, 0, 0, 2, 3, 3, 0, 4, 3, 2, 4, 0, 2, 0, 2, 3, 4, 2, 3, 2, 0, 2, 3, 4, 2, 0, 0, 0, 4, 0, 2, 3, 4, 0, 3, 3, 4, 4, 3, 3, 0, 2, 4, 0, 3, 3, 2, 2, 4, 2, 4, 0, 4, 0, 2, 3, 0, 2, 2, 3, 0, 4, 3, 0, 0, 0, 3, 4, 2, 4, 3, 0, 4, 3, 3, 3, 0, 2, 4, 4, 4, 4, 0, 4, 2, 4, 0, 3, 4, 3, 2, 3, 3, 0, 4, 0, 3, 3, 4, 0, 3, 0, 4, 0, 3, 4, 4, 4, 3, 3, 2, 3, 2, 4, 3, 2, 4, 0, 0, 3, 2, 4, 4, 2, 3, 0, 2, 3, 0, 4, 2, 0, 3, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.80      0.84      0.82       100\n",
      "           3       0.76      0.91      0.83       100\n",
      "           4       0.58      0.89      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2031494602560997, Val acc: 0.7\n",
      "Tiempo total de entrenamiento: 645.8713 [s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader,val_loader=get_training_loaders(synthetic_SN=fake_wgangp.detach().cpu(),batch_size=32,file_name=\"stamp_dataset_only_images_63.pkl\",label_as_strings=True)\n",
    "print(torch.bincount(train_loader.dataset.labels.to(torch.int)))\n",
    "curves=trainer(train_loader,val_loader,epochs=30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10000 supernovas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_img = 10000\n",
    "gen_1 = Generator(z_dim).to(device)\n",
    "gen_1.load_state_dict(torch.load('dcgan'))\n",
    "gen = Generator(z_dim).to(device)\n",
    "gen.load_state_dict(torch.load('wgangp'))\n",
    "fake_noise = get_noise(num_img, z_dim, device=device)\n",
    "fake_dcgan = gen_1(fake_noise)\n",
    "fake_wgangp= gen(fake_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14542, 11396, 14523,  9599, 10534])\n",
      "tensor([100, 100, 100, 100, 100])\n",
      "Epoch 1/30\n",
      "Iteration 0 - Batch 0/1894 - Train loss: 1.6264009475708008, Train acc: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 - Batch 100/1894 - Train loss: 1.4241950889625172, Train acc: 0.588799504950495\n",
      "Iteration 200 - Batch 200/1894 - Train loss: 1.3668650608157638, Train acc: 0.6100746268656716\n",
      "Iteration 300 - Batch 300/1894 - Train loss: 1.3408069032371241, Train acc: 0.6177325581395349\n",
      "Iteration 400 - Batch 400/1894 - Train loss: 1.3260554690610737, Train acc: 0.6213372817955112\n",
      "Iteration 500 - Batch 500/1894 - Train loss: 1.3150510076515214, Train acc: 0.6245009980039921\n",
      "Iteration 600 - Batch 600/1894 - Train loss: 1.3039790739037234, Train acc: 0.6309796173044925\n",
      "Iteration 700 - Batch 700/1894 - Train loss: 1.295360170995628, Train acc: 0.6356098430813124\n",
      "Iteration 800 - Batch 800/1894 - Train loss: 1.2883568641993586, Train acc: 0.6395521223470662\n",
      "Iteration 900 - Batch 900/1894 - Train loss: 1.2816956454720534, Train acc: 0.6436945061043285\n",
      "Iteration 1000 - Batch 1000/1894 - Train loss: 1.2777441406583452, Train acc: 0.6455731768231768\n",
      "Iteration 1100 - Batch 1100/1894 - Train loss: 1.2721557249057087, Train acc: 0.6493812443233424\n",
      "Iteration 1200 - Batch 1200/1894 - Train loss: 1.2688120310749242, Train acc: 0.6511240632805995\n",
      "Iteration 1300 - Batch 1300/1894 - Train loss: 1.265404690145805, Train acc: 0.653271521906226\n",
      "Iteration 1400 - Batch 1400/1894 - Train loss: 1.2617736196279696, Train acc: 0.655870806566738\n",
      "Iteration 1500 - Batch 1500/1894 - Train loss: 1.257452280262484, Train acc: 0.6594145569620253\n",
      "Iteration 1600 - Batch 1600/1894 - Train loss: 1.2534960794270151, Train acc: 0.662535134291068\n",
      "Iteration 1700 - Batch 1700/1894 - Train loss: 1.249414698857549, Train acc: 0.6659134332745443\n",
      "Iteration 1800 - Batch 1800/1894 - Train loss: 1.2451451539927096, Train acc: 0.6696973903387007\n",
      "[2, 2, 3, 2, 0, 3, 0, 3, 2, 4, 4, 4, 1, 1, 3, 1, 4, 1, 2, 4, 3, 2, 1, 0, 1, 4, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 4, 2, 0, 3, 4, 1, 3, 4, 0, 0, 0, 4, 2, 2, 1, 0, 4, 1, 2, 1, 0, 2, 0, 4, 3, 3, 1, 2, 1, 0, 2, 4, 0, 4, 3, 3, 4, 2, 3, 4, 4, 3, 1, 2, 2, 4, 4, 0, 4, 0, 1, 2, 4, 1, 0, 2, 0, 2, 3, 4, 3, 1, 1, 0, 2, 0, 3, 4, 3, 2, 2, 1, 0, 3, 1, 4, 0, 4, 4, 2, 4, 3, 1, 3, 2, 0, 0, 2, 0, 0, 1, 3, 3, 2, 4, 2, 3, 0, 4, 1, 3, 3, 0, 0, 0, 0, 4, 2, 4, 4, 3, 3, 1, 0, 2, 0, 2, 0, 4, 1, 2, 1, 1, 0, 2, 0, 1, 1, 4, 2, 4, 2, 3, 4, 2, 2, 4, 4, 0, 3, 2, 3, 3, 2, 1, 4, 1, 2, 2, 2, 3, 4, 1, 0, 1, 4, 3, 1, 0, 2, 0, 3, 3, 3, 4, 4, 3, 0, 1, 3, 0, 3, 3, 4, 3, 1, 4, 3, 1, 1, 2, 1, 0, 2, 1, 0, 1, 1, 2, 2, 0, 3, 2, 1, 3, 2, 2, 0, 2, 4, 0, 2, 3, 4, 2, 1, 2, 0, 4, 0, 2, 1, 3, 0, 2, 3, 0, 1, 0, 2, 4, 4, 0, 3, 4, 0, 1, 4, 2, 3, 4, 1, 0, 2, 1, 2, 3, 1, 0, 2, 0, 1, 2, 0, 4, 4, 4, 2, 4, 2, 0, 3, 2, 4, 1, 3, 1, 3, 0, 4, 3, 0, 0, 4, 0, 4, 0, 2, 2, 0, 2, 3, 1, 1, 3, 3, 1, 3, 1, 3, 4, 3, 4, 0, 4, 2, 4, 4, 4, 4, 0, 1, 4, 0, 3, 0, 1, 3, 3, 1, 0, 4, 4, 0, 0, 2, 4, 1, 3, 3, 2, 1, 1, 1, 0, 3, 4, 3, 2, 3, 4, 3, 1, 3, 1, 4, 4, 1, 0, 0, 1, 2, 2, 3, 4, 1, 0, 3, 0, 2, 2, 3, 3, 2, 2, 0, 0, 2, 1, 4, 3, 0, 4, 2, 3, 4, 4, 1, 1, 0, 0, 3, 3, 0, 3, 3, 3, 1, 2, 1, 4, 3, 1, 2, 2, 0, 0, 2, 2, 2, 2, 3, 1, 3, 0, 4, 4, 0, 0, 2, 3, 2, 3, 1, 0, 3, 4, 3, 4, 2, 1, 2, 0, 3, 2, 1, 4, 0, 3, 0, 1, 3, 0, 1, 1, 1, 4, 1, 1, 0, 3, 3, 0, 4, 2, 0, 0, 1, 4, 4, 4, 4, 0, 4, 3, 2, 1, 1, 0, 2, 4, 1, 2, 0, 2, 4, 4, 4, 2, 2, 1, 3, 1, 0, 3, 1, 3, 4, 3, 2, 4, 1, 2, 0]\n",
      "[2, 2, 4, 4, 0, 3, 4, 3, 2, 4, 4, 2, 4, 0, 3, 4, 4, 3, 0, 3, 4, 2, 4, 0, 4, 4, 0, 2, 4, 3, 4, 2, 2, 3, 4, 3, 4, 2, 2, 4, 2, 4, 3, 4, 4, 0, 0, 2, 2, 2, 3, 0, 2, 4, 2, 2, 2, 2, 0, 4, 3, 3, 3, 0, 2, 0, 0, 4, 0, 4, 4, 3, 4, 2, 0, 4, 4, 3, 3, 0, 4, 2, 4, 0, 4, 0, 4, 2, 4, 2, 0, 0, 0, 2, 4, 3, 3, 0, 0, 4, 2, 0, 3, 4, 3, 2, 2, 4, 0, 3, 2, 4, 4, 4, 4, 2, 4, 3, 4, 3, 2, 0, 0, 2, 0, 2, 3, 3, 3, 2, 2, 2, 3, 0, 4, 4, 3, 3, 4, 0, 0, 0, 4, 2, 4, 4, 4, 0, 3, 2, 2, 0, 0, 2, 4, 2, 2, 2, 0, 0, 2, 0, 4, 2, 2, 2, 4, 0, 3, 4, 4, 3, 4, 4, 0, 3, 4, 3, 3, 2, 3, 4, 2, 2, 0, 2, 3, 4, 3, 0, 4, 4, 3, 3, 0, 2, 0, 2, 3, 2, 4, 4, 2, 0, 3, 3, 0, 2, 3, 4, 3, 4, 4, 3, 2, 4, 2, 3, 0, 0, 3, 0, 0, 2, 2, 2, 3, 3, 0, 4, 3, 2, 2, 0, 0, 4, 0, 0, 3, 4, 2, 4, 2, 2, 4, 0, 2, 2, 3, 0, 0, 3, 0, 4, 0, 2, 4, 4, 0, 4, 4, 3, 2, 4, 2, 4, 4, 4, 0, 2, 0, 2, 4, 4, 0, 2, 0, 2, 2, 4, 2, 4, 4, 2, 4, 2, 0, 3, 4, 4, 2, 3, 3, 4, 0, 4, 3, 0, 2, 4, 0, 4, 4, 2, 2, 0, 2, 3, 0, 3, 3, 2, 0, 2, 0, 3, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 0, 3, 4, 0, 3, 0, 4, 2, 3, 3, 2, 4, 4, 0, 0, 2, 4, 4, 3, 3, 2, 4, 3, 4, 0, 3, 4, 4, 2, 3, 4, 3, 2, 3, 4, 3, 2, 4, 0, 2, 4, 2, 2, 3, 4, 2, 0, 3, 4, 2, 2, 3, 4, 2, 2, 2, 0, 2, 2, 4, 0, 0, 3, 2, 2, 2, 4, 2, 4, 2, 4, 2, 3, 2, 3, 4, 3, 4, 0, 2, 4, 3, 4, 0, 4, 2, 0, 2, 2, 2, 2, 3, 3, 3, 0, 4, 4, 0, 0, 2, 2, 4, 3, 2, 2, 3, 4, 4, 4, 2, 4, 2, 2, 3, 2, 0, 4, 0, 3, 0, 3, 3, 0, 0, 4, 4, 3, 3, 0, 2, 4, 3, 2, 4, 2, 0, 0, 2, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 0, 2, 2, 4, 4, 1, 2, 4, 2, 2, 4, 3, 3, 3, 4, 3, 2, 4, 4, 2, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.53      0.76      0.62       100\n",
      "           3       0.70      0.70      0.70       100\n",
      "           4       0.54      0.83      0.65       100\n",
      "\n",
      "    accuracy                           0.60       500\n",
      "   macro avg       0.49      0.60      0.53       500\n",
      "weighted avg       0.49      0.60      0.53       500\n",
      "\n",
      "Val loss: 1.3034134358167648, Val acc: 0.596\n",
      "Epoch 2/30\n",
      "Iteration 1900 - Batch 6/1894 - Train loss: 1.1690758296421595, Train acc: 0.7321428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 - Batch 106/1894 - Train loss: 1.1685985738986007, Train acc: 0.7348130841121495\n",
      "Iteration 2100 - Batch 206/1894 - Train loss: 1.1542231863823489, Train acc: 0.7496980676328503\n",
      "Iteration 2200 - Batch 306/1894 - Train loss: 1.1538242854978829, Train acc: 0.7505089576547231\n",
      "Iteration 2300 - Batch 406/1894 - Train loss: 1.1505803905189476, Train acc: 0.753762285012285\n",
      "Iteration 2400 - Batch 506/1894 - Train loss: 1.1487653944384182, Train acc: 0.7551158777120316\n",
      "Iteration 2500 - Batch 606/1894 - Train loss: 1.144754840966308, Train acc: 0.7592668863261944\n",
      "Iteration 2600 - Batch 706/1894 - Train loss: 1.1419692067310867, Train acc: 0.7619342291371994\n",
      "Iteration 2700 - Batch 806/1894 - Train loss: 1.1417320539073874, Train acc: 0.7618494423791822\n",
      "Iteration 2800 - Batch 906/1894 - Train loss: 1.1424144478196478, Train acc: 0.7610942668136714\n",
      "Iteration 2900 - Batch 1006/1894 - Train loss: 1.1404954638358025, Train acc: 0.7630027308838133\n",
      "Iteration 3000 - Batch 1106/1894 - Train loss: 1.1375846252208803, Train acc: 0.7657802619692864\n",
      "Iteration 3100 - Batch 1206/1894 - Train loss: 1.1363782861455967, Train acc: 0.7670619304059652\n",
      "Iteration 3200 - Batch 1306/1894 - Train loss: 1.1345843883443627, Train acc: 0.7686734889058914\n",
      "Iteration 3300 - Batch 1406/1894 - Train loss: 1.1325742977260271, Train acc: 0.7707000710732054\n",
      "Iteration 3400 - Batch 1506/1894 - Train loss: 1.1303436283489372, Train acc: 0.7731627405441274\n",
      "Iteration 3500 - Batch 1606/1894 - Train loss: 1.1278599016994293, Train acc: 0.7757467330429372\n",
      "Iteration 3600 - Batch 1706/1894 - Train loss: 1.1268283732466762, Train acc: 0.7767647920328061\n",
      "Iteration 3700 - Batch 1806/1894 - Train loss: 1.1255165319714548, Train acc: 0.7781198118428334\n",
      "[3, 2, 2, 0, 0, 4, 1, 4, 1, 2, 2, 4, 3, 3, 4, 0, 3, 2, 0, 0, 2, 3, 0, 0, 2, 0, 2, 4, 0, 1, 3, 2, 3, 2, 2, 2, 0, 3, 0, 1, 1, 4, 2, 3, 0, 0, 2, 0, 4, 3, 3, 0, 4, 4, 4, 4, 2, 4, 1, 4, 0, 0, 3, 2, 1, 1, 1, 0, 0, 4, 1, 0, 3, 4, 3, 3, 2, 1, 3, 1, 1, 0, 1, 1, 0, 2, 2, 0, 3, 2, 2, 3, 1, 1, 0, 0, 3, 4, 4, 2, 4, 0, 0, 3, 3, 1, 4, 1, 0, 0, 0, 3, 1, 4, 2, 3, 3, 3, 3, 4, 3, 3, 0, 4, 0, 1, 2, 4, 4, 2, 2, 3, 2, 3, 3, 3, 4, 1, 4, 3, 1, 2, 3, 0, 0, 4, 3, 2, 1, 3, 1, 1, 4, 3, 0, 3, 1, 1, 2, 0, 4, 3, 2, 0, 1, 0, 4, 1, 0, 2, 3, 2, 4, 4, 0, 0, 1, 1, 3, 1, 2, 2, 3, 4, 2, 2, 0, 4, 0, 1, 2, 4, 4, 2, 1, 4, 4, 4, 4, 3, 3, 4, 0, 0, 2, 1, 1, 4, 4, 2, 2, 2, 4, 2, 4, 2, 3, 2, 3, 4, 1, 2, 1, 3, 1, 2, 4, 1, 3, 3, 2, 1, 2, 4, 4, 3, 3, 0, 1, 0, 3, 1, 0, 4, 1, 1, 1, 4, 3, 4, 1, 3, 3, 0, 1, 0, 2, 3, 1, 4, 3, 3, 1, 3, 3, 3, 1, 1, 3, 4, 2, 0, 0, 4, 4, 2, 4, 0, 0, 0, 1, 3, 1, 4, 2, 2, 0, 1, 0, 4, 4, 1, 4, 4, 4, 0, 0, 1, 0, 0, 2, 4, 2, 3, 4, 1, 4, 2, 0, 4, 4, 0, 0, 2, 0, 2, 0, 0, 2, 4, 3, 1, 2, 1, 3, 3, 0, 4, 1, 3, 3, 2, 3, 2, 3, 2, 0, 1, 0, 1, 2, 2, 1, 4, 0, 1, 1, 2, 2, 2, 0, 1, 3, 4, 4, 4, 3, 4, 4, 4, 3, 0, 2, 3, 1, 4, 3, 3, 4, 0, 4, 4, 1, 0, 2, 3, 1, 1, 0, 2, 3, 3, 2, 0, 0, 1, 2, 1, 4, 3, 4, 0, 3, 2, 0, 0, 2, 3, 2, 4, 4, 1, 1, 2, 3, 2, 4, 0, 1, 3, 0, 1, 2, 3, 4, 4, 3, 1, 3, 4, 3, 1, 4, 2, 0, 2, 0, 4, 0, 1, 1, 0, 4, 1, 1, 1, 1, 4, 0, 0, 2, 0, 2, 2, 0, 2, 0, 3, 4, 3, 2, 4, 1, 4, 3, 2, 1, 1, 1, 3, 1, 3, 1, 2, 2, 2, 2, 3, 1, 0, 1, 4, 3, 2, 0, 3, 3, 1, 2, 2, 0, 0, 2, 2, 1, 1, 4, 0, 0, 2, 1, 3, 1, 3, 0, 4, 2, 1, 4, 0]\n",
      "[4, 2, 2, 0, 0, 4, 3, 4, 3, 4, 4, 4, 3, 3, 4, 4, 3, 2, 4, 0, 2, 4, 0, 0, 2, 0, 2, 3, 0, 2, 3, 2, 3, 2, 2, 2, 2, 3, 0, 4, 4, 4, 2, 3, 0, 0, 2, 0, 2, 3, 3, 0, 4, 4, 4, 4, 2, 4, 4, 4, 0, 0, 3, 2, 0, 4, 4, 0, 4, 4, 4, 0, 3, 4, 4, 4, 2, 3, 3, 4, 4, 0, 4, 4, 0, 2, 4, 0, 3, 2, 2, 3, 4, 4, 4, 0, 3, 4, 4, 2, 2, 0, 0, 4, 3, 2, 4, 4, 0, 4, 0, 3, 4, 4, 2, 3, 3, 3, 4, 4, 3, 3, 2, 4, 2, 4, 4, 4, 4, 2, 2, 3, 2, 4, 4, 3, 4, 4, 4, 4, 4, 2, 3, 0, 0, 4, 3, 2, 3, 3, 4, 0, 2, 4, 0, 3, 4, 4, 2, 0, 4, 3, 2, 0, 4, 0, 4, 4, 0, 2, 3, 2, 4, 4, 0, 2, 2, 4, 3, 4, 2, 2, 3, 4, 4, 2, 2, 4, 0, 4, 2, 4, 4, 2, 2, 4, 3, 4, 4, 4, 3, 4, 0, 0, 2, 4, 0, 4, 4, 2, 2, 2, 4, 2, 4, 2, 3, 2, 3, 4, 3, 0, 4, 3, 0, 2, 4, 3, 3, 3, 2, 4, 2, 4, 4, 4, 4, 2, 3, 0, 3, 0, 0, 4, 4, 4, 4, 4, 3, 4, 0, 3, 4, 0, 4, 0, 2, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4, 0, 2, 0, 4, 4, 2, 4, 0, 2, 0, 4, 4, 4, 2, 2, 2, 0, 4, 0, 4, 4, 4, 4, 4, 4, 2, 0, 0, 0, 2, 2, 4, 2, 4, 4, 0, 4, 2, 0, 4, 4, 2, 0, 2, 4, 2, 0, 0, 2, 4, 3, 3, 2, 3, 3, 3, 0, 4, 4, 3, 3, 2, 3, 2, 3, 0, 2, 4, 0, 3, 2, 2, 4, 4, 2, 4, 4, 2, 2, 2, 0, 2, 4, 4, 4, 4, 3, 4, 4, 4, 4, 0, 2, 4, 4, 4, 3, 3, 4, 0, 4, 4, 4, 0, 2, 3, 3, 2, 0, 2, 3, 4, 2, 0, 0, 4, 2, 4, 4, 3, 4, 0, 3, 2, 4, 0, 2, 3, 2, 4, 4, 0, 4, 4, 4, 2, 4, 4, 4, 3, 0, 4, 2, 3, 4, 4, 3, 4, 3, 4, 3, 4, 4, 2, 2, 3, 0, 4, 0, 4, 3, 0, 4, 4, 4, 4, 2, 4, 0, 2, 2, 0, 0, 4, 0, 2, 4, 3, 4, 0, 2, 4, 4, 4, 3, 2, 2, 2, 3, 3, 3, 4, 2, 2, 2, 2, 2, 3, 4, 2, 4, 4, 3, 0, 4, 3, 3, 4, 2, 3, 2, 4, 2, 2, 4, 4, 4, 2, 0, 2, 3, 3, 4, 3, 0, 4, 2, 4, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.73      0.86      0.79       100\n",
      "           3       0.78      0.76      0.77       100\n",
      "           4       0.47      0.94      0.63       100\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.56      0.65      0.59       500\n",
      "weighted avg       0.56      0.65      0.59       500\n",
      "\n",
      "Val loss: 1.2507953196763992, Val acc: 0.654\n",
      "Epoch 3/30\n",
      "Iteration 3800 - Batch 12/1894 - Train loss: 1.108567503782419, Train acc: 0.7980769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3900 - Batch 112/1894 - Train loss: 1.1139675716383268, Train acc: 0.7881637168141593\n",
      "Iteration 4000 - Batch 212/1894 - Train loss: 1.1068451292637929, Train acc: 0.7953345070422535\n",
      "Iteration 4100 - Batch 312/1894 - Train loss: 1.10423158285336, Train acc: 0.7985223642172524\n",
      "Iteration 4200 - Batch 412/1894 - Train loss: 1.0967312583623152, Train acc: 0.8068250605326877\n",
      "Iteration 4300 - Batch 512/1894 - Train loss: 1.0968972707120066, Train acc: 0.8064692982456141\n",
      "Iteration 4400 - Batch 612/1894 - Train loss: 1.096688980573931, Train acc: 0.8065864600326265\n",
      "Iteration 4500 - Batch 712/1894 - Train loss: 1.0957669758696376, Train acc: 0.8075473352033661\n",
      "Iteration 4600 - Batch 812/1894 - Train loss: 1.0942235403541856, Train acc: 0.8091559040590406\n",
      "Iteration 4700 - Batch 912/1894 - Train loss: 1.0938915052784757, Train acc: 0.8094879518072289\n",
      "Iteration 4800 - Batch 1012/1894 - Train loss: 1.0935390414513817, Train acc: 0.8098469891411648\n",
      "Iteration 4900 - Batch 1112/1894 - Train loss: 1.0926222731053883, Train acc: 0.8109838274932615\n",
      "Iteration 5000 - Batch 1212/1894 - Train loss: 1.0920128037589498, Train acc: 0.8114437345424568\n",
      "Iteration 5100 - Batch 1312/1894 - Train loss: 1.092195674969963, Train acc: 0.8112623762376238\n",
      "Iteration 5200 - Batch 1412/1894 - Train loss: 1.0911294760977386, Train acc: 0.8123894196744516\n",
      "Iteration 5300 - Batch 1512/1894 - Train loss: 1.0893692171345148, Train acc: 0.8142556179775281\n",
      "Iteration 5400 - Batch 1612/1894 - Train loss: 1.0883011324244556, Train acc: 0.8155223186608803\n",
      "Iteration 5500 - Batch 1712/1894 - Train loss: 1.0871625499842255, Train acc: 0.8166776123759486\n",
      "Iteration 5600 - Batch 1812/1894 - Train loss: 1.086125392875682, Train acc: 0.8177744070601214\n",
      "[0, 2, 4, 4, 3, 2, 1, 3, 3, 1, 2, 0, 2, 4, 2, 2, 3, 4, 2, 0, 1, 1, 4, 3, 3, 0, 1, 0, 3, 4, 1, 1, 2, 3, 3, 0, 2, 4, 1, 2, 3, 2, 4, 0, 0, 2, 2, 1, 1, 3, 4, 3, 2, 3, 3, 1, 0, 0, 1, 0, 3, 4, 1, 4, 4, 3, 2, 1, 4, 2, 0, 0, 3, 0, 4, 4, 0, 2, 0, 1, 0, 4, 4, 2, 3, 3, 3, 4, 0, 1, 2, 3, 1, 3, 0, 0, 3, 3, 1, 3, 0, 0, 1, 0, 2, 3, 2, 4, 4, 3, 2, 0, 0, 3, 3, 2, 2, 4, 3, 0, 4, 1, 4, 4, 2, 1, 3, 0, 2, 4, 1, 0, 0, 2, 4, 1, 1, 0, 2, 4, 1, 2, 1, 4, 3, 1, 3, 3, 1, 4, 0, 3, 3, 1, 2, 1, 3, 3, 2, 0, 1, 1, 4, 4, 1, 0, 1, 2, 3, 4, 2, 1, 0, 1, 1, 0, 1, 1, 1, 3, 0, 1, 0, 0, 4, 3, 4, 3, 0, 0, 0, 4, 3, 2, 3, 0, 2, 3, 4, 3, 1, 2, 3, 2, 3, 4, 1, 0, 3, 3, 2, 2, 3, 1, 2, 0, 4, 0, 1, 0, 2, 4, 3, 0, 3, 2, 2, 1, 4, 4, 3, 3, 4, 1, 2, 1, 3, 0, 4, 0, 2, 4, 4, 2, 1, 1, 3, 3, 0, 0, 3, 0, 4, 1, 4, 2, 2, 3, 1, 4, 4, 2, 3, 2, 4, 2, 2, 3, 4, 3, 4, 2, 3, 0, 2, 1, 4, 3, 1, 2, 2, 0, 3, 1, 1, 0, 1, 2, 2, 1, 4, 1, 2, 1, 2, 0, 4, 4, 4, 3, 1, 0, 4, 4, 0, 4, 4, 3, 4, 1, 0, 0, 1, 3, 3, 0, 2, 2, 2, 2, 1, 2, 3, 2, 0, 0, 0, 4, 3, 1, 1, 4, 3, 1, 0, 4, 4, 4, 0, 1, 4, 2, 3, 3, 2, 4, 2, 1, 1, 1, 4, 4, 1, 0, 0, 1, 0, 1, 3, 4, 2, 0, 4, 1, 4, 0, 3, 4, 3, 1, 2, 1, 0, 0, 3, 2, 4, 3, 2, 3, 4, 3, 1, 1, 3, 1, 3, 2, 2, 1, 2, 4, 0, 0, 1, 0, 4, 2, 1, 0, 1, 4, 1, 4, 4, 0, 0, 2, 3, 4, 3, 0, 1, 0, 3, 0, 1, 4, 3, 0, 4, 1, 1, 0, 4, 4, 1, 2, 0, 4, 1, 0, 2, 2, 2, 4, 2, 1, 2, 1, 2, 4, 2, 4, 2, 4, 0, 2, 4, 1, 0, 2, 1, 1, 0, 2, 0, 0, 0, 3, 3, 2, 2, 3, 3, 0, 2, 3, 1, 0, 3, 1, 3, 3, 1, 2, 4, 0, 0, 2, 4, 3, 2, 3, 0, 2, 0, 0, 4, 3, 3, 2, 2, 4, 4, 1, 4, 0, 4, 2]\n",
      "[2, 2, 4, 4, 3, 2, 4, 3, 3, 3, 2, 0, 2, 4, 2, 2, 3, 4, 2, 0, 0, 4, 4, 3, 3, 0, 3, 0, 3, 4, 3, 3, 2, 3, 3, 0, 2, 4, 2, 2, 3, 2, 4, 0, 0, 2, 2, 4, 4, 3, 4, 3, 2, 3, 3, 4, 2, 2, 0, 0, 3, 2, 2, 4, 4, 4, 2, 4, 4, 2, 0, 0, 3, 0, 2, 4, 0, 2, 0, 3, 0, 4, 4, 0, 3, 3, 3, 4, 0, 2, 2, 3, 2, 3, 0, 0, 3, 3, 4, 3, 0, 4, 4, 0, 2, 2, 2, 4, 4, 3, 2, 2, 0, 3, 4, 2, 2, 4, 3, 0, 4, 0, 4, 4, 0, 4, 3, 0, 2, 4, 0, 0, 0, 2, 2, 2, 0, 4, 2, 4, 0, 0, 2, 4, 3, 4, 4, 4, 4, 4, 0, 3, 3, 4, 2, 4, 3, 3, 2, 0, 4, 4, 4, 4, 0, 0, 2, 2, 3, 4, 2, 2, 0, 0, 0, 2, 4, 3, 2, 3, 0, 2, 0, 0, 4, 3, 4, 3, 2, 0, 0, 4, 3, 2, 3, 2, 0, 3, 4, 3, 3, 2, 3, 2, 3, 4, 4, 0, 3, 3, 2, 2, 3, 4, 2, 0, 4, 0, 2, 0, 2, 4, 3, 0, 3, 2, 0, 4, 4, 4, 4, 4, 2, 4, 2, 3, 3, 2, 4, 0, 2, 2, 4, 2, 4, 4, 3, 3, 0, 4, 3, 2, 4, 0, 4, 2, 2, 3, 2, 4, 4, 2, 3, 2, 4, 2, 2, 4, 4, 4, 2, 2, 3, 0, 2, 3, 4, 4, 0, 2, 0, 0, 3, 0, 4, 0, 3, 2, 2, 4, 4, 4, 2, 2, 2, 0, 4, 4, 4, 3, 0, 0, 4, 4, 0, 4, 4, 3, 4, 3, 2, 2, 0, 3, 3, 0, 0, 2, 2, 2, 4, 2, 3, 3, 0, 0, 0, 2, 3, 2, 0, 4, 3, 3, 0, 2, 4, 4, 0, 4, 0, 2, 3, 3, 0, 2, 2, 3, 4, 4, 4, 4, 2, 2, 2, 2, 0, 0, 3, 4, 2, 0, 4, 2, 4, 0, 3, 2, 3, 2, 2, 3, 0, 0, 3, 2, 4, 3, 2, 3, 4, 3, 4, 3, 3, 4, 3, 2, 0, 4, 2, 4, 0, 2, 4, 2, 4, 2, 0, 2, 2, 4, 4, 4, 4, 4, 0, 2, 3, 4, 0, 0, 4, 0, 3, 2, 3, 4, 4, 0, 2, 2, 4, 0, 4, 4, 4, 2, 0, 4, 0, 0, 2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 3, 2, 4, 0, 2, 4, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 3, 3, 2, 2, 3, 3, 4, 2, 3, 3, 0, 4, 0, 3, 3, 4, 2, 4, 0, 0, 2, 4, 3, 3, 3, 0, 2, 4, 2, 2, 4, 3, 2, 3, 4, 4, 4, 4, 0, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.62      0.88      0.72       100\n",
      "           3       0.80      0.86      0.83       100\n",
      "           4       0.59      0.86      0.70       100\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.54      0.67      0.60       500\n",
      "weighted avg       0.54      0.67      0.60       500\n",
      "\n",
      "Val loss: 1.236380621790886, Val acc: 0.668\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5700 - Batch 18/1894 - Train loss: 1.0791457577755577, Train acc: 0.8240131578947368\n",
      "Iteration 5800 - Batch 118/1894 - Train loss: 1.0829231148006535, Train acc: 0.8216911764705882\n",
      "Iteration 5900 - Batch 218/1894 - Train loss: 1.0767402618987376, Train acc: 0.826769406392694\n",
      "Iteration 6000 - Batch 318/1894 - Train loss: 1.0749829673094435, Train acc: 0.8286637931034483\n",
      "Iteration 6100 - Batch 418/1894 - Train loss: 1.07460559822779, Train acc: 0.8288335322195705\n",
      "Iteration 6200 - Batch 518/1894 - Train loss: 1.073859986427432, Train acc: 0.8297206165703276\n",
      "Iteration 6300 - Batch 618/1894 - Train loss: 1.0737108758655234, Train acc: 0.8297657512116317\n",
      "Iteration 6400 - Batch 718/1894 - Train loss: 1.075353080440463, Train acc: 0.8278859527121002\n",
      "Iteration 6500 - Batch 818/1894 - Train loss: 1.0740358526016767, Train acc: 0.8294032356532357\n",
      "Iteration 6600 - Batch 918/1894 - Train loss: 1.0729114769332686, Train acc: 0.8305223068552775\n",
      "Iteration 6700 - Batch 1018/1894 - Train loss: 1.0716497023042448, Train acc: 0.8316670755642787\n",
      "Iteration 6800 - Batch 1118/1894 - Train loss: 1.0710938246363078, Train acc: 0.8323279714030384\n",
      "Iteration 6900 - Batch 1218/1894 - Train loss: 1.0709180315563775, Train acc: 0.8324958982772764\n",
      "Iteration 7000 - Batch 1318/1894 - Train loss: 1.0702357250149273, Train acc: 0.8332780515542078\n",
      "Iteration 7100 - Batch 1418/1894 - Train loss: 1.070755901472765, Train acc: 0.8326726568005638\n",
      "Iteration 7200 - Batch 1518/1894 - Train loss: 1.0706125122689354, Train acc: 0.8328258722843976\n",
      "Iteration 7300 - Batch 1618/1894 - Train loss: 1.070191610956575, Train acc: 0.8332882952439777\n",
      "Iteration 7400 - Batch 1718/1894 - Train loss: 1.069903821359893, Train acc: 0.8335333042466551\n",
      "Iteration 7500 - Batch 1818/1894 - Train loss: 1.0693558499733127, Train acc: 0.8340434304562947\n",
      "[1, 1, 4, 2, 0, 3, 3, 2, 3, 3, 4, 0, 2, 1, 3, 2, 4, 3, 0, 4, 3, 0, 2, 2, 0, 4, 3, 2, 1, 0, 4, 0, 1, 3, 1, 1, 4, 1, 1, 4, 4, 2, 0, 4, 3, 2, 2, 2, 4, 4, 1, 0, 1, 2, 3, 4, 0, 0, 4, 2, 0, 4, 3, 1, 0, 4, 0, 2, 1, 4, 0, 0, 1, 3, 0, 1, 0, 2, 4, 0, 1, 2, 2, 2, 0, 3, 2, 4, 0, 3, 1, 4, 0, 2, 0, 0, 0, 0, 4, 4, 0, 4, 1, 2, 4, 1, 3, 3, 2, 0, 2, 2, 4, 0, 1, 0, 3, 3, 1, 0, 2, 0, 1, 3, 2, 1, 0, 4, 1, 4, 0, 1, 1, 0, 2, 0, 2, 2, 1, 1, 3, 1, 1, 1, 3, 3, 3, 3, 0, 1, 1, 0, 3, 2, 3, 3, 2, 3, 0, 3, 1, 4, 1, 0, 3, 1, 3, 0, 3, 1, 0, 2, 4, 3, 4, 1, 3, 2, 4, 4, 1, 0, 1, 4, 3, 2, 1, 3, 2, 3, 3, 1, 4, 2, 2, 1, 3, 3, 1, 2, 2, 4, 1, 4, 4, 2, 1, 3, 3, 2, 0, 0, 4, 2, 1, 0, 2, 2, 0, 4, 3, 3, 1, 4, 3, 4, 2, 0, 4, 4, 0, 0, 4, 0, 3, 4, 1, 3, 0, 4, 0, 3, 3, 0, 4, 4, 2, 2, 3, 4, 2, 4, 4, 3, 0, 2, 0, 4, 2, 3, 2, 2, 2, 3, 4, 2, 4, 4, 1, 0, 3, 1, 4, 3, 1, 3, 2, 2, 1, 1, 3, 1, 3, 3, 4, 1, 0, 0, 2, 4, 4, 2, 1, 1, 4, 1, 0, 4, 1, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 0, 4, 4, 3, 3, 0, 1, 2, 1, 3, 4, 1, 3, 0, 2, 4, 2, 3, 2, 2, 2, 2, 4, 4, 4, 3, 0, 0, 3, 4, 2, 1, 3, 3, 1, 4, 4, 4, 1, 3, 3, 0, 3, 3, 3, 1, 1, 0, 0, 4, 2, 0, 3, 3, 0, 3, 2, 4, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 1, 4, 0, 3, 0, 1, 2, 3, 2, 4, 2, 2, 4, 0, 1, 4, 1, 0, 4, 2, 0, 2, 4, 2, 0, 2, 1, 4, 2, 0, 0, 2, 2, 1, 2, 0, 4, 0, 4, 3, 4, 2, 0, 1, 4, 3, 0, 4, 1, 4, 0, 2, 4, 0, 4, 1, 3, 4, 2, 2, 1, 2, 1, 2, 0, 4, 0, 0, 1, 1, 1, 0, 0, 4, 1, 3, 1, 3, 0, 2, 2, 0, 4, 1, 3, 4, 1, 3, 3, 0, 4, 2, 0, 2, 4, 1, 2, 3, 4, 3, 1, 3, 2, 0, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 4, 3, 0, 4, 1, 4, 1]\n",
      "[3, 4, 4, 2, 0, 3, 3, 2, 3, 3, 4, 0, 2, 3, 4, 2, 4, 3, 0, 4, 3, 2, 2, 2, 0, 4, 3, 2, 4, 3, 4, 0, 0, 3, 0, 3, 4, 4, 4, 2, 4, 2, 0, 4, 3, 2, 2, 0, 4, 4, 3, 0, 4, 2, 3, 3, 2, 0, 4, 2, 0, 4, 3, 3, 0, 4, 2, 2, 2, 4, 0, 0, 2, 3, 0, 3, 0, 0, 3, 0, 2, 0, 2, 2, 2, 3, 2, 4, 0, 3, 4, 4, 0, 2, 2, 2, 0, 0, 4, 4, 2, 0, 4, 2, 4, 2, 3, 3, 2, 4, 2, 2, 4, 2, 3, 0, 3, 3, 4, 0, 2, 0, 4, 3, 2, 3, 0, 4, 0, 4, 0, 0, 0, 0, 2, 0, 0, 2, 3, 4, 3, 4, 2, 4, 3, 4, 3, 2, 2, 4, 3, 0, 3, 2, 3, 3, 2, 3, 0, 3, 2, 4, 4, 0, 3, 4, 3, 0, 3, 4, 4, 3, 4, 3, 4, 0, 0, 2, 4, 4, 0, 0, 4, 4, 4, 2, 4, 3, 2, 3, 3, 4, 4, 0, 0, 4, 3, 3, 2, 2, 2, 4, 4, 4, 0, 2, 4, 2, 3, 3, 0, 0, 4, 2, 4, 2, 2, 2, 0, 4, 3, 3, 3, 4, 3, 4, 2, 0, 4, 4, 0, 4, 4, 0, 3, 4, 4, 4, 0, 4, 4, 3, 3, 0, 2, 4, 2, 0, 3, 4, 2, 4, 3, 3, 0, 2, 0, 4, 2, 3, 2, 0, 0, 3, 4, 2, 4, 0, 0, 0, 3, 4, 4, 3, 3, 3, 2, 2, 4, 4, 3, 2, 3, 3, 4, 0, 2, 0, 2, 4, 4, 2, 4, 4, 2, 3, 0, 4, 4, 4, 2, 3, 3, 3, 4, 3, 4, 3, 3, 2, 3, 2, 4, 2, 3, 3, 0, 4, 2, 4, 3, 4, 2, 3, 0, 4, 4, 2, 3, 2, 0, 2, 2, 4, 4, 3, 3, 0, 0, 4, 4, 2, 4, 3, 3, 0, 4, 4, 4, 3, 3, 3, 0, 3, 3, 3, 3, 2, 2, 0, 4, 2, 0, 4, 3, 0, 3, 2, 4, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 3, 4, 0, 3, 2, 4, 2, 3, 2, 4, 0, 0, 4, 2, 4, 4, 4, 0, 4, 2, 4, 2, 4, 2, 0, 2, 4, 4, 2, 0, 0, 2, 2, 4, 2, 0, 4, 0, 4, 3, 4, 2, 0, 4, 4, 3, 0, 4, 0, 2, 0, 2, 3, 0, 0, 4, 3, 4, 4, 2, 4, 2, 3, 2, 0, 4, 0, 0, 3, 0, 4, 2, 0, 4, 2, 4, 4, 4, 0, 2, 2, 0, 4, 4, 3, 4, 3, 3, 4, 0, 4, 2, 0, 2, 4, 0, 2, 3, 4, 3, 3, 3, 2, 0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 0, 4, 3, 0, 4, 0, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.78      0.73       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.68      0.83      0.75       100\n",
      "           3       0.75      0.85      0.79       100\n",
      "           4       0.57      0.86      0.69       100\n",
      "\n",
      "    accuracy                           0.66       500\n",
      "   macro avg       0.54      0.66      0.59       500\n",
      "weighted avg       0.54      0.66      0.59       500\n",
      "\n",
      "Val loss: 1.2343676313757896, Val acc: 0.664\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7600 - Batch 24/1894 - Train loss: 1.0680922627449037, Train acc: 0.8375\n",
      "Iteration 7700 - Batch 124/1894 - Train loss: 1.0636423959732055, Train acc: 0.84075\n",
      "Iteration 7800 - Batch 224/1894 - Train loss: 1.067224707338545, Train acc: 0.8366666666666667\n",
      "Iteration 7900 - Batch 324/1894 - Train loss: 1.0647209864396316, Train acc: 0.8391346153846154\n",
      "Iteration 8000 - Batch 424/1894 - Train loss: 1.0672317479638493, Train acc: 0.8363970588235294\n",
      "Iteration 8100 - Batch 524/1894 - Train loss: 1.0645252756845383, Train acc: 0.8394642857142857\n",
      "Iteration 8200 - Batch 624/1894 - Train loss: 1.063549420928955, Train acc: 0.84075\n",
      "Iteration 8300 - Batch 724/1894 - Train loss: 1.0640994644987172, Train acc: 0.8396120689655172\n",
      "Iteration 8400 - Batch 824/1894 - Train loss: 1.063761878374851, Train acc: 0.8396969696969697\n",
      "Iteration 8500 - Batch 924/1894 - Train loss: 1.0628064105961774, Train acc: 0.8408108108108108\n",
      "Iteration 8600 - Batch 1024/1894 - Train loss: 1.0639388397844827, Train acc: 0.8396341463414634\n",
      "Iteration 8700 - Batch 1124/1894 - Train loss: 1.0646350547472636, Train acc: 0.8390555555555556\n",
      "Iteration 8800 - Batch 1224/1894 - Train loss: 1.0648448911005137, Train acc: 0.8390306122448979\n",
      "Iteration 8900 - Batch 1324/1894 - Train loss: 1.0649391740672993, Train acc: 0.8388679245283018\n",
      "Iteration 9000 - Batch 1424/1894 - Train loss: 1.0643462022563868, Train acc: 0.839561403508772\n",
      "Iteration 9100 - Batch 1524/1894 - Train loss: 1.0634535211031555, Train acc: 0.8404303278688524\n",
      "Iteration 9200 - Batch 1624/1894 - Train loss: 1.0626715210034297, Train acc: 0.8411923076923077\n",
      "Iteration 9300 - Batch 1724/1894 - Train loss: 1.0625403797799262, Train acc: 0.841231884057971\n",
      "Iteration 9400 - Batch 1824/1894 - Train loss: 1.0623380308935086, Train acc: 0.8414554794520548\n",
      "[0, 3, 1, 0, 0, 0, 4, 0, 2, 2, 4, 3, 1, 0, 4, 2, 2, 4, 1, 4, 0, 1, 0, 2, 4, 0, 3, 0, 4, 2, 4, 1, 1, 3, 0, 1, 0, 4, 0, 4, 2, 2, 4, 2, 2, 1, 1, 2, 3, 1, 0, 1, 2, 0, 3, 1, 3, 2, 4, 1, 3, 3, 2, 4, 4, 4, 2, 2, 0, 1, 2, 1, 2, 2, 3, 1, 1, 4, 0, 4, 3, 1, 3, 3, 4, 4, 2, 3, 0, 0, 2, 1, 1, 0, 2, 2, 1, 0, 0, 3, 4, 2, 0, 2, 4, 1, 1, 3, 0, 1, 0, 4, 3, 0, 0, 1, 3, 2, 4, 0, 2, 0, 1, 1, 2, 3, 2, 1, 2, 1, 2, 1, 4, 4, 0, 2, 0, 4, 2, 0, 3, 3, 4, 4, 1, 3, 0, 0, 4, 1, 0, 3, 2, 1, 4, 3, 3, 4, 3, 3, 1, 2, 4, 3, 4, 0, 4, 2, 3, 1, 1, 3, 2, 4, 0, 0, 3, 1, 0, 1, 2, 3, 0, 1, 3, 0, 4, 0, 3, 1, 2, 0, 1, 4, 4, 0, 2, 0, 2, 1, 0, 0, 2, 1, 0, 3, 0, 0, 3, 3, 1, 4, 2, 2, 1, 0, 1, 2, 1, 2, 1, 3, 3, 4, 2, 0, 3, 4, 0, 4, 3, 0, 3, 2, 2, 0, 2, 2, 1, 0, 3, 4, 3, 4, 4, 4, 3, 1, 0, 3, 2, 4, 2, 3, 2, 4, 3, 0, 4, 1, 0, 4, 2, 4, 4, 1, 1, 3, 3, 3, 0, 1, 0, 1, 2, 2, 4, 2, 2, 3, 2, 4, 4, 3, 2, 0, 0, 0, 3, 4, 3, 3, 2, 3, 1, 1, 1, 4, 0, 1, 1, 3, 4, 1, 3, 4, 3, 2, 3, 0, 0, 2, 2, 3, 2, 1, 1, 1, 2, 3, 1, 0, 1, 0, 2, 2, 3, 4, 4, 1, 4, 1, 3, 3, 1, 4, 3, 0, 2, 0, 3, 0, 4, 0, 2, 2, 2, 3, 4, 3, 1, 4, 4, 0, 0, 1, 4, 1, 4, 3, 1, 2, 0, 3, 3, 3, 4, 3, 3, 1, 4, 3, 2, 3, 2, 0, 4, 2, 4, 0, 1, 3, 1, 4, 2, 1, 0, 1, 1, 1, 3, 4, 1, 3, 2, 4, 1, 4, 0, 4, 1, 1, 4, 2, 4, 3, 1, 2, 2, 0, 3, 1, 0, 1, 4, 0, 0, 0, 2, 0, 0, 1, 2, 3, 4, 3, 3, 4, 2, 2, 2, 4, 4, 4, 2, 3, 4, 3, 1, 2, 0, 4, 2, 0, 1, 4, 4, 0, 4, 0, 0, 4, 0, 4, 1, 2, 4, 0, 1, 1, 3, 4, 2, 4, 3, 3, 0, 3, 3, 4, 3, 4, 4, 1, 3, 2, 3, 2, 3, 1, 3, 3, 1, 0, 4, 0, 0, 1, 2, 2, 2, 3, 2, 1, 1, 0, 2, 1, 2, 0]\n",
      "[0, 3, 2, 0, 0, 0, 4, 0, 2, 2, 4, 3, 3, 0, 4, 2, 0, 4, 0, 4, 0, 4, 0, 2, 4, 0, 3, 4, 4, 2, 4, 4, 2, 3, 0, 4, 4, 4, 0, 4, 2, 2, 4, 2, 2, 3, 4, 2, 3, 0, 0, 4, 3, 0, 3, 2, 3, 2, 4, 2, 3, 3, 2, 4, 4, 4, 2, 2, 0, 4, 2, 4, 4, 2, 3, 3, 3, 4, 0, 4, 4, 4, 3, 3, 3, 4, 2, 3, 0, 0, 2, 0, 4, 0, 2, 2, 4, 0, 0, 3, 4, 2, 0, 2, 3, 3, 0, 3, 4, 3, 0, 4, 3, 0, 0, 4, 3, 2, 4, 0, 2, 2, 2, 4, 2, 3, 2, 0, 0, 3, 2, 3, 4, 4, 0, 2, 0, 4, 0, 4, 3, 3, 4, 4, 4, 4, 0, 0, 4, 4, 0, 4, 0, 3, 4, 3, 3, 2, 3, 3, 4, 2, 4, 3, 3, 0, 4, 2, 3, 3, 3, 3, 2, 4, 0, 0, 3, 2, 0, 4, 2, 3, 0, 4, 3, 0, 4, 0, 3, 4, 2, 4, 4, 4, 3, 0, 0, 0, 0, 3, 0, 0, 2, 3, 0, 3, 0, 0, 3, 3, 4, 4, 2, 2, 4, 4, 4, 2, 0, 2, 2, 3, 3, 4, 4, 4, 3, 4, 0, 4, 3, 0, 3, 2, 2, 0, 2, 0, 4, 0, 3, 4, 3, 4, 4, 4, 3, 4, 0, 3, 2, 4, 2, 3, 2, 4, 3, 0, 4, 4, 0, 4, 2, 4, 4, 4, 0, 3, 3, 3, 4, 4, 0, 3, 2, 0, 4, 2, 2, 3, 2, 4, 4, 3, 3, 0, 0, 0, 3, 4, 3, 3, 2, 4, 4, 3, 4, 4, 0, 4, 4, 3, 4, 4, 3, 3, 3, 2, 3, 0, 0, 2, 2, 3, 4, 4, 3, 4, 2, 4, 3, 0, 4, 0, 0, 2, 3, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 0, 2, 0, 4, 0, 4, 0, 0, 2, 2, 3, 4, 3, 4, 4, 4, 0, 0, 4, 4, 4, 4, 3, 3, 2, 0, 4, 0, 3, 4, 3, 3, 0, 4, 3, 4, 3, 2, 0, 4, 0, 4, 0, 0, 3, 4, 4, 3, 4, 0, 0, 3, 0, 3, 4, 4, 3, 2, 3, 4, 4, 4, 4, 4, 3, 4, 2, 4, 3, 4, 2, 2, 0, 3, 3, 0, 4, 3, 4, 0, 0, 2, 0, 2, 2, 2, 3, 4, 3, 3, 4, 2, 0, 2, 4, 4, 4, 0, 3, 4, 3, 3, 2, 0, 4, 0, 0, 4, 4, 4, 0, 4, 0, 0, 3, 4, 4, 4, 2, 4, 0, 3, 4, 3, 4, 2, 4, 2, 3, 0, 3, 3, 4, 3, 4, 4, 3, 3, 2, 3, 0, 3, 3, 3, 3, 3, 0, 4, 0, 0, 2, 2, 2, 0, 3, 2, 4, 4, 0, 0, 4, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.76      0.80       100\n",
      "           3       0.70      0.90      0.79       100\n",
      "           4       0.54      0.91      0.68       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.57      0.69      0.61       500\n",
      "weighted avg       0.57      0.69      0.61       500\n",
      "\n",
      "Val loss: 1.2151167318224907, Val acc: 0.686\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9500 - Batch 30/1894 - Train loss: 1.0576605181540213, Train acc: 0.8497983870967742\n",
      "Iteration 9600 - Batch 130/1894 - Train loss: 1.0562096065237323, Train acc: 0.8475667938931297\n",
      "Iteration 9700 - Batch 230/1894 - Train loss: 1.0603498883577653, Train acc: 0.8429383116883117\n",
      "Iteration 9800 - Batch 330/1894 - Train loss: 1.0576868795556245, Train acc: 0.8454493957703928\n",
      "Iteration 9900 - Batch 430/1894 - Train loss: 1.0589671112821717, Train acc: 0.8441850348027842\n",
      "Iteration 10000 - Batch 530/1894 - Train loss: 1.057980655725842, Train acc: 0.845162429378531\n",
      "Iteration 10100 - Batch 630/1894 - Train loss: 1.057822434535684, Train acc: 0.8453843106180665\n",
      "Iteration 10200 - Batch 730/1894 - Train loss: 1.0599881828891269, Train acc: 0.842937756497948\n",
      "Iteration 10300 - Batch 830/1894 - Train loss: 1.059031387026703, Train acc: 0.8442012635379061\n",
      "Iteration 10400 - Batch 930/1894 - Train loss: 1.0589088131098434, Train acc: 0.844421321160043\n",
      "Iteration 10500 - Batch 1030/1894 - Train loss: 1.0583121243549942, Train acc: 0.845144277400582\n",
      "Iteration 10600 - Batch 1130/1894 - Train loss: 1.0580437754657182, Train acc: 0.8454907161803713\n",
      "Iteration 10700 - Batch 1230/1894 - Train loss: 1.057764549356084, Train acc: 0.8456539398862714\n",
      "Iteration 10800 - Batch 1330/1894 - Train loss: 1.0582666560548486, Train acc: 0.8452761081893313\n",
      "Iteration 10900 - Batch 1430/1894 - Train loss: 1.0575842456664346, Train acc: 0.8459993011879804\n",
      "Iteration 11000 - Batch 1530/1894 - Train loss: 1.0577380021439122, Train acc: 0.8459136185499674\n",
      "Iteration 11100 - Batch 1630/1894 - Train loss: 1.0572120014836202, Train acc: 0.846470723482526\n",
      "Iteration 11200 - Batch 1730/1894 - Train loss: 1.0572867067751341, Train acc: 0.8464579722703639\n",
      "Iteration 11300 - Batch 1830/1894 - Train loss: 1.0565438516344416, Train acc: 0.8472317039868924\n",
      "[1, 1, 2, 2, 4, 4, 1, 4, 1, 1, 4, 1, 0, 0, 2, 2, 3, 3, 1, 0, 3, 4, 1, 0, 3, 2, 1, 2, 1, 2, 1, 4, 3, 0, 3, 0, 0, 4, 0, 3, 2, 2, 3, 3, 4, 3, 0, 2, 0, 4, 4, 1, 1, 2, 4, 3, 0, 0, 4, 2, 4, 1, 4, 1, 1, 3, 3, 0, 4, 3, 4, 1, 3, 3, 3, 3, 0, 3, 2, 0, 1, 3, 2, 0, 4, 2, 3, 4, 2, 3, 1, 2, 0, 4, 1, 4, 2, 1, 4, 2, 2, 1, 2, 0, 4, 0, 2, 0, 3, 1, 4, 4, 1, 0, 3, 1, 4, 2, 2, 3, 0, 3, 2, 2, 2, 3, 2, 4, 2, 3, 2, 3, 2, 4, 1, 4, 2, 4, 3, 4, 0, 4, 3, 2, 1, 1, 3, 0, 0, 4, 1, 0, 2, 2, 3, 4, 1, 3, 4, 0, 1, 3, 3, 2, 4, 2, 1, 3, 3, 0, 4, 3, 4, 0, 0, 2, 0, 2, 2, 4, 0, 3, 3, 4, 0, 3, 3, 1, 0, 1, 0, 3, 2, 3, 4, 2, 4, 4, 2, 0, 1, 3, 4, 1, 1, 4, 1, 1, 2, 1, 1, 0, 2, 4, 1, 1, 2, 0, 1, 1, 1, 4, 1, 4, 2, 4, 1, 0, 0, 2, 1, 1, 4, 4, 1, 3, 2, 0, 1, 2, 3, 2, 4, 1, 1, 2, 2, 0, 2, 2, 4, 0, 0, 1, 4, 3, 4, 0, 2, 2, 4, 4, 3, 3, 1, 2, 4, 0, 1, 1, 0, 0, 0, 3, 3, 3, 1, 4, 1, 2, 3, 4, 1, 4, 4, 2, 1, 0, 3, 1, 3, 2, 0, 3, 4, 0, 1, 0, 2, 2, 4, 4, 3, 3, 1, 2, 0, 4, 4, 3, 1, 2, 0, 0, 0, 3, 1, 2, 4, 0, 0, 2, 0, 0, 1, 1, 4, 3, 2, 0, 2, 2, 4, 2, 4, 3, 3, 2, 1, 4, 0, 3, 1, 3, 3, 2, 0, 3, 3, 1, 4, 0, 2, 0, 2, 3, 0, 3, 4, 2, 0, 3, 0, 4, 1, 2, 2, 4, 0, 1, 3, 3, 0, 3, 1, 4, 0, 3, 4, 4, 1, 2, 4, 1, 0, 0, 0, 3, 0, 1, 4, 2, 3, 3, 3, 0, 2, 0, 3, 4, 3, 2, 3, 4, 0, 2, 3, 2, 0, 0, 4, 2, 0, 1, 4, 1, 0, 0, 2, 2, 3, 3, 0, 0, 2, 4, 1, 3, 0, 2, 2, 1, 0, 4, 2, 2, 0, 2, 1, 3, 1, 1, 1, 4, 3, 4, 4, 2, 1, 3, 4, 3, 1, 4, 1, 0, 3, 3, 0, 4, 3, 4, 1, 2, 2, 4, 3, 4, 0, 0, 1, 0, 1, 2, 0, 4, 1, 3, 1, 0, 3, 1, 4, 2, 4, 0, 0, 3, 4, 1, 0, 1, 1, 1, 0, 4, 2, 2, 3, 1]\n",
      "[3, 2, 2, 0, 4, 4, 4, 4, 4, 4, 4, 3, 0, 0, 2, 2, 3, 3, 3, 0, 3, 4, 3, 0, 3, 2, 4, 2, 0, 2, 4, 4, 3, 0, 3, 0, 0, 4, 0, 3, 2, 2, 3, 3, 4, 3, 0, 2, 0, 4, 4, 4, 0, 2, 4, 3, 0, 0, 4, 2, 4, 0, 4, 3, 4, 3, 3, 0, 4, 3, 4, 0, 3, 3, 3, 3, 0, 3, 3, 0, 4, 3, 2, 0, 4, 2, 3, 4, 2, 3, 3, 2, 0, 3, 4, 4, 2, 0, 4, 2, 2, 4, 0, 0, 4, 0, 0, 0, 3, 4, 4, 4, 4, 0, 3, 4, 4, 2, 2, 3, 0, 0, 2, 2, 2, 3, 2, 4, 2, 3, 2, 3, 2, 4, 0, 3, 2, 4, 4, 4, 0, 4, 3, 2, 0, 4, 4, 4, 0, 4, 2, 2, 0, 2, 3, 0, 2, 3, 4, 0, 0, 3, 3, 3, 4, 2, 3, 3, 3, 0, 3, 3, 4, 0, 0, 3, 0, 0, 2, 4, 0, 3, 3, 4, 0, 3, 3, 4, 0, 3, 0, 3, 2, 3, 4, 2, 4, 4, 0, 0, 4, 3, 4, 3, 2, 4, 0, 3, 2, 3, 0, 0, 2, 4, 3, 4, 2, 0, 0, 0, 0, 4, 4, 4, 2, 4, 4, 0, 0, 0, 3, 4, 4, 4, 3, 3, 2, 0, 4, 2, 3, 2, 4, 4, 2, 2, 2, 0, 2, 2, 4, 0, 0, 4, 4, 3, 4, 0, 2, 0, 4, 4, 3, 3, 4, 2, 4, 0, 0, 0, 0, 0, 0, 3, 3, 4, 4, 4, 4, 2, 3, 4, 0, 3, 0, 2, 4, 0, 3, 3, 3, 2, 0, 3, 4, 0, 4, 0, 2, 2, 4, 0, 3, 3, 3, 2, 0, 3, 4, 3, 2, 0, 0, 0, 4, 3, 4, 2, 2, 0, 0, 0, 0, 0, 4, 4, 4, 3, 0, 4, 3, 0, 4, 2, 2, 3, 3, 2, 4, 4, 0, 3, 0, 3, 3, 0, 0, 3, 3, 4, 3, 0, 0, 0, 2, 3, 0, 3, 3, 2, 0, 3, 0, 4, 4, 2, 2, 4, 0, 3, 3, 3, 0, 3, 3, 4, 0, 3, 4, 4, 0, 2, 4, 4, 0, 4, 0, 3, 0, 4, 4, 2, 3, 3, 2, 0, 0, 0, 3, 4, 3, 2, 3, 4, 0, 2, 3, 2, 0, 0, 4, 0, 0, 4, 4, 4, 0, 0, 2, 2, 3, 3, 0, 0, 2, 4, 3, 3, 0, 2, 2, 3, 0, 4, 2, 2, 2, 2, 4, 3, 3, 4, 0, 3, 3, 4, 3, 2, 2, 3, 4, 3, 3, 2, 4, 0, 3, 3, 0, 4, 4, 4, 4, 0, 0, 4, 3, 4, 0, 0, 4, 0, 0, 2, 0, 4, 4, 3, 0, 0, 3, 2, 4, 2, 4, 0, 0, 3, 4, 3, 0, 2, 3, 4, 0, 4, 2, 2, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.84      0.78      0.81       100\n",
      "           3       0.71      0.94      0.81       100\n",
      "           4       0.62      0.85      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2011206299066544, Val acc: 0.702\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11400 - Batch 36/1894 - Train loss: 1.0561247725744505, Train acc: 0.8471283783783784\n",
      "Iteration 11500 - Batch 136/1894 - Train loss: 1.0434593893315671, Train acc: 0.8606295620437956\n",
      "Iteration 11600 - Batch 236/1894 - Train loss: 1.0495899045517676, Train acc: 0.8540348101265823\n",
      "Iteration 11700 - Batch 336/1894 - Train loss: 1.0496237734305045, Train acc: 0.8542284866468842\n",
      "Iteration 11800 - Batch 436/1894 - Train loss: 1.0523400209861162, Train acc: 0.8514731121281465\n",
      "Iteration 11900 - Batch 536/1894 - Train loss: 1.0545134160327734, Train acc: 0.8495693668528864\n",
      "Iteration 12000 - Batch 636/1894 - Train loss: 1.0542113605997814, Train acc: 0.8499313186813187\n",
      "Iteration 12100 - Batch 736/1894 - Train loss: 1.0535090735518302, Train acc: 0.8505766621438263\n",
      "Iteration 12200 - Batch 836/1894 - Train loss: 1.0535641791857557, Train acc: 0.8504330943847073\n",
      "Iteration 12300 - Batch 936/1894 - Train loss: 1.0538603269684912, Train acc: 0.8500867129135539\n",
      "Iteration 12400 - Batch 1036/1894 - Train loss: 1.053811504847748, Train acc: 0.8501386210221794\n",
      "Iteration 12500 - Batch 1136/1894 - Train loss: 1.0532890467027247, Train acc: 0.8507036059806509\n",
      "Iteration 12600 - Batch 1236/1894 - Train loss: 1.0526422299294098, Train acc: 0.8514551333872271\n",
      "Iteration 12700 - Batch 1336/1894 - Train loss: 1.0521568839195155, Train acc: 0.8520241211667913\n",
      "Iteration 12800 - Batch 1436/1894 - Train loss: 1.0517030161706291, Train acc: 0.8525139178844816\n",
      "Iteration 12900 - Batch 1536/1894 - Train loss: 1.0520398413972103, Train acc: 0.8522690305790501\n",
      "Iteration 13000 - Batch 1636/1894 - Train loss: 1.0513730234828895, Train acc: 0.852970372632865\n",
      "Iteration 13100 - Batch 1736/1894 - Train loss: 1.051609125711071, Train acc: 0.8527094127806563\n",
      "Iteration 13200 - Batch 1836/1894 - Train loss: 1.051053060061528, Train acc: 0.8532764017419706\n",
      "[2, 4, 1, 2, 0, 3, 2, 3, 3, 0, 0, 4, 0, 0, 0, 1, 2, 1, 4, 4, 1, 1, 2, 1, 3, 3, 3, 4, 0, 2, 0, 4, 0, 0, 4, 2, 3, 0, 3, 0, 2, 0, 2, 3, 2, 1, 4, 1, 4, 1, 2, 0, 1, 1, 1, 3, 4, 2, 1, 2, 2, 0, 2, 4, 3, 3, 0, 4, 4, 2, 1, 0, 4, 3, 3, 0, 1, 3, 0, 2, 2, 2, 2, 3, 2, 3, 1, 0, 1, 1, 3, 2, 3, 2, 2, 4, 0, 4, 3, 4, 0, 4, 0, 2, 3, 4, 0, 1, 1, 3, 1, 2, 3, 2, 3, 0, 1, 2, 2, 4, 1, 1, 3, 3, 2, 1, 3, 0, 4, 2, 1, 4, 3, 0, 3, 2, 2, 2, 3, 0, 0, 2, 3, 2, 2, 3, 4, 0, 3, 1, 3, 3, 3, 1, 1, 4, 0, 0, 4, 2, 2, 2, 3, 3, 1, 2, 3, 2, 2, 3, 0, 4, 2, 0, 2, 0, 1, 4, 3, 0, 4, 1, 0, 0, 3, 2, 2, 0, 3, 3, 4, 1, 4, 3, 1, 1, 4, 4, 4, 2, 1, 4, 4, 4, 2, 0, 1, 2, 2, 4, 2, 4, 0, 0, 1, 1, 2, 1, 1, 2, 3, 1, 4, 3, 4, 2, 4, 4, 4, 2, 0, 1, 0, 1, 1, 0, 0, 4, 0, 2, 4, 1, 2, 4, 2, 0, 4, 3, 0, 1, 4, 3, 0, 0, 2, 1, 0, 4, 1, 1, 3, 1, 0, 0, 2, 2, 0, 2, 0, 3, 3, 0, 2, 2, 3, 0, 4, 3, 4, 3, 3, 2, 0, 2, 2, 0, 3, 4, 3, 4, 1, 1, 3, 1, 1, 2, 4, 0, 2, 1, 4, 3, 2, 4, 2, 0, 2, 4, 0, 1, 1, 0, 3, 1, 0, 1, 0, 4, 2, 1, 3, 0, 4, 0, 0, 4, 2, 2, 4, 3, 4, 1, 4, 0, 2, 0, 3, 1, 2, 3, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 0, 4, 2, 0, 4, 4, 4, 1, 1, 1, 3, 4, 3, 3, 1, 3, 1, 2, 2, 3, 1, 1, 4, 2, 0, 1, 1, 2, 3, 3, 0, 3, 0, 2, 3, 1, 3, 2, 1, 3, 2, 0, 3, 1, 3, 3, 2, 1, 1, 0, 1, 4, 1, 4, 1, 4, 2, 1, 4, 3, 3, 0, 4, 4, 4, 3, 3, 3, 1, 3, 3, 0, 0, 1, 0, 2, 1, 4, 3, 4, 1, 3, 1, 1, 0, 4, 0, 0, 0, 0, 4, 2, 4, 4, 4, 0, 4, 4, 0, 0, 2, 2, 4, 3, 3, 4, 3, 4, 4, 1, 1, 0, 3, 0, 1, 4, 3, 3, 3, 2, 4, 4, 3, 1, 3, 0, 2, 2, 4, 4, 2, 0, 4, 4, 4, 0, 4, 3, 0, 2, 1, 1, 1, 4, 4, 3]\n",
      "[2, 4, 4, 2, 0, 4, 2, 3, 3, 2, 0, 4, 0, 0, 0, 2, 0, 0, 4, 2, 4, 4, 2, 2, 3, 0, 3, 4, 0, 2, 0, 4, 0, 0, 4, 2, 3, 0, 3, 0, 2, 4, 2, 3, 2, 4, 0, 4, 4, 4, 3, 0, 3, 3, 4, 3, 4, 2, 0, 2, 2, 0, 2, 4, 3, 3, 3, 4, 4, 2, 4, 0, 4, 3, 3, 0, 4, 3, 0, 2, 2, 2, 2, 3, 2, 4, 2, 0, 3, 4, 3, 2, 3, 2, 2, 4, 0, 2, 3, 4, 0, 4, 0, 2, 3, 2, 0, 2, 4, 3, 4, 2, 3, 2, 3, 0, 4, 2, 0, 4, 3, 3, 3, 4, 0, 4, 3, 0, 4, 2, 0, 4, 3, 2, 3, 2, 2, 2, 3, 0, 0, 2, 3, 2, 3, 3, 4, 0, 4, 3, 4, 3, 3, 3, 4, 4, 0, 0, 4, 0, 2, 2, 3, 3, 2, 2, 3, 2, 2, 3, 0, 4, 2, 0, 2, 0, 4, 4, 3, 0, 4, 3, 0, 2, 3, 2, 2, 2, 3, 3, 4, 0, 4, 4, 4, 0, 4, 4, 4, 2, 4, 4, 4, 4, 2, 0, 3, 2, 2, 4, 2, 4, 0, 0, 4, 4, 2, 4, 4, 2, 4, 3, 4, 3, 4, 2, 4, 4, 4, 2, 0, 0, 0, 4, 0, 0, 0, 4, 2, 2, 4, 4, 2, 4, 0, 0, 4, 3, 0, 3, 4, 4, 2, 0, 0, 0, 0, 4, 4, 3, 3, 2, 0, 2, 2, 2, 2, 2, 0, 3, 3, 0, 2, 2, 3, 0, 4, 3, 4, 3, 3, 2, 0, 2, 2, 0, 3, 4, 3, 4, 0, 4, 4, 4, 0, 2, 4, 2, 0, 4, 4, 3, 2, 4, 2, 0, 2, 4, 0, 3, 2, 4, 3, 0, 0, 4, 0, 4, 2, 3, 3, 0, 4, 0, 0, 4, 0, 2, 4, 4, 4, 0, 4, 0, 2, 4, 4, 4, 2, 3, 0, 0, 0, 4, 0, 0, 4, 4, 0, 0, 0, 2, 2, 3, 0, 4, 2, 0, 4, 4, 4, 2, 3, 4, 3, 3, 3, 3, 0, 3, 0, 2, 2, 3, 4, 0, 4, 0, 4, 0, 3, 2, 3, 4, 0, 3, 0, 2, 3, 2, 3, 2, 3, 3, 3, 0, 3, 2, 4, 3, 0, 4, 3, 0, 3, 4, 3, 4, 2, 4, 2, 4, 4, 3, 4, 0, 4, 4, 2, 3, 3, 3, 3, 3, 3, 2, 0, 3, 0, 2, 0, 4, 3, 4, 2, 3, 4, 3, 0, 4, 3, 2, 0, 0, 4, 2, 4, 2, 4, 0, 4, 4, 0, 0, 2, 2, 4, 3, 3, 4, 3, 4, 4, 3, 3, 0, 4, 0, 2, 4, 3, 4, 3, 2, 4, 2, 3, 4, 3, 0, 2, 2, 4, 4, 0, 0, 2, 3, 0, 0, 4, 3, 0, 2, 4, 0, 4, 4, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.83      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.73      0.85      0.78       100\n",
      "           3       0.72      0.82      0.77       100\n",
      "           4       0.59      0.89      0.71       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.55      0.68      0.60       500\n",
      "weighted avg       0.55      0.68      0.60       500\n",
      "\n",
      "Val loss: 1.2246977463364601, Val acc: 0.678\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13300 - Batch 42/1894 - Train loss: 1.0488368383673734, Train acc: 0.8553779069767442\n",
      "Iteration 13400 - Batch 142/1894 - Train loss: 1.0503737238737254, Train acc: 0.8529283216783217\n",
      "Iteration 13500 - Batch 242/1894 - Train loss: 1.0498137172357536, Train acc: 0.8541666666666666\n",
      "Iteration 13600 - Batch 342/1894 - Train loss: 1.0499318796413633, Train acc: 0.8540451895043731\n",
      "Iteration 13700 - Batch 442/1894 - Train loss: 1.0496865510940552, Train acc: 0.8541901805869074\n",
      "Iteration 13800 - Batch 542/1894 - Train loss: 1.0473437673698691, Train acc: 0.8566413443830571\n",
      "Iteration 13900 - Batch 642/1894 - Train loss: 1.0479702064260539, Train acc: 0.8560458786936236\n",
      "Iteration 14000 - Batch 742/1894 - Train loss: 1.0478295833072944, Train acc: 0.8560733512786003\n",
      "Iteration 14100 - Batch 842/1894 - Train loss: 1.0486963759679104, Train acc: 0.8551304863582444\n",
      "Iteration 14200 - Batch 942/1894 - Train loss: 1.0487154650789303, Train acc: 0.8551497879109226\n",
      "Iteration 14300 - Batch 1042/1894 - Train loss: 1.0482294326889205, Train acc: 0.8557046979865772\n",
      "Iteration 14400 - Batch 1142/1894 - Train loss: 1.0487203110964385, Train acc: 0.8552602799650044\n",
      "Iteration 14500 - Batch 1242/1894 - Train loss: 1.0493839570618597, Train acc: 0.854635961383749\n",
      "Iteration 14600 - Batch 1342/1894 - Train loss: 1.0496839058993916, Train acc: 0.85433730454207\n",
      "Iteration 14700 - Batch 1442/1894 - Train loss: 1.0491516592183712, Train acc: 0.854838011088011\n",
      "Iteration 14800 - Batch 1542/1894 - Train loss: 1.049338597758436, Train acc: 0.8546257290991575\n",
      "Iteration 14900 - Batch 1642/1894 - Train loss: 1.048901389991809, Train acc: 0.8550859707851491\n",
      "Iteration 15000 - Batch 1742/1894 - Train loss: 1.0485169757937673, Train acc: 0.8554396156052783\n",
      "Iteration 15100 - Batch 1842/1894 - Train loss: 1.0485540093511456, Train acc: 0.8553648941942485\n",
      "[2, 1, 4, 3, 4, 1, 3, 3, 1, 4, 0, 2, 2, 1, 4, 2, 4, 3, 1, 0, 2, 2, 4, 3, 1, 0, 4, 2, 0, 4, 4, 3, 0, 1, 0, 2, 0, 4, 1, 1, 0, 4, 4, 1, 3, 1, 2, 3, 1, 4, 4, 2, 3, 1, 0, 2, 1, 1, 1, 3, 1, 0, 1, 1, 1, 3, 2, 0, 1, 3, 4, 3, 3, 0, 4, 4, 0, 0, 1, 2, 0, 2, 3, 0, 0, 4, 2, 4, 0, 1, 0, 3, 3, 3, 2, 4, 3, 1, 2, 3, 3, 2, 1, 2, 3, 1, 4, 0, 0, 1, 4, 4, 1, 4, 1, 1, 1, 1, 4, 2, 3, 3, 0, 3, 2, 4, 1, 1, 2, 1, 0, 1, 4, 0, 0, 1, 4, 3, 2, 1, 1, 0, 3, 2, 1, 0, 0, 3, 1, 3, 1, 4, 2, 2, 0, 4, 1, 1, 2, 4, 4, 0, 0, 0, 0, 4, 4, 0, 2, 4, 4, 3, 1, 4, 2, 1, 0, 0, 0, 4, 1, 0, 2, 3, 2, 3, 2, 3, 3, 2, 1, 1, 1, 4, 2, 4, 3, 2, 3, 1, 2, 0, 2, 2, 3, 4, 2, 2, 4, 1, 2, 0, 1, 0, 3, 3, 1, 3, 0, 4, 4, 1, 0, 3, 4, 3, 0, 2, 4, 3, 0, 1, 2, 1, 1, 2, 0, 3, 1, 4, 0, 2, 2, 3, 2, 3, 3, 3, 2, 2, 3, 4, 4, 3, 2, 1, 2, 4, 4, 3, 4, 4, 2, 0, 0, 4, 1, 0, 1, 2, 2, 3, 4, 4, 4, 0, 4, 4, 4, 3, 0, 4, 2, 4, 3, 4, 1, 2, 1, 1, 0, 0, 2, 0, 0, 4, 1, 1, 3, 3, 4, 3, 1, 0, 3, 4, 0, 2, 3, 1, 1, 0, 3, 1, 0, 4, 3, 2, 2, 1, 2, 0, 1, 3, 0, 3, 0, 4, 3, 0, 4, 3, 0, 2, 1, 0, 1, 2, 4, 3, 4, 0, 4, 2, 2, 1, 4, 3, 3, 0, 2, 2, 4, 0, 4, 0, 1, 0, 0, 0, 3, 4, 3, 0, 2, 3, 2, 1, 2, 1, 0, 3, 4, 1, 1, 3, 1, 3, 2, 2, 2, 0, 2, 3, 4, 1, 0, 2, 0, 1, 3, 3, 1, 2, 0, 2, 4, 3, 3, 3, 2, 0, 2, 0, 2, 4, 3, 4, 4, 3, 0, 1, 1, 3, 0, 4, 4, 0, 4, 0, 1, 4, 2, 1, 4, 2, 3, 1, 3, 3, 4, 3, 1, 0, 4, 2, 3, 3, 2, 2, 3, 1, 1, 4, 0, 1, 0, 0, 4, 0, 4, 3, 4, 0, 1, 4, 2, 3, 2, 3, 3, 3, 2, 2, 0, 3, 4, 3, 2, 3, 1, 4, 1, 2, 4, 2, 0, 0, 2, 4, 2, 2, 2, 0, 0, 3, 1, 3, 2, 0, 2, 1, 4, 1, 0, 2, 0, 2, 4, 0]\n",
      "[0, 0, 4, 3, 4, 3, 3, 3, 0, 4, 0, 2, 2, 4, 2, 2, 4, 3, 4, 0, 2, 2, 4, 3, 4, 4, 4, 2, 0, 4, 4, 3, 0, 2, 2, 2, 2, 4, 4, 3, 0, 4, 4, 0, 3, 4, 2, 3, 3, 4, 4, 2, 3, 2, 0, 2, 4, 3, 0, 3, 0, 0, 3, 3, 0, 3, 2, 4, 4, 3, 4, 3, 3, 4, 4, 4, 2, 0, 4, 2, 0, 3, 3, 0, 2, 4, 2, 2, 2, 4, 0, 4, 4, 3, 3, 4, 4, 2, 2, 3, 3, 2, 4, 2, 3, 4, 4, 4, 0, 4, 4, 4, 3, 4, 0, 3, 4, 4, 4, 2, 3, 3, 0, 3, 2, 4, 4, 4, 4, 3, 0, 3, 4, 2, 0, 2, 4, 3, 2, 4, 3, 0, 3, 0, 4, 0, 0, 3, 0, 3, 3, 4, 2, 2, 2, 4, 4, 3, 2, 4, 4, 0, 2, 0, 0, 4, 4, 0, 2, 4, 4, 3, 2, 4, 2, 4, 2, 0, 0, 4, 0, 0, 2, 3, 4, 3, 2, 3, 3, 0, 4, 4, 3, 4, 2, 4, 3, 0, 4, 3, 2, 0, 2, 2, 3, 4, 2, 2, 4, 0, 2, 0, 4, 0, 3, 3, 3, 3, 0, 4, 4, 0, 0, 3, 4, 3, 0, 0, 4, 3, 0, 4, 2, 2, 3, 2, 4, 2, 4, 4, 2, 2, 2, 3, 2, 3, 3, 3, 2, 2, 3, 4, 4, 3, 2, 3, 2, 4, 3, 3, 4, 4, 2, 2, 0, 4, 3, 0, 4, 2, 2, 0, 4, 4, 4, 0, 4, 4, 4, 4, 0, 4, 2, 4, 3, 4, 0, 2, 4, 2, 0, 0, 2, 4, 2, 4, 4, 3, 3, 3, 4, 3, 4, 0, 4, 4, 0, 2, 3, 4, 4, 0, 3, 4, 0, 4, 3, 2, 2, 0, 2, 0, 4, 3, 0, 3, 0, 4, 3, 0, 4, 4, 0, 2, 4, 2, 4, 0, 4, 3, 4, 0, 4, 2, 2, 4, 4, 3, 3, 0, 2, 2, 4, 4, 4, 2, 4, 0, 0, 0, 3, 4, 3, 0, 2, 3, 2, 2, 2, 4, 0, 3, 4, 4, 4, 3, 4, 4, 2, 2, 2, 0, 2, 3, 4, 4, 0, 2, 2, 4, 4, 4, 3, 2, 4, 2, 4, 4, 2, 3, 2, 0, 2, 0, 2, 4, 3, 4, 4, 3, 2, 4, 4, 3, 0, 4, 4, 0, 4, 0, 3, 4, 2, 4, 4, 2, 3, 4, 3, 3, 4, 3, 2, 4, 4, 2, 3, 3, 2, 2, 3, 4, 4, 4, 0, 4, 0, 0, 4, 0, 2, 4, 4, 0, 4, 4, 2, 3, 2, 4, 3, 3, 2, 2, 0, 3, 4, 3, 2, 3, 0, 4, 2, 2, 4, 2, 0, 0, 0, 4, 2, 0, 2, 0, 0, 3, 4, 3, 2, 2, 2, 2, 4, 4, 0, 2, 0, 2, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.72      0.88      0.79       100\n",
      "           3       0.77      0.84      0.80       100\n",
      "           4       0.55      0.96      0.70       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.56      0.68      0.61       500\n",
      "weighted avg       0.56      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2203632071614265, Val acc: 0.682\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15200 - Batch 48/1894 - Train loss: 1.0627234967387453, Train acc: 0.8399234693877551\n",
      "Iteration 15300 - Batch 148/1894 - Train loss: 1.0474088860038142, Train acc: 0.856753355704698\n",
      "Iteration 15400 - Batch 248/1894 - Train loss: 1.0469460501728287, Train acc: 0.8575552208835341\n",
      "Iteration 15500 - Batch 348/1894 - Train loss: 1.0473134024095399, Train acc: 0.8568230659025788\n",
      "Iteration 15600 - Batch 448/1894 - Train loss: 1.0449108599554457, Train acc: 0.85913140311804\n",
      "Iteration 15700 - Batch 548/1894 - Train loss: 1.0449049109101078, Train acc: 0.8587204007285975\n",
      "Iteration 15800 - Batch 648/1894 - Train loss: 1.0445771833597604, Train acc: 0.8591583204930663\n",
      "Iteration 15900 - Batch 748/1894 - Train loss: 1.0447686932911382, Train acc: 0.8591038050734312\n",
      "Iteration 16000 - Batch 848/1894 - Train loss: 1.0445874659136132, Train acc: 0.8590253239104829\n",
      "Iteration 16100 - Batch 948/1894 - Train loss: 1.0432443275215502, Train acc: 0.860445205479452\n",
      "Iteration 16200 - Batch 1048/1894 - Train loss: 1.0430221259878065, Train acc: 0.8605815061963775\n",
      "Iteration 16300 - Batch 1148/1894 - Train loss: 1.0425437558101922, Train acc: 0.8611020452567449\n",
      "Iteration 16400 - Batch 1248/1894 - Train loss: 1.043277458823901, Train acc: 0.8603382706164932\n",
      "Iteration 16500 - Batch 1348/1894 - Train loss: 1.0434439154445374, Train acc: 0.8600815418828762\n",
      "Iteration 16600 - Batch 1448/1894 - Train loss: 1.044702870916547, Train acc: 0.8588681849551415\n",
      "Iteration 16700 - Batch 1548/1894 - Train loss: 1.0445974721225175, Train acc: 0.8589816010329244\n",
      "Iteration 16800 - Batch 1648/1894 - Train loss: 1.044195110505823, Train acc: 0.8593655245603395\n",
      "Iteration 16900 - Batch 1748/1894 - Train loss: 1.0439864947088382, Train acc: 0.8595983419096627\n",
      "Iteration 17000 - Batch 1848/1894 - Train loss: 1.0441924248146586, Train acc: 0.8594848566792861\n",
      "[3, 1, 4, 2, 2, 1, 4, 1, 2, 3, 0, 1, 2, 3, 2, 0, 0, 3, 4, 3, 0, 1, 0, 0, 2, 2, 0, 1, 3, 2, 0, 0, 1, 0, 2, 0, 1, 2, 4, 4, 2, 2, 4, 0, 3, 2, 0, 0, 0, 0, 3, 3, 4, 1, 2, 0, 4, 4, 1, 3, 1, 3, 0, 4, 1, 1, 3, 2, 0, 2, 4, 2, 2, 2, 2, 4, 1, 4, 2, 1, 2, 2, 1, 0, 4, 4, 2, 2, 4, 1, 4, 2, 1, 0, 4, 1, 3, 2, 0, 1, 2, 3, 0, 3, 4, 3, 3, 1, 4, 1, 4, 4, 3, 0, 2, 3, 0, 0, 2, 0, 2, 0, 0, 0, 4, 0, 1, 3, 0, 3, 2, 1, 2, 3, 0, 0, 3, 1, 2, 3, 0, 4, 2, 0, 1, 1, 0, 4, 2, 4, 3, 0, 2, 4, 3, 4, 1, 2, 2, 4, 3, 0, 2, 1, 3, 2, 1, 2, 2, 0, 4, 4, 4, 0, 2, 0, 0, 1, 4, 4, 0, 3, 1, 0, 0, 1, 0, 3, 3, 4, 3, 2, 0, 3, 3, 2, 3, 4, 2, 1, 4, 2, 3, 0, 0, 1, 0, 2, 1, 3, 0, 1, 2, 2, 0, 3, 1, 0, 2, 3, 4, 4, 1, 3, 0, 1, 4, 3, 2, 3, 3, 3, 2, 1, 2, 1, 3, 3, 2, 1, 1, 4, 2, 2, 2, 4, 4, 1, 3, 4, 0, 4, 3, 0, 4, 3, 0, 3, 3, 4, 2, 4, 2, 1, 2, 3, 4, 1, 3, 3, 3, 3, 4, 2, 0, 1, 1, 3, 1, 0, 4, 3, 3, 1, 1, 0, 1, 3, 1, 0, 1, 4, 4, 0, 1, 4, 3, 1, 3, 2, 1, 1, 0, 2, 0, 2, 2, 4, 4, 1, 0, 1, 0, 0, 4, 2, 1, 1, 0, 0, 2, 3, 3, 3, 3, 3, 4, 1, 3, 4, 1, 1, 2, 2, 4, 2, 2, 1, 3, 2, 1, 2, 3, 0, 4, 0, 4, 3, 4, 3, 4, 0, 0, 0, 0, 3, 1, 2, 1, 0, 0, 4, 3, 0, 3, 3, 1, 0, 3, 3, 3, 4, 4, 0, 3, 3, 1, 3, 0, 1, 3, 3, 3, 2, 2, 2, 0, 1, 1, 4, 2, 2, 4, 1, 4, 1, 3, 1, 4, 1, 0, 4, 2, 1, 4, 4, 2, 1, 2, 4, 0, 4, 0, 1, 3, 1, 4, 2, 1, 0, 4, 0, 1, 2, 4, 4, 4, 3, 0, 4, 1, 2, 2, 4, 2, 4, 4, 0, 4, 2, 1, 1, 0, 1, 1, 4, 4, 3, 3, 3, 3, 2, 0, 3, 2, 1, 2, 1, 0, 4, 4, 4, 2, 2, 2, 1, 1, 4, 4, 4, 3, 4, 0, 3, 0, 3, 3, 1, 1, 1, 3, 4, 0, 4, 3, 2, 3, 2, 4, 1, 2, 1, 0, 2, 0, 0, 1, 4, 0, 4]\n",
      "[3, 4, 4, 0, 2, 4, 4, 4, 2, 3, 0, 4, 2, 3, 2, 0, 0, 4, 4, 3, 0, 3, 0, 0, 2, 0, 0, 3, 3, 2, 0, 0, 3, 0, 2, 0, 2, 0, 4, 4, 2, 0, 4, 0, 3, 2, 0, 0, 0, 0, 3, 3, 2, 0, 0, 4, 4, 4, 0, 4, 0, 3, 0, 4, 3, 4, 3, 2, 2, 2, 4, 2, 0, 2, 2, 4, 3, 3, 0, 4, 2, 0, 4, 0, 4, 4, 2, 3, 4, 4, 4, 3, 2, 0, 0, 4, 3, 2, 0, 2, 2, 3, 0, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 4, 0, 4, 3, 0, 3, 2, 4, 3, 3, 2, 0, 3, 2, 2, 3, 0, 4, 2, 0, 2, 3, 0, 4, 2, 4, 3, 0, 2, 4, 3, 4, 4, 2, 2, 4, 3, 4, 2, 4, 3, 2, 2, 2, 2, 0, 4, 0, 4, 0, 2, 0, 0, 4, 4, 4, 0, 3, 4, 0, 0, 0, 0, 3, 3, 4, 3, 2, 0, 4, 3, 0, 3, 4, 0, 3, 4, 2, 3, 0, 0, 4, 0, 2, 4, 3, 0, 3, 2, 2, 0, 3, 3, 4, 2, 3, 4, 4, 0, 3, 0, 4, 4, 3, 0, 3, 3, 3, 2, 4, 2, 4, 3, 3, 2, 2, 4, 4, 2, 2, 0, 4, 4, 3, 3, 4, 0, 4, 0, 0, 4, 3, 0, 3, 4, 4, 0, 4, 2, 4, 2, 3, 4, 4, 0, 3, 3, 3, 4, 2, 0, 4, 3, 3, 4, 2, 4, 3, 4, 4, 4, 0, 4, 3, 4, 0, 2, 0, 4, 0, 3, 4, 3, 4, 3, 2, 4, 4, 0, 2, 4, 2, 2, 4, 4, 4, 0, 3, 0, 0, 4, 2, 2, 0, 0, 0, 2, 3, 3, 3, 4, 3, 4, 4, 3, 4, 3, 0, 2, 0, 4, 2, 2, 4, 2, 2, 0, 2, 3, 0, 3, 0, 4, 3, 4, 3, 4, 4, 2, 0, 2, 3, 4, 2, 3, 0, 0, 4, 3, 0, 4, 3, 0, 0, 3, 3, 3, 4, 4, 0, 3, 3, 4, 3, 0, 4, 3, 3, 3, 2, 0, 2, 0, 0, 3, 2, 2, 0, 4, 4, 4, 0, 3, 2, 4, 4, 0, 4, 2, 3, 4, 4, 2, 4, 2, 4, 0, 4, 0, 0, 3, 2, 4, 2, 3, 0, 4, 0, 4, 2, 0, 4, 4, 3, 0, 4, 4, 2, 2, 4, 2, 2, 4, 0, 4, 2, 0, 4, 0, 3, 2, 4, 4, 3, 3, 3, 4, 2, 0, 3, 0, 3, 2, 4, 0, 3, 3, 4, 2, 2, 0, 0, 4, 4, 4, 4, 3, 4, 0, 2, 0, 3, 3, 4, 4, 3, 3, 4, 0, 4, 3, 2, 3, 2, 4, 3, 2, 2, 0, 2, 0, 0, 4, 4, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.76      0.78      0.77       100\n",
      "           3       0.73      0.87      0.79       100\n",
      "           4       0.59      0.88      0.70       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.56      0.69      0.61       500\n",
      "weighted avg       0.56      0.69      0.61       500\n",
      "\n",
      "Val loss: 1.2132357731461525, Val acc: 0.686\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17100 - Batch 54/1894 - Train loss: 1.0515887585553256, Train acc: 0.8511363636363637\n",
      "Iteration 17200 - Batch 154/1894 - Train loss: 1.0479555987542675, Train acc: 0.8558467741935484\n",
      "Iteration 17300 - Batch 254/1894 - Train loss: 1.0485605064560386, Train acc: 0.8547794117647058\n",
      "Iteration 17400 - Batch 354/1894 - Train loss: 1.0460705758820117, Train acc: 0.8571302816901408\n",
      "Iteration 17500 - Batch 454/1894 - Train loss: 1.04420006275177, Train acc: 0.8592032967032966\n",
      "Iteration 17600 - Batch 554/1894 - Train loss: 1.0448016817505295, Train acc: 0.8586711711711712\n",
      "Iteration 17700 - Batch 654/1894 - Train loss: 1.0458247675240495, Train acc: 0.8575858778625954\n",
      "Iteration 17800 - Batch 754/1894 - Train loss: 1.0449210249035563, Train acc: 0.8584437086092715\n",
      "Iteration 17900 - Batch 854/1894 - Train loss: 1.0438348300275746, Train acc: 0.8597222222222223\n",
      "Iteration 18000 - Batch 954/1894 - Train loss: 1.0429338108182578, Train acc: 0.8606675392670157\n",
      "Iteration 18100 - Batch 1054/1894 - Train loss: 1.0424831403375237, Train acc: 0.860989336492891\n",
      "Iteration 18200 - Batch 1154/1894 - Train loss: 1.0428040454914043, Train acc: 0.8606060606060606\n",
      "Iteration 18300 - Batch 1254/1894 - Train loss: 1.043975178558988, Train acc: 0.8594621513944223\n",
      "Iteration 18400 - Batch 1354/1894 - Train loss: 1.0431586149873768, Train acc: 0.8603551660516605\n",
      "Iteration 18500 - Batch 1454/1894 - Train loss: 1.0428952464533017, Train acc: 0.8606529209621994\n",
      "Iteration 18600 - Batch 1554/1894 - Train loss: 1.0424932034835939, Train acc: 0.8610530546623795\n",
      "Iteration 18700 - Batch 1654/1894 - Train loss: 1.0422714419235275, Train acc: 0.8612537764350453\n",
      "Iteration 18800 - Batch 1754/1894 - Train loss: 1.0420610395591823, Train acc: 0.8614494301994302\n",
      "Iteration 18900 - Batch 1854/1894 - Train loss: 1.0419437917737626, Train acc: 0.8616071428571429\n",
      "[4, 1, 4, 2, 3, 0, 3, 0, 0, 0, 2, 0, 3, 3, 1, 2, 1, 0, 1, 3, 2, 4, 4, 0, 1, 4, 2, 0, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 1, 1, 2, 4, 4, 1, 4, 1, 3, 1, 0, 3, 1, 3, 2, 1, 2, 0, 4, 1, 2, 4, 3, 4, 0, 0, 0, 3, 4, 4, 1, 2, 2, 4, 1, 3, 1, 3, 4, 4, 3, 3, 1, 0, 0, 4, 1, 0, 3, 0, 2, 3, 4, 1, 1, 2, 1, 2, 4, 3, 1, 1, 3, 1, 1, 4, 2, 2, 1, 1, 3, 4, 2, 2, 0, 2, 4, 1, 2, 0, 4, 2, 4, 1, 3, 0, 3, 4, 4, 0, 0, 0, 2, 4, 1, 2, 4, 0, 0, 4, 0, 4, 0, 1, 3, 0, 4, 0, 0, 1, 1, 4, 3, 0, 4, 4, 4, 3, 3, 2, 4, 2, 3, 1, 4, 4, 0, 0, 4, 4, 0, 2, 0, 1, 2, 0, 1, 2, 1, 2, 2, 3, 3, 0, 0, 4, 2, 3, 1, 0, 1, 0, 1, 2, 0, 0, 0, 3, 0, 1, 2, 1, 4, 2, 4, 2, 2, 4, 4, 3, 0, 2, 1, 4, 3, 3, 0, 4, 3, 3, 3, 1, 2, 3, 4, 0, 4, 2, 2, 3, 2, 3, 4, 1, 2, 1, 4, 4, 0, 4, 2, 1, 2, 4, 1, 1, 0, 4, 0, 4, 4, 3, 2, 0, 4, 2, 0, 4, 2, 4, 2, 4, 0, 4, 4, 4, 2, 3, 3, 2, 3, 4, 0, 2, 2, 4, 0, 1, 3, 3, 1, 2, 3, 1, 4, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 2, 0, 4, 1, 4, 4, 2, 2, 2, 2, 3, 0, 3, 1, 2, 3, 0, 1, 1, 1, 3, 4, 2, 0, 1, 4, 2, 4, 1, 2, 3, 1, 2, 0, 4, 4, 1, 1, 1, 0, 1, 0, 2, 4, 2, 3, 3, 2, 0, 0, 2, 4, 2, 3, 0, 3, 1, 1, 4, 3, 1, 2, 4, 1, 0, 1, 4, 0, 2, 4, 1, 3, 3, 0, 2, 3, 2, 0, 1, 4, 3, 1, 1, 2, 3, 3, 0, 0, 4, 0, 3, 0, 0, 1, 2, 4, 3, 1, 2, 3, 3, 1, 1, 3, 2, 4, 0, 2, 3, 3, 0, 2, 0, 4, 0, 1, 1, 2, 1, 4, 0, 2, 2, 2, 4, 3, 0, 4, 2, 4, 0, 2, 2, 4, 3, 1, 1, 1, 4, 0, 2, 4, 3, 1, 0, 2, 2, 3, 4, 1, 1, 0, 0, 3, 3, 0, 3, 1, 3, 4, 0, 3, 1, 3, 1, 1, 4, 2, 0, 2, 1, 1, 4, 2, 2, 1, 3, 4, 3, 2, 1, 3, 2, 0, 0, 2, 1, 1, 2, 1, 0, 3, 1, 0, 1, 2, 3, 2, 3, 0, 1, 4, 3, 2, 2, 4, 0]\n",
      "[4, 4, 4, 2, 3, 0, 3, 0, 0, 0, 2, 0, 3, 3, 4, 0, 4, 0, 3, 3, 0, 4, 0, 0, 4, 4, 2, 0, 3, 0, 3, 3, 0, 0, 3, 4, 0, 3, 0, 4, 0, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 3, 2, 0, 2, 0, 4, 4, 2, 4, 3, 4, 0, 0, 0, 3, 4, 4, 4, 2, 2, 4, 0, 3, 4, 3, 4, 4, 3, 3, 4, 0, 0, 4, 4, 0, 0, 0, 2, 3, 4, 4, 3, 2, 3, 2, 4, 3, 4, 3, 3, 3, 0, 4, 2, 2, 4, 0, 3, 4, 3, 2, 0, 2, 4, 0, 2, 0, 4, 2, 4, 3, 3, 0, 3, 4, 4, 0, 0, 0, 2, 4, 4, 2, 4, 0, 0, 4, 0, 4, 0, 3, 3, 0, 4, 0, 0, 0, 3, 4, 4, 0, 0, 4, 2, 3, 4, 0, 4, 2, 4, 4, 4, 4, 0, 0, 4, 4, 0, 2, 0, 4, 2, 2, 3, 2, 0, 2, 2, 3, 3, 0, 0, 4, 2, 3, 4, 0, 4, 0, 4, 3, 0, 0, 0, 3, 0, 4, 2, 4, 4, 0, 4, 2, 3, 4, 4, 3, 0, 2, 2, 4, 3, 4, 0, 4, 3, 3, 3, 4, 0, 3, 4, 0, 4, 2, 2, 3, 2, 3, 4, 4, 2, 0, 4, 4, 4, 4, 2, 3, 2, 4, 4, 3, 0, 4, 0, 4, 4, 4, 2, 0, 4, 2, 0, 4, 2, 2, 2, 4, 0, 4, 4, 4, 2, 3, 3, 0, 3, 4, 2, 2, 2, 4, 0, 4, 3, 3, 2, 2, 3, 4, 4, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 2, 0, 2, 4, 4, 4, 2, 2, 2, 2, 3, 0, 3, 4, 2, 3, 0, 4, 0, 4, 3, 4, 0, 0, 3, 4, 2, 4, 4, 2, 3, 0, 2, 0, 3, 4, 3, 4, 4, 4, 3, 0, 2, 4, 3, 3, 3, 2, 0, 3, 2, 4, 2, 3, 0, 3, 4, 4, 4, 3, 4, 2, 4, 3, 0, 2, 4, 0, 2, 4, 4, 3, 3, 0, 2, 3, 2, 0, 3, 4, 3, 0, 4, 0, 3, 4, 0, 0, 4, 0, 4, 0, 0, 4, 2, 4, 3, 4, 2, 3, 4, 2, 3, 3, 2, 4, 0, 0, 3, 3, 0, 2, 0, 4, 0, 3, 3, 2, 3, 4, 0, 2, 2, 2, 4, 3, 0, 4, 2, 4, 0, 2, 2, 4, 3, 4, 3, 0, 4, 4, 2, 4, 3, 2, 0, 2, 0, 3, 4, 4, 3, 0, 0, 3, 3, 0, 3, 0, 3, 4, 0, 3, 4, 3, 0, 0, 4, 2, 0, 2, 3, 0, 4, 2, 2, 3, 3, 3, 3, 2, 0, 3, 0, 0, 0, 2, 4, 4, 2, 4, 0, 3, 4, 0, 4, 2, 3, 2, 3, 0, 4, 4, 3, 0, 0, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.93      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.82      0.85       100\n",
      "           3       0.74      0.90      0.81       100\n",
      "           4       0.58      0.92      0.71       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1910467371344566, Val acc: 0.714\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19000 - Batch 60/1894 - Train loss: 1.0272109264233074, Train acc: 0.8790983606557377\n",
      "Iteration 19100 - Batch 160/1894 - Train loss: 1.0314885300138723, Train acc: 0.873641304347826\n",
      "Iteration 19200 - Batch 260/1894 - Train loss: 1.0300886409492784, Train acc: 0.8746408045977011\n",
      "Iteration 19300 - Batch 360/1894 - Train loss: 1.0326616917620735, Train acc: 0.8717105263157895\n",
      "Iteration 19400 - Batch 460/1894 - Train loss: 1.0344206706303578, Train acc: 0.8697125813449024\n",
      "Iteration 19500 - Batch 560/1894 - Train loss: 1.0356651762377558, Train acc: 0.8685940285204992\n",
      "Iteration 19600 - Batch 660/1894 - Train loss: 1.0364663049961904, Train acc: 0.8675775340393344\n",
      "Iteration 19700 - Batch 760/1894 - Train loss: 1.0376712227932883, Train acc: 0.8662943495400789\n",
      "Iteration 19800 - Batch 860/1894 - Train loss: 1.0382965051338648, Train acc: 0.8655632984901278\n",
      "Iteration 19900 - Batch 960/1894 - Train loss: 1.037766347814673, Train acc: 0.8660574921956296\n",
      "Iteration 20000 - Batch 1060/1894 - Train loss: 1.037393248777812, Train acc: 0.8663701696512723\n",
      "Iteration 20100 - Batch 1160/1894 - Train loss: 1.0379096188491834, Train acc: 0.865848406546081\n",
      "Iteration 20200 - Batch 1260/1894 - Train loss: 1.0380800420759595, Train acc: 0.8656819984139572\n",
      "Iteration 20300 - Batch 1360/1894 - Train loss: 1.0385095797243755, Train acc: 0.8653104335047759\n",
      "Iteration 20400 - Batch 1460/1894 - Train loss: 1.0386781687201252, Train acc: 0.8651180698151951\n",
      "Iteration 20500 - Batch 1560/1894 - Train loss: 1.038417179335546, Train acc: 0.8653307174887892\n",
      "Iteration 20600 - Batch 1660/1894 - Train loss: 1.0381450118392723, Train acc: 0.8656118302227573\n",
      "Iteration 20700 - Batch 1760/1894 - Train loss: 1.0389847677922397, Train acc: 0.8648495173197047\n",
      "Iteration 20800 - Batch 1860/1894 - Train loss: 1.038930285335676, Train acc: 0.8649079795808705\n",
      "[4, 2, 1, 0, 0, 3, 0, 0, 1, 1, 1, 4, 0, 1, 0, 4, 4, 1, 1, 3, 0, 1, 3, 4, 3, 1, 1, 2, 3, 1, 2, 2, 4, 4, 1, 3, 2, 3, 0, 0, 1, 3, 1, 4, 1, 1, 0, 1, 1, 1, 1, 2, 1, 3, 0, 0, 4, 3, 0, 0, 0, 4, 2, 0, 2, 0, 0, 2, 1, 2, 4, 4, 0, 4, 2, 2, 0, 0, 3, 0, 1, 0, 3, 2, 1, 3, 4, 3, 4, 0, 3, 3, 0, 1, 0, 3, 4, 4, 4, 3, 2, 2, 3, 2, 4, 0, 0, 0, 3, 2, 0, 0, 0, 1, 2, 0, 1, 1, 1, 1, 2, 3, 1, 3, 3, 2, 4, 3, 4, 1, 1, 1, 2, 0, 4, 3, 1, 1, 0, 3, 0, 3, 4, 0, 1, 1, 0, 3, 2, 4, 0, 0, 4, 3, 4, 3, 0, 0, 1, 4, 3, 2, 4, 0, 0, 2, 1, 1, 0, 3, 0, 2, 3, 0, 3, 4, 1, 3, 1, 2, 4, 2, 4, 0, 0, 3, 3, 1, 3, 1, 0, 0, 4, 3, 1, 4, 1, 2, 0, 2, 1, 3, 2, 3, 2, 4, 2, 3, 2, 2, 4, 0, 1, 2, 3, 3, 2, 3, 4, 3, 2, 1, 2, 4, 4, 4, 2, 3, 4, 2, 0, 1, 4, 2, 0, 2, 2, 1, 3, 4, 2, 0, 2, 3, 0, 4, 1, 4, 2, 4, 4, 1, 3, 1, 2, 4, 4, 4, 4, 3, 3, 3, 2, 0, 0, 4, 4, 4, 3, 2, 2, 3, 1, 4, 2, 4, 4, 3, 3, 4, 0, 4, 3, 1, 3, 3, 2, 0, 3, 0, 2, 4, 4, 0, 1, 3, 2, 0, 1, 0, 2, 4, 2, 3, 4, 3, 1, 2, 2, 2, 0, 1, 4, 1, 1, 2, 2, 2, 0, 4, 0, 4, 1, 0, 2, 3, 2, 0, 1, 3, 1, 3, 3, 3, 4, 3, 2, 2, 4, 0, 1, 4, 1, 3, 1, 0, 4, 3, 4, 0, 3, 3, 0, 1, 4, 0, 1, 1, 1, 3, 1, 1, 3, 1, 0, 4, 2, 1, 1, 1, 0, 3, 0, 0, 1, 2, 0, 3, 4, 4, 1, 3, 1, 0, 1, 4, 1, 4, 3, 0, 0, 1, 0, 3, 3, 1, 2, 1, 4, 4, 1, 1, 1, 4, 2, 2, 4, 2, 2, 1, 2, 3, 0, 3, 1, 0, 0, 3, 3, 1, 1, 2, 1, 0, 2, 0, 2, 3, 2, 0, 2, 1, 2, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 1, 0, 0, 1, 4, 4, 2, 2, 3, 3, 2, 4, 1, 0, 4, 3, 3, 1, 2, 4, 2, 3, 3, 0, 3, 3, 0, 2, 0, 2, 4, 2, 4, 4, 2, 0, 2, 2, 4, 2, 4, 0, 3, 2, 0, 3, 0, 4, 2, 4, 3, 2, 3, 2, 2, 2, 2]\n",
      "[4, 3, 0, 0, 0, 3, 0, 0, 3, 4, 2, 4, 0, 4, 2, 4, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 0, 2, 0, 4, 2, 2, 4, 4, 4, 3, 2, 3, 0, 0, 3, 3, 0, 4, 0, 4, 0, 3, 0, 4, 0, 2, 4, 3, 0, 0, 4, 3, 0, 0, 0, 4, 0, 2, 2, 0, 0, 2, 4, 2, 4, 4, 0, 4, 0, 2, 0, 0, 3, 0, 3, 0, 3, 2, 2, 3, 4, 3, 4, 0, 3, 3, 0, 4, 0, 3, 4, 4, 4, 3, 2, 0, 3, 3, 4, 0, 0, 0, 4, 2, 0, 0, 0, 3, 0, 0, 0, 4, 3, 4, 2, 3, 2, 3, 3, 2, 2, 3, 2, 0, 2, 2, 2, 0, 4, 3, 3, 3, 0, 3, 0, 3, 4, 0, 2, 3, 0, 3, 2, 4, 0, 0, 4, 3, 4, 3, 3, 0, 0, 4, 3, 2, 4, 0, 0, 2, 4, 4, 0, 3, 0, 2, 4, 0, 3, 4, 4, 3, 2, 2, 4, 2, 4, 0, 0, 3, 3, 3, 4, 0, 0, 0, 4, 3, 3, 0, 0, 0, 0, 2, 4, 3, 2, 3, 2, 4, 2, 3, 2, 2, 4, 0, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 2, 4, 4, 4, 2, 3, 4, 0, 0, 0, 4, 2, 0, 2, 2, 4, 3, 4, 2, 2, 2, 3, 0, 4, 4, 4, 2, 4, 4, 3, 3, 4, 2, 4, 4, 4, 4, 3, 3, 3, 0, 3, 0, 4, 4, 4, 3, 2, 2, 3, 4, 4, 2, 4, 4, 3, 3, 4, 0, 4, 3, 4, 3, 3, 2, 0, 3, 0, 2, 4, 4, 2, 3, 3, 2, 0, 4, 2, 2, 4, 2, 3, 4, 3, 4, 0, 2, 0, 0, 0, 4, 3, 0, 2, 2, 2, 0, 4, 2, 4, 4, 2, 2, 3, 2, 0, 3, 3, 4, 3, 3, 3, 4, 3, 2, 2, 4, 0, 4, 3, 3, 3, 3, 0, 4, 3, 4, 0, 3, 3, 0, 4, 4, 0, 3, 0, 0, 3, 3, 3, 3, 4, 0, 3, 2, 3, 4, 3, 0, 3, 0, 0, 4, 2, 0, 3, 4, 4, 4, 3, 0, 2, 4, 3, 3, 4, 3, 4, 0, 0, 0, 4, 3, 4, 2, 4, 4, 4, 3, 3, 3, 4, 2, 2, 4, 2, 0, 4, 2, 3, 0, 4, 3, 0, 0, 3, 3, 0, 4, 2, 0, 0, 2, 0, 2, 3, 2, 0, 2, 4, 2, 4, 4, 4, 4, 3, 2, 4, 4, 2, 3, 0, 2, 0, 4, 4, 4, 2, 2, 3, 3, 3, 3, 4, 0, 2, 3, 3, 2, 2, 4, 2, 3, 3, 0, 3, 3, 4, 2, 0, 2, 4, 2, 4, 4, 2, 0, 2, 2, 4, 2, 4, 0, 3, 0, 0, 3, 0, 4, 0, 4, 3, 2, 3, 2, 2, 2, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.85      0.82       100\n",
      "           3       0.70      0.94      0.80       100\n",
      "           4       0.64      0.89      0.75       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1923820152878761, Val acc: 0.708\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20900 - Batch 66/1894 - Train loss: 1.0435555577278137, Train acc: 0.8605410447761194\n",
      "Iteration 21000 - Batch 166/1894 - Train loss: 1.0359921062777857, Train acc: 0.8677020958083832\n",
      "Iteration 21100 - Batch 266/1894 - Train loss: 1.032219556610236, Train acc: 0.8719569288389513\n",
      "Iteration 21200 - Batch 366/1894 - Train loss: 1.0332806058410728, Train acc: 0.8704870572207084\n",
      "Iteration 21300 - Batch 466/1894 - Train loss: 1.0338822051850836, Train acc: 0.869914346895075\n",
      "Iteration 21400 - Batch 566/1894 - Train loss: 1.0332135404649025, Train acc: 0.8705908289241623\n",
      "Iteration 21500 - Batch 666/1894 - Train loss: 1.03376379649321, Train acc: 0.8698931784107946\n",
      "Iteration 21600 - Batch 766/1894 - Train loss: 1.0334639000612877, Train acc: 0.8701515645371578\n",
      "Iteration 21700 - Batch 866/1894 - Train loss: 1.0335062009378013, Train acc: 0.8698817762399077\n",
      "Iteration 21800 - Batch 966/1894 - Train loss: 1.0342733480937725, Train acc: 0.8691830403309204\n",
      "Iteration 21900 - Batch 1066/1894 - Train loss: 1.0344593782456208, Train acc: 0.8691424554826617\n",
      "Iteration 22000 - Batch 1166/1894 - Train loss: 1.0346664262308254, Train acc: 0.8688946015424165\n",
      "Iteration 22100 - Batch 1266/1894 - Train loss: 1.0351789016467714, Train acc: 0.8683405682715075\n",
      "Iteration 22200 - Batch 1366/1894 - Train loss: 1.035865112212599, Train acc: 0.8676389904901244\n",
      "Iteration 22300 - Batch 1466/1894 - Train loss: 1.036017586564075, Train acc: 0.8675230061349694\n",
      "Iteration 22400 - Batch 1566/1894 - Train loss: 1.036020363792159, Train acc: 0.867601308232291\n",
      "Iteration 22500 - Batch 1666/1894 - Train loss: 1.0365300772428943, Train acc: 0.8671453209358129\n",
      "Iteration 22600 - Batch 1766/1894 - Train loss: 1.0367097852253009, Train acc: 0.8670062252405206\n",
      "Iteration 22700 - Batch 1866/1894 - Train loss: 1.036917601796351, Train acc: 0.8667983395822174\n",
      "[2, 1, 2, 4, 0, 0, 3, 3, 1, 3, 1, 4, 2, 4, 1, 0, 1, 1, 2, 4, 0, 4, 1, 0, 2, 0, 4, 4, 0, 3, 3, 4, 4, 3, 4, 3, 2, 0, 2, 2, 4, 2, 4, 3, 1, 0, 1, 0, 4, 2, 3, 0, 4, 1, 4, 1, 0, 2, 1, 2, 4, 3, 3, 4, 4, 4, 0, 4, 4, 0, 0, 2, 3, 3, 1, 1, 1, 4, 3, 3, 3, 1, 4, 1, 2, 3, 1, 0, 3, 3, 4, 2, 3, 0, 3, 1, 1, 1, 3, 3, 3, 1, 3, 1, 1, 3, 0, 0, 0, 4, 2, 2, 4, 0, 3, 0, 0, 0, 2, 2, 4, 1, 3, 1, 1, 3, 3, 4, 4, 2, 4, 0, 3, 1, 2, 2, 2, 3, 2, 1, 3, 1, 2, 1, 3, 1, 1, 2, 4, 2, 2, 2, 2, 1, 1, 4, 3, 2, 0, 0, 1, 2, 1, 2, 1, 4, 1, 2, 2, 4, 1, 3, 3, 2, 1, 0, 4, 1, 0, 3, 0, 3, 1, 1, 3, 4, 4, 4, 3, 2, 2, 0, 3, 2, 2, 4, 2, 2, 4, 2, 2, 3, 0, 1, 2, 4, 0, 1, 2, 0, 1, 2, 2, 1, 2, 3, 0, 1, 1, 4, 4, 2, 4, 2, 3, 3, 3, 4, 2, 4, 0, 0, 2, 3, 2, 2, 0, 2, 1, 4, 0, 3, 1, 2, 0, 0, 0, 1, 1, 4, 2, 2, 3, 0, 3, 0, 0, 3, 2, 2, 2, 0, 1, 4, 2, 3, 1, 0, 2, 1, 4, 4, 3, 0, 1, 1, 0, 1, 3, 3, 3, 3, 2, 1, 0, 3, 2, 0, 1, 1, 4, 0, 0, 1, 0, 1, 3, 1, 1, 1, 2, 4, 4, 0, 0, 2, 0, 3, 3, 0, 1, 0, 4, 1, 3, 3, 1, 0, 0, 3, 3, 4, 4, 2, 0, 0, 0, 4, 4, 3, 4, 3, 2, 4, 3, 4, 1, 0, 0, 4, 4, 1, 4, 4, 4, 0, 0, 3, 0, 1, 0, 2, 3, 4, 1, 4, 2, 2, 1, 1, 1, 1, 0, 4, 4, 2, 3, 0, 4, 2, 4, 2, 4, 3, 0, 4, 3, 2, 1, 3, 2, 1, 3, 3, 0, 1, 3, 1, 0, 2, 3, 1, 3, 4, 0, 3, 2, 2, 3, 3, 0, 2, 2, 2, 1, 0, 2, 1, 4, 4, 0, 1, 3, 2, 1, 4, 3, 0, 2, 2, 1, 4, 4, 3, 2, 1, 4, 4, 3, 0, 0, 2, 0, 3, 4, 2, 0, 4, 3, 0, 0, 0, 1, 2, 0, 3, 4, 1, 4, 4, 1, 4, 1, 4, 0, 0, 3, 0, 2, 0, 2, 3, 0, 1, 1, 4, 3, 3, 4, 0, 3, 2, 0, 4, 3, 2, 0, 3, 4, 2, 4, 1, 4, 4, 4, 4, 1, 3, 3, 2, 0, 4, 2, 0, 1, 3, 0, 0, 2, 1]\n",
      "[2, 4, 0, 3, 0, 0, 3, 3, 4, 3, 4, 4, 2, 2, 0, 0, 4, 0, 2, 4, 0, 4, 4, 0, 2, 0, 4, 4, 0, 3, 3, 3, 4, 3, 3, 3, 0, 0, 2, 2, 4, 2, 4, 3, 4, 0, 4, 0, 4, 2, 3, 0, 4, 4, 0, 4, 4, 2, 0, 2, 4, 3, 3, 4, 4, 4, 0, 4, 4, 0, 0, 2, 3, 3, 3, 3, 4, 2, 3, 3, 3, 3, 4, 0, 2, 3, 3, 0, 3, 3, 4, 2, 4, 0, 3, 4, 4, 4, 3, 3, 3, 2, 3, 3, 2, 3, 0, 0, 0, 4, 2, 2, 4, 0, 3, 0, 0, 4, 2, 2, 4, 3, 3, 2, 4, 3, 3, 4, 3, 2, 4, 0, 3, 4, 2, 2, 2, 3, 2, 2, 3, 4, 2, 3, 3, 0, 0, 2, 4, 2, 0, 2, 2, 0, 4, 4, 3, 2, 2, 0, 4, 2, 4, 0, 3, 4, 3, 0, 2, 3, 4, 3, 3, 2, 4, 0, 4, 3, 0, 3, 2, 4, 2, 3, 3, 4, 4, 3, 3, 0, 0, 0, 4, 2, 0, 4, 2, 2, 4, 2, 2, 3, 0, 3, 2, 4, 4, 4, 2, 0, 0, 2, 2, 4, 2, 3, 0, 0, 4, 4, 4, 2, 4, 2, 3, 4, 3, 4, 2, 4, 0, 2, 2, 4, 2, 2, 0, 2, 2, 4, 0, 3, 4, 2, 0, 0, 0, 4, 4, 4, 2, 2, 3, 0, 3, 0, 0, 3, 3, 2, 2, 0, 4, 4, 2, 3, 4, 0, 2, 4, 4, 4, 3, 0, 4, 3, 0, 4, 3, 3, 3, 3, 2, 4, 0, 3, 2, 0, 3, 0, 4, 0, 0, 4, 0, 0, 3, 4, 0, 4, 0, 4, 4, 0, 0, 2, 0, 4, 3, 0, 3, 0, 4, 3, 3, 3, 0, 0, 0, 3, 3, 4, 4, 2, 0, 0, 0, 4, 4, 3, 4, 0, 2, 4, 3, 4, 4, 0, 0, 4, 4, 4, 2, 4, 0, 0, 0, 3, 0, 3, 0, 2, 3, 4, 3, 4, 2, 2, 3, 4, 3, 3, 0, 4, 4, 0, 3, 0, 4, 0, 4, 0, 4, 3, 2, 4, 3, 2, 3, 3, 2, 4, 3, 3, 2, 4, 3, 0, 2, 2, 3, 4, 3, 4, 3, 3, 2, 2, 3, 3, 0, 0, 3, 2, 2, 0, 2, 4, 4, 4, 4, 2, 4, 3, 3, 4, 3, 0, 2, 2, 4, 4, 4, 3, 2, 4, 4, 4, 3, 0, 0, 2, 2, 3, 4, 2, 0, 4, 3, 0, 0, 0, 4, 2, 0, 3, 4, 4, 4, 2, 2, 4, 4, 4, 0, 0, 3, 0, 2, 0, 2, 3, 0, 4, 0, 4, 3, 4, 4, 0, 3, 2, 0, 4, 3, 2, 4, 3, 4, 2, 4, 0, 4, 4, 4, 4, 4, 3, 3, 2, 0, 4, 2, 0, 4, 3, 2, 0, 2, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.84      0.82       100\n",
      "           3       0.73      0.91      0.81       100\n",
      "           4       0.58      0.88      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2046411484479904, Val acc: 0.698\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22800 - Batch 72/1894 - Train loss: 1.0302122896664763, Train acc: 0.875\n",
      "Iteration 22900 - Batch 172/1894 - Train loss: 1.0292391091412891, Train acc: 0.8759031791907514\n",
      "Iteration 23000 - Batch 272/1894 - Train loss: 1.0363346327355494, Train acc: 0.868246336996337\n",
      "Iteration 23100 - Batch 372/1894 - Train loss: 1.0378972344679742, Train acc: 0.8663706434316354\n",
      "Iteration 23200 - Batch 472/1894 - Train loss: 1.037854859113189, Train acc: 0.8662790697674418\n",
      "Iteration 23300 - Batch 572/1894 - Train loss: 1.0357965782258731, Train acc: 0.868346422338569\n",
      "Iteration 23400 - Batch 672/1894 - Train loss: 1.0357592182917545, Train acc: 0.8681277860326895\n",
      "Iteration 23500 - Batch 772/1894 - Train loss: 1.0357024879381542, Train acc: 0.868127425614489\n",
      "Iteration 23600 - Batch 872/1894 - Train loss: 1.035155468653431, Train acc: 0.8686998854524628\n",
      "Iteration 23700 - Batch 972/1894 - Train loss: 1.0357460277911203, Train acc: 0.8681269270298048\n",
      "Iteration 23800 - Batch 1072/1894 - Train loss: 1.0346736606880536, Train acc: 0.869291705498602\n",
      "Iteration 23900 - Batch 1172/1894 - Train loss: 1.0345238892318647, Train acc: 0.8694852941176471\n",
      "Iteration 24000 - Batch 1272/1894 - Train loss: 1.0345660865260031, Train acc: 0.8694520816967792\n",
      "Iteration 24100 - Batch 1372/1894 - Train loss: 1.0346189203352627, Train acc: 0.8693781864530226\n",
      "Iteration 24200 - Batch 1472/1894 - Train loss: 1.0345086850686211, Train acc: 0.8694628309572301\n",
      "Iteration 24300 - Batch 1572/1894 - Train loss: 1.0347236558956017, Train acc: 0.8692784488239034\n",
      "Iteration 24400 - Batch 1672/1894 - Train loss: 1.0344315945068947, Train acc: 0.869583084279737\n",
      "Iteration 24500 - Batch 1772/1894 - Train loss: 1.0337603314744506, Train acc: 0.8702234912577552\n",
      "Iteration 24600 - Batch 1872/1894 - Train loss: 1.0337710254534769, Train acc: 0.8701781900694073\n",
      "[2, 0, 2, 1, 2, 0, 3, 2, 3, 0, 3, 1, 4, 4, 3, 1, 0, 4, 2, 0, 4, 0, 1, 1, 4, 0, 4, 0, 3, 3, 1, 0, 4, 2, 0, 4, 3, 2, 4, 1, 0, 0, 0, 0, 1, 3, 0, 3, 1, 3, 0, 1, 0, 1, 1, 2, 1, 1, 0, 4, 4, 4, 1, 0, 0, 1, 2, 0, 2, 3, 1, 3, 4, 1, 2, 2, 0, 2, 1, 2, 1, 0, 4, 3, 3, 3, 2, 4, 4, 2, 0, 3, 2, 0, 3, 3, 1, 0, 4, 0, 0, 1, 2, 4, 2, 3, 3, 4, 2, 4, 3, 3, 4, 3, 2, 1, 4, 1, 4, 2, 1, 1, 0, 3, 3, 0, 1, 2, 4, 0, 0, 0, 1, 0, 1, 1, 2, 0, 3, 4, 4, 0, 2, 1, 4, 4, 4, 0, 1, 0, 2, 4, 3, 4, 0, 3, 4, 4, 1, 4, 3, 1, 3, 2, 3, 4, 3, 3, 0, 0, 0, 2, 4, 0, 3, 1, 3, 2, 4, 0, 2, 4, 2, 0, 1, 3, 4, 4, 4, 2, 1, 1, 1, 0, 1, 0, 3, 2, 3, 3, 1, 2, 4, 1, 0, 3, 2, 2, 2, 1, 0, 2, 0, 3, 1, 4, 3, 1, 2, 4, 4, 3, 3, 4, 1, 4, 3, 1, 1, 1, 0, 2, 1, 3, 0, 3, 2, 4, 4, 2, 3, 2, 2, 4, 1, 0, 1, 4, 4, 0, 4, 3, 4, 1, 4, 0, 3, 0, 1, 3, 1, 1, 1, 3, 0, 2, 2, 4, 1, 3, 0, 2, 0, 4, 2, 0, 3, 1, 3, 0, 0, 1, 3, 2, 3, 1, 0, 0, 3, 3, 4, 4, 2, 0, 3, 4, 3, 1, 2, 1, 2, 0, 2, 2, 3, 1, 3, 0, 1, 4, 3, 2, 0, 2, 4, 4, 2, 0, 0, 2, 0, 3, 4, 1, 0, 2, 3, 4, 2, 2, 3, 0, 0, 3, 0, 2, 0, 2, 4, 3, 2, 0, 1, 2, 2, 1, 2, 4, 3, 0, 4, 1, 1, 1, 2, 0, 4, 1, 3, 1, 1, 0, 2, 1, 4, 2, 4, 2, 2, 4, 2, 1, 0, 0, 0, 4, 1, 0, 0, 4, 2, 2, 4, 0, 3, 2, 4, 3, 1, 3, 3, 4, 2, 1, 2, 1, 3, 1, 2, 2, 4, 0, 0, 1, 4, 1, 0, 1, 2, 0, 1, 4, 4, 2, 3, 4, 2, 2, 1, 2, 4, 0, 3, 1, 2, 1, 2, 4, 0, 3, 3, 3, 4, 3, 2, 4, 3, 3, 3, 2, 3, 3, 1, 4, 2, 4, 0, 3, 0, 0, 4, 4, 1, 3, 1, 3, 3, 2, 4, 4, 1, 3, 0, 3, 4, 3, 4, 2, 4, 1, 2, 3, 1, 3, 0, 4, 0, 4, 3, 4, 1, 0, 2, 2, 2, 3, 0, 3, 2, 2, 1, 2, 4, 1, 1, 3, 4, 2, 1, 1]\n",
      "[2, 0, 2, 0, 2, 2, 4, 3, 3, 0, 4, 4, 4, 4, 3, 0, 0, 4, 2, 2, 4, 0, 4, 4, 4, 0, 4, 0, 3, 3, 4, 0, 4, 0, 0, 4, 3, 2, 4, 4, 0, 0, 3, 0, 4, 3, 0, 3, 0, 4, 0, 4, 0, 4, 3, 0, 3, 0, 0, 4, 4, 4, 4, 0, 0, 4, 2, 0, 2, 3, 2, 3, 4, 0, 2, 2, 0, 2, 0, 2, 4, 0, 4, 3, 3, 3, 2, 3, 4, 2, 0, 3, 2, 0, 3, 3, 4, 0, 4, 0, 0, 4, 2, 4, 2, 4, 3, 4, 2, 4, 3, 3, 4, 3, 2, 3, 4, 4, 4, 3, 0, 0, 0, 3, 0, 0, 4, 2, 4, 0, 0, 0, 4, 0, 4, 0, 2, 0, 3, 4, 0, 0, 2, 3, 4, 4, 4, 0, 4, 2, 3, 4, 3, 4, 0, 3, 4, 4, 4, 2, 4, 4, 3, 2, 3, 4, 4, 3, 0, 0, 0, 2, 3, 0, 3, 4, 3, 2, 4, 0, 2, 4, 0, 0, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 0, 3, 2, 3, 3, 3, 2, 4, 4, 0, 3, 2, 2, 0, 4, 0, 2, 0, 4, 4, 4, 3, 4, 2, 4, 4, 3, 3, 4, 0, 4, 3, 4, 0, 4, 0, 2, 2, 3, 0, 3, 0, 4, 4, 2, 3, 0, 2, 4, 4, 0, 3, 4, 4, 0, 2, 3, 4, 4, 4, 0, 3, 0, 0, 3, 0, 3, 4, 3, 0, 0, 2, 4, 4, 3, 0, 2, 4, 4, 2, 0, 3, 0, 3, 0, 0, 4, 3, 2, 3, 0, 0, 0, 3, 3, 4, 4, 2, 0, 3, 4, 4, 3, 2, 3, 2, 0, 2, 2, 3, 2, 3, 0, 4, 4, 3, 2, 0, 2, 4, 4, 2, 4, 4, 0, 0, 4, 4, 4, 0, 2, 3, 2, 2, 2, 3, 0, 0, 4, 0, 2, 0, 0, 4, 3, 2, 0, 3, 2, 0, 4, 0, 4, 3, 0, 4, 4, 3, 4, 2, 0, 4, 3, 3, 0, 2, 0, 3, 4, 4, 2, 4, 2, 0, 4, 2, 3, 0, 0, 0, 4, 4, 0, 0, 4, 2, 2, 4, 0, 3, 0, 4, 3, 4, 3, 3, 4, 2, 0, 2, 3, 3, 4, 2, 2, 4, 0, 0, 0, 4, 3, 0, 3, 2, 0, 4, 0, 4, 2, 3, 4, 2, 2, 0, 2, 4, 0, 3, 3, 0, 3, 2, 4, 0, 3, 3, 3, 4, 3, 2, 4, 3, 3, 3, 2, 3, 3, 4, 4, 2, 4, 0, 3, 0, 0, 4, 4, 4, 3, 4, 3, 3, 2, 4, 4, 3, 3, 0, 3, 3, 3, 4, 2, 4, 4, 2, 3, 0, 3, 0, 4, 0, 4, 3, 4, 3, 0, 2, 2, 2, 3, 0, 3, 2, 2, 4, 0, 4, 3, 0, 3, 4, 2, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.81      0.84       100\n",
      "           3       0.74      0.88      0.80       100\n",
      "           4       0.59      0.92      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1979606822133064, Val acc: 0.706\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24700 - Batch 78/1894 - Train loss: 1.0307154014140745, Train acc: 0.8734177215189873\n",
      "Iteration 24800 - Batch 178/1894 - Train loss: 1.0284961904893375, Train acc: 0.8763966480446927\n",
      "Iteration 24900 - Batch 278/1894 - Train loss: 1.030062470812097, Train acc: 0.8743279569892473\n",
      "Iteration 25000 - Batch 378/1894 - Train loss: 1.0322089736254045, Train acc: 0.8712895778364116\n",
      "Iteration 25100 - Batch 478/1894 - Train loss: 1.03273161356036, Train acc: 0.8711508350730689\n",
      "Iteration 25200 - Batch 578/1894 - Train loss: 1.0319408367746645, Train acc: 0.8719775474956822\n",
      "Iteration 25300 - Batch 678/1894 - Train loss: 1.030859400228829, Train acc: 0.8730670103092784\n",
      "Iteration 25400 - Batch 778/1894 - Train loss: 1.030844178141617, Train acc: 0.8729942233632862\n",
      "Iteration 25500 - Batch 878/1894 - Train loss: 1.0308277643581298, Train acc: 0.8729735494880546\n",
      "Iteration 25600 - Batch 978/1894 - Train loss: 1.0303721381646254, Train acc: 0.8733720633299284\n",
      "Iteration 25700 - Batch 1078/1894 - Train loss: 1.030555116290622, Train acc: 0.8733202038924931\n",
      "Iteration 25800 - Batch 1178/1894 - Train loss: 1.0301559489090832, Train acc: 0.8738072519083969\n",
      "Iteration 25900 - Batch 1278/1894 - Train loss: 1.0301247139383425, Train acc: 0.8738760750586395\n",
      "Iteration 26000 - Batch 1378/1894 - Train loss: 1.0304030144966712, Train acc: 0.8736176577229877\n",
      "Iteration 26100 - Batch 1478/1894 - Train loss: 1.030859106372062, Train acc: 0.8732040229885057\n",
      "Iteration 26200 - Batch 1578/1894 - Train loss: 1.0304401732457447, Train acc: 0.8736740025332489\n",
      "Iteration 26300 - Batch 1678/1894 - Train loss: 1.0308558809182131, Train acc: 0.8732318344252531\n",
      "Iteration 26400 - Batch 1778/1894 - Train loss: 1.0305636906436215, Train acc: 0.8735244519392917\n",
      "Iteration 26500 - Batch 1878/1894 - Train loss: 1.0308788274754357, Train acc: 0.8731539382650346\n",
      "[0, 4, 3, 0, 0, 2, 1, 4, 0, 1, 3, 3, 2, 0, 2, 4, 0, 1, 2, 4, 4, 3, 4, 2, 3, 0, 4, 4, 2, 2, 4, 4, 0, 1, 0, 0, 4, 3, 2, 3, 0, 2, 1, 0, 4, 4, 3, 4, 3, 3, 4, 2, 1, 4, 2, 1, 2, 3, 0, 0, 4, 0, 1, 2, 2, 2, 0, 1, 4, 0, 3, 3, 1, 0, 0, 1, 1, 2, 1, 3, 1, 2, 4, 2, 2, 2, 1, 3, 0, 3, 3, 2, 4, 3, 3, 4, 1, 4, 2, 0, 2, 1, 1, 0, 3, 3, 0, 0, 0, 0, 2, 3, 3, 2, 2, 0, 0, 1, 2, 3, 3, 1, 3, 1, 2, 1, 1, 4, 4, 2, 0, 2, 0, 1, 4, 2, 1, 4, 2, 4, 4, 3, 1, 4, 3, 4, 2, 4, 0, 2, 1, 3, 3, 3, 0, 2, 0, 3, 2, 0, 3, 1, 3, 3, 0, 4, 4, 4, 0, 4, 1, 1, 3, 3, 2, 2, 4, 3, 2, 4, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 3, 3, 0, 3, 0, 4, 3, 4, 4, 2, 2, 2, 2, 2, 0, 3, 2, 4, 4, 2, 1, 2, 4, 3, 3, 3, 1, 1, 0, 0, 3, 4, 4, 3, 3, 4, 3, 3, 0, 3, 1, 1, 4, 0, 0, 0, 4, 0, 4, 0, 2, 3, 3, 2, 3, 2, 0, 1, 1, 3, 3, 1, 4, 0, 2, 1, 1, 3, 3, 4, 1, 3, 4, 3, 4, 1, 2, 4, 4, 3, 2, 4, 4, 1, 1, 2, 4, 4, 1, 1, 2, 2, 1, 2, 3, 2, 3, 2, 3, 3, 3, 3, 0, 4, 1, 4, 0, 4, 1, 3, 3, 1, 3, 2, 3, 2, 1, 4, 1, 2, 2, 0, 1, 1, 4, 1, 1, 0, 1, 0, 2, 4, 1, 3, 0, 2, 4, 4, 2, 0, 4, 4, 0, 1, 0, 2, 1, 4, 4, 1, 0, 1, 1, 3, 2, 0, 2, 1, 1, 4, 0, 1, 2, 0, 2, 4, 2, 2, 3, 3, 2, 2, 1, 3, 0, 0, 0, 3, 0, 0, 1, 4, 2, 1, 0, 0, 0, 1, 3, 3, 0, 4, 2, 0, 3, 4, 1, 0, 1, 2, 4, 3, 1, 0, 4, 2, 4, 0, 4, 3, 1, 4, 3, 0, 3, 0, 4, 1, 2, 1, 1, 4, 0, 0, 1, 1, 4, 3, 3, 0, 1, 0, 4, 2, 0, 3, 4, 2, 2, 4, 4, 0, 4, 2, 1, 2, 2, 1, 3, 0, 3, 1, 4, 2, 4, 4, 4, 0, 1, 1, 3, 0, 2, 4, 0, 1, 1, 1, 1, 0, 1, 2, 3, 0, 3, 4, 2, 0, 0, 2, 1, 0, 1, 3, 3, 3, 0, 2, 3, 1, 0, 3, 4, 2, 2, 2, 4, 4, 1, 1, 4, 2, 4, 2, 0, 2, 2, 3, 3, 1]\n",
      "[0, 4, 3, 0, 0, 2, 4, 4, 0, 4, 3, 3, 2, 4, 0, 4, 0, 4, 2, 4, 4, 3, 4, 2, 3, 0, 4, 4, 2, 2, 4, 4, 0, 3, 0, 0, 4, 3, 2, 3, 0, 2, 4, 0, 4, 4, 3, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 3, 0, 0, 4, 4, 3, 2, 2, 2, 0, 0, 4, 0, 3, 3, 3, 0, 0, 4, 4, 2, 4, 4, 4, 2, 4, 0, 0, 0, 4, 3, 0, 3, 3, 2, 4, 4, 3, 4, 3, 3, 2, 0, 0, 3, 4, 2, 3, 3, 0, 4, 0, 0, 2, 3, 3, 2, 0, 4, 0, 4, 2, 3, 3, 4, 3, 0, 2, 0, 3, 4, 4, 2, 0, 0, 0, 0, 4, 0, 3, 4, 2, 4, 4, 3, 4, 4, 3, 4, 2, 4, 0, 2, 2, 3, 3, 4, 0, 2, 0, 3, 3, 0, 3, 4, 3, 3, 4, 4, 4, 2, 0, 4, 3, 4, 3, 3, 2, 2, 3, 3, 0, 4, 0, 0, 4, 3, 4, 4, 2, 0, 0, 0, 3, 3, 0, 3, 0, 4, 3, 4, 2, 0, 2, 2, 2, 2, 0, 3, 2, 4, 4, 2, 4, 2, 4, 3, 3, 3, 3, 3, 0, 0, 3, 4, 4, 3, 3, 4, 3, 3, 0, 3, 4, 3, 4, 0, 0, 0, 4, 0, 4, 0, 2, 3, 3, 0, 3, 2, 4, 4, 4, 4, 0, 0, 4, 0, 2, 4, 3, 3, 3, 4, 3, 3, 4, 3, 4, 3, 2, 4, 4, 4, 2, 4, 4, 3, 4, 0, 4, 3, 4, 4, 0, 2, 4, 2, 3, 2, 3, 2, 3, 3, 3, 3, 0, 4, 4, 4, 0, 4, 3, 3, 3, 3, 3, 2, 3, 2, 4, 4, 3, 0, 2, 0, 3, 4, 4, 0, 4, 0, 0, 0, 2, 4, 0, 3, 0, 0, 4, 4, 2, 0, 4, 4, 0, 3, 0, 2, 3, 4, 4, 3, 0, 0, 3, 3, 2, 0, 2, 3, 4, 4, 0, 4, 2, 0, 2, 4, 2, 4, 3, 3, 2, 2, 4, 3, 0, 0, 0, 3, 0, 2, 4, 4, 2, 4, 4, 0, 0, 3, 3, 3, 0, 4, 2, 0, 3, 4, 3, 0, 0, 0, 4, 4, 4, 0, 4, 0, 4, 0, 4, 4, 4, 4, 4, 0, 3, 0, 4, 4, 2, 4, 4, 4, 0, 0, 3, 4, 4, 3, 3, 0, 0, 0, 4, 2, 0, 3, 4, 2, 2, 4, 4, 0, 4, 2, 4, 2, 2, 0, 4, 0, 3, 4, 4, 2, 4, 4, 4, 0, 4, 0, 3, 0, 2, 4, 0, 3, 0, 0, 4, 0, 4, 2, 3, 0, 3, 4, 2, 0, 4, 2, 4, 0, 0, 3, 3, 3, 0, 2, 3, 4, 0, 3, 4, 0, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 0, 2, 3, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.94      0.79      0.86       100\n",
      "           3       0.72      0.88      0.79       100\n",
      "           4       0.57      0.95      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.59      0.70      0.63       500\n",
      "weighted avg       0.59      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1961231753230095, Val acc: 0.704\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26600 - Batch 84/1894 - Train loss: 1.0353369369226344, Train acc: 0.8702205882352941\n",
      "Iteration 26700 - Batch 184/1894 - Train loss: 1.0373104878374049, Train acc: 0.8670608108108108\n",
      "Iteration 26800 - Batch 284/1894 - Train loss: 1.0324082477050915, Train acc: 0.8712719298245614\n",
      "Iteration 26900 - Batch 384/1894 - Train loss: 1.0339502754149499, Train acc: 0.8698051948051948\n",
      "Iteration 27000 - Batch 484/1894 - Train loss: 1.033764203307555, Train acc: 0.8700386597938145\n",
      "Iteration 27100 - Batch 584/1894 - Train loss: 1.0327544926578163, Train acc: 0.8711004273504274\n",
      "Iteration 27200 - Batch 684/1894 - Train loss: 1.032053115768154, Train acc: 0.8718065693430657\n",
      "Iteration 27300 - Batch 784/1894 - Train loss: 1.032257049174825, Train acc: 0.8716162420382165\n",
      "Iteration 27400 - Batch 884/1894 - Train loss: 1.0319541289307976, Train acc: 0.8718926553672316\n",
      "Iteration 27500 - Batch 984/1894 - Train loss: 1.0314853737196947, Train acc: 0.8725571065989848\n",
      "Iteration 27600 - Batch 1084/1894 - Train loss: 1.0302874786513192, Train acc: 0.8738191244239631\n",
      "Iteration 27700 - Batch 1184/1894 - Train loss: 1.0312888972366911, Train acc: 0.872837552742616\n",
      "Iteration 27800 - Batch 1284/1894 - Train loss: 1.0314289825435743, Train acc: 0.8725924124513619\n",
      "Iteration 27900 - Batch 1384/1894 - Train loss: 1.0316744354657748, Train acc: 0.8723149819494584\n",
      "Iteration 28000 - Batch 1484/1894 - Train loss: 1.0316858334172052, Train acc: 0.8723905723905724\n",
      "Iteration 28100 - Batch 1584/1894 - Train loss: 1.0313844064808795, Train acc: 0.872653785488959\n",
      "Iteration 28200 - Batch 1684/1894 - Train loss: 1.03163409480709, Train acc: 0.8724221068249258\n",
      "Iteration 28300 - Batch 1784/1894 - Train loss: 1.0317963150035099, Train acc: 0.8723039215686275\n",
      "Iteration 28400 - Batch 1884/1894 - Train loss: 1.0317849508331056, Train acc: 0.8723143236074271\n",
      "[1, 1, 2, 4, 3, 0, 4, 2, 1, 2, 3, 3, 4, 0, 0, 3, 0, 3, 2, 4, 3, 3, 2, 1, 0, 3, 2, 3, 3, 2, 0, 4, 0, 3, 2, 2, 3, 4, 4, 0, 2, 1, 0, 3, 2, 2, 3, 2, 3, 1, 0, 3, 2, 4, 1, 1, 4, 1, 3, 2, 0, 0, 2, 2, 4, 4, 0, 0, 1, 1, 1, 2, 3, 2, 1, 4, 1, 1, 2, 1, 1, 3, 0, 4, 2, 4, 4, 0, 1, 1, 0, 4, 0, 2, 3, 3, 2, 2, 3, 0, 1, 3, 2, 1, 1, 4, 4, 3, 0, 4, 1, 4, 2, 3, 1, 3, 2, 3, 4, 2, 1, 0, 4, 3, 4, 1, 4, 3, 2, 4, 4, 0, 4, 0, 0, 1, 1, 4, 0, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 4, 0, 4, 4, 1, 4, 0, 2, 3, 2, 3, 1, 1, 0, 4, 1, 3, 2, 1, 4, 3, 3, 3, 4, 2, 3, 1, 2, 2, 4, 2, 2, 0, 2, 1, 3, 0, 2, 1, 1, 4, 3, 0, 0, 3, 1, 2, 2, 1, 4, 0, 2, 1, 3, 0, 1, 1, 3, 0, 2, 3, 0, 3, 1, 0, 4, 2, 4, 2, 0, 1, 1, 2, 4, 3, 2, 3, 0, 2, 0, 2, 1, 0, 0, 3, 1, 4, 0, 2, 2, 0, 4, 0, 0, 3, 0, 1, 4, 0, 1, 4, 3, 1, 4, 4, 4, 4, 2, 1, 1, 4, 2, 2, 0, 0, 3, 4, 2, 4, 3, 4, 0, 2, 1, 1, 4, 2, 1, 3, 0, 3, 4, 2, 2, 1, 3, 1, 1, 1, 4, 0, 1, 0, 3, 3, 4, 0, 1, 2, 1, 1, 2, 2, 1, 0, 3, 3, 2, 1, 2, 3, 4, 0, 3, 3, 4, 2, 0, 1, 3, 2, 4, 3, 4, 3, 0, 4, 0, 1, 3, 2, 2, 4, 3, 0, 4, 3, 4, 0, 1, 4, 1, 3, 2, 1, 3, 1, 1, 3, 2, 3, 1, 0, 0, 0, 0, 0, 3, 3, 0, 2, 2, 0, 1, 2, 2, 4, 0, 4, 0, 4, 1, 1, 1, 1, 2, 2, 4, 4, 4, 3, 3, 2, 0, 0, 0, 1, 3, 4, 0, 2, 4, 0, 1, 3, 3, 3, 2, 0, 1, 0, 3, 1, 2, 3, 3, 3, 4, 4, 2, 0, 4, 3, 3, 3, 4, 2, 2, 0, 3, 0, 1, 0, 0, 3, 2, 2, 2, 1, 0, 0, 1, 2, 4, 4, 4, 3, 0, 1, 3, 0, 1, 1, 2, 1, 3, 4, 4, 3, 2, 3, 1, 1, 0, 4, 4, 4, 1, 4, 0, 0, 3, 3, 0, 0, 4, 4, 3, 1, 2, 4, 4, 3, 2, 4, 4, 4, 1, 3, 3, 4, 2, 1, 3, 0, 2, 4, 2, 1, 4, 3, 0, 4, 2, 4, 2, 2, 1, 4]\n",
      "[0, 4, 2, 3, 3, 0, 4, 2, 4, 2, 3, 0, 4, 0, 0, 3, 0, 3, 2, 4, 3, 3, 3, 0, 0, 3, 2, 3, 4, 2, 0, 4, 0, 3, 2, 2, 3, 3, 4, 0, 0, 3, 0, 3, 0, 2, 3, 2, 3, 3, 0, 3, 2, 4, 4, 4, 3, 3, 3, 0, 0, 0, 2, 2, 4, 4, 0, 0, 2, 0, 0, 2, 3, 2, 3, 4, 2, 3, 2, 4, 4, 3, 2, 4, 2, 4, 4, 0, 4, 3, 0, 4, 0, 2, 3, 3, 2, 2, 3, 0, 4, 3, 2, 4, 3, 4, 4, 3, 0, 4, 4, 4, 2, 3, 4, 3, 2, 3, 4, 2, 0, 0, 4, 3, 4, 3, 4, 3, 2, 4, 4, 0, 4, 0, 0, 0, 3, 3, 0, 2, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0, 4, 4, 0, 4, 0, 0, 3, 0, 3, 4, 4, 0, 4, 0, 3, 2, 4, 4, 3, 4, 3, 4, 2, 3, 0, 2, 2, 4, 2, 2, 4, 2, 4, 3, 0, 2, 3, 4, 4, 3, 0, 0, 3, 4, 2, 0, 3, 4, 0, 2, 4, 3, 2, 3, 3, 3, 0, 0, 3, 0, 3, 4, 0, 4, 2, 4, 2, 0, 4, 0, 3, 4, 3, 2, 3, 0, 2, 0, 2, 3, 0, 0, 3, 0, 4, 0, 2, 2, 0, 4, 0, 0, 3, 0, 4, 4, 0, 4, 4, 3, 4, 4, 4, 4, 4, 2, 3, 4, 4, 2, 2, 0, 0, 3, 4, 2, 4, 3, 4, 0, 2, 4, 0, 4, 2, 3, 3, 0, 3, 4, 0, 2, 0, 3, 3, 3, 3, 4, 0, 3, 0, 3, 3, 4, 0, 3, 2, 4, 4, 2, 2, 3, 0, 3, 3, 2, 4, 2, 3, 4, 0, 4, 3, 4, 2, 0, 4, 3, 2, 4, 3, 4, 3, 0, 4, 0, 0, 3, 0, 2, 4, 3, 0, 4, 3, 4, 0, 0, 4, 3, 3, 2, 0, 3, 4, 0, 3, 2, 3, 4, 0, 0, 0, 0, 4, 3, 3, 0, 2, 2, 0, 3, 3, 0, 4, 0, 4, 0, 4, 4, 4, 4, 3, 2, 2, 4, 4, 4, 3, 3, 2, 0, 4, 0, 0, 3, 4, 0, 0, 4, 0, 3, 3, 3, 3, 0, 0, 2, 0, 3, 4, 0, 3, 3, 3, 4, 4, 2, 0, 4, 3, 4, 3, 4, 2, 2, 0, 3, 0, 4, 0, 0, 3, 0, 2, 2, 4, 0, 0, 0, 2, 2, 4, 4, 3, 0, 0, 3, 0, 2, 4, 2, 3, 3, 4, 4, 3, 0, 3, 0, 4, 0, 4, 4, 4, 0, 4, 0, 2, 3, 4, 0, 0, 4, 4, 3, 3, 0, 4, 4, 3, 2, 4, 0, 4, 0, 4, 3, 4, 0, 0, 3, 0, 2, 4, 2, 4, 4, 3, 0, 4, 2, 4, 0, 2, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.77      0.83       100\n",
      "           3       0.72      0.93      0.81       100\n",
      "           4       0.65      0.94      0.77       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1942987889051437, Val acc: 0.712\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28500 - Batch 90/1894 - Train loss: 1.0277873690311725, Train acc: 0.8774038461538461\n",
      "Iteration 28600 - Batch 190/1894 - Train loss: 1.0299095776692735, Train acc: 0.8745091623036649\n",
      "Iteration 28700 - Batch 290/1894 - Train loss: 1.0310059943559653, Train acc: 0.8729596219931272\n",
      "Iteration 28800 - Batch 390/1894 - Train loss: 1.0318889724629006, Train acc: 0.871403452685422\n",
      "Iteration 28900 - Batch 490/1894 - Train loss: 1.0310817364519822, Train acc: 0.8721359470468432\n",
      "Iteration 29000 - Batch 590/1894 - Train loss: 1.0306758407610523, Train acc: 0.8727263113367174\n",
      "Iteration 29100 - Batch 690/1894 - Train loss: 1.02996315271223, Train acc: 0.8734623733719248\n",
      "Iteration 29200 - Batch 790/1894 - Train loss: 1.029464285232023, Train acc: 0.8742098609355247\n",
      "Iteration 29300 - Batch 890/1894 - Train loss: 1.0294939038060464, Train acc: 0.8742283950617284\n",
      "Iteration 29400 - Batch 990/1894 - Train loss: 1.0298779520810433, Train acc: 0.8738647830474269\n",
      "Iteration 29500 - Batch 1090/1894 - Train loss: 1.0310065763789946, Train acc: 0.8726225939505041\n",
      "Iteration 29600 - Batch 1190/1894 - Train loss: 1.0308053312834125, Train acc: 0.87276973131822\n",
      "Iteration 29700 - Batch 1290/1894 - Train loss: 1.031059804948885, Train acc: 0.8724583656080558\n",
      "Iteration 29800 - Batch 1390/1894 - Train loss: 1.0315500223576637, Train acc: 0.8720120416966212\n",
      "Iteration 29900 - Batch 1490/1894 - Train loss: 1.031721391508357, Train acc: 0.8718351777330651\n",
      "Iteration 30000 - Batch 1590/1894 - Train loss: 1.0311927578870341, Train acc: 0.8724269327467001\n",
      "Iteration 30100 - Batch 1690/1894 - Train loss: 1.0312705275083278, Train acc: 0.8723388527498521\n",
      "Iteration 30200 - Batch 1790/1894 - Train loss: 1.0315568933002381, Train acc: 0.8720337800111669\n",
      "Iteration 30300 - Batch 1890/1894 - Train loss: 1.031097231687912, Train acc: 0.8726037810682179\n",
      "[3, 3, 1, 4, 1, 1, 0, 0, 2, 2, 1, 3, 0, 1, 1, 4, 0, 4, 3, 2, 2, 3, 0, 4, 1, 4, 3, 2, 0, 3, 3, 0, 0, 3, 3, 4, 0, 2, 3, 3, 4, 0, 3, 3, 0, 1, 1, 4, 0, 2, 1, 2, 2, 1, 4, 3, 0, 1, 0, 0, 3, 0, 0, 4, 2, 0, 0, 0, 3, 0, 4, 4, 0, 0, 2, 4, 2, 4, 0, 2, 0, 2, 0, 4, 4, 1, 2, 2, 1, 0, 2, 1, 4, 0, 1, 0, 1, 2, 3, 3, 2, 2, 2, 2, 1, 4, 4, 2, 1, 4, 4, 2, 1, 0, 2, 4, 2, 2, 2, 2, 1, 1, 2, 3, 1, 0, 3, 2, 3, 3, 0, 2, 4, 1, 2, 3, 0, 2, 1, 0, 3, 3, 2, 0, 1, 3, 0, 4, 0, 2, 1, 2, 3, 4, 3, 4, 0, 0, 4, 1, 3, 0, 1, 0, 1, 0, 2, 1, 2, 4, 3, 3, 4, 4, 2, 3, 0, 0, 0, 3, 0, 3, 1, 4, 4, 1, 1, 0, 0, 2, 2, 1, 4, 0, 4, 0, 3, 3, 4, 2, 3, 1, 1, 2, 2, 2, 3, 0, 3, 1, 3, 0, 1, 1, 0, 3, 4, 3, 0, 2, 2, 1, 3, 1, 2, 2, 4, 4, 2, 2, 2, 3, 3, 1, 1, 0, 3, 0, 4, 1, 4, 3, 3, 3, 2, 4, 1, 4, 1, 2, 4, 3, 4, 0, 2, 2, 4, 1, 4, 4, 3, 3, 4, 2, 4, 1, 0, 4, 3, 0, 4, 0, 0, 2, 1, 4, 1, 4, 3, 3, 0, 4, 3, 4, 2, 4, 2, 1, 1, 0, 1, 2, 3, 2, 0, 4, 4, 1, 1, 3, 0, 1, 1, 1, 3, 3, 4, 1, 3, 2, 0, 4, 3, 1, 3, 3, 3, 0, 1, 1, 1, 2, 1, 2, 2, 1, 4, 2, 3, 0, 0, 4, 2, 4, 2, 0, 4, 0, 0, 3, 3, 4, 2, 2, 3, 4, 1, 1, 2, 4, 0, 4, 2, 2, 1, 4, 0, 1, 0, 2, 1, 0, 0, 3, 3, 4, 1, 3, 4, 2, 0, 2, 4, 2, 0, 3, 1, 4, 4, 0, 3, 0, 3, 4, 3, 2, 2, 1, 3, 2, 0, 1, 3, 1, 3, 0, 1, 0, 3, 0, 2, 4, 4, 0, 4, 2, 2, 0, 0, 1, 0, 4, 1, 4, 3, 4, 3, 2, 0, 2, 0, 2, 4, 1, 4, 1, 1, 4, 1, 4, 1, 1, 4, 2, 4, 0, 4, 4, 0, 3, 0, 4, 1, 1, 2, 1, 0, 0, 2, 3, 1, 4, 2, 3, 2, 2, 2, 2, 4, 4, 1, 2, 3, 1, 0, 0, 1, 1, 1, 4, 1, 3, 4, 3, 4, 3, 3, 1, 3, 2, 3, 0, 4, 3, 1, 1, 3, 3, 3, 4, 3, 0, 1, 4, 2, 2, 4, 3, 1, 3]\n",
      "[4, 3, 4, 4, 0, 3, 0, 0, 2, 2, 2, 3, 0, 4, 4, 3, 0, 4, 3, 2, 3, 3, 0, 4, 4, 3, 3, 2, 0, 0, 3, 2, 0, 3, 3, 4, 0, 2, 3, 3, 4, 0, 3, 3, 0, 4, 3, 4, 0, 2, 4, 2, 2, 2, 4, 4, 0, 4, 0, 0, 3, 4, 0, 4, 2, 0, 2, 0, 3, 4, 4, 4, 0, 0, 2, 4, 2, 4, 0, 2, 0, 2, 2, 4, 4, 3, 2, 2, 4, 0, 2, 0, 4, 0, 3, 0, 3, 2, 3, 3, 4, 2, 0, 2, 4, 4, 4, 2, 4, 4, 4, 2, 4, 0, 2, 4, 2, 2, 2, 2, 3, 0, 2, 3, 0, 0, 3, 2, 3, 3, 0, 0, 4, 4, 2, 3, 4, 0, 3, 0, 3, 3, 2, 0, 2, 3, 0, 4, 4, 2, 4, 2, 3, 4, 3, 4, 0, 0, 4, 3, 3, 0, 4, 0, 4, 0, 2, 0, 2, 4, 3, 3, 4, 4, 0, 3, 4, 0, 0, 3, 0, 3, 4, 4, 4, 0, 4, 0, 0, 0, 2, 4, 4, 0, 4, 4, 3, 3, 4, 0, 3, 4, 2, 2, 2, 2, 3, 0, 3, 4, 3, 0, 3, 4, 0, 3, 4, 3, 0, 2, 2, 0, 3, 4, 2, 2, 4, 4, 2, 2, 2, 3, 4, 3, 4, 0, 3, 2, 4, 3, 4, 3, 4, 3, 2, 4, 3, 4, 0, 2, 4, 3, 4, 0, 2, 2, 4, 3, 4, 4, 3, 3, 4, 0, 4, 4, 0, 4, 3, 0, 4, 0, 2, 2, 3, 4, 4, 4, 3, 3, 0, 4, 3, 4, 2, 4, 2, 3, 4, 4, 4, 2, 3, 2, 0, 4, 4, 2, 4, 3, 0, 4, 4, 3, 3, 3, 4, 3, 3, 2, 0, 3, 4, 4, 3, 3, 4, 0, 4, 3, 3, 2, 4, 2, 2, 0, 4, 0, 3, 0, 2, 4, 2, 4, 2, 0, 4, 0, 4, 3, 3, 4, 0, 0, 3, 4, 3, 0, 2, 4, 0, 4, 2, 2, 4, 4, 0, 3, 0, 2, 0, 2, 0, 3, 3, 4, 3, 3, 4, 2, 0, 2, 2, 0, 0, 3, 4, 4, 4, 0, 3, 0, 3, 4, 3, 2, 2, 4, 3, 2, 0, 4, 3, 3, 3, 0, 4, 0, 3, 0, 2, 4, 4, 4, 4, 2, 2, 0, 0, 2, 0, 4, 4, 4, 3, 3, 2, 2, 4, 2, 0, 4, 4, 0, 4, 3, 3, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 4, 0, 3, 0, 4, 4, 2, 2, 4, 0, 0, 2, 3, 0, 4, 2, 3, 2, 2, 2, 2, 4, 4, 0, 2, 3, 2, 0, 2, 2, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 0, 3, 2, 3, 0, 4, 3, 4, 4, 3, 4, 3, 4, 3, 0, 4, 4, 0, 2, 4, 3, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.82      0.84      0.83       100\n",
      "           3       0.75      0.90      0.82       100\n",
      "           4       0.57      0.95      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1989605277776718, Val acc: 0.702\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30400 - Batch 96/1894 - Train loss: 1.0187611592184638, Train acc: 0.8865979381443299\n",
      "Iteration 30500 - Batch 196/1894 - Train loss: 1.0280439711464238, Train acc: 0.8769035532994924\n",
      "Iteration 30600 - Batch 296/1894 - Train loss: 1.029103372434173, Train acc: 0.8759469696969697\n",
      "Iteration 30700 - Batch 396/1894 - Train loss: 1.0307518761764545, Train acc: 0.8737405541561712\n",
      "Iteration 30800 - Batch 496/1894 - Train loss: 1.0327193305286124, Train acc: 0.8716675050301811\n",
      "Iteration 30900 - Batch 596/1894 - Train loss: 1.0324273883198174, Train acc: 0.8719116415410385\n",
      "Iteration 31000 - Batch 696/1894 - Train loss: 1.0306877674297075, Train acc: 0.8736101147776184\n",
      "Iteration 31100 - Batch 796/1894 - Train loss: 1.0314294636025183, Train acc: 0.8726866373902133\n",
      "Iteration 31200 - Batch 896/1894 - Train loss: 1.0315246325538576, Train acc: 0.8724916387959866\n",
      "Iteration 31300 - Batch 996/1894 - Train loss: 1.0317656483908475, Train acc: 0.8723044132397192\n",
      "Iteration 31400 - Batch 1096/1894 - Train loss: 1.0316023810842196, Train acc: 0.8724077028258888\n",
      "Iteration 31500 - Batch 1196/1894 - Train loss: 1.0312480028211424, Train acc: 0.8728331244778613\n",
      "Iteration 31600 - Batch 1296/1894 - Train loss: 1.0310431479396687, Train acc: 0.8730965690053971\n",
      "Iteration 31700 - Batch 1396/1894 - Train loss: 1.0312480622303852, Train acc: 0.8728301717967072\n",
      "Iteration 31800 - Batch 1496/1894 - Train loss: 1.0312622314544224, Train acc: 0.8727663660654643\n",
      "Iteration 31900 - Batch 1596/1894 - Train loss: 1.0311847884130985, Train acc: 0.8727105510331872\n",
      "Iteration 32000 - Batch 1696/1894 - Train loss: 1.0313696760462534, Train acc: 0.8725324101355333\n",
      "Iteration 32100 - Batch 1796/1894 - Train loss: 1.0310089447860527, Train acc: 0.8729131886477463\n",
      "[2, 4, 3, 3, 2, 3, 3, 1, 2, 3, 3, 2, 0, 3, 1, 0, 4, 1, 1, 2, 3, 4, 2, 4, 3, 2, 4, 0, 0, 0, 3, 2, 3, 4, 2, 2, 3, 1, 2, 0, 2, 2, 1, 3, 0, 4, 1, 1, 3, 3, 4, 0, 2, 3, 0, 1, 0, 3, 1, 4, 0, 1, 3, 0, 1, 0, 1, 2, 4, 1, 2, 3, 2, 1, 3, 1, 2, 1, 4, 4, 0, 3, 4, 4, 0, 0, 4, 3, 2, 4, 4, 0, 1, 1, 1, 3, 3, 1, 0, 3, 3, 2, 4, 1, 2, 4, 4, 2, 2, 2, 3, 4, 2, 2, 4, 2, 3, 4, 3, 2, 4, 1, 2, 2, 1, 2, 0, 4, 4, 4, 3, 0, 1, 4, 3, 2, 3, 1, 3, 1, 4, 3, 2, 1, 1, 1, 4, 4, 1, 0, 1, 0, 0, 4, 3, 3, 2, 4, 3, 3, 0, 0, 4, 3, 3, 0, 0, 2, 3, 1, 3, 4, 3, 4, 4, 1, 2, 0, 2, 2, 0, 0, 2, 0, 4, 2, 0, 1, 3, 2, 4, 4, 0, 2, 0, 3, 0, 4, 1, 2, 2, 4, 1, 0, 0, 0, 4, 1, 3, 1, 4, 4, 1, 0, 1, 0, 2, 3, 0, 4, 0, 4, 3, 4, 1, 0, 3, 3, 3, 4, 4, 1, 1, 4, 0, 3, 4, 2, 4, 1, 4, 1, 0, 4, 2, 3, 0, 2, 1, 3, 4, 4, 4, 1, 0, 3, 1, 1, 0, 0, 4, 1, 2, 1, 4, 1, 2, 3, 2, 2, 2, 2, 1, 3, 4, 3, 4, 2, 4, 0, 2, 0, 2, 3, 3, 3, 4, 3, 2, 4, 1, 2, 3, 0, 0, 2, 4, 2, 4, 2, 1, 0, 4, 4, 1, 3, 1, 4, 1, 2, 2, 0, 0, 4, 2, 0, 3, 4, 2, 0, 4, 1, 3, 2, 3, 3, 3, 4, 4, 4, 1, 4, 0, 0, 2, 0, 0, 1, 1, 1, 2, 4, 3, 0, 1, 3, 4, 3, 2, 3, 0, 1, 3, 3, 1, 3, 0, 2, 3, 2, 4, 0, 0, 0, 3, 4, 2, 1, 2, 4, 0, 3, 2, 2, 4, 2, 0, 1, 2, 0, 1, 0, 4, 2, 0, 0, 3, 3, 1, 0, 1, 2, 0, 0, 1, 0, 3, 4, 0, 4, 2, 3, 0, 3, 1, 3, 0, 2, 4, 4, 2, 1, 0, 4, 4, 1, 2, 2, 2, 1, 0, 2, 2, 4, 1, 1, 2, 0, 4, 1, 1, 2, 0, 1, 4, 3, 2, 3, 1, 2, 1, 2, 1, 3, 0, 0, 2, 3, 0, 4, 0, 0, 0, 0, 1, 3, 0, 3, 0, 0, 1, 4, 0, 4, 2, 1, 0, 1, 3, 3, 1, 1, 3, 4, 3, 2, 2, 3, 1, 2, 4, 1, 1, 0, 3, 4, 3, 2, 1, 3, 1, 1, 4, 1, 0, 0, 1, 2, 3, 1]\n",
      "[2, 2, 3, 3, 2, 3, 3, 0, 2, 3, 3, 2, 4, 3, 0, 0, 4, 0, 4, 0, 3, 4, 2, 4, 3, 2, 4, 0, 0, 0, 3, 0, 3, 4, 2, 2, 3, 4, 2, 4, 2, 2, 4, 3, 0, 4, 4, 4, 4, 3, 2, 0, 0, 3, 0, 2, 0, 3, 4, 4, 0, 4, 3, 0, 3, 0, 4, 2, 4, 2, 0, 3, 2, 0, 3, 4, 2, 3, 0, 4, 0, 3, 4, 4, 0, 0, 4, 3, 2, 4, 4, 0, 4, 4, 4, 3, 3, 4, 0, 3, 3, 2, 4, 3, 2, 4, 4, 2, 2, 2, 3, 4, 2, 2, 4, 2, 4, 3, 3, 2, 4, 3, 2, 2, 3, 2, 0, 4, 4, 2, 3, 0, 0, 3, 4, 2, 3, 0, 2, 0, 4, 3, 2, 4, 4, 4, 4, 4, 3, 0, 0, 0, 0, 3, 3, 3, 0, 4, 3, 3, 0, 2, 4, 3, 3, 0, 0, 2, 3, 3, 3, 4, 3, 4, 4, 3, 2, 0, 2, 0, 0, 0, 2, 0, 4, 2, 0, 4, 3, 2, 4, 4, 4, 2, 0, 4, 0, 4, 0, 2, 0, 4, 4, 0, 0, 2, 4, 4, 3, 3, 4, 4, 2, 0, 4, 0, 2, 3, 4, 4, 0, 4, 3, 4, 4, 0, 3, 3, 3, 4, 3, 4, 3, 4, 0, 3, 4, 2, 4, 4, 4, 0, 0, 4, 2, 3, 0, 2, 4, 4, 4, 4, 4, 4, 0, 3, 4, 3, 0, 0, 4, 4, 2, 4, 4, 0, 2, 3, 2, 2, 2, 2, 4, 3, 4, 3, 4, 0, 4, 0, 2, 0, 2, 3, 3, 3, 4, 3, 2, 4, 4, 2, 3, 0, 0, 0, 4, 0, 4, 2, 0, 0, 4, 4, 3, 3, 4, 4, 4, 2, 2, 0, 0, 4, 2, 0, 3, 4, 2, 0, 4, 3, 3, 0, 3, 3, 3, 4, 4, 4, 3, 4, 0, 0, 2, 0, 0, 3, 4, 3, 0, 4, 3, 0, 0, 3, 4, 3, 2, 3, 0, 0, 3, 3, 0, 3, 2, 2, 3, 0, 4, 0, 0, 0, 3, 4, 0, 4, 2, 4, 0, 3, 2, 2, 4, 3, 2, 4, 2, 4, 0, 2, 4, 2, 0, 0, 3, 3, 4, 0, 4, 2, 0, 0, 4, 0, 3, 4, 0, 4, 2, 3, 2, 3, 0, 3, 0, 2, 4, 4, 2, 4, 0, 4, 3, 4, 2, 2, 2, 4, 0, 2, 2, 4, 4, 2, 2, 0, 4, 3, 0, 2, 0, 3, 4, 3, 2, 4, 4, 0, 3, 2, 3, 3, 0, 2, 2, 3, 0, 4, 0, 0, 0, 0, 3, 3, 0, 4, 0, 0, 3, 4, 4, 4, 2, 0, 0, 2, 3, 2, 4, 3, 3, 4, 3, 0, 2, 3, 4, 2, 4, 4, 2, 2, 3, 4, 3, 2, 0, 3, 3, 4, 4, 4, 3, 0, 4, 0, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.81      0.82      0.82       100\n",
      "           3       0.75      0.91      0.82       100\n",
      "           4       0.59      0.91      0.72       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2114918529987335, Val acc: 0.698\n",
      "Epoch 18/30\n",
      "Iteration 32200 - Batch 2/1894 - Train loss: 1.032331943511963, Train acc: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32300 - Batch 102/1894 - Train loss: 1.030334991158791, Train acc: 0.875\n",
      "Iteration 32400 - Batch 202/1894 - Train loss: 1.0251706970736312, Train acc: 0.8799261083743842\n",
      "Iteration 32500 - Batch 302/1894 - Train loss: 1.0252593429175147, Train acc: 0.8794348184818482\n",
      "Iteration 32600 - Batch 402/1894 - Train loss: 1.0229349713171683, Train acc: 0.8818238213399504\n",
      "Iteration 32700 - Batch 502/1894 - Train loss: 1.0261557852297607, Train acc: 0.8782927435387674\n",
      "Iteration 32800 - Batch 602/1894 - Train loss: 1.0275178866006842, Train acc: 0.8765547263681592\n",
      "Iteration 32900 - Batch 702/1894 - Train loss: 1.0273357344046765, Train acc: 0.8766891891891891\n",
      "Iteration 33000 - Batch 802/1894 - Train loss: 1.0270255555399923, Train acc: 0.8770625778331258\n",
      "Iteration 33100 - Batch 902/1894 - Train loss: 1.0272359597854572, Train acc: 0.8769725913621262\n",
      "Iteration 33200 - Batch 1002/1894 - Train loss: 1.0284071083915078, Train acc: 0.8759035393818544\n",
      "Iteration 33300 - Batch 1102/1894 - Train loss: 1.0273190575735416, Train acc: 0.8769832275611967\n",
      "Iteration 33400 - Batch 1202/1894 - Train loss: 1.0266669675001776, Train acc: 0.8776756026600167\n",
      "Iteration 33500 - Batch 1302/1894 - Train loss: 1.0267440190886135, Train acc: 0.8775901765157329\n",
      "Iteration 33600 - Batch 1402/1894 - Train loss: 1.027143603635531, Train acc: 0.8771605488239487\n",
      "Iteration 33700 - Batch 1502/1894 - Train loss: 1.026682331136918, Train acc: 0.8776197604790419\n",
      "Iteration 33800 - Batch 1602/1894 - Train loss: 1.02714203538853, Train acc: 0.8771444167186525\n",
      "Iteration 33900 - Batch 1702/1894 - Train loss: 1.0270983544924788, Train acc: 0.8772570463887258\n",
      "Iteration 34000 - Batch 1802/1894 - Train loss: 1.0276811480257686, Train acc: 0.8766118968386023\n",
      "[4, 3, 4, 3, 2, 1, 1, 2, 2, 0, 2, 1, 2, 4, 0, 2, 0, 1, 4, 3, 2, 4, 4, 4, 2, 3, 0, 2, 3, 1, 0, 0, 4, 4, 0, 2, 3, 2, 0, 0, 3, 0, 4, 1, 0, 4, 4, 0, 3, 1, 3, 1, 4, 3, 0, 3, 0, 3, 4, 3, 1, 3, 3, 0, 4, 4, 4, 0, 1, 3, 1, 4, 3, 0, 0, 1, 3, 1, 4, 4, 2, 4, 2, 4, 4, 3, 1, 0, 1, 1, 3, 2, 2, 3, 3, 3, 3, 2, 4, 2, 1, 2, 2, 1, 2, 2, 3, 4, 0, 0, 4, 2, 4, 3, 2, 4, 3, 1, 1, 4, 2, 0, 1, 1, 2, 2, 0, 1, 1, 4, 3, 1, 4, 0, 2, 2, 1, 1, 3, 4, 1, 1, 0, 4, 1, 3, 0, 1, 1, 2, 4, 4, 4, 4, 2, 2, 2, 0, 2, 4, 3, 3, 4, 2, 0, 4, 0, 0, 2, 0, 3, 1, 0, 4, 1, 1, 0, 4, 2, 2, 1, 4, 4, 3, 1, 2, 3, 4, 1, 2, 4, 3, 0, 3, 2, 3, 0, 0, 0, 0, 0, 0, 2, 1, 3, 0, 1, 0, 4, 0, 1, 1, 3, 2, 4, 4, 4, 1, 4, 1, 1, 2, 1, 2, 4, 2, 0, 0, 3, 0, 4, 4, 1, 2, 2, 0, 2, 3, 2, 0, 0, 2, 2, 2, 4, 2, 2, 0, 4, 0, 0, 3, 3, 2, 0, 1, 0, 1, 2, 3, 3, 0, 1, 0, 1, 3, 3, 3, 3, 4, 4, 0, 0, 3, 0, 1, 1, 3, 0, 3, 1, 1, 1, 4, 2, 2, 0, 2, 1, 0, 2, 2, 1, 1, 0, 2, 4, 1, 4, 3, 4, 1, 4, 4, 1, 2, 3, 3, 0, 3, 3, 4, 0, 0, 4, 0, 3, 4, 3, 2, 4, 1, 4, 2, 1, 1, 0, 1, 3, 4, 2, 4, 3, 2, 3, 2, 2, 3, 4, 0, 0, 1, 1, 3, 0, 2, 2, 3, 4, 2, 3, 4, 2, 3, 0, 4, 2, 4, 0, 0, 1, 2, 1, 4, 0, 4, 4, 1, 2, 1, 4, 1, 1, 2, 4, 4, 2, 3, 4, 1, 1, 4, 2, 0, 0, 0, 3, 1, 0, 2, 3, 1, 2, 2, 2, 2, 3, 1, 1, 0, 1, 3, 2, 2, 3, 1, 3, 2, 1, 0, 0, 0, 2, 3, 4, 1, 3, 0, 3, 1, 0, 2, 4, 2, 0, 2, 3, 4, 0, 1, 2, 1, 2, 3, 0, 3, 3, 4, 0, 0, 3, 3, 1, 4, 2, 4, 1, 3, 0, 2, 1, 3, 2, 3, 3, 3, 3, 3, 0, 3, 1, 1, 4, 1, 4, 2, 0, 1, 3, 4, 0, 1, 0, 3, 1, 4, 4, 2, 4, 3, 4, 4, 0, 4, 0, 1, 1, 0, 3, 0, 2, 3, 3, 1, 3, 3, 4, 0, 2, 1]\n",
      "[4, 3, 4, 3, 0, 2, 4, 2, 2, 0, 2, 4, 0, 4, 0, 2, 0, 4, 4, 3, 2, 4, 4, 4, 2, 3, 0, 0, 3, 4, 0, 0, 4, 4, 0, 2, 3, 2, 0, 4, 3, 0, 4, 4, 0, 4, 4, 0, 3, 3, 3, 4, 4, 3, 0, 3, 4, 3, 4, 3, 4, 3, 4, 0, 0, 4, 4, 0, 3, 3, 4, 4, 3, 2, 0, 4, 3, 4, 4, 4, 2, 2, 2, 4, 3, 3, 4, 0, 4, 3, 3, 2, 2, 4, 3, 3, 4, 2, 4, 2, 3, 2, 2, 2, 2, 2, 3, 4, 0, 0, 4, 2, 4, 3, 2, 4, 3, 4, 3, 4, 2, 4, 4, 0, 2, 2, 0, 0, 4, 4, 2, 3, 4, 4, 2, 0, 3, 4, 3, 4, 3, 4, 0, 4, 0, 3, 0, 3, 3, 2, 4, 4, 4, 4, 2, 2, 2, 0, 2, 4, 3, 3, 4, 0, 0, 4, 0, 0, 2, 2, 3, 3, 0, 4, 2, 3, 0, 4, 2, 0, 3, 4, 4, 3, 3, 2, 3, 4, 4, 0, 3, 3, 0, 3, 2, 3, 0, 0, 0, 0, 0, 4, 2, 4, 3, 0, 3, 0, 4, 0, 4, 4, 3, 2, 3, 4, 4, 0, 4, 4, 4, 3, 0, 2, 4, 2, 0, 0, 3, 0, 4, 4, 0, 2, 2, 0, 2, 3, 2, 0, 0, 2, 2, 2, 4, 2, 2, 0, 4, 2, 0, 3, 3, 3, 0, 4, 0, 3, 2, 3, 3, 0, 4, 3, 4, 3, 3, 3, 3, 4, 4, 0, 0, 3, 0, 4, 0, 3, 0, 3, 4, 3, 3, 4, 0, 2, 0, 2, 4, 4, 2, 2, 2, 4, 0, 2, 4, 3, 4, 3, 4, 4, 4, 4, 4, 2, 3, 3, 0, 3, 3, 3, 0, 0, 4, 0, 4, 4, 3, 2, 4, 4, 4, 2, 0, 3, 0, 4, 3, 4, 0, 4, 3, 2, 3, 2, 3, 3, 4, 0, 0, 0, 4, 3, 0, 2, 2, 3, 4, 2, 3, 4, 2, 3, 0, 4, 0, 4, 0, 0, 3, 0, 4, 4, 0, 4, 4, 2, 2, 4, 4, 4, 4, 0, 4, 4, 2, 3, 4, 0, 0, 0, 2, 4, 0, 0, 3, 4, 0, 2, 3, 4, 2, 2, 2, 2, 3, 4, 4, 0, 3, 3, 2, 2, 3, 4, 3, 2, 0, 0, 0, 0, 0, 3, 4, 3, 3, 0, 3, 4, 0, 2, 4, 2, 2, 2, 3, 4, 0, 0, 2, 4, 0, 3, 0, 3, 3, 4, 4, 0, 3, 3, 0, 4, 2, 4, 4, 3, 0, 3, 4, 3, 0, 3, 3, 3, 4, 3, 0, 3, 3, 0, 4, 0, 4, 2, 4, 3, 3, 4, 0, 3, 0, 3, 3, 4, 4, 2, 4, 3, 4, 4, 0, 4, 0, 4, 2, 0, 3, 0, 2, 3, 3, 4, 4, 4, 4, 0, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.81      0.84       100\n",
      "           3       0.72      0.92      0.81       100\n",
      "           4       0.58      0.93      0.72       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2009713277220726, Val acc: 0.704\n",
      "Epoch 19/30\n",
      "Iteration 34100 - Batch 8/1894 - Train loss: 1.005651421017117, Train acc: 0.8993055555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34200 - Batch 108/1894 - Train loss: 1.0226548155513377, Train acc: 0.8813073394495413\n",
      "Iteration 34300 - Batch 208/1894 - Train loss: 1.026176505396811, Train acc: 0.8773923444976076\n",
      "Iteration 34400 - Batch 308/1894 - Train loss: 1.0272344618939273, Train acc: 0.8762135922330098\n",
      "Iteration 34500 - Batch 408/1894 - Train loss: 1.0280968146102645, Train acc: 0.8753820293398533\n",
      "Iteration 34600 - Batch 508/1894 - Train loss: 1.0272615232261553, Train acc: 0.8764120825147348\n",
      "Iteration 34700 - Batch 608/1894 - Train loss: 1.0285774441971176, Train acc: 0.8752565681444991\n",
      "Iteration 34800 - Batch 708/1894 - Train loss: 1.0269843514782753, Train acc: 0.8770715796897038\n",
      "Iteration 34900 - Batch 808/1894 - Train loss: 1.0278439739136525, Train acc: 0.8761974660074165\n",
      "Iteration 35000 - Batch 908/1894 - Train loss: 1.0286753155348456, Train acc: 0.875309405940594\n",
      "Iteration 35100 - Batch 1008/1894 - Train loss: 1.0279141557582896, Train acc: 0.8760220515361744\n",
      "Iteration 35200 - Batch 1108/1894 - Train loss: 1.0274924269874854, Train acc: 0.8764652840396754\n",
      "Iteration 35300 - Batch 1208/1894 - Train loss: 1.0283666591786274, Train acc: 0.8754652605459057\n",
      "Iteration 35400 - Batch 1308/1894 - Train loss: 1.0281889751906428, Train acc: 0.8757161955691367\n",
      "Iteration 35500 - Batch 1408/1894 - Train loss: 1.0287394059135864, Train acc: 0.875221788502484\n",
      "Iteration 35600 - Batch 1508/1894 - Train loss: 1.0290905776760133, Train acc: 0.8749792909211398\n",
      "Iteration 35700 - Batch 1608/1894 - Train loss: 1.0288022762874107, Train acc: 0.8752719080174021\n",
      "Iteration 35800 - Batch 1708/1894 - Train loss: 1.029045238838062, Train acc: 0.8750731421884143\n",
      "Iteration 35900 - Batch 1808/1894 - Train loss: 1.0287094592982198, Train acc: 0.8754491431730238\n",
      "[0, 3, 4, 0, 2, 2, 4, 4, 3, 0, 2, 3, 3, 2, 4, 0, 3, 2, 1, 4, 1, 4, 0, 0, 1, 0, 0, 0, 0, 0, 1, 3, 2, 4, 2, 3, 4, 4, 1, 0, 3, 4, 2, 0, 3, 3, 0, 4, 4, 3, 2, 2, 4, 4, 3, 1, 4, 1, 1, 4, 2, 1, 0, 2, 3, 1, 3, 3, 2, 1, 2, 1, 3, 4, 1, 3, 1, 3, 1, 0, 1, 0, 3, 4, 4, 4, 0, 3, 3, 3, 3, 2, 3, 0, 2, 2, 0, 1, 1, 3, 4, 2, 4, 3, 4, 4, 2, 3, 1, 3, 0, 4, 0, 2, 2, 0, 2, 0, 3, 0, 1, 0, 0, 0, 2, 3, 2, 3, 3, 2, 4, 4, 2, 2, 3, 1, 2, 4, 1, 1, 0, 0, 3, 4, 4, 4, 4, 2, 2, 1, 1, 4, 1, 3, 1, 1, 1, 4, 1, 2, 1, 3, 1, 3, 1, 0, 2, 2, 1, 0, 4, 0, 0, 3, 0, 2, 2, 3, 1, 2, 4, 2, 2, 2, 3, 4, 2, 4, 2, 0, 1, 1, 2, 1, 2, 0, 2, 4, 4, 1, 2, 1, 3, 4, 2, 4, 2, 0, 0, 1, 1, 4, 2, 4, 3, 3, 2, 1, 3, 4, 1, 0, 1, 1, 0, 2, 0, 1, 3, 4, 4, 3, 1, 0, 0, 2, 3, 3, 0, 0, 4, 3, 1, 2, 4, 0, 3, 1, 0, 2, 0, 4, 2, 0, 1, 0, 1, 2, 4, 1, 2, 0, 2, 3, 2, 0, 2, 0, 3, 1, 1, 0, 1, 1, 4, 2, 1, 3, 4, 1, 0, 4, 0, 3, 1, 0, 0, 4, 2, 2, 4, 2, 0, 3, 2, 2, 3, 4, 1, 3, 2, 3, 0, 4, 0, 4, 3, 3, 1, 0, 0, 4, 3, 1, 3, 4, 4, 0, 2, 1, 0, 4, 2, 1, 0, 0, 1, 1, 0, 2, 2, 1, 1, 3, 4, 4, 2, 4, 2, 2, 4, 4, 1, 4, 1, 1, 3, 3, 3, 4, 1, 3, 2, 0, 3, 4, 4, 3, 3, 0, 3, 2, 1, 0, 3, 0, 0, 0, 3, 3, 1, 2, 4, 4, 3, 0, 0, 2, 1, 4, 0, 3, 3, 0, 0, 3, 3, 4, 1, 0, 0, 1, 3, 4, 2, 1, 3, 0, 1, 0, 1, 2, 3, 4, 0, 1, 4, 0, 1, 0, 4, 3, 0, 2, 4, 4, 1, 2, 2, 0, 4, 3, 1, 2, 4, 4, 2, 4, 0, 1, 4, 3, 0, 4, 4, 2, 2, 3, 1, 0, 0, 2, 3, 2, 0, 0, 3, 1, 3, 2, 4, 3, 2, 4, 4, 1, 2, 0, 1, 0, 2, 4, 4, 2, 4, 3, 3, 4, 4, 2, 3, 1, 2, 2, 4, 1, 0, 1, 3, 3, 3, 2, 3, 3, 4, 0, 2, 1, 1, 4, 1, 3, 2, 1, 1, 0, 3, 1, 2, 1]\n",
      "[0, 3, 4, 0, 2, 2, 4, 4, 3, 0, 2, 3, 3, 2, 4, 0, 3, 0, 3, 4, 3, 2, 0, 4, 3, 4, 0, 0, 0, 0, 3, 3, 2, 4, 2, 3, 4, 4, 3, 0, 4, 0, 2, 0, 3, 3, 0, 4, 4, 3, 2, 2, 2, 4, 3, 4, 4, 4, 3, 4, 2, 4, 0, 2, 3, 4, 3, 3, 2, 3, 0, 3, 3, 4, 4, 3, 0, 3, 3, 0, 0, 0, 4, 4, 4, 2, 0, 4, 3, 3, 3, 0, 3, 0, 0, 2, 0, 4, 3, 3, 4, 2, 4, 3, 4, 3, 2, 3, 0, 3, 0, 4, 0, 2, 2, 0, 0, 0, 3, 0, 4, 2, 4, 0, 2, 3, 2, 4, 3, 2, 4, 4, 2, 2, 3, 0, 2, 4, 3, 3, 0, 0, 3, 4, 4, 4, 4, 2, 2, 4, 0, 4, 4, 3, 0, 0, 3, 4, 4, 2, 3, 3, 4, 3, 3, 0, 2, 0, 3, 0, 4, 0, 0, 3, 0, 2, 2, 3, 3, 2, 3, 2, 0, 2, 3, 4, 2, 4, 2, 0, 4, 4, 2, 0, 0, 0, 2, 4, 4, 4, 2, 4, 3, 4, 2, 4, 2, 0, 0, 0, 0, 4, 2, 4, 3, 3, 2, 0, 4, 4, 4, 0, 0, 0, 0, 2, 0, 4, 3, 4, 4, 3, 4, 0, 0, 2, 3, 3, 0, 0, 4, 3, 3, 0, 4, 0, 3, 4, 0, 2, 0, 4, 2, 0, 2, 0, 3, 2, 4, 0, 2, 0, 2, 3, 2, 0, 3, 0, 3, 3, 2, 0, 3, 2, 3, 2, 4, 3, 4, 4, 4, 4, 0, 3, 0, 4, 0, 4, 0, 2, 4, 0, 0, 3, 2, 4, 3, 4, 0, 3, 2, 3, 0, 4, 0, 4, 4, 3, 4, 0, 0, 4, 3, 4, 3, 4, 4, 0, 0, 4, 0, 4, 0, 3, 0, 0, 3, 2, 2, 2, 0, 4, 4, 3, 4, 4, 0, 4, 2, 0, 4, 4, 3, 4, 3, 4, 3, 3, 3, 4, 4, 3, 2, 0, 4, 4, 4, 3, 3, 0, 3, 2, 4, 0, 3, 0, 0, 2, 3, 3, 4, 2, 4, 4, 3, 0, 0, 0, 3, 4, 0, 4, 3, 0, 0, 3, 3, 4, 4, 0, 4, 3, 3, 4, 2, 0, 3, 0, 4, 0, 3, 2, 3, 0, 0, 4, 4, 0, 4, 0, 4, 0, 0, 0, 4, 4, 3, 3, 3, 0, 4, 3, 0, 2, 4, 4, 2, 4, 0, 3, 4, 3, 0, 4, 3, 2, 2, 3, 4, 0, 0, 2, 3, 2, 4, 0, 3, 0, 3, 2, 4, 4, 2, 4, 4, 4, 2, 0, 0, 0, 2, 4, 4, 2, 4, 3, 3, 4, 4, 2, 3, 4, 2, 2, 4, 2, 0, 0, 3, 3, 3, 2, 3, 3, 4, 0, 2, 4, 4, 4, 2, 3, 2, 4, 4, 0, 3, 4, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.78      0.82       100\n",
      "           3       0.71      0.90      0.79       100\n",
      "           4       0.60      0.91      0.73       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2072507664561272, Val acc: 0.698\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36000 - Batch 14/1894 - Train loss: 1.0043519973754882, Train acc: 0.9\n",
      "Iteration 36100 - Batch 114/1894 - Train loss: 1.0287120819091797, Train acc: 0.8758152173913043\n",
      "Iteration 36200 - Batch 214/1894 - Train loss: 1.0294628792030867, Train acc: 0.8751453488372093\n",
      "Iteration 36300 - Batch 314/1894 - Train loss: 1.0283087123008001, Train acc: 0.8761904761904762\n",
      "Iteration 36400 - Batch 414/1894 - Train loss: 1.025840174720948, Train acc: 0.8786897590361445\n",
      "Iteration 36500 - Batch 514/1894 - Train loss: 1.0264961141984439, Train acc: 0.8779733009708738\n",
      "Iteration 36600 - Batch 614/1894 - Train loss: 1.0260835858864512, Train acc: 0.8783028455284553\n",
      "Iteration 36700 - Batch 714/1894 - Train loss: 1.0266867028249727, Train acc: 0.8775349650349651\n",
      "Iteration 36800 - Batch 814/1894 - Train loss: 1.0273727187349753, Train acc: 0.8768788343558283\n",
      "Iteration 36900 - Batch 914/1894 - Train loss: 1.0261232673144731, Train acc: 0.8780054644808744\n",
      "Iteration 37000 - Batch 1014/1894 - Train loss: 1.0262033428464616, Train acc: 0.8779248768472906\n",
      "Iteration 37100 - Batch 1114/1894 - Train loss: 1.0261573065556753, Train acc: 0.8779428251121076\n",
      "Iteration 37200 - Batch 1214/1894 - Train loss: 1.0256185272593557, Train acc: 0.8784722222222222\n",
      "Iteration 37300 - Batch 1314/1894 - Train loss: 1.0255221004268515, Train acc: 0.8784933460076045\n",
      "Iteration 37400 - Batch 1414/1894 - Train loss: 1.0256553794385688, Train acc: 0.8783568904593639\n",
      "Iteration 37500 - Batch 1514/1894 - Train loss: 1.0260875892324417, Train acc: 0.8779290429042904\n",
      "Iteration 37600 - Batch 1614/1894 - Train loss: 1.0254888209027033, Train acc: 0.8785410216718266\n",
      "Iteration 37700 - Batch 1714/1894 - Train loss: 1.025376338340103, Train acc: 0.8786989795918367\n",
      "Iteration 37800 - Batch 1814/1894 - Train loss: 1.0254602218134015, Train acc: 0.8785812672176309\n",
      "[1, 2, 2, 4, 2, 0, 4, 3, 3, 3, 2, 2, 1, 1, 3, 1, 0, 2, 4, 0, 1, 1, 0, 1, 4, 1, 2, 0, 2, 4, 1, 4, 3, 4, 1, 3, 0, 2, 2, 3, 1, 1, 4, 2, 3, 3, 2, 4, 4, 3, 2, 1, 0, 4, 0, 1, 2, 1, 2, 3, 3, 3, 2, 1, 1, 1, 1, 1, 2, 0, 3, 4, 0, 4, 0, 3, 2, 3, 4, 2, 4, 3, 0, 3, 4, 2, 0, 2, 3, 1, 1, 4, 1, 3, 1, 3, 3, 4, 4, 3, 4, 4, 1, 4, 4, 2, 2, 1, 3, 3, 0, 2, 3, 0, 4, 2, 1, 2, 3, 0, 0, 0, 1, 2, 0, 2, 3, 3, 1, 3, 1, 4, 1, 2, 4, 1, 3, 4, 0, 2, 0, 2, 2, 0, 1, 1, 0, 2, 2, 4, 2, 1, 2, 0, 4, 0, 1, 4, 1, 3, 0, 4, 1, 2, 3, 0, 4, 4, 0, 2, 2, 3, 0, 1, 0, 2, 3, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 3, 2, 1, 1, 4, 2, 2, 0, 0, 2, 1, 0, 1, 4, 1, 0, 3, 4, 2, 0, 2, 0, 2, 2, 3, 2, 2, 0, 3, 1, 1, 0, 2, 4, 4, 4, 3, 1, 1, 4, 2, 3, 4, 1, 4, 2, 1, 0, 3, 1, 2, 0, 1, 0, 4, 1, 0, 3, 4, 2, 2, 0, 3, 1, 0, 2, 3, 1, 0, 2, 3, 2, 4, 0, 1, 4, 2, 0, 4, 1, 3, 2, 4, 0, 4, 1, 1, 3, 0, 2, 4, 0, 4, 3, 0, 1, 1, 1, 3, 1, 4, 1, 0, 2, 0, 4, 1, 0, 2, 4, 2, 2, 3, 4, 3, 4, 1, 3, 0, 4, 0, 1, 4, 3, 2, 2, 1, 0, 4, 3, 2, 0, 1, 3, 2, 1, 4, 2, 3, 1, 1, 3, 4, 2, 3, 2, 0, 3, 4, 4, 0, 0, 3, 1, 0, 3, 2, 3, 1, 0, 2, 4, 4, 0, 2, 2, 1, 3, 3, 0, 0, 2, 2, 2, 0, 3, 4, 0, 0, 4, 0, 1, 2, 4, 3, 0, 3, 4, 2, 2, 4, 3, 2, 4, 1, 3, 4, 4, 4, 3, 4, 3, 4, 4, 0, 3, 3, 1, 3, 3, 0, 3, 1, 4, 0, 3, 2, 0, 3, 1, 0, 0, 4, 0, 1, 3, 1, 3, 1, 3, 4, 3, 0, 2, 3, 2, 3, 1, 4, 0, 3, 0, 4, 3, 2, 0, 2, 4, 3, 0, 3, 0, 4, 2, 1, 4, 0, 3, 3, 4, 4, 4, 1, 1, 2, 4, 3, 1, 3, 4, 1, 4, 0, 4, 3, 0, 4, 2, 2, 1, 1, 4, 0, 0, 3, 0, 3, 4, 1, 3, 2, 2, 3, 0, 0, 4, 1, 2, 2, 3, 4, 4, 1, 2, 2, 4, 0, 0, 2, 1, 3, 4, 0]\n",
      "[4, 2, 2, 4, 2, 0, 4, 4, 3, 3, 2, 0, 3, 4, 4, 4, 4, 2, 4, 0, 0, 0, 0, 3, 4, 3, 2, 0, 2, 4, 2, 4, 3, 0, 3, 3, 0, 2, 2, 3, 4, 4, 2, 2, 3, 3, 2, 4, 4, 4, 2, 4, 0, 4, 0, 0, 0, 4, 0, 3, 3, 3, 3, 4, 0, 4, 4, 0, 2, 0, 3, 4, 0, 4, 0, 3, 2, 3, 4, 2, 4, 3, 0, 3, 4, 0, 4, 2, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 4, 0, 2, 4, 3, 3, 4, 2, 3, 0, 4, 2, 3, 2, 3, 0, 2, 0, 4, 2, 0, 0, 3, 3, 2, 3, 3, 4, 4, 2, 4, 2, 4, 4, 4, 2, 0, 2, 2, 0, 3, 4, 0, 2, 2, 4, 2, 0, 2, 0, 4, 0, 3, 4, 3, 3, 0, 4, 3, 0, 3, 0, 4, 4, 0, 2, 2, 3, 0, 4, 0, 2, 3, 4, 0, 0, 0, 3, 0, 3, 0, 3, 0, 3, 2, 4, 4, 4, 2, 2, 0, 0, 2, 0, 0, 3, 4, 4, 0, 3, 4, 2, 0, 0, 0, 0, 4, 3, 2, 2, 0, 3, 4, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 2, 3, 4, 2, 4, 2, 0, 0, 3, 3, 2, 2, 4, 0, 4, 4, 0, 3, 4, 2, 2, 0, 3, 0, 4, 0, 3, 0, 0, 2, 0, 2, 4, 0, 4, 4, 2, 0, 4, 3, 3, 0, 4, 0, 4, 4, 4, 3, 0, 2, 4, 0, 4, 3, 0, 4, 4, 3, 3, 4, 4, 0, 0, 2, 0, 4, 4, 0, 2, 4, 2, 2, 3, 4, 3, 2, 3, 3, 0, 4, 0, 4, 4, 3, 2, 2, 4, 3, 4, 3, 0, 2, 4, 3, 2, 4, 4, 2, 3, 4, 3, 3, 4, 2, 3, 0, 0, 3, 4, 4, 0, 0, 4, 3, 0, 3, 2, 3, 0, 0, 2, 4, 4, 0, 0, 2, 3, 3, 3, 0, 0, 2, 2, 0, 0, 3, 4, 0, 0, 4, 0, 0, 2, 4, 3, 0, 3, 3, 2, 2, 3, 3, 2, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 2, 3, 3, 4, 3, 3, 0, 3, 4, 4, 0, 3, 2, 0, 3, 4, 2, 0, 4, 0, 3, 3, 4, 3, 0, 3, 4, 3, 0, 2, 3, 2, 3, 3, 4, 2, 4, 0, 4, 3, 2, 0, 2, 3, 3, 2, 3, 0, 4, 2, 3, 4, 0, 4, 3, 4, 4, 4, 3, 0, 2, 4, 3, 0, 3, 4, 4, 4, 0, 4, 3, 0, 4, 2, 3, 4, 3, 4, 0, 0, 3, 0, 3, 4, 4, 3, 2, 2, 3, 0, 0, 4, 3, 2, 2, 3, 4, 4, 4, 2, 2, 4, 0, 0, 2, 4, 3, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.81      0.84       100\n",
      "           3       0.73      0.91      0.81       100\n",
      "           4       0.59      0.94      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.194224290549755, Val acc: 0.706\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37900 - Batch 20/1894 - Train loss: 1.0145218883241927, Train acc: 0.8883928571428571\n",
      "Iteration 38000 - Batch 120/1894 - Train loss: 1.0183529371072437, Train acc: 0.8861053719008265\n",
      "Iteration 38100 - Batch 220/1894 - Train loss: 1.0170900249912729, Train acc: 0.8865950226244343\n",
      "Iteration 38200 - Batch 320/1894 - Train loss: 1.02001522634631, Train acc: 0.884053738317757\n",
      "Iteration 38300 - Batch 420/1894 - Train loss: 1.0206730079764141, Train acc: 0.8834619952494062\n",
      "Iteration 38400 - Batch 520/1894 - Train loss: 1.021992734320562, Train acc: 0.8820777351247601\n",
      "Iteration 38500 - Batch 620/1894 - Train loss: 1.0234425339529865, Train acc: 0.8804347826086957\n",
      "Iteration 38600 - Batch 720/1894 - Train loss: 1.023309769395651, Train acc: 0.8807645631067961\n",
      "Iteration 38700 - Batch 820/1894 - Train loss: 1.023445778584219, Train acc: 0.8805953105968332\n",
      "Iteration 38800 - Batch 920/1894 - Train loss: 1.0239642149203505, Train acc: 0.8800556460369164\n",
      "Iteration 38900 - Batch 1020/1894 - Train loss: 1.0238388867849935, Train acc: 0.8802338393731636\n",
      "Iteration 39000 - Batch 1120/1894 - Train loss: 1.0245431237301583, Train acc: 0.8794881801962533\n",
      "Iteration 39100 - Batch 1220/1894 - Train loss: 1.025637974463751, Train acc: 0.8783527846027847\n",
      "Iteration 39200 - Batch 1320/1894 - Train loss: 1.0257467777777765, Train acc: 0.878217259651779\n",
      "Iteration 39300 - Batch 1420/1894 - Train loss: 1.0263094404983655, Train acc: 0.8775950035186488\n",
      "Iteration 39400 - Batch 1520/1894 - Train loss: 1.025937598289274, Train acc: 0.8779585798816568\n",
      "Iteration 39500 - Batch 1620/1894 - Train loss: 1.0258564709661038, Train acc: 0.8781037939543491\n",
      "Iteration 39600 - Batch 1720/1894 - Train loss: 1.025923228346976, Train acc: 0.8780505520046484\n",
      "Iteration 39700 - Batch 1820/1894 - Train loss: 1.0258952421450733, Train acc: 0.8780889621087314\n",
      "[0, 0, 1, 0, 4, 0, 1, 1, 2, 0, 0, 1, 3, 2, 3, 4, 2, 3, 0, 2, 0, 3, 1, 3, 0, 2, 2, 0, 2, 2, 3, 1, 2, 1, 3, 0, 1, 0, 2, 3, 4, 0, 0, 0, 0, 4, 3, 4, 2, 2, 3, 0, 0, 3, 4, 0, 1, 0, 4, 3, 2, 4, 4, 1, 3, 2, 2, 4, 0, 3, 2, 1, 1, 4, 2, 1, 0, 3, 0, 1, 4, 1, 3, 1, 3, 3, 2, 0, 0, 4, 1, 4, 2, 0, 2, 1, 2, 1, 2, 4, 0, 1, 4, 3, 1, 0, 1, 4, 4, 2, 1, 4, 0, 2, 1, 4, 0, 0, 2, 4, 4, 1, 1, 3, 3, 1, 0, 2, 0, 4, 0, 0, 0, 2, 1, 1, 2, 1, 2, 1, 4, 0, 4, 2, 3, 3, 3, 3, 1, 3, 3, 3, 1, 4, 2, 1, 2, 3, 4, 3, 2, 4, 2, 4, 4, 2, 4, 0, 3, 3, 2, 1, 0, 4, 0, 2, 2, 2, 4, 2, 4, 0, 1, 4, 4, 4, 2, 3, 1, 0, 2, 3, 1, 1, 4, 1, 1, 3, 1, 1, 1, 3, 4, 2, 0, 1, 3, 4, 0, 3, 0, 4, 2, 1, 2, 3, 2, 2, 4, 4, 2, 3, 1, 0, 1, 1, 3, 4, 3, 1, 4, 3, 1, 2, 3, 2, 1, 1, 3, 4, 2, 2, 3, 4, 1, 1, 0, 2, 3, 0, 3, 4, 2, 3, 4, 4, 3, 3, 3, 1, 3, 4, 0, 2, 4, 0, 1, 3, 4, 0, 1, 2, 1, 2, 3, 1, 4, 0, 0, 3, 1, 2, 2, 3, 1, 4, 0, 1, 0, 4, 4, 3, 0, 4, 2, 4, 0, 4, 0, 4, 1, 1, 0, 3, 0, 0, 3, 2, 0, 2, 4, 4, 2, 3, 4, 3, 2, 0, 2, 0, 4, 3, 3, 3, 2, 0, 2, 0, 4, 1, 4, 0, 4, 0, 4, 2, 4, 1, 1, 4, 1, 4, 2, 3, 2, 1, 4, 0, 1, 3, 2, 0, 4, 1, 3, 0, 3, 2, 0, 1, 3, 2, 2, 2, 2, 1, 0, 3, 4, 4, 2, 1, 0, 3, 2, 3, 1, 4, 1, 4, 2, 4, 3, 3, 3, 1, 1, 0, 0, 1, 2, 2, 1, 3, 3, 2, 4, 1, 3, 3, 0, 2, 2, 4, 1, 4, 2, 0, 3, 4, 2, 1, 2, 3, 3, 1, 4, 0, 0, 4, 3, 0, 1, 2, 4, 2, 0, 1, 0, 3, 2, 2, 4, 0, 4, 1, 1, 1, 0, 3, 3, 0, 1, 4, 2, 4, 0, 0, 3, 2, 3, 3, 0, 3, 1, 1, 0, 4, 0, 0, 1, 1, 1, 0, 3, 4, 1, 2, 3, 4, 0, 0, 3, 2, 3, 3, 3, 3, 0, 2, 4, 1, 2, 3, 2, 0, 1, 0, 4, 2, 4, 4, 0, 0, 2, 4, 4, 4, 1, 3]\n",
      "[0, 0, 4, 0, 4, 0, 4, 0, 0, 0, 4, 4, 3, 0, 4, 4, 2, 3, 0, 2, 0, 3, 3, 3, 0, 2, 2, 0, 2, 2, 3, 0, 2, 3, 3, 0, 4, 0, 2, 3, 4, 4, 0, 0, 0, 4, 3, 4, 2, 0, 3, 0, 0, 3, 4, 0, 4, 0, 4, 3, 2, 4, 4, 4, 3, 0, 0, 4, 0, 3, 2, 3, 4, 4, 2, 4, 0, 3, 0, 2, 4, 0, 3, 2, 3, 4, 2, 0, 0, 4, 0, 4, 2, 0, 2, 4, 2, 3, 0, 4, 0, 3, 4, 3, 3, 0, 4, 4, 4, 2, 4, 4, 0, 2, 4, 4, 0, 0, 2, 4, 4, 0, 4, 3, 3, 4, 0, 2, 0, 4, 0, 0, 0, 2, 4, 3, 2, 0, 2, 4, 4, 0, 4, 2, 3, 3, 3, 3, 4, 3, 3, 3, 0, 4, 2, 4, 2, 3, 4, 3, 2, 3, 2, 4, 4, 2, 4, 0, 3, 3, 0, 4, 0, 4, 4, 2, 2, 2, 4, 0, 4, 0, 3, 4, 4, 4, 2, 3, 0, 0, 2, 3, 3, 3, 4, 0, 4, 3, 3, 3, 4, 3, 4, 2, 4, 2, 3, 4, 0, 3, 0, 4, 2, 0, 0, 3, 2, 2, 4, 4, 0, 3, 3, 0, 4, 4, 4, 4, 3, 0, 4, 3, 3, 0, 3, 2, 4, 4, 3, 4, 3, 0, 3, 4, 4, 0, 0, 2, 3, 0, 4, 4, 2, 3, 4, 4, 4, 3, 3, 4, 3, 4, 0, 2, 4, 0, 3, 3, 4, 0, 4, 2, 0, 0, 3, 4, 4, 0, 0, 3, 3, 2, 2, 3, 4, 3, 0, 4, 0, 4, 4, 3, 0, 4, 2, 4, 0, 4, 0, 4, 4, 3, 0, 4, 0, 0, 3, 2, 0, 2, 4, 4, 2, 3, 4, 3, 2, 0, 2, 0, 4, 3, 2, 3, 0, 0, 2, 4, 4, 0, 4, 0, 4, 0, 0, 2, 4, 4, 3, 4, 4, 2, 2, 3, 0, 4, 4, 0, 4, 4, 2, 0, 4, 0, 3, 0, 2, 2, 0, 3, 3, 0, 2, 2, 2, 4, 0, 3, 4, 4, 2, 4, 0, 3, 2, 3, 3, 4, 4, 4, 2, 4, 4, 3, 3, 4, 0, 0, 2, 4, 2, 2, 4, 3, 3, 2, 0, 4, 3, 3, 0, 3, 2, 3, 4, 4, 2, 0, 3, 4, 2, 4, 2, 3, 3, 4, 4, 0, 0, 3, 3, 0, 4, 2, 4, 2, 0, 0, 0, 3, 2, 2, 4, 0, 4, 4, 4, 4, 0, 3, 4, 0, 4, 4, 2, 4, 0, 0, 2, 2, 3, 3, 0, 3, 3, 4, 0, 4, 0, 4, 4, 3, 4, 0, 3, 4, 4, 2, 3, 4, 0, 0, 3, 2, 3, 3, 3, 3, 0, 2, 4, 4, 0, 3, 2, 0, 3, 0, 4, 2, 4, 4, 0, 0, 2, 4, 4, 4, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.81      0.86       100\n",
      "           3       0.75      0.88      0.81       100\n",
      "           4       0.57      0.93      0.70       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1912799961864948, Val acc: 0.71\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39800 - Batch 26/1894 - Train loss: 1.0107212331559923, Train acc: 0.8946759259259259\n",
      "Iteration 39900 - Batch 126/1894 - Train loss: 1.0169133802098551, Train acc: 0.8865649606299213\n",
      "Iteration 40000 - Batch 226/1894 - Train loss: 1.022461526719484, Train acc: 0.8807819383259912\n",
      "Iteration 40100 - Batch 326/1894 - Train loss: 1.0205337109915706, Train acc: 0.8829319571865444\n",
      "Iteration 40200 - Batch 426/1894 - Train loss: 1.0221607223048423, Train acc: 0.8813670960187353\n",
      "Iteration 40300 - Batch 526/1894 - Train loss: 1.0223448517426594, Train acc: 0.881404174573055\n",
      "Iteration 40400 - Batch 626/1894 - Train loss: 1.0223534515980137, Train acc: 0.8815291068580542\n",
      "Iteration 40500 - Batch 726/1894 - Train loss: 1.0220730526083273, Train acc: 0.8817916093535075\n",
      "Iteration 40600 - Batch 826/1894 - Train loss: 1.021466012372936, Train acc: 0.8824818621523579\n",
      "Iteration 40700 - Batch 926/1894 - Train loss: 1.0224815099113325, Train acc: 0.8814387810140237\n",
      "Iteration 40800 - Batch 1026/1894 - Train loss: 1.0230545135180464, Train acc: 0.8809335443037974\n",
      "Iteration 40900 - Batch 1126/1894 - Train loss: 1.0231655249049838, Train acc: 0.8808229813664596\n",
      "Iteration 41000 - Batch 1226/1894 - Train loss: 1.0237635056372085, Train acc: 0.8802974735126324\n",
      "Iteration 41100 - Batch 1326/1894 - Train loss: 1.0240526403712435, Train acc: 0.8799924642049737\n",
      "Iteration 41200 - Batch 1426/1894 - Train loss: 1.0237618353538942, Train acc: 0.8802338822704976\n",
      "Iteration 41300 - Batch 1526/1894 - Train loss: 1.023592202664983, Train acc: 0.8804027504911591\n",
      "Iteration 41400 - Batch 1626/1894 - Train loss: 1.0238839893452434, Train acc: 0.880089889366933\n",
      "Iteration 41500 - Batch 1726/1894 - Train loss: 1.0233274681345879, Train acc: 0.8805551534452808\n",
      "Iteration 41600 - Batch 1826/1894 - Train loss: 1.0235252694869603, Train acc: 0.8803366174055829\n",
      "[4, 1, 1, 3, 2, 0, 1, 1, 1, 3, 2, 2, 3, 1, 3, 4, 0, 0, 1, 3, 3, 2, 3, 1, 3, 0, 2, 2, 0, 2, 3, 2, 1, 2, 0, 1, 3, 3, 4, 3, 1, 3, 4, 2, 1, 1, 2, 1, 0, 3, 2, 0, 4, 0, 0, 4, 3, 2, 4, 3, 1, 4, 1, 3, 3, 2, 2, 3, 4, 0, 2, 2, 2, 2, 2, 3, 1, 4, 1, 1, 3, 1, 0, 1, 2, 3, 2, 3, 4, 0, 4, 0, 4, 1, 2, 4, 1, 4, 4, 0, 4, 4, 3, 2, 4, 1, 2, 4, 0, 3, 2, 1, 2, 2, 4, 4, 0, 3, 1, 1, 3, 1, 4, 1, 2, 0, 3, 2, 4, 1, 3, 4, 1, 0, 0, 0, 1, 4, 2, 3, 4, 4, 1, 2, 2, 2, 1, 0, 0, 0, 3, 1, 2, 2, 1, 2, 3, 1, 3, 2, 1, 4, 1, 1, 2, 1, 0, 1, 0, 1, 0, 3, 3, 3, 1, 0, 4, 4, 0, 0, 2, 4, 3, 3, 4, 4, 1, 0, 4, 0, 2, 1, 3, 0, 3, 2, 4, 1, 0, 4, 2, 4, 3, 3, 4, 1, 3, 4, 0, 3, 0, 3, 3, 4, 3, 0, 1, 4, 0, 4, 0, 1, 3, 4, 4, 1, 4, 4, 3, 3, 0, 1, 3, 2, 1, 4, 2, 4, 2, 1, 1, 2, 4, 1, 0, 2, 4, 4, 3, 4, 4, 1, 3, 1, 0, 3, 1, 4, 1, 0, 2, 3, 0, 3, 0, 1, 3, 2, 1, 4, 2, 1, 0, 3, 0, 4, 1, 2, 3, 3, 3, 2, 4, 4, 0, 0, 2, 2, 0, 3, 0, 0, 0, 1, 0, 4, 2, 2, 3, 4, 4, 0, 3, 1, 0, 1, 3, 3, 4, 2, 1, 4, 2, 0, 0, 0, 2, 1, 3, 2, 2, 4, 2, 1, 0, 4, 4, 1, 4, 3, 3, 0, 3, 3, 3, 1, 1, 0, 3, 3, 0, 0, 1, 2, 1, 2, 2, 1, 2, 4, 1, 3, 0, 2, 1, 0, 2, 3, 2, 4, 0, 3, 1, 4, 2, 0, 4, 1, 0, 4, 0, 2, 0, 4, 0, 1, 4, 1, 1, 1, 4, 0, 0, 4, 2, 2, 4, 4, 2, 0, 2, 4, 1, 2, 4, 4, 4, 1, 2, 3, 3, 2, 0, 4, 3, 3, 3, 1, 3, 1, 0, 1, 3, 3, 2, 4, 0, 0, 3, 0, 3, 0, 1, 1, 4, 2, 2, 2, 2, 3, 0, 2, 2, 1, 0, 0, 0, 3, 0, 0, 0, 3, 2, 1, 4, 4, 2, 4, 1, 4, 0, 0, 2, 2, 4, 4, 1, 0, 4, 2, 3, 2, 4, 3, 4, 2, 2, 4, 3, 2, 1, 2, 1, 2, 3, 3, 0, 1, 4, 0, 3, 0, 0, 0, 2, 0, 2, 1, 3, 4, 1, 2, 3, 4, 4, 3, 0, 0, 0, 3]\n",
      "[4, 4, 4, 3, 0, 4, 2, 0, 4, 3, 2, 2, 3, 3, 3, 4, 0, 0, 0, 3, 2, 2, 3, 4, 3, 0, 2, 2, 0, 2, 3, 2, 0, 2, 0, 3, 3, 3, 4, 3, 4, 3, 4, 2, 0, 3, 3, 0, 0, 3, 3, 0, 4, 0, 0, 4, 3, 2, 4, 3, 3, 4, 4, 3, 3, 2, 0, 3, 4, 0, 2, 2, 2, 2, 2, 3, 3, 4, 4, 0, 3, 0, 0, 4, 2, 3, 2, 3, 4, 0, 4, 0, 4, 3, 0, 4, 0, 4, 4, 2, 4, 4, 3, 2, 4, 4, 2, 4, 0, 3, 2, 4, 2, 0, 4, 4, 0, 3, 0, 3, 3, 3, 4, 0, 0, 0, 3, 2, 4, 4, 3, 4, 3, 0, 0, 0, 4, 4, 2, 3, 3, 4, 4, 2, 0, 2, 0, 0, 0, 0, 3, 4, 2, 2, 4, 2, 3, 3, 3, 2, 4, 4, 4, 0, 2, 3, 0, 4, 0, 4, 0, 3, 3, 3, 0, 0, 4, 4, 3, 0, 2, 4, 3, 3, 4, 4, 0, 0, 4, 0, 2, 4, 4, 0, 3, 2, 4, 0, 0, 4, 2, 2, 3, 3, 4, 3, 3, 4, 0, 3, 0, 3, 3, 4, 3, 0, 4, 2, 0, 4, 0, 4, 3, 2, 4, 3, 0, 4, 3, 3, 0, 0, 3, 0, 4, 4, 2, 4, 2, 4, 4, 0, 4, 4, 0, 2, 4, 4, 3, 4, 4, 4, 4, 0, 0, 3, 4, 4, 4, 0, 0, 3, 0, 3, 0, 3, 3, 2, 4, 4, 2, 0, 0, 0, 0, 3, 4, 0, 3, 3, 3, 2, 4, 4, 0, 0, 2, 0, 0, 3, 0, 0, 0, 4, 0, 4, 2, 0, 3, 4, 4, 0, 3, 4, 0, 4, 3, 4, 4, 2, 3, 4, 2, 0, 0, 0, 3, 2, 3, 2, 2, 4, 2, 0, 4, 4, 4, 3, 4, 3, 3, 0, 3, 3, 3, 4, 4, 0, 3, 3, 0, 0, 0, 0, 3, 2, 2, 3, 2, 4, 4, 4, 0, 0, 0, 0, 0, 3, 2, 4, 0, 4, 3, 4, 2, 0, 4, 0, 0, 3, 0, 2, 0, 4, 0, 4, 4, 4, 3, 3, 4, 0, 0, 4, 2, 2, 4, 4, 2, 0, 2, 4, 3, 0, 4, 4, 0, 4, 0, 3, 3, 2, 0, 4, 3, 3, 3, 0, 3, 3, 0, 3, 3, 3, 2, 4, 0, 0, 3, 0, 3, 0, 3, 2, 0, 0, 2, 0, 2, 4, 0, 2, 0, 4, 0, 0, 0, 3, 0, 0, 4, 3, 2, 3, 4, 4, 2, 4, 2, 4, 0, 0, 2, 2, 3, 4, 3, 0, 4, 0, 3, 0, 4, 3, 4, 2, 2, 4, 3, 2, 0, 2, 0, 2, 4, 3, 0, 4, 4, 0, 3, 0, 0, 0, 0, 0, 2, 3, 3, 4, 0, 2, 3, 4, 4, 3, 0, 0, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.95      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.74      0.81       100\n",
      "           3       0.72      0.91      0.80       100\n",
      "           4       0.63      0.90      0.74       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.62       500\n",
      "weighted avg       0.58      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.1996024176478386, Val acc: 0.7\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41700 - Batch 32/1894 - Train loss: 1.030084830341917, Train acc: 0.8740530303030303\n",
      "Iteration 41800 - Batch 132/1894 - Train loss: 1.026522033196643, Train acc: 0.8778195488721805\n",
      "Iteration 41900 - Batch 232/1894 - Train loss: 1.0260399147676296, Train acc: 0.8776824034334764\n",
      "Iteration 42000 - Batch 332/1894 - Train loss: 1.026201091550134, Train acc: 0.8778153153153153\n",
      "Iteration 42100 - Batch 432/1894 - Train loss: 1.0228647213885196, Train acc: 0.88135103926097\n",
      "Iteration 42200 - Batch 532/1894 - Train loss: 1.024645262095539, Train acc: 0.8797490619136961\n",
      "Iteration 42300 - Batch 632/1894 - Train loss: 1.0233829641982466, Train acc: 0.8809241706161137\n",
      "Iteration 42400 - Batch 732/1894 - Train loss: 1.0234183887830373, Train acc: 0.8809259890859482\n",
      "Iteration 42500 - Batch 832/1894 - Train loss: 1.023669951889409, Train acc: 0.8806647659063626\n",
      "Iteration 42600 - Batch 932/1894 - Train loss: 1.0233465345598367, Train acc: 0.8809284565916399\n",
      "Iteration 42700 - Batch 1032/1894 - Train loss: 1.022500890499163, Train acc: 0.8818066311713456\n",
      "Iteration 42800 - Batch 1132/1894 - Train loss: 1.0235392132483008, Train acc: 0.8807369814651368\n",
      "Iteration 42900 - Batch 1232/1894 - Train loss: 1.0232979710374726, Train acc: 0.8809813463098135\n",
      "Iteration 43000 - Batch 1332/1894 - Train loss: 1.0236509837607022, Train acc: 0.8806029632408102\n",
      "Iteration 43100 - Batch 1432/1894 - Train loss: 1.023976462958829, Train acc: 0.8802555826936497\n",
      "Iteration 43200 - Batch 1532/1894 - Train loss: 1.0238056813123098, Train acc: 0.8804223744292238\n",
      "Iteration 43300 - Batch 1632/1894 - Train loss: 1.023222579630474, Train acc: 0.8810088793631353\n",
      "Iteration 43400 - Batch 1732/1894 - Train loss: 1.0229503752108056, Train acc: 0.8812752452394691\n",
      "Iteration 43500 - Batch 1832/1894 - Train loss: 1.0232854568431498, Train acc: 0.8809499454446263\n",
      "[2, 2, 0, 2, 0, 4, 3, 2, 4, 0, 4, 3, 2, 0, 1, 1, 1, 1, 1, 0, 4, 0, 4, 3, 4, 3, 4, 0, 3, 1, 3, 4, 4, 2, 1, 3, 1, 3, 3, 2, 1, 2, 2, 2, 3, 1, 3, 0, 0, 2, 0, 2, 0, 4, 2, 4, 2, 1, 0, 2, 2, 4, 4, 3, 4, 1, 4, 1, 3, 2, 1, 4, 0, 4, 4, 3, 0, 2, 1, 3, 4, 0, 3, 1, 2, 4, 1, 1, 0, 4, 0, 4, 3, 1, 3, 2, 2, 2, 2, 1, 1, 1, 2, 0, 4, 0, 1, 1, 3, 0, 4, 2, 3, 4, 3, 3, 3, 4, 3, 3, 0, 3, 1, 1, 3, 4, 2, 4, 1, 0, 4, 4, 2, 2, 3, 0, 1, 1, 3, 2, 4, 3, 1, 3, 1, 3, 0, 3, 4, 0, 3, 1, 2, 2, 0, 1, 1, 1, 1, 1, 4, 3, 3, 3, 3, 0, 3, 2, 1, 2, 0, 4, 0, 3, 4, 1, 3, 0, 1, 1, 3, 0, 0, 0, 0, 3, 0, 0, 2, 0, 4, 4, 4, 4, 2, 3, 3, 3, 3, 1, 2, 2, 4, 2, 2, 2, 0, 1, 0, 4, 4, 1, 1, 2, 3, 3, 0, 0, 4, 2, 4, 0, 3, 0, 1, 0, 2, 4, 3, 2, 4, 1, 2, 2, 4, 2, 3, 0, 0, 2, 1, 0, 2, 0, 2, 2, 1, 0, 4, 4, 1, 4, 1, 2, 1, 3, 4, 4, 0, 0, 1, 4, 0, 2, 4, 0, 4, 3, 3, 3, 3, 1, 1, 2, 1, 4, 3, 2, 1, 4, 3, 3, 4, 4, 3, 4, 1, 0, 3, 4, 2, 0, 4, 2, 4, 0, 3, 3, 3, 3, 2, 2, 0, 2, 2, 3, 0, 1, 0, 4, 2, 0, 2, 0, 2, 4, 4, 1, 1, 4, 2, 0, 0, 4, 0, 0, 3, 2, 4, 3, 4, 0, 1, 1, 2, 3, 4, 3, 3, 2, 3, 4, 1, 2, 0, 3, 1, 2, 3, 4, 3, 4, 4, 0, 4, 2, 1, 2, 2, 2, 0, 3, 4, 2, 4, 4, 2, 1, 1, 1, 0, 0, 0, 3, 4, 3, 1, 3, 0, 0, 1, 2, 4, 4, 4, 2, 2, 2, 3, 0, 2, 1, 2, 0, 0, 0, 3, 3, 0, 1, 2, 1, 1, 1, 2, 4, 4, 1, 1, 3, 0, 0, 0, 3, 2, 1, 2, 4, 2, 4, 4, 0, 1, 1, 2, 3, 1, 1, 0, 0, 0, 0, 0, 1, 1, 4, 0, 1, 2, 1, 4, 2, 4, 4, 2, 1, 3, 0, 0, 4, 1, 3, 2, 2, 1, 3, 2, 2, 2, 3, 4, 2, 0, 3, 1, 0, 3, 0, 4, 3, 3, 1, 1, 3, 3, 4, 4, 1, 1, 3, 1, 0, 4, 3, 0, 3, 0, 2, 1, 1, 4, 0, 2, 1, 4, 3, 1, 2, 0, 0]\n",
      "[0, 2, 0, 0, 0, 4, 3, 2, 4, 0, 4, 3, 2, 0, 4, 4, 4, 4, 0, 0, 4, 0, 4, 3, 4, 4, 4, 0, 4, 3, 3, 2, 4, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 0, 4, 2, 0, 2, 0, 3, 2, 4, 2, 3, 0, 0, 2, 4, 4, 3, 4, 4, 4, 3, 3, 0, 3, 4, 0, 4, 4, 3, 0, 2, 4, 3, 4, 0, 3, 3, 2, 4, 4, 4, 0, 4, 0, 4, 3, 4, 3, 2, 2, 2, 2, 3, 0, 3, 0, 0, 4, 4, 4, 0, 3, 4, 4, 2, 3, 3, 3, 3, 3, 4, 3, 3, 0, 3, 0, 3, 3, 4, 0, 4, 4, 0, 4, 4, 2, 2, 4, 0, 3, 4, 3, 2, 4, 3, 0, 3, 4, 4, 0, 3, 4, 0, 3, 4, 2, 2, 0, 0, 3, 0, 4, 2, 4, 3, 3, 3, 3, 0, 3, 2, 4, 2, 0, 4, 0, 3, 4, 4, 3, 0, 3, 4, 3, 0, 0, 0, 0, 3, 0, 0, 2, 0, 4, 4, 4, 4, 2, 3, 3, 3, 3, 4, 2, 0, 4, 2, 0, 2, 4, 4, 0, 4, 4, 3, 4, 2, 3, 3, 4, 0, 4, 0, 4, 4, 3, 0, 4, 4, 2, 4, 3, 3, 4, 4, 0, 0, 4, 2, 3, 2, 0, 2, 4, 0, 0, 0, 2, 2, 4, 0, 4, 2, 3, 4, 3, 0, 4, 3, 4, 4, 0, 0, 4, 4, 0, 2, 4, 0, 4, 4, 3, 3, 3, 3, 3, 2, 3, 4, 3, 0, 4, 4, 3, 3, 4, 4, 3, 4, 4, 0, 3, 4, 2, 0, 3, 2, 4, 0, 3, 4, 3, 3, 0, 2, 0, 2, 2, 3, 0, 3, 0, 4, 0, 0, 2, 0, 2, 4, 4, 3, 0, 4, 2, 0, 0, 4, 0, 0, 3, 2, 4, 3, 4, 0, 4, 4, 2, 3, 4, 3, 3, 2, 3, 4, 4, 2, 0, 3, 4, 2, 3, 4, 3, 4, 4, 0, 4, 2, 4, 2, 2, 2, 0, 3, 4, 2, 4, 4, 2, 4, 4, 4, 0, 0, 0, 3, 4, 3, 4, 3, 0, 0, 4, 2, 4, 4, 4, 2, 0, 0, 0, 0, 2, 4, 2, 0, 0, 0, 2, 3, 0, 4, 2, 0, 4, 0, 2, 4, 3, 2, 3, 4, 0, 0, 0, 3, 2, 3, 0, 4, 0, 4, 4, 0, 4, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 3, 2, 3, 4, 2, 4, 3, 2, 4, 2, 0, 4, 4, 4, 3, 0, 0, 4, 3, 2, 2, 2, 3, 4, 2, 0, 4, 3, 0, 3, 0, 4, 4, 3, 0, 0, 3, 3, 3, 4, 4, 4, 3, 4, 0, 4, 3, 0, 3, 0, 2, 4, 0, 4, 0, 2, 3, 4, 3, 0, 2, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.77      0.82       100\n",
      "           3       0.73      0.88      0.80       100\n",
      "           4       0.57      0.92      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.62       500\n",
      "weighted avg       0.58      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2090003862977028, Val acc: 0.696\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43600 - Batch 38/1894 - Train loss: 1.025584639647068, Train acc: 0.8774038461538461\n",
      "Iteration 43700 - Batch 138/1894 - Train loss: 1.020011840106772, Train acc: 0.8835431654676259\n",
      "Iteration 43800 - Batch 238/1894 - Train loss: 1.019500856619001, Train acc: 0.8844142259414226\n",
      "Iteration 43900 - Batch 338/1894 - Train loss: 1.0220218856426115, Train acc: 0.8820058997050148\n",
      "Iteration 44000 - Batch 438/1894 - Train loss: 1.0237068504027191, Train acc: 0.8804812072892938\n",
      "Iteration 44100 - Batch 538/1894 - Train loss: 1.0236970728093928, Train acc: 0.8804499072356216\n",
      "Iteration 44200 - Batch 638/1894 - Train loss: 1.0246799983702168, Train acc: 0.8793525039123631\n",
      "Iteration 44300 - Batch 738/1894 - Train loss: 1.0248416473481587, Train acc: 0.8791441136671178\n",
      "Iteration 44400 - Batch 838/1894 - Train loss: 1.023816914112264, Train acc: 0.880177294398093\n",
      "Iteration 44500 - Batch 938/1894 - Train loss: 1.0236772947544996, Train acc: 0.8802582534611288\n",
      "Iteration 44600 - Batch 1038/1894 - Train loss: 1.0232857159976207, Train acc: 0.8806243984600578\n",
      "Iteration 44700 - Batch 1138/1894 - Train loss: 1.0228019909339583, Train acc: 0.8812006145741879\n",
      "Iteration 44800 - Batch 1238/1894 - Train loss: 1.0221212405269429, Train acc: 0.8818351493139629\n",
      "Iteration 44900 - Batch 1338/1894 - Train loss: 1.022161948850032, Train acc: 0.8818614637789395\n",
      "Iteration 45000 - Batch 1438/1894 - Train loss: 1.0224946784923439, Train acc: 0.8814280750521195\n",
      "Iteration 45100 - Batch 1538/1894 - Train loss: 1.0227162901885793, Train acc: 0.8810916179337231\n",
      "Iteration 45200 - Batch 1638/1894 - Train loss: 1.0230558771342313, Train acc: 0.8807771507016473\n",
      "Iteration 45300 - Batch 1738/1894 - Train loss: 1.0228412124601982, Train acc: 0.8809840425531915\n",
      "Iteration 45400 - Batch 1838/1894 - Train loss: 1.0225786748886627, Train acc: 0.8812533985861881\n",
      "[4, 3, 1, 1, 2, 4, 1, 2, 2, 1, 0, 0, 3, 2, 1, 0, 1, 4, 3, 1, 4, 1, 1, 3, 2, 3, 2, 3, 1, 2, 0, 2, 0, 2, 0, 3, 0, 3, 1, 4, 3, 0, 0, 0, 1, 1, 3, 3, 4, 3, 3, 2, 2, 3, 1, 2, 4, 4, 4, 2, 1, 0, 0, 0, 0, 3, 4, 3, 3, 3, 4, 0, 4, 1, 3, 4, 4, 0, 1, 2, 0, 0, 2, 4, 3, 4, 2, 3, 2, 2, 3, 4, 2, 3, 4, 2, 0, 2, 0, 1, 3, 2, 3, 4, 3, 3, 2, 3, 0, 1, 0, 0, 1, 0, 1, 1, 4, 3, 3, 0, 3, 1, 0, 3, 0, 0, 1, 0, 3, 3, 1, 1, 0, 2, 2, 3, 3, 2, 4, 0, 2, 3, 1, 4, 4, 0, 4, 1, 3, 1, 3, 3, 2, 0, 4, 3, 4, 3, 2, 1, 3, 2, 2, 3, 3, 1, 2, 4, 1, 4, 0, 2, 2, 1, 4, 4, 3, 1, 2, 4, 4, 3, 4, 3, 0, 4, 2, 1, 0, 0, 2, 2, 4, 0, 0, 1, 3, 3, 0, 1, 2, 3, 3, 1, 2, 2, 1, 1, 0, 4, 2, 3, 2, 4, 2, 1, 1, 0, 2, 4, 2, 0, 2, 1, 3, 2, 3, 3, 4, 3, 3, 3, 1, 4, 2, 3, 2, 1, 0, 1, 3, 1, 4, 4, 2, 0, 4, 0, 0, 2, 0, 4, 0, 1, 4, 3, 3, 1, 1, 4, 4, 1, 2, 2, 3, 1, 0, 0, 1, 2, 0, 1, 0, 4, 1, 3, 4, 3, 4, 3, 0, 4, 4, 1, 2, 2, 2, 4, 4, 3, 4, 3, 4, 4, 0, 3, 3, 1, 1, 0, 4, 0, 0, 4, 3, 2, 4, 1, 4, 2, 2, 1, 3, 2, 0, 1, 0, 1, 0, 4, 2, 0, 0, 4, 3, 4, 4, 2, 0, 2, 3, 0, 4, 2, 1, 1, 2, 2, 3, 1, 2, 0, 0, 1, 2, 4, 1, 4, 0, 2, 0, 4, 4, 4, 4, 4, 1, 3, 0, 0, 0, 2, 0, 2, 0, 3, 0, 1, 3, 1, 2, 2, 0, 1, 3, 3, 0, 3, 4, 2, 2, 1, 4, 0, 1, 1, 4, 3, 3, 4, 1, 4, 3, 1, 1, 4, 1, 4, 1, 0, 1, 0, 2, 1, 0, 1, 2, 3, 2, 3, 1, 1, 1, 2, 4, 4, 4, 4, 4, 1, 4, 0, 2, 1, 2, 0, 3, 4, 1, 3, 2, 3, 2, 1, 1, 1, 4, 0, 4, 2, 0, 2, 3, 4, 3, 1, 4, 0, 4, 3, 2, 0, 2, 0, 0, 0, 1, 4, 4, 0, 4, 2, 1, 4, 0, 0, 0, 2, 0, 1, 2, 4, 3, 2, 2, 3, 1, 4, 2, 3, 1, 2, 1, 1, 4, 2, 0, 0, 2, 0, 3, 3, 4, 3, 1, 2, 0, 3, 0, 2]\n",
      "[4, 3, 3, 4, 2, 4, 4, 2, 2, 4, 0, 0, 3, 2, 3, 0, 0, 4, 3, 3, 4, 4, 4, 3, 2, 3, 2, 3, 4, 2, 0, 2, 2, 2, 2, 3, 2, 3, 4, 4, 3, 0, 0, 0, 3, 4, 3, 3, 4, 2, 3, 2, 2, 3, 0, 2, 4, 4, 4, 2, 2, 0, 0, 0, 0, 3, 4, 4, 3, 3, 4, 0, 4, 3, 3, 2, 0, 0, 4, 2, 0, 0, 2, 4, 3, 3, 2, 4, 2, 0, 4, 4, 0, 3, 4, 2, 0, 2, 2, 0, 3, 2, 3, 4, 2, 3, 2, 3, 0, 3, 0, 4, 3, 2, 3, 4, 4, 3, 3, 0, 3, 2, 3, 3, 0, 0, 2, 0, 3, 3, 4, 3, 0, 2, 2, 4, 3, 2, 4, 3, 2, 3, 4, 3, 4, 0, 4, 3, 3, 4, 3, 3, 2, 0, 4, 3, 4, 3, 2, 4, 3, 2, 2, 3, 3, 4, 2, 4, 4, 4, 0, 0, 2, 0, 4, 4, 3, 4, 2, 4, 4, 3, 4, 3, 0, 4, 2, 2, 0, 0, 2, 2, 4, 0, 0, 4, 3, 3, 0, 4, 2, 3, 3, 4, 2, 2, 3, 0, 0, 4, 2, 3, 2, 4, 2, 2, 0, 0, 2, 4, 2, 0, 2, 3, 3, 2, 3, 3, 4, 0, 4, 3, 0, 4, 2, 3, 2, 0, 0, 4, 3, 0, 2, 4, 2, 0, 4, 0, 0, 2, 0, 4, 0, 3, 4, 3, 3, 4, 0, 4, 4, 4, 3, 2, 3, 4, 0, 0, 4, 0, 0, 3, 0, 4, 4, 3, 4, 3, 4, 3, 0, 4, 4, 2, 2, 2, 2, 4, 4, 3, 4, 3, 4, 4, 0, 2, 3, 4, 4, 0, 4, 0, 2, 4, 3, 2, 4, 2, 4, 2, 2, 3, 3, 2, 0, 0, 0, 2, 2, 4, 2, 0, 0, 4, 3, 4, 0, 2, 0, 2, 3, 0, 0, 2, 4, 4, 2, 0, 3, 3, 2, 0, 0, 2, 0, 2, 4, 4, 0, 2, 4, 4, 4, 4, 4, 4, 0, 3, 0, 2, 0, 2, 4, 2, 0, 3, 0, 4, 3, 4, 2, 2, 0, 3, 3, 3, 0, 3, 4, 2, 2, 0, 4, 0, 4, 4, 4, 3, 4, 4, 4, 2, 3, 4, 2, 4, 4, 4, 0, 0, 3, 0, 2, 4, 0, 4, 2, 3, 2, 3, 4, 3, 3, 2, 4, 4, 4, 4, 4, 4, 4, 0, 2, 4, 2, 0, 4, 4, 2, 3, 2, 3, 0, 2, 3, 4, 4, 0, 4, 2, 0, 2, 4, 4, 3, 0, 4, 0, 4, 3, 2, 4, 2, 0, 0, 0, 4, 4, 4, 0, 4, 2, 2, 4, 0, 0, 0, 0, 0, 2, 2, 4, 3, 2, 2, 3, 4, 4, 2, 3, 4, 0, 4, 3, 4, 2, 0, 0, 2, 0, 3, 3, 4, 3, 4, 0, 0, 3, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.75      0.88      0.81       100\n",
      "           3       0.77      0.88      0.82       100\n",
      "           4       0.60      0.91      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1991026028990746, Val acc: 0.706\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45500 - Batch 44/1894 - Train loss: 1.016778180334303, Train acc: 0.8847222222222222\n",
      "Iteration 45600 - Batch 144/1894 - Train loss: 1.0225973277256406, Train acc: 0.8821120689655172\n",
      "Iteration 45700 - Batch 244/1894 - Train loss: 1.0177497656977907, Train acc: 0.8864795918367347\n",
      "Iteration 45800 - Batch 344/1894 - Train loss: 1.0183770984843157, Train acc: 0.8858695652173914\n",
      "Iteration 45900 - Batch 444/1894 - Train loss: 1.017426621646024, Train acc: 0.8867977528089888\n",
      "Iteration 46000 - Batch 544/1894 - Train loss: 1.0180094925635452, Train acc: 0.8862958715596331\n",
      "Iteration 46100 - Batch 644/1894 - Train loss: 1.0182748910068542, Train acc: 0.8858527131782946\n",
      "Iteration 46200 - Batch 744/1894 - Train loss: 1.0186850394178557, Train acc: 0.8854026845637584\n",
      "Iteration 46300 - Batch 844/1894 - Train loss: 1.0187655139956955, Train acc: 0.8853550295857988\n",
      "Iteration 46400 - Batch 944/1894 - Train loss: 1.0202549350955499, Train acc: 0.883829365079365\n",
      "Iteration 46500 - Batch 1044/1894 - Train loss: 1.0206138950785952, Train acc: 0.8835227272727273\n",
      "Iteration 46600 - Batch 1144/1894 - Train loss: 1.019886196752823, Train acc: 0.8842248908296944\n",
      "Iteration 46700 - Batch 1244/1894 - Train loss: 1.0197445593684553, Train acc: 0.8844126506024096\n",
      "Iteration 46800 - Batch 1344/1894 - Train loss: 1.020185222102807, Train acc: 0.8839916356877323\n",
      "Iteration 46900 - Batch 1444/1894 - Train loss: 1.020621255937332, Train acc: 0.8835207612456747\n",
      "Iteration 47000 - Batch 1544/1894 - Train loss: 1.020441331060959, Train acc: 0.8837378640776699\n",
      "Iteration 47100 - Batch 1644/1894 - Train loss: 1.0206301288039488, Train acc: 0.8835676291793313\n",
      "Iteration 47200 - Batch 1744/1894 - Train loss: 1.020678098461348, Train acc: 0.8835243553008596\n",
      "Iteration 47300 - Batch 1844/1894 - Train loss: 1.0212603626858574, Train acc: 0.8829268292682927\n",
      "[1, 2, 4, 3, 0, 4, 4, 0, 2, 2, 4, 4, 1, 2, 3, 3, 3, 3, 1, 4, 1, 3, 4, 3, 1, 0, 0, 2, 2, 1, 3, 3, 4, 4, 4, 2, 1, 0, 4, 0, 2, 0, 0, 0, 3, 4, 3, 3, 2, 3, 3, 1, 1, 3, 1, 4, 2, 1, 0, 3, 0, 1, 4, 0, 2, 2, 2, 1, 3, 4, 3, 3, 1, 1, 0, 2, 4, 4, 2, 0, 4, 0, 3, 4, 4, 3, 3, 2, 2, 1, 1, 0, 3, 1, 3, 1, 3, 1, 1, 2, 0, 2, 4, 0, 0, 3, 3, 1, 4, 2, 3, 4, 2, 1, 3, 2, 2, 0, 1, 4, 1, 0, 0, 1, 1, 4, 3, 1, 1, 2, 3, 2, 4, 3, 4, 2, 1, 1, 4, 4, 0, 2, 2, 4, 4, 1, 3, 0, 1, 1, 1, 2, 3, 0, 3, 2, 1, 1, 2, 1, 3, 0, 0, 4, 1, 2, 4, 2, 0, 2, 0, 2, 0, 3, 3, 4, 3, 0, 3, 3, 1, 4, 2, 1, 2, 1, 0, 3, 4, 2, 0, 3, 0, 0, 1, 2, 1, 0, 2, 0, 3, 1, 4, 3, 2, 2, 0, 2, 2, 0, 4, 4, 0, 0, 1, 0, 3, 3, 0, 0, 4, 4, 3, 4, 2, 4, 2, 3, 3, 3, 3, 0, 3, 0, 0, 1, 1, 3, 2, 0, 4, 3, 1, 1, 1, 3, 4, 0, 4, 4, 4, 0, 1, 4, 1, 2, 4, 1, 0, 4, 2, 3, 0, 0, 2, 2, 2, 1, 4, 1, 3, 1, 4, 1, 0, 0, 1, 4, 3, 0, 4, 2, 1, 2, 0, 4, 1, 3, 1, 2, 0, 4, 4, 0, 1, 1, 0, 2, 0, 2, 1, 3, 4, 2, 4, 0, 0, 2, 4, 0, 4, 0, 2, 2, 2, 1, 2, 1, 2, 3, 3, 0, 1, 3, 4, 2, 3, 1, 1, 2, 3, 2, 4, 4, 3, 3, 3, 0, 3, 0, 3, 1, 3, 2, 2, 4, 1, 3, 1, 2, 3, 4, 3, 0, 2, 2, 4, 1, 0, 4, 2, 2, 2, 2, 2, 0, 1, 2, 3, 3, 1, 2, 4, 4, 0, 2, 3, 1, 4, 4, 0, 0, 0, 4, 4, 2, 1, 2, 0, 0, 4, 3, 3, 0, 4, 2, 4, 4, 0, 4, 3, 3, 0, 2, 4, 0, 0, 0, 1, 4, 1, 2, 4, 3, 0, 3, 0, 3, 1, 4, 3, 1, 0, 2, 4, 4, 4, 4, 4, 2, 4, 0, 3, 3, 2, 2, 2, 4, 3, 3, 4, 1, 1, 3, 0, 4, 0, 4, 1, 0, 0, 0, 0, 2, 0, 2, 4, 3, 2, 1, 2, 2, 3, 3, 4, 1, 4, 0, 1, 0, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 3, 3, 4, 4, 3, 0, 4, 3, 2, 2, 0, 0, 3, 1, 0, 1, 2, 1, 1, 2]\n",
      "[3, 2, 4, 3, 0, 4, 2, 0, 2, 2, 4, 4, 4, 0, 3, 3, 3, 3, 0, 4, 2, 3, 3, 3, 4, 0, 0, 2, 2, 0, 3, 3, 4, 4, 4, 2, 4, 0, 4, 4, 2, 0, 0, 0, 3, 3, 3, 3, 2, 3, 3, 4, 3, 3, 4, 4, 2, 2, 0, 3, 0, 4, 4, 0, 3, 2, 2, 0, 3, 4, 3, 3, 0, 0, 0, 2, 4, 4, 2, 0, 4, 0, 3, 4, 0, 3, 3, 2, 2, 0, 4, 0, 3, 4, 3, 0, 3, 3, 2, 2, 0, 2, 4, 2, 0, 3, 3, 4, 4, 0, 3, 4, 0, 3, 3, 2, 2, 0, 0, 4, 0, 0, 0, 3, 3, 4, 3, 4, 2, 3, 3, 2, 4, 3, 4, 0, 3, 4, 4, 4, 0, 0, 2, 4, 4, 3, 3, 0, 0, 3, 4, 2, 3, 0, 3, 2, 3, 4, 2, 3, 3, 0, 0, 4, 3, 2, 4, 0, 0, 0, 4, 2, 0, 3, 3, 4, 3, 0, 3, 3, 0, 4, 2, 0, 2, 4, 0, 3, 4, 2, 0, 3, 0, 0, 0, 2, 0, 0, 2, 0, 3, 4, 4, 3, 0, 2, 0, 2, 0, 0, 4, 4, 0, 0, 0, 2, 3, 3, 0, 0, 4, 4, 3, 4, 2, 4, 2, 3, 0, 3, 3, 0, 3, 2, 0, 4, 3, 3, 2, 0, 4, 3, 3, 3, 4, 3, 4, 0, 4, 4, 4, 0, 4, 4, 3, 2, 3, 4, 0, 4, 2, 3, 3, 0, 3, 0, 2, 2, 4, 2, 3, 4, 4, 4, 0, 0, 0, 4, 4, 0, 4, 2, 3, 2, 0, 4, 4, 3, 0, 2, 0, 3, 4, 0, 2, 3, 4, 2, 0, 2, 4, 3, 3, 2, 4, 0, 2, 2, 4, 0, 4, 0, 2, 2, 2, 4, 2, 4, 0, 3, 3, 0, 3, 3, 4, 2, 3, 0, 4, 2, 3, 2, 4, 4, 3, 3, 3, 0, 3, 0, 3, 4, 3, 2, 2, 4, 0, 3, 4, 2, 3, 4, 4, 0, 2, 2, 4, 4, 0, 4, 2, 0, 2, 2, 2, 0, 4, 2, 3, 3, 3, 2, 4, 4, 0, 2, 3, 3, 4, 4, 0, 0, 0, 4, 4, 2, 0, 2, 0, 0, 4, 3, 3, 0, 4, 2, 2, 4, 0, 3, 3, 3, 0, 0, 4, 0, 4, 0, 4, 4, 4, 2, 4, 3, 0, 3, 0, 3, 3, 4, 3, 4, 0, 2, 4, 4, 0, 4, 0, 2, 4, 0, 3, 3, 2, 2, 2, 4, 3, 3, 4, 3, 3, 3, 2, 3, 0, 2, 3, 0, 0, 0, 0, 2, 0, 0, 4, 3, 2, 3, 2, 2, 3, 3, 4, 4, 4, 0, 4, 0, 4, 3, 2, 3, 4, 4, 0, 4, 4, 3, 3, 3, 4, 4, 3, 0, 4, 4, 2, 2, 0, 0, 3, 3, 0, 3, 2, 4, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.83      0.84       100\n",
      "           3       0.70      0.96      0.81       100\n",
      "           4       0.64      0.87      0.74       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1910531371831894, Val acc: 0.712\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47400 - Batch 50/1894 - Train loss: 1.021438533184575, Train acc: 0.8829656862745098\n",
      "Iteration 47500 - Batch 150/1894 - Train loss: 1.023316691253359, Train acc: 0.8812086092715232\n",
      "Iteration 47600 - Batch 250/1894 - Train loss: 1.0283201049523525, Train acc: 0.8758715139442231\n",
      "Iteration 47700 - Batch 350/1894 - Train loss: 1.0285905445063557, Train acc: 0.8753561253561254\n",
      "Iteration 47800 - Batch 450/1894 - Train loss: 1.026510653368914, Train acc: 0.8774251662971175\n",
      "Iteration 47900 - Batch 550/1894 - Train loss: 1.0259792108068448, Train acc: 0.878062613430127\n",
      "Iteration 48000 - Batch 650/1894 - Train loss: 1.023548369217212, Train acc: 0.8803283410138248\n",
      "Iteration 48100 - Batch 750/1894 - Train loss: 1.022474469817907, Train acc: 0.8814081225033289\n",
      "Iteration 48200 - Batch 850/1894 - Train loss: 1.0214881901875505, Train acc: 0.8825646298472385\n",
      "Iteration 48300 - Batch 950/1894 - Train loss: 1.0217996594406955, Train acc: 0.882229232386961\n",
      "Iteration 48400 - Batch 1050/1894 - Train loss: 1.021284213415449, Train acc: 0.8827604662226451\n",
      "Iteration 48500 - Batch 1150/1894 - Train loss: 1.021195730937242, Train acc: 0.8829278887923545\n",
      "Iteration 48600 - Batch 1250/1894 - Train loss: 1.0209046895269582, Train acc: 0.8832683852917665\n",
      "Iteration 48700 - Batch 1350/1894 - Train loss: 1.02083500308694, Train acc: 0.883419689119171\n",
      "Iteration 48800 - Batch 1450/1894 - Train loss: 1.020620141499294, Train acc: 0.8835501378359751\n",
      "Iteration 48900 - Batch 1550/1894 - Train loss: 1.0202613113619756, Train acc: 0.8838652482269503\n",
      "Iteration 49000 - Batch 1650/1894 - Train loss: 1.0203769364767115, Train acc: 0.883744700181708\n",
      "Iteration 49100 - Batch 1750/1894 - Train loss: 1.0207890426343267, Train acc: 0.8833345231296402\n",
      "Iteration 49200 - Batch 1850/1894 - Train loss: 1.0212664291190174, Train acc: 0.88290113452188\n",
      "[2, 0, 4, 4, 2, 2, 2, 4, 4, 4, 0, 1, 2, 1, 0, 2, 1, 1, 0, 1, 3, 1, 3, 2, 0, 3, 0, 1, 2, 0, 0, 1, 3, 3, 1, 4, 0, 4, 0, 2, 1, 3, 2, 4, 0, 2, 1, 3, 2, 1, 1, 1, 0, 0, 3, 0, 3, 4, 3, 3, 4, 3, 4, 2, 4, 4, 0, 4, 1, 0, 0, 3, 1, 1, 0, 2, 1, 3, 4, 0, 2, 1, 3, 1, 3, 2, 3, 3, 4, 2, 4, 1, 0, 2, 3, 2, 1, 1, 0, 0, 3, 0, 0, 4, 2, 0, 2, 2, 0, 4, 3, 3, 1, 2, 1, 0, 0, 4, 2, 4, 1, 2, 2, 3, 3, 0, 4, 4, 2, 4, 2, 0, 1, 2, 0, 1, 1, 3, 4, 1, 2, 0, 4, 2, 2, 2, 1, 1, 0, 4, 0, 3, 2, 1, 2, 1, 2, 1, 3, 2, 3, 2, 3, 4, 4, 1, 1, 4, 2, 0, 1, 4, 0, 4, 4, 0, 4, 0, 2, 3, 0, 4, 2, 2, 2, 0, 0, 2, 0, 1, 1, 1, 2, 4, 2, 1, 4, 2, 0, 4, 3, 4, 3, 3, 2, 3, 0, 1, 0, 2, 2, 3, 4, 4, 1, 0, 3, 2, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 3, 3, 4, 1, 4, 1, 0, 4, 4, 0, 0, 3, 0, 2, 0, 0, 3, 1, 1, 4, 3, 3, 2, 3, 0, 3, 3, 2, 1, 0, 3, 3, 3, 2, 3, 3, 2, 4, 3, 3, 0, 1, 1, 0, 1, 3, 1, 2, 0, 0, 4, 1, 1, 0, 3, 2, 3, 3, 1, 2, 2, 0, 1, 4, 1, 4, 0, 1, 3, 3, 4, 3, 1, 2, 1, 3, 2, 0, 1, 0, 0, 4, 4, 3, 3, 4, 4, 4, 2, 2, 3, 3, 3, 1, 2, 3, 4, 2, 4, 0, 3, 2, 4, 3, 2, 4, 2, 4, 0, 4, 2, 4, 1, 1, 1, 4, 4, 1, 0, 2, 3, 3, 3, 4, 4, 1, 1, 3, 3, 0, 4, 1, 3, 0, 4, 3, 4, 1, 4, 2, 1, 3, 3, 2, 3, 0, 4, 2, 4, 0, 4, 1, 2, 4, 2, 3, 2, 4, 1, 2, 1, 2, 3, 2, 4, 4, 1, 4, 2, 2, 2, 2, 4, 3, 3, 3, 1, 0, 4, 1, 0, 3, 2, 2, 0, 3, 4, 2, 1, 4, 2, 3, 2, 1, 2, 3, 3, 1, 2, 4, 2, 2, 0, 1, 0, 2, 4, 2, 0, 0, 4, 4, 3, 0, 0, 4, 4, 1, 4, 3, 1, 4, 4, 3, 0, 4, 1, 0, 0, 4, 3, 1, 4, 3, 0, 2, 3, 1, 4, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 1, 3, 3, 3, 1, 1, 4, 0, 0, 2, 0, 3, 0, 0, 2, 1, 4, 1, 1, 4, 3, 4]\n",
      "[0, 4, 4, 4, 2, 0, 2, 4, 4, 4, 0, 4, 2, 4, 0, 0, 3, 4, 0, 4, 3, 4, 3, 2, 0, 3, 0, 3, 2, 4, 0, 0, 3, 3, 0, 4, 0, 4, 0, 2, 4, 3, 2, 4, 0, 0, 3, 3, 0, 4, 4, 3, 0, 0, 3, 0, 3, 4, 3, 3, 4, 3, 4, 2, 4, 4, 0, 4, 0, 0, 0, 3, 4, 0, 0, 2, 4, 3, 4, 0, 2, 3, 3, 4, 3, 2, 3, 3, 4, 2, 4, 3, 0, 2, 3, 2, 3, 4, 0, 0, 3, 0, 0, 4, 0, 0, 0, 2, 0, 4, 3, 3, 4, 2, 4, 0, 0, 4, 3, 4, 0, 2, 0, 3, 3, 0, 4, 4, 2, 4, 2, 0, 4, 2, 4, 4, 3, 3, 4, 3, 2, 0, 4, 2, 2, 2, 4, 0, 0, 4, 0, 3, 2, 4, 2, 3, 2, 4, 3, 2, 3, 2, 3, 4, 2, 3, 4, 4, 2, 0, 3, 4, 0, 4, 3, 0, 4, 0, 0, 3, 0, 4, 2, 2, 2, 0, 0, 2, 0, 4, 4, 4, 2, 4, 2, 4, 4, 2, 0, 4, 3, 4, 3, 3, 2, 3, 0, 4, 4, 2, 2, 3, 3, 4, 0, 0, 3, 4, 0, 3, 4, 0, 0, 0, 0, 2, 0, 2, 3, 3, 4, 4, 4, 4, 0, 4, 4, 0, 0, 3, 0, 2, 0, 4, 3, 3, 4, 4, 3, 3, 0, 3, 0, 3, 3, 2, 4, 0, 3, 3, 4, 2, 4, 3, 2, 4, 3, 3, 0, 0, 3, 0, 3, 3, 0, 2, 0, 0, 4, 4, 3, 0, 2, 3, 3, 3, 0, 2, 2, 0, 4, 4, 0, 4, 0, 4, 3, 3, 4, 0, 4, 0, 0, 3, 2, 0, 4, 0, 0, 4, 4, 3, 3, 4, 0, 4, 2, 0, 3, 3, 3, 2, 2, 3, 4, 0, 0, 3, 3, 0, 4, 3, 0, 4, 2, 4, 0, 4, 2, 4, 4, 2, 3, 4, 3, 4, 0, 2, 3, 3, 3, 4, 3, 4, 4, 3, 3, 0, 4, 4, 4, 0, 4, 3, 4, 4, 4, 2, 3, 3, 3, 2, 3, 0, 4, 0, 4, 0, 4, 3, 2, 4, 0, 3, 2, 4, 0, 2, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 3, 3, 3, 4, 0, 4, 0, 0, 4, 2, 2, 4, 3, 4, 2, 4, 4, 2, 3, 2, 4, 2, 3, 3, 4, 2, 4, 2, 0, 0, 4, 0, 2, 4, 2, 0, 0, 4, 4, 3, 0, 0, 4, 4, 2, 4, 3, 4, 4, 4, 3, 0, 4, 3, 0, 0, 4, 3, 3, 4, 3, 0, 2, 3, 3, 4, 3, 3, 4, 0, 0, 0, 0, 0, 3, 2, 0, 3, 3, 3, 3, 3, 4, 4, 0, 0, 2, 0, 3, 0, 0, 2, 4, 4, 4, 4, 4, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.92      0.78      0.84       100\n",
      "           3       0.72      0.92      0.81       100\n",
      "           4       0.58      0.93      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1936106607317924, Val acc: 0.71\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49300 - Batch 56/1894 - Train loss: 1.0235394082571332, Train acc: 0.881578947368421\n",
      "Iteration 49400 - Batch 156/1894 - Train loss: 1.0202207219828465, Train acc: 0.8839570063694268\n",
      "Iteration 49500 - Batch 256/1894 - Train loss: 1.0143032892668757, Train acc: 0.8900778210116731\n",
      "Iteration 49600 - Batch 356/1894 - Train loss: 1.0178793274721845, Train acc: 0.8861169467787114\n",
      "Iteration 49700 - Batch 456/1894 - Train loss: 1.0166683803502006, Train acc: 0.887308533916849\n",
      "Iteration 49800 - Batch 556/1894 - Train loss: 1.0160144937744688, Train acc: 0.8879039497307002\n",
      "Iteration 49900 - Batch 656/1894 - Train loss: 1.0172673673390253, Train acc: 0.8867009132420092\n",
      "Iteration 50000 - Batch 756/1894 - Train loss: 1.0162348329154787, Train acc: 0.8877146631439894\n",
      "Iteration 50100 - Batch 856/1894 - Train loss: 1.0170104911196607, Train acc: 0.8870697199533255\n",
      "Iteration 50200 - Batch 956/1894 - Train loss: 1.0172692493709776, Train acc: 0.8868534482758621\n",
      "Iteration 50300 - Batch 1056/1894 - Train loss: 1.0181519556068088, Train acc: 0.8860868022705771\n",
      "Iteration 50400 - Batch 1156/1894 - Train loss: 1.01788440926279, Train acc: 0.8863169835782195\n",
      "Iteration 50500 - Batch 1256/1894 - Train loss: 1.0184446714563604, Train acc: 0.8857398568019093\n",
      "Iteration 50600 - Batch 1356/1894 - Train loss: 1.0185181188425247, Train acc: 0.8856853352984525\n",
      "Iteration 50700 - Batch 1456/1894 - Train loss: 1.0186224448083605, Train acc: 0.8855310569663692\n",
      "Iteration 50800 - Batch 1556/1894 - Train loss: 1.0194948423574886, Train acc: 0.884613840719332\n",
      "Iteration 50900 - Batch 1656/1894 - Train loss: 1.0193576674613885, Train acc: 0.8847880205190103\n",
      "Iteration 51000 - Batch 1756/1894 - Train loss: 1.0195600670986578, Train acc: 0.8845510813887308\n",
      "Iteration 51100 - Batch 1856/1894 - Train loss: 1.0194590932654, Train acc: 0.8846425686591276\n",
      "[2, 4, 2, 4, 3, 1, 2, 1, 2, 0, 2, 4, 4, 0, 3, 2, 3, 0, 1, 2, 1, 4, 0, 1, 4, 4, 4, 0, 1, 2, 2, 0, 4, 2, 0, 0, 1, 3, 4, 0, 4, 1, 1, 3, 0, 0, 4, 1, 2, 1, 4, 1, 0, 1, 2, 3, 2, 2, 1, 1, 0, 2, 0, 3, 2, 0, 1, 4, 1, 2, 2, 3, 0, 3, 0, 2, 2, 2, 1, 0, 3, 0, 2, 3, 4, 2, 1, 4, 4, 1, 4, 3, 1, 3, 4, 1, 2, 0, 3, 1, 4, 1, 3, 1, 0, 1, 4, 2, 3, 3, 4, 0, 2, 2, 2, 1, 3, 0, 3, 0, 0, 4, 0, 1, 3, 1, 0, 2, 3, 1, 0, 4, 3, 3, 4, 4, 0, 4, 1, 2, 2, 3, 1, 3, 1, 2, 2, 0, 3, 4, 3, 1, 4, 4, 2, 1, 3, 2, 4, 4, 1, 1, 1, 4, 1, 1, 4, 4, 2, 0, 4, 0, 3, 1, 2, 4, 2, 1, 0, 4, 1, 4, 4, 3, 3, 4, 0, 2, 2, 2, 4, 3, 4, 4, 2, 2, 1, 0, 2, 1, 3, 2, 4, 4, 0, 0, 3, 3, 1, 3, 1, 1, 3, 0, 4, 3, 3, 1, 2, 0, 0, 2, 1, 4, 2, 2, 2, 4, 4, 2, 2, 0, 2, 3, 0, 4, 2, 3, 1, 0, 3, 4, 1, 3, 0, 4, 1, 2, 1, 4, 4, 1, 0, 4, 3, 2, 3, 2, 1, 0, 4, 2, 0, 3, 0, 3, 1, 3, 3, 0, 1, 2, 3, 4, 2, 0, 0, 2, 4, 4, 1, 2, 2, 1, 3, 3, 1, 1, 1, 2, 1, 0, 4, 1, 3, 3, 1, 3, 2, 3, 2, 0, 3, 0, 4, 1, 1, 3, 2, 0, 4, 0, 2, 2, 3, 1, 0, 0, 4, 4, 2, 1, 0, 4, 4, 2, 0, 0, 2, 1, 4, 2, 1, 3, 1, 3, 4, 2, 3, 1, 3, 2, 0, 3, 3, 4, 0, 2, 3, 2, 3, 1, 3, 0, 3, 2, 3, 2, 3, 2, 4, 1, 1, 0, 1, 1, 3, 2, 4, 3, 4, 0, 1, 4, 4, 3, 4, 3, 3, 1, 1, 4, 3, 1, 0, 0, 0, 0, 2, 1, 4, 1, 1, 0, 0, 3, 0, 1, 0, 4, 0, 4, 4, 1, 0, 0, 4, 0, 0, 0, 4, 3, 2, 4, 2, 0, 2, 4, 3, 2, 3, 1, 4, 4, 4, 0, 1, 0, 1, 2, 1, 0, 2, 2, 1, 4, 2, 2, 0, 1, 4, 4, 0, 0, 2, 4, 2, 0, 0, 4, 3, 4, 2, 4, 3, 4, 1, 1, 0, 3, 3, 2, 2, 3, 3, 2, 0, 0, 3, 3, 0, 0, 3, 4, 1, 1, 3, 1, 2, 3, 4, 0, 0, 3, 3, 0, 3, 0, 1, 3, 3, 2, 4, 0, 3, 0, 2, 3, 4, 3]\n",
      "[2, 4, 2, 4, 3, 2, 2, 4, 2, 0, 0, 4, 4, 0, 3, 2, 3, 0, 3, 2, 4, 4, 0, 3, 4, 4, 4, 0, 4, 2, 2, 2, 2, 2, 0, 0, 4, 3, 4, 0, 4, 2, 4, 3, 2, 0, 4, 4, 2, 4, 4, 4, 0, 2, 2, 3, 2, 2, 4, 4, 0, 0, 0, 3, 4, 0, 3, 4, 4, 2, 0, 3, 0, 3, 0, 2, 2, 2, 4, 0, 3, 4, 2, 4, 4, 2, 3, 3, 4, 2, 4, 3, 3, 3, 4, 3, 2, 0, 3, 4, 4, 4, 3, 3, 0, 4, 3, 0, 3, 3, 3, 0, 2, 2, 2, 3, 3, 0, 3, 0, 0, 4, 0, 3, 3, 3, 0, 2, 3, 4, 0, 4, 3, 3, 4, 4, 0, 4, 4, 2, 2, 3, 2, 3, 4, 2, 2, 0, 3, 4, 4, 0, 4, 4, 2, 0, 3, 2, 4, 4, 4, 2, 4, 2, 3, 4, 4, 4, 2, 0, 4, 0, 3, 0, 2, 4, 2, 4, 0, 4, 4, 4, 0, 3, 3, 4, 0, 2, 2, 2, 4, 2, 4, 2, 2, 2, 0, 0, 2, 2, 4, 2, 4, 4, 0, 0, 3, 3, 4, 3, 4, 4, 4, 0, 4, 3, 3, 0, 2, 0, 0, 2, 2, 4, 2, 2, 0, 4, 4, 0, 2, 0, 2, 3, 0, 4, 2, 3, 3, 0, 3, 3, 3, 3, 2, 4, 4, 2, 0, 4, 4, 0, 0, 4, 3, 2, 3, 2, 4, 0, 4, 2, 4, 3, 0, 3, 4, 4, 3, 0, 3, 2, 3, 4, 2, 0, 0, 2, 3, 4, 3, 2, 3, 4, 3, 3, 4, 3, 4, 0, 4, 0, 4, 0, 3, 3, 3, 3, 2, 3, 2, 2, 3, 0, 4, 3, 4, 4, 2, 0, 4, 0, 2, 3, 3, 4, 0, 2, 4, 4, 2, 0, 0, 4, 4, 2, 0, 0, 2, 3, 4, 2, 3, 4, 4, 3, 4, 2, 3, 4, 3, 2, 4, 3, 3, 4, 0, 0, 3, 2, 3, 4, 3, 2, 3, 2, 3, 2, 3, 2, 4, 4, 4, 4, 3, 4, 3, 2, 4, 3, 4, 0, 2, 4, 4, 3, 4, 3, 3, 0, 3, 4, 3, 2, 0, 0, 2, 0, 2, 4, 4, 4, 4, 0, 0, 3, 0, 4, 0, 4, 0, 4, 4, 4, 0, 0, 4, 0, 0, 4, 4, 3, 2, 4, 0, 0, 2, 4, 3, 0, 3, 4, 4, 4, 4, 0, 4, 2, 3, 2, 3, 0, 2, 2, 0, 4, 2, 0, 0, 4, 4, 4, 0, 0, 0, 4, 0, 0, 4, 4, 3, 4, 2, 4, 3, 4, 4, 3, 0, 3, 3, 2, 2, 3, 3, 2, 2, 0, 3, 3, 0, 0, 3, 4, 4, 4, 3, 4, 0, 3, 4, 0, 4, 3, 3, 0, 3, 2, 3, 3, 3, 0, 4, 0, 3, 0, 2, 3, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.77      0.82      0.80       100\n",
      "           3       0.74      0.92      0.82       100\n",
      "           4       0.57      0.91      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2048407346010208, Val acc: 0.696\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 51200 - Batch 62/1894 - Train loss: 1.0072646680332364, Train acc: 0.8968253968253969\n",
      "Iteration 51300 - Batch 162/1894 - Train loss: 1.0190271175712164, Train acc: 0.8855444785276073\n",
      "Iteration 51400 - Batch 262/1894 - Train loss: 1.0212365737886029, Train acc: 0.8833174904942965\n",
      "Iteration 51500 - Batch 362/1894 - Train loss: 1.0216208029712857, Train acc: 0.8826618457300276\n",
      "Iteration 51600 - Batch 462/1894 - Train loss: 1.0204440048909857, Train acc: 0.8837742980561555\n",
      "Iteration 51700 - Batch 562/1894 - Train loss: 1.0199266971745669, Train acc: 0.8842695381882771\n",
      "Iteration 51800 - Batch 662/1894 - Train loss: 1.0188952229501256, Train acc: 0.8851809954751131\n",
      "Iteration 51900 - Batch 762/1894 - Train loss: 1.0192597343599812, Train acc: 0.8848705766710354\n",
      "Iteration 52000 - Batch 862/1894 - Train loss: 1.0194826535664732, Train acc: 0.8847407300115875\n",
      "Iteration 52100 - Batch 962/1894 - Train loss: 1.0185717800448368, Train acc: 0.8855789200415368\n",
      "Iteration 52200 - Batch 1062/1894 - Train loss: 1.0185731150917814, Train acc: 0.8854950611476952\n",
      "Iteration 52300 - Batch 1162/1894 - Train loss: 1.0197780692977119, Train acc: 0.8842164660361135\n",
      "Iteration 52400 - Batch 1262/1894 - Train loss: 1.0196859145202244, Train acc: 0.8842290182106096\n",
      "Iteration 52500 - Batch 1362/1894 - Train loss: 1.0193339926481073, Train acc: 0.884698275862069\n",
      "Iteration 52600 - Batch 1462/1894 - Train loss: 1.019219246859104, Train acc: 0.8848684210526315\n",
      "Iteration 52700 - Batch 1562/1894 - Train loss: 1.019504328301833, Train acc: 0.8844969609724888\n",
      "Iteration 52800 - Batch 1662/1894 - Train loss: 1.019787851185664, Train acc: 0.8842453397474443\n",
      "Iteration 52900 - Batch 1762/1894 - Train loss: 1.0199560435806834, Train acc: 0.8840931650595576\n",
      "Iteration 53000 - Batch 1862/1894 - Train loss: 1.0200859294805358, Train acc: 0.8839573268921095\n",
      "[4, 1, 2, 4, 0, 1, 4, 3, 4, 1, 3, 2, 1, 2, 3, 2, 0, 2, 3, 3, 0, 1, 2, 0, 0, 2, 3, 1, 0, 4, 2, 3, 4, 3, 2, 1, 3, 1, 4, 0, 3, 4, 0, 3, 0, 4, 2, 3, 2, 2, 4, 3, 4, 2, 1, 1, 2, 0, 4, 0, 1, 3, 2, 2, 4, 2, 4, 0, 2, 2, 3, 2, 0, 1, 0, 2, 4, 3, 3, 2, 4, 1, 3, 4, 4, 1, 3, 0, 2, 4, 0, 4, 1, 1, 3, 2, 0, 0, 2, 1, 4, 2, 1, 4, 1, 3, 1, 4, 3, 0, 2, 4, 0, 4, 2, 1, 3, 3, 2, 2, 4, 2, 0, 0, 3, 4, 1, 0, 4, 0, 4, 2, 2, 1, 1, 2, 2, 4, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 4, 0, 1, 1, 0, 0, 1, 2, 3, 0, 3, 3, 2, 0, 0, 1, 3, 1, 4, 2, 1, 4, 4, 2, 1, 3, 0, 1, 3, 0, 4, 4, 1, 2, 2, 0, 3, 4, 4, 4, 4, 2, 3, 3, 0, 3, 2, 0, 1, 0, 0, 3, 0, 1, 0, 1, 2, 2, 0, 3, 2, 2, 4, 4, 1, 4, 3, 3, 4, 4, 1, 3, 3, 1, 1, 1, 1, 0, 0, 0, 2, 1, 3, 3, 4, 0, 2, 1, 1, 1, 1, 3, 2, 1, 2, 4, 1, 2, 1, 2, 3, 3, 2, 2, 2, 0, 4, 2, 3, 2, 1, 4, 3, 0, 1, 1, 3, 1, 1, 4, 4, 3, 2, 1, 4, 0, 2, 1, 4, 1, 3, 2, 0, 0, 4, 1, 4, 4, 2, 1, 1, 1, 3, 4, 2, 3, 4, 0, 4, 1, 3, 2, 4, 4, 3, 3, 2, 4, 0, 3, 1, 4, 4, 4, 3, 3, 1, 0, 0, 4, 0, 4, 3, 3, 1, 2, 0, 0, 4, 0, 1, 4, 4, 1, 0, 1, 2, 0, 1, 4, 2, 3, 2, 3, 4, 0, 2, 2, 2, 2, 4, 3, 1, 3, 4, 1, 0, 1, 1, 4, 4, 2, 1, 3, 4, 2, 1, 4, 4, 3, 2, 4, 0, 3, 2, 0, 3, 0, 0, 0, 3, 3, 3, 2, 1, 1, 4, 4, 1, 2, 2, 3, 0, 0, 4, 3, 0, 0, 0, 0, 4, 1, 3, 0, 4, 0, 2, 2, 3, 4, 1, 3, 3, 3, 0, 4, 3, 3, 1, 2, 2, 2, 3, 1, 3, 1, 0, 1, 1, 4, 1, 3, 2, 3, 1, 0, 0, 4, 4, 0, 1, 3, 0, 3, 0, 2, 0, 0, 4, 1, 2, 3, 3, 0, 2, 3, 1, 1, 3, 2, 1, 4, 0, 0, 0, 2, 4, 4, 4, 3, 3, 3, 3, 1, 4, 4, 3, 2, 3, 1, 1, 3, 2, 3, 0, 0, 0, 0, 2, 3, 4, 4, 1, 1, 2, 2, 1, 2, 0, 1, 0, 4]\n",
      "[4, 2, 2, 4, 0, 4, 3, 3, 4, 4, 3, 2, 4, 2, 3, 2, 0, 2, 3, 3, 0, 4, 2, 0, 0, 2, 3, 3, 0, 4, 2, 3, 4, 3, 2, 3, 3, 3, 4, 0, 3, 4, 0, 3, 0, 4, 2, 3, 2, 2, 4, 3, 4, 0, 4, 3, 0, 0, 4, 2, 3, 3, 2, 2, 4, 2, 4, 0, 2, 2, 3, 2, 0, 4, 0, 2, 2, 3, 4, 2, 4, 3, 0, 4, 4, 0, 3, 4, 0, 4, 0, 4, 4, 3, 3, 2, 0, 0, 2, 3, 4, 2, 4, 4, 4, 3, 3, 4, 3, 2, 2, 4, 0, 4, 2, 3, 3, 3, 2, 2, 4, 2, 0, 2, 3, 4, 4, 0, 4, 0, 4, 3, 2, 4, 0, 2, 2, 4, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 4, 0, 0, 2, 0, 0, 3, 2, 3, 0, 3, 3, 2, 0, 0, 0, 3, 4, 4, 2, 4, 4, 4, 2, 4, 3, 0, 4, 3, 0, 4, 4, 4, 2, 2, 0, 3, 4, 4, 4, 3, 3, 3, 3, 0, 3, 0, 0, 3, 0, 0, 4, 0, 3, 0, 4, 2, 0, 0, 3, 0, 2, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 3, 3, 4, 2, 0, 0, 0, 0, 2, 3, 3, 3, 4, 0, 2, 2, 4, 0, 4, 3, 2, 0, 2, 2, 4, 2, 4, 0, 3, 3, 0, 2, 2, 0, 4, 2, 3, 2, 4, 3, 3, 4, 4, 4, 3, 4, 3, 4, 4, 3, 2, 4, 4, 0, 0, 3, 4, 4, 3, 2, 0, 0, 4, 3, 0, 4, 0, 4, 3, 0, 3, 4, 2, 3, 4, 0, 4, 4, 3, 2, 4, 4, 3, 3, 2, 4, 0, 3, 3, 4, 4, 4, 3, 3, 4, 0, 0, 3, 0, 4, 3, 4, 3, 0, 0, 0, 4, 0, 0, 4, 4, 4, 0, 4, 3, 0, 2, 4, 2, 3, 2, 3, 4, 0, 2, 2, 2, 2, 4, 3, 4, 3, 3, 0, 0, 0, 4, 4, 4, 2, 4, 3, 4, 0, 4, 4, 0, 3, 2, 4, 0, 3, 2, 0, 3, 0, 2, 0, 3, 4, 3, 2, 4, 4, 4, 4, 4, 2, 2, 3, 0, 0, 4, 3, 4, 0, 0, 0, 4, 3, 3, 0, 4, 0, 2, 2, 3, 4, 4, 3, 3, 3, 0, 0, 3, 3, 4, 2, 2, 0, 3, 4, 3, 2, 2, 4, 3, 4, 0, 3, 2, 3, 2, 0, 0, 4, 4, 0, 0, 3, 0, 3, 0, 2, 0, 0, 4, 3, 0, 3, 3, 4, 2, 3, 4, 0, 4, 0, 4, 4, 0, 2, 0, 2, 4, 4, 4, 3, 3, 3, 3, 0, 4, 4, 3, 2, 3, 4, 4, 3, 2, 3, 0, 2, 0, 4, 2, 3, 4, 4, 0, 3, 2, 2, 3, 2, 0, 4, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.84      0.82      0.83       100\n",
      "           3       0.73      0.94      0.82       100\n",
      "           4       0.60      0.90      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1959831416606903, Val acc: 0.708\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53100 - Batch 68/1894 - Train loss: 1.0142125530519348, Train acc: 0.8890398550724637\n",
      "Iteration 53200 - Batch 168/1894 - Train loss: 1.021162883417141, Train acc: 0.8827662721893491\n",
      "Iteration 53300 - Batch 268/1894 - Train loss: 1.0223109693332233, Train acc: 0.8816217472118959\n",
      "Iteration 53400 - Batch 368/1894 - Train loss: 1.0201574646360505, Train acc: 0.8835535230352304\n",
      "Iteration 53500 - Batch 468/1894 - Train loss: 1.020696718301346, Train acc: 0.8831289978678039\n",
      "Iteration 53600 - Batch 568/1894 - Train loss: 1.0208498916223723, Train acc: 0.882853690685413\n",
      "Iteration 53700 - Batch 668/1894 - Train loss: 1.0199336871972533, Train acc: 0.8839218983557549\n",
      "Iteration 53800 - Batch 768/1894 - Train loss: 1.0200067247773954, Train acc: 0.8839808192457738\n",
      "Iteration 53900 - Batch 868/1894 - Train loss: 1.0198280874412546, Train acc: 0.8842059838895282\n",
      "Iteration 54000 - Batch 968/1894 - Train loss: 1.0197127807128048, Train acc: 0.8842556759545923\n",
      "Iteration 54100 - Batch 1068/1894 - Train loss: 1.0189362323875177, Train acc: 0.8851145930776426\n",
      "Iteration 54200 - Batch 1168/1894 - Train loss: 1.0195937484528286, Train acc: 0.8843830196749358\n",
      "Iteration 54300 - Batch 1268/1894 - Train loss: 1.019152194848673, Train acc: 0.8848502758077226\n",
      "Iteration 54400 - Batch 1368/1894 - Train loss: 1.0193009383927478, Train acc: 0.8847014243973703\n",
      "Iteration 54500 - Batch 1468/1894 - Train loss: 1.0188671474232813, Train acc: 0.8850833900612661\n",
      "Iteration 54600 - Batch 1568/1894 - Train loss: 1.0182587040162072, Train acc: 0.8857154238368388\n",
      "Iteration 54700 - Batch 1668/1894 - Train loss: 1.0182497301381672, Train acc: 0.8857661773517076\n",
      "Iteration 54800 - Batch 1768/1894 - Train loss: 1.0178573223208895, Train acc: 0.8861115036743923\n",
      "Iteration 54900 - Batch 1868/1894 - Train loss: 1.0184787511825562, Train acc: 0.8854668271803103\n",
      "[3, 2, 0, 3, 3, 1, 4, 1, 1, 2, 2, 0, 1, 0, 0, 3, 3, 4, 2, 4, 1, 0, 3, 2, 3, 2, 4, 3, 3, 1, 1, 2, 2, 4, 4, 0, 1, 0, 2, 4, 4, 4, 1, 1, 1, 0, 4, 0, 4, 4, 4, 1, 4, 4, 1, 4, 3, 2, 4, 3, 2, 0, 1, 0, 2, 4, 2, 4, 4, 3, 0, 2, 3, 0, 3, 4, 0, 3, 0, 2, 4, 4, 2, 3, 2, 0, 1, 4, 0, 2, 3, 0, 4, 0, 2, 4, 2, 3, 3, 4, 4, 1, 1, 4, 4, 0, 3, 0, 2, 4, 2, 3, 1, 0, 3, 0, 4, 3, 3, 0, 3, 3, 2, 3, 4, 2, 2, 4, 2, 3, 1, 3, 3, 3, 2, 1, 1, 0, 0, 0, 1, 3, 0, 1, 3, 1, 0, 3, 4, 0, 3, 3, 4, 4, 0, 2, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 2, 2, 1, 1, 1, 4, 4, 1, 3, 4, 1, 2, 3, 4, 4, 1, 1, 3, 3, 4, 2, 3, 2, 3, 0, 3, 4, 0, 2, 4, 3, 0, 2, 1, 0, 2, 3, 3, 4, 2, 0, 1, 4, 3, 2, 2, 2, 1, 0, 3, 1, 1, 2, 4, 0, 3, 1, 1, 1, 0, 0, 2, 4, 3, 4, 2, 0, 0, 2, 3, 0, 2, 3, 0, 2, 2, 2, 4, 1, 2, 4, 1, 4, 1, 3, 2, 4, 1, 4, 2, 4, 1, 2, 4, 3, 0, 0, 0, 2, 1, 1, 0, 4, 0, 2, 0, 3, 0, 3, 2, 1, 3, 3, 2, 4, 4, 0, 2, 1, 1, 0, 0, 0, 3, 4, 3, 3, 0, 1, 3, 3, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 2, 3, 1, 4, 3, 1, 2, 0, 2, 4, 2, 0, 0, 2, 0, 3, 1, 4, 0, 2, 1, 4, 1, 3, 1, 1, 0, 4, 4, 2, 0, 2, 3, 2, 2, 1, 0, 1, 1, 3, 3, 4, 0, 3, 0, 1, 3, 2, 0, 1, 4, 2, 2, 2, 0, 0, 1, 4, 2, 1, 1, 3, 1, 4, 1, 3, 0, 1, 0, 1, 4, 4, 0, 1, 0, 2, 4, 1, 1, 0, 3, 4, 2, 3, 3, 1, 2, 2, 3, 4, 0, 2, 4, 4, 1, 2, 0, 3, 0, 3, 3, 0, 2, 0, 3, 3, 2, 1, 4, 3, 1, 3, 4, 2, 0, 4, 0, 2, 4, 2, 2, 1, 4, 1, 4, 2, 2, 1, 4, 2, 4, 4, 1, 3, 4, 4, 3, 3, 2, 1, 0, 2, 3, 1, 1, 1, 0, 3, 4, 4, 2, 2, 2, 3, 1, 2, 3, 3, 0, 0, 0, 2, 0, 4, 4, 2, 3, 0, 4, 3, 3, 2, 1, 4, 4, 4, 1, 0, 3, 2, 0, 4, 3, 4, 0, 4, 1, 3, 3, 1, 2, 1, 0]\n",
      "[3, 2, 0, 3, 3, 0, 4, 3, 4, 2, 2, 0, 0, 0, 0, 3, 3, 4, 2, 4, 4, 0, 3, 0, 3, 2, 4, 3, 3, 0, 4, 2, 0, 4, 4, 0, 0, 4, 2, 4, 4, 4, 4, 4, 4, 0, 4, 0, 4, 3, 4, 4, 4, 4, 0, 4, 3, 2, 4, 3, 2, 0, 4, 0, 2, 4, 2, 4, 4, 3, 0, 2, 3, 0, 3, 4, 0, 3, 0, 2, 4, 4, 2, 3, 2, 0, 2, 4, 0, 0, 3, 0, 4, 4, 2, 3, 2, 3, 3, 4, 4, 4, 2, 4, 4, 0, 3, 0, 2, 4, 2, 3, 4, 0, 4, 0, 4, 4, 3, 0, 3, 3, 2, 3, 4, 2, 3, 4, 2, 3, 4, 3, 3, 3, 2, 3, 3, 0, 0, 0, 4, 3, 0, 3, 3, 3, 2, 3, 4, 0, 3, 3, 4, 4, 0, 2, 0, 3, 3, 4, 0, 0, 3, 0, 4, 0, 2, 2, 0, 4, 4, 4, 4, 3, 3, 4, 4, 0, 3, 4, 4, 4, 3, 3, 3, 3, 2, 3, 2, 3, 0, 3, 4, 2, 2, 4, 3, 0, 2, 0, 0, 2, 4, 3, 4, 2, 4, 0, 4, 3, 2, 2, 2, 4, 0, 3, 0, 4, 2, 4, 0, 2, 4, 4, 4, 0, 0, 2, 4, 3, 4, 2, 0, 0, 2, 3, 0, 2, 3, 0, 2, 2, 2, 4, 4, 2, 4, 0, 2, 4, 3, 2, 4, 3, 4, 2, 3, 4, 2, 4, 4, 0, 0, 0, 2, 0, 4, 0, 4, 0, 2, 2, 3, 0, 3, 0, 2, 3, 3, 2, 4, 4, 0, 0, 4, 4, 0, 0, 0, 3, 4, 3, 3, 0, 3, 3, 3, 4, 0, 4, 4, 3, 0, 2, 2, 2, 2, 2, 3, 0, 4, 3, 4, 0, 0, 2, 4, 0, 0, 0, 2, 0, 3, 4, 4, 0, 2, 3, 4, 4, 4, 4, 4, 0, 4, 4, 2, 0, 0, 3, 2, 2, 3, 0, 4, 4, 4, 4, 4, 0, 3, 0, 0, 3, 2, 0, 0, 4, 2, 2, 2, 0, 0, 4, 4, 0, 4, 0, 3, 4, 4, 0, 3, 0, 4, 0, 4, 4, 2, 0, 4, 0, 2, 4, 3, 3, 0, 3, 4, 2, 3, 3, 0, 2, 2, 4, 4, 0, 2, 4, 4, 0, 2, 0, 3, 0, 3, 3, 4, 0, 0, 3, 3, 2, 4, 4, 3, 4, 3, 3, 0, 0, 4, 0, 2, 4, 2, 2, 0, 4, 4, 4, 2, 0, 4, 4, 4, 4, 4, 2, 3, 4, 4, 3, 3, 2, 3, 0, 2, 3, 2, 4, 3, 4, 3, 4, 4, 2, 2, 2, 3, 4, 2, 4, 3, 0, 0, 0, 2, 0, 4, 4, 2, 3, 0, 4, 3, 4, 2, 2, 4, 4, 4, 0, 0, 3, 2, 4, 4, 0, 4, 0, 4, 4, 3, 3, 0, 2, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.85      0.85       100\n",
      "           3       0.77      0.88      0.82       100\n",
      "           4       0.57      0.93      0.71       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.64       500\n",
      "weighted avg       0.58      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.191241294145584, Val acc: 0.712\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 55000 - Batch 74/1894 - Train loss: 1.0147825463612874, Train acc: 0.8891666666666667\n",
      "Iteration 55100 - Batch 174/1894 - Train loss: 1.016863121986389, Train acc: 0.8873214285714286\n",
      "Iteration 55200 - Batch 274/1894 - Train loss: 1.0169179071079602, Train acc: 0.8872727272727273\n",
      "Iteration 55300 - Batch 374/1894 - Train loss: 1.0172236660321554, Train acc: 0.887\n",
      "Iteration 55400 - Batch 474/1894 - Train loss: 1.016704358678115, Train acc: 0.8876973684210526\n",
      "Iteration 55500 - Batch 574/1894 - Train loss: 1.0168092408387557, Train acc: 0.8878804347826087\n",
      "Iteration 55600 - Batch 674/1894 - Train loss: 1.0181426207224529, Train acc: 0.8865277777777778\n",
      "Iteration 55700 - Batch 774/1894 - Train loss: 1.0191113688099769, Train acc: 0.8855241935483871\n",
      "Iteration 55800 - Batch 874/1894 - Train loss: 1.0182744953972953, Train acc: 0.88625\n",
      "Iteration 55900 - Batch 974/1894 - Train loss: 1.0182963671439733, Train acc: 0.8861538461538462\n",
      "Iteration 56000 - Batch 1074/1894 - Train loss: 1.0181071079054544, Train acc: 0.8863081395348837\n",
      "Iteration 56100 - Batch 1174/1894 - Train loss: 1.0179481971517523, Train acc: 0.8863563829787234\n",
      "Iteration 56200 - Batch 1274/1894 - Train loss: 1.0171921860937978, Train acc: 0.886985294117647\n",
      "Iteration 56300 - Batch 1374/1894 - Train loss: 1.0177930256236682, Train acc: 0.8863636363636364\n",
      "Iteration 56400 - Batch 1474/1894 - Train loss: 1.0177910081006714, Train acc: 0.8864194915254238\n",
      "Iteration 56500 - Batch 1574/1894 - Train loss: 1.0176323819160462, Train acc: 0.8865873015873016\n",
      "Iteration 56600 - Batch 1674/1894 - Train loss: 1.0169509167813544, Train acc: 0.8872388059701493\n",
      "Iteration 56700 - Batch 1774/1894 - Train loss: 1.016917388237698, Train acc: 0.8872711267605634\n",
      "Iteration 56800 - Batch 1874/1894 - Train loss: 1.01638169409434, Train acc: 0.8877666666666667\n",
      "[2, 1, 2, 3, 2, 3, 1, 4, 0, 1, 3, 4, 3, 0, 4, 4, 3, 0, 2, 0, 3, 1, 1, 1, 0, 0, 4, 0, 2, 3, 1, 1, 3, 4, 0, 0, 1, 0, 0, 4, 1, 0, 3, 1, 1, 0, 3, 3, 3, 4, 0, 2, 1, 0, 2, 4, 3, 0, 2, 0, 1, 3, 2, 3, 0, 0, 2, 0, 4, 1, 2, 4, 4, 2, 4, 1, 1, 1, 4, 2, 4, 2, 1, 1, 4, 0, 1, 1, 2, 2, 0, 4, 3, 0, 1, 3, 2, 0, 4, 2, 4, 3, 2, 4, 2, 2, 0, 2, 2, 0, 0, 0, 4, 1, 4, 2, 4, 2, 2, 2, 3, 2, 0, 0, 0, 1, 1, 2, 4, 1, 3, 0, 1, 3, 1, 4, 3, 0, 2, 0, 3, 2, 4, 3, 0, 3, 1, 1, 1, 1, 0, 1, 1, 3, 3, 2, 0, 4, 3, 0, 1, 1, 0, 2, 4, 0, 2, 0, 2, 3, 1, 0, 4, 3, 3, 0, 3, 3, 4, 0, 2, 3, 0, 4, 4, 4, 0, 1, 2, 3, 1, 2, 3, 1, 3, 4, 0, 1, 4, 3, 3, 2, 4, 1, 0, 4, 4, 0, 1, 3, 0, 1, 3, 4, 3, 0, 0, 0, 2, 1, 3, 1, 4, 3, 4, 0, 3, 3, 3, 0, 1, 2, 3, 1, 1, 3, 4, 4, 1, 3, 0, 4, 0, 0, 3, 1, 4, 3, 4, 1, 1, 4, 3, 1, 2, 2, 2, 0, 3, 0, 2, 4, 4, 0, 4, 0, 4, 3, 4, 1, 4, 3, 0, 3, 3, 4, 0, 2, 3, 2, 3, 2, 4, 0, 2, 2, 1, 3, 2, 0, 4, 2, 3, 0, 3, 0, 4, 4, 3, 3, 1, 4, 0, 3, 1, 0, 0, 4, 4, 1, 1, 0, 3, 3, 1, 4, 2, 4, 1, 2, 3, 1, 4, 1, 2, 0, 1, 0, 3, 2, 4, 2, 1, 1, 2, 4, 2, 2, 3, 0, 3, 1, 2, 2, 4, 0, 3, 1, 4, 2, 4, 3, 4, 1, 3, 1, 1, 4, 2, 3, 4, 2, 0, 0, 3, 2, 4, 1, 1, 0, 3, 4, 3, 1, 4, 2, 1, 4, 3, 4, 1, 4, 2, 1, 4, 1, 2, 0, 1, 1, 4, 3, 4, 1, 2, 2, 4, 2, 1, 0, 4, 2, 1, 0, 2, 2, 0, 3, 4, 1, 4, 0, 2, 0, 4, 0, 4, 4, 4, 3, 3, 4, 3, 2, 3, 0, 2, 3, 1, 1, 3, 2, 0, 4, 3, 4, 2, 2, 2, 1, 3, 3, 4, 3, 2, 2, 1, 1, 3, 1, 2, 2, 0, 0, 1, 4, 3, 1, 2, 0, 1, 0, 2, 2, 0, 0, 4, 1, 0, 3, 2, 4, 3, 2, 3, 2, 1, 2, 4, 2, 2, 2, 0, 3, 2, 0, 1, 2, 1, 4, 0, 1, 4, 4, 3, 2, 2, 0, 3, 0]\n",
      "[2, 4, 2, 3, 4, 3, 4, 4, 0, 2, 3, 4, 4, 0, 4, 4, 3, 0, 2, 0, 3, 2, 2, 3, 0, 0, 4, 0, 2, 3, 4, 2, 3, 4, 0, 0, 2, 4, 2, 4, 4, 0, 3, 0, 3, 0, 4, 3, 3, 4, 0, 3, 4, 0, 0, 4, 3, 0, 2, 0, 0, 3, 2, 3, 0, 0, 2, 0, 4, 4, 2, 3, 4, 2, 4, 3, 4, 0, 4, 2, 4, 2, 3, 4, 4, 0, 4, 3, 2, 2, 0, 0, 0, 0, 0, 3, 2, 0, 4, 2, 3, 4, 2, 4, 2, 2, 0, 2, 2, 0, 2, 4, 4, 4, 0, 0, 4, 2, 2, 2, 3, 2, 0, 0, 0, 4, 4, 2, 4, 0, 3, 0, 4, 3, 3, 4, 3, 0, 2, 0, 3, 0, 4, 3, 0, 3, 3, 4, 0, 3, 0, 3, 3, 3, 3, 2, 0, 4, 3, 0, 4, 4, 2, 2, 4, 0, 2, 0, 2, 3, 4, 0, 4, 3, 3, 0, 3, 3, 4, 0, 2, 3, 0, 4, 4, 4, 0, 0, 2, 3, 4, 2, 3, 4, 3, 4, 0, 4, 3, 4, 4, 2, 4, 4, 2, 4, 4, 0, 4, 3, 0, 0, 3, 4, 3, 0, 0, 0, 2, 0, 3, 2, 4, 3, 4, 0, 3, 3, 3, 4, 3, 2, 3, 0, 4, 3, 4, 4, 4, 3, 0, 4, 0, 4, 3, 4, 4, 3, 4, 3, 3, 4, 3, 4, 2, 2, 2, 0, 3, 0, 2, 4, 4, 0, 4, 0, 4, 3, 3, 4, 4, 3, 0, 3, 3, 4, 0, 2, 3, 2, 3, 2, 4, 0, 0, 2, 4, 3, 2, 0, 4, 2, 3, 0, 3, 0, 4, 4, 3, 3, 3, 4, 0, 3, 3, 0, 2, 4, 4, 3, 3, 0, 3, 3, 3, 4, 2, 4, 3, 2, 3, 4, 4, 4, 2, 0, 3, 0, 3, 2, 4, 2, 3, 4, 2, 4, 2, 2, 3, 0, 3, 4, 0, 2, 4, 4, 3, 4, 4, 2, 4, 3, 3, 4, 3, 4, 4, 4, 2, 3, 4, 2, 0, 0, 3, 2, 4, 2, 0, 0, 3, 4, 3, 0, 4, 2, 3, 4, 3, 4, 4, 4, 2, 0, 4, 3, 2, 4, 0, 4, 4, 3, 4, 4, 2, 2, 4, 2, 3, 0, 4, 0, 4, 0, 2, 2, 0, 3, 4, 0, 4, 0, 0, 0, 4, 0, 4, 2, 4, 3, 3, 4, 3, 2, 3, 0, 2, 3, 0, 4, 3, 2, 0, 4, 3, 4, 2, 2, 0, 3, 3, 3, 4, 3, 0, 2, 4, 0, 3, 4, 2, 0, 0, 2, 3, 4, 4, 4, 3, 0, 4, 0, 0, 0, 0, 0, 4, 3, 0, 4, 2, 4, 3, 2, 3, 2, 3, 2, 4, 2, 2, 2, 0, 3, 2, 0, 4, 2, 0, 4, 0, 3, 4, 4, 3, 2, 2, 0, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.88      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.85      0.85       100\n",
      "           3       0.72      0.92      0.81       100\n",
      "           4       0.61      0.92      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.64       500\n",
      "weighted avg       0.58      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1853946819901466, Val acc: 0.714\n",
      "Tiempo total de entrenamiento: 758.5879 [s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader,val_loader=get_training_loaders(synthetic_SN=fake_dcgan.detach().cpu(),batch_size=32,file_name=\"stamp_dataset_only_images_63.pkl\",label_as_strings=True)\n",
    "print(torch.bincount(train_loader.dataset.labels.to(torch.int)))\n",
    "print(torch.bincount(val_loader.dataset.labels.to(torch.int)))\n",
    "curves=trainer(train_loader,val_loader,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14542, 11396, 14523,  9599, 10534])\n",
      "Epoch 1/30\n",
      "Iteration 0 - Batch 0/1894 - Train loss: 1.6031157970428467, Train acc: 0.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 - Batch 100/1894 - Train loss: 1.4164990257508685, Train acc: 0.568069306930693\n",
      "Iteration 200 - Batch 200/1894 - Train loss: 1.3721076303453588, Train acc: 0.5935945273631841\n",
      "Iteration 300 - Batch 300/1894 - Train loss: 1.3423717041744345, Train acc: 0.6122300664451827\n",
      "Iteration 400 - Batch 400/1894 - Train loss: 1.32646831312679, Train acc: 0.6187655860349127\n",
      "Iteration 500 - Batch 500/1894 - Train loss: 1.3167081105256986, Train acc: 0.6214446107784432\n",
      "Iteration 600 - Batch 600/1894 - Train loss: 1.3079982498124514, Train acc: 0.6256759567387687\n",
      "Iteration 700 - Batch 700/1894 - Train loss: 1.2999287204293484, Train acc: 0.6299037089871612\n",
      "Iteration 800 - Batch 800/1894 - Train loss: 1.291869018408243, Train acc: 0.6347144194756554\n",
      "Iteration 900 - Batch 900/1894 - Train loss: 1.2848987976268975, Train acc: 0.6391856270810211\n",
      "Iteration 1000 - Batch 1000/1894 - Train loss: 1.2789363913483671, Train acc: 0.6429820179820179\n",
      "Iteration 1100 - Batch 1100/1894 - Train loss: 1.2739953676426443, Train acc: 0.6463442325158947\n",
      "Iteration 1200 - Batch 1200/1894 - Train loss: 1.2681427994536718, Train acc: 0.6507077435470441\n",
      "Iteration 1300 - Batch 1300/1894 - Train loss: 1.2632376388986692, Train acc: 0.6543764411990777\n",
      "Iteration 1400 - Batch 1400/1894 - Train loss: 1.2567036943211034, Train acc: 0.6600642398286938\n",
      "Iteration 1500 - Batch 1500/1894 - Train loss: 1.2504447943206471, Train acc: 0.6657020319786808\n",
      "Iteration 1600 - Batch 1600/1894 - Train loss: 1.2440799883497573, Train acc: 0.6712211118051218\n",
      "Iteration 1700 - Batch 1700/1894 - Train loss: 1.2379397322751717, Train acc: 0.6768445032333921\n",
      "Iteration 1800 - Batch 1800/1894 - Train loss: 1.2323198127852486, Train acc: 0.6818954747362577\n",
      "[2, 2, 3, 2, 4, 4, 0, 0, 4, 1, 0, 2, 4, 1, 1, 0, 3, 1, 3, 4, 0, 2, 4, 4, 0, 1, 2, 3, 0, 0, 4, 2, 3, 3, 1, 4, 1, 2, 2, 1, 0, 2, 2, 0, 3, 1, 3, 0, 3, 1, 4, 4, 0, 4, 0, 1, 1, 2, 2, 3, 0, 2, 3, 1, 4, 2, 0, 0, 2, 2, 4, 1, 0, 1, 4, 0, 2, 2, 4, 0, 1, 2, 0, 4, 1, 3, 2, 3, 3, 3, 1, 1, 1, 2, 3, 4, 0, 3, 3, 2, 2, 0, 3, 0, 0, 2, 4, 0, 1, 0, 3, 0, 2, 4, 1, 4, 3, 1, 2, 3, 4, 1, 2, 4, 0, 2, 4, 3, 3, 4, 4, 1, 4, 4, 2, 2, 1, 3, 1, 0, 1, 2, 4, 0, 4, 3, 4, 1, 3, 4, 2, 4, 1, 4, 1, 0, 1, 2, 4, 2, 2, 4, 0, 3, 1, 2, 1, 3, 2, 0, 3, 2, 0, 0, 3, 3, 0, 3, 2, 3, 2, 4, 3, 1, 0, 0, 1, 1, 4, 4, 4, 4, 3, 3, 2, 0, 0, 4, 1, 1, 0, 4, 4, 1, 4, 2, 3, 1, 0, 3, 2, 4, 4, 1, 0, 0, 2, 3, 2, 4, 2, 2, 0, 2, 1, 4, 4, 3, 4, 3, 0, 2, 1, 4, 1, 1, 4, 3, 2, 3, 0, 3, 4, 1, 4, 2, 0, 1, 1, 3, 0, 3, 0, 4, 1, 4, 1, 0, 0, 1, 1, 4, 1, 3, 0, 0, 3, 4, 4, 0, 3, 3, 4, 1, 3, 3, 1, 1, 4, 2, 1, 3, 4, 1, 1, 0, 4, 4, 2, 0, 1, 3, 4, 1, 4, 2, 3, 0, 3, 4, 2, 4, 4, 1, 0, 2, 0, 0, 1, 1, 0, 0, 3, 2, 3, 1, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 0, 3, 4, 0, 1, 1, 1, 2, 1, 4, 4, 2, 2, 4, 4, 0, 1, 2, 0, 2, 3, 1, 1, 0, 2, 2, 3, 0, 0, 4, 0, 4, 1, 0, 4, 3, 1, 4, 4, 3, 1, 2, 4, 0, 1, 4, 0, 0, 1, 3, 2, 4, 3, 1, 4, 1, 3, 3, 3, 3, 3, 2, 3, 3, 0, 1, 2, 0, 3, 4, 2, 0, 3, 2, 3, 4, 2, 3, 4, 4, 0, 4, 2, 1, 0, 0, 2, 2, 4, 0, 3, 2, 2, 4, 1, 2, 0, 1, 4, 2, 4, 3, 1, 4, 0, 3, 4, 2, 4, 1, 1, 2, 2, 1, 4, 2, 2, 0, 3, 1, 3, 0, 2, 1, 2, 3, 2, 1, 0, 3, 0, 2, 3, 1, 0, 1, 1, 1, 0, 0, 2, 2, 3, 3, 2, 4, 1, 0, 3, 0, 1, 1, 3, 4, 3, 2, 1, 0, 1, 3, 2, 0, 4, 2, 0, 3, 0, 0, 0, 0]\n",
      "[2, 2, 4, 2, 2, 4, 2, 0, 4, 0, 0, 2, 4, 3, 0, 0, 3, 0, 3, 4, 0, 2, 4, 4, 0, 4, 2, 4, 0, 0, 4, 0, 3, 4, 4, 4, 4, 0, 0, 3, 0, 2, 2, 0, 3, 2, 4, 0, 3, 3, 3, 4, 0, 4, 0, 3, 3, 2, 2, 3, 0, 4, 3, 4, 4, 2, 2, 2, 2, 2, 2, 0, 0, 4, 4, 0, 2, 2, 4, 0, 2, 2, 0, 4, 4, 3, 4, 3, 3, 3, 0, 4, 3, 2, 4, 4, 0, 3, 4, 2, 4, 0, 3, 0, 0, 2, 4, 0, 3, 0, 3, 4, 2, 2, 4, 4, 3, 4, 0, 3, 4, 4, 2, 4, 0, 3, 4, 3, 3, 3, 4, 4, 4, 4, 2, 2, 4, 2, 2, 0, 4, 2, 4, 0, 4, 3, 4, 4, 3, 4, 2, 4, 0, 4, 4, 0, 0, 2, 4, 2, 2, 4, 0, 3, 4, 3, 0, 3, 0, 0, 3, 2, 0, 0, 3, 3, 0, 3, 2, 3, 2, 4, 3, 2, 2, 0, 4, 4, 4, 4, 4, 4, 4, 3, 2, 0, 0, 4, 4, 2, 2, 4, 4, 4, 4, 0, 3, 4, 0, 3, 2, 2, 4, 0, 0, 4, 0, 3, 2, 4, 2, 2, 0, 0, 3, 4, 4, 3, 4, 3, 4, 2, 4, 4, 2, 3, 4, 3, 2, 4, 0, 3, 4, 2, 4, 0, 0, 2, 4, 3, 0, 3, 0, 4, 4, 4, 4, 2, 0, 4, 4, 4, 4, 3, 0, 0, 3, 4, 4, 0, 3, 3, 4, 0, 2, 3, 4, 4, 4, 2, 3, 3, 2, 3, 4, 0, 4, 4, 2, 4, 4, 3, 3, 3, 4, 2, 3, 0, 3, 4, 2, 2, 4, 2, 0, 2, 0, 0, 4, 2, 0, 0, 3, 2, 3, 3, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 0, 3, 2, 3, 4, 2, 2, 4, 3, 2, 4, 4, 4, 2, 2, 4, 4, 0, 0, 4, 4, 0, 3, 2, 0, 0, 2, 2, 3, 2, 0, 4, 0, 4, 4, 0, 4, 3, 0, 4, 4, 3, 4, 2, 4, 0, 4, 4, 2, 0, 4, 4, 2, 4, 3, 4, 4, 4, 0, 3, 3, 4, 3, 2, 3, 3, 0, 2, 2, 2, 3, 4, 2, 2, 3, 2, 3, 4, 2, 3, 4, 4, 2, 4, 2, 3, 0, 2, 2, 2, 4, 2, 3, 2, 2, 4, 3, 2, 4, 3, 4, 2, 2, 3, 3, 4, 0, 3, 4, 2, 4, 4, 2, 2, 2, 3, 4, 2, 3, 0, 3, 2, 3, 0, 2, 2, 2, 3, 0, 4, 2, 3, 0, 2, 4, 4, 0, 4, 4, 4, 0, 0, 2, 2, 4, 3, 2, 4, 0, 0, 4, 4, 2, 4, 3, 4, 3, 0, 3, 4, 4, 3, 2, 4, 4, 0, 0, 3, 0, 0, 2, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.65      0.79      0.71       100\n",
      "           3       0.76      0.84      0.80       100\n",
      "           4       0.55      0.90      0.68       100\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.54      0.65      0.58       500\n",
      "weighted avg       0.54      0.65      0.58       500\n",
      "\n",
      "Val loss: 1.2520429342985153, Val acc: 0.654\n",
      "Epoch 2/30\n",
      "Iteration 1900 - Batch 6/1894 - Train loss: 1.1384982211249215, Train acc: 0.7589285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2000 - Batch 106/1894 - Train loss: 1.1240690807315792, Train acc: 0.7786214953271028\n",
      "Iteration 2100 - Batch 206/1894 - Train loss: 1.1218515654692902, Train acc: 0.782608695652174\n",
      "Iteration 2200 - Batch 306/1894 - Train loss: 1.121993431050925, Train acc: 0.7826750814332247\n",
      "Iteration 2300 - Batch 406/1894 - Train loss: 1.1215378519065258, Train acc: 0.7827088452088452\n",
      "Iteration 2400 - Batch 506/1894 - Train loss: 1.119996950000936, Train acc: 0.7843318540433925\n",
      "Iteration 2500 - Batch 606/1894 - Train loss: 1.1171914527600837, Train acc: 0.786913097199341\n",
      "Iteration 2600 - Batch 706/1894 - Train loss: 1.1142554207266304, Train acc: 0.7900901697312589\n",
      "Iteration 2700 - Batch 806/1894 - Train loss: 1.1118553859889138, Train acc: 0.7921700743494424\n",
      "Iteration 2800 - Batch 906/1894 - Train loss: 1.1104587214652863, Train acc: 0.7933778941565601\n",
      "Iteration 2900 - Batch 1006/1894 - Train loss: 1.1102157213837056, Train acc: 0.7934148460774578\n",
      "Iteration 3000 - Batch 1106/1894 - Train loss: 1.1090198397205666, Train acc: 0.7947719060523939\n",
      "Iteration 3100 - Batch 1206/1894 - Train loss: 1.1067182901681902, Train acc: 0.7970173985086992\n",
      "Iteration 3200 - Batch 1306/1894 - Train loss: 1.1051518230741044, Train acc: 0.7985845447589901\n",
      "Iteration 3300 - Batch 1406/1894 - Train loss: 1.1042018083705916, Train acc: 0.7995513503909026\n",
      "Iteration 3400 - Batch 1506/1894 - Train loss: 1.1038985878881746, Train acc: 0.7999543795620438\n",
      "Iteration 3500 - Batch 1606/1894 - Train loss: 1.1025283437525921, Train acc: 0.8013962352209085\n",
      "Iteration 3600 - Batch 1706/1894 - Train loss: 1.1020849063582216, Train acc: 0.8019002636203867\n",
      "Iteration 3700 - Batch 1806/1894 - Train loss: 1.1005929290555627, Train acc: 0.8035244881018262\n",
      "[3, 3, 4, 4, 2, 3, 2, 0, 2, 4, 1, 3, 4, 3, 0, 1, 0, 4, 2, 1, 3, 1, 3, 2, 3, 1, 0, 0, 1, 4, 2, 1, 1, 0, 2, 0, 1, 2, 3, 1, 3, 1, 2, 4, 4, 0, 1, 0, 3, 4, 0, 0, 1, 4, 1, 1, 0, 3, 0, 1, 2, 1, 1, 3, 2, 4, 2, 4, 3, 3, 0, 0, 3, 3, 0, 3, 1, 0, 4, 4, 4, 0, 0, 1, 4, 0, 4, 1, 4, 4, 0, 1, 3, 2, 0, 4, 4, 3, 3, 0, 3, 0, 1, 3, 4, 3, 1, 2, 2, 4, 4, 4, 1, 4, 2, 1, 1, 2, 2, 1, 0, 4, 2, 2, 0, 1, 4, 0, 0, 2, 1, 1, 1, 0, 2, 1, 3, 2, 3, 3, 2, 4, 0, 2, 3, 2, 4, 4, 2, 4, 4, 2, 1, 0, 0, 0, 0, 0, 0, 1, 4, 3, 0, 2, 3, 2, 3, 1, 1, 4, 2, 4, 2, 1, 0, 3, 2, 2, 4, 4, 0, 3, 3, 1, 2, 2, 4, 0, 0, 2, 4, 2, 3, 2, 2, 2, 3, 2, 3, 0, 0, 4, 0, 4, 0, 3, 2, 4, 0, 2, 1, 1, 0, 4, 2, 3, 4, 1, 4, 2, 4, 0, 2, 4, 1, 3, 1, 0, 4, 1, 2, 0, 3, 3, 4, 2, 0, 3, 1, 2, 0, 3, 4, 0, 0, 1, 2, 2, 0, 2, 2, 3, 2, 1, 3, 0, 1, 1, 1, 0, 0, 1, 3, 4, 2, 0, 4, 2, 4, 0, 4, 3, 1, 2, 1, 4, 3, 1, 4, 4, 0, 3, 1, 0, 3, 0, 2, 2, 1, 1, 4, 3, 2, 3, 0, 2, 3, 1, 2, 0, 3, 3, 2, 4, 3, 1, 3, 2, 4, 4, 1, 4, 1, 3, 3, 1, 2, 3, 3, 0, 1, 0, 1, 4, 0, 1, 2, 0, 2, 4, 0, 3, 4, 3, 0, 2, 0, 3, 3, 4, 0, 1, 4, 2, 2, 3, 4, 3, 3, 2, 3, 4, 4, 0, 3, 2, 0, 1, 2, 1, 1, 4, 2, 0, 0, 4, 2, 2, 3, 4, 2, 1, 3, 0, 0, 1, 1, 4, 2, 2, 3, 4, 4, 0, 0, 1, 2, 1, 3, 4, 2, 4, 0, 4, 3, 2, 1, 1, 4, 1, 1, 1, 3, 3, 3, 0, 0, 4, 3, 2, 3, 4, 3, 4, 1, 3, 0, 2, 4, 1, 1, 1, 4, 3, 1, 3, 1, 1, 1, 4, 1, 1, 1, 0, 1, 4, 2, 3, 0, 2, 4, 0, 3, 3, 4, 2, 2, 4, 3, 4, 0, 3, 4, 0, 2, 4, 4, 2, 0, 2, 2, 0, 0, 2, 1, 1, 2, 1, 1, 4, 2, 1, 2, 1, 4, 3, 3, 0, 3, 1, 0, 4, 3, 1, 4, 0, 3, 4, 3, 2, 3, 0, 2, 3, 0, 2, 0, 3, 3, 0]\n",
      "[2, 4, 4, 2, 2, 3, 2, 0, 2, 4, 4, 3, 4, 3, 0, 3, 0, 4, 0, 3, 0, 0, 3, 0, 3, 3, 0, 0, 0, 4, 2, 3, 0, 2, 2, 0, 2, 2, 3, 2, 3, 2, 2, 4, 4, 0, 4, 0, 3, 4, 2, 0, 4, 4, 0, 4, 0, 3, 0, 0, 0, 0, 4, 3, 2, 4, 2, 4, 2, 4, 0, 0, 3, 3, 0, 3, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 4, 2, 3, 3, 2, 0, 4, 4, 3, 3, 0, 3, 0, 2, 3, 4, 3, 2, 2, 2, 2, 4, 4, 3, 4, 2, 2, 4, 2, 2, 3, 0, 2, 2, 2, 0, 4, 4, 0, 0, 2, 4, 0, 4, 0, 0, 4, 3, 2, 3, 3, 2, 4, 0, 2, 3, 2, 4, 2, 2, 4, 4, 2, 4, 0, 0, 2, 0, 0, 0, 0, 4, 3, 0, 2, 3, 3, 3, 4, 4, 4, 2, 4, 2, 3, 0, 3, 2, 2, 4, 4, 0, 3, 3, 0, 2, 2, 4, 0, 0, 2, 4, 2, 3, 3, 2, 2, 3, 2, 3, 0, 4, 3, 0, 4, 0, 3, 2, 4, 0, 2, 0, 4, 0, 4, 2, 4, 4, 4, 4, 2, 4, 0, 2, 4, 4, 3, 4, 0, 4, 0, 2, 0, 3, 3, 4, 2, 0, 3, 0, 2, 2, 3, 4, 0, 0, 4, 2, 2, 0, 0, 2, 3, 2, 2, 3, 0, 4, 0, 2, 4, 0, 4, 3, 4, 2, 0, 4, 2, 4, 0, 2, 3, 3, 2, 4, 2, 3, 4, 4, 4, 0, 4, 0, 0, 3, 0, 2, 2, 0, 4, 4, 3, 2, 3, 0, 2, 4, 4, 2, 0, 3, 3, 2, 4, 3, 4, 3, 2, 4, 4, 4, 4, 0, 3, 3, 4, 2, 3, 3, 0, 4, 0, 2, 4, 0, 4, 0, 0, 2, 4, 4, 3, 4, 3, 4, 2, 0, 3, 3, 4, 0, 4, 4, 2, 2, 3, 4, 3, 3, 0, 3, 4, 4, 0, 3, 0, 0, 4, 2, 3, 4, 2, 2, 0, 0, 2, 0, 2, 3, 4, 0, 3, 3, 0, 0, 0, 0, 3, 2, 2, 4, 4, 4, 0, 0, 0, 2, 3, 3, 4, 2, 4, 0, 4, 4, 2, 4, 2, 4, 3, 4, 4, 3, 3, 2, 0, 0, 2, 3, 0, 3, 4, 3, 4, 4, 3, 0, 2, 4, 3, 3, 4, 4, 3, 4, 4, 4, 2, 4, 4, 2, 3, 4, 4, 3, 4, 2, 3, 2, 2, 4, 0, 3, 3, 4, 2, 2, 4, 4, 4, 2, 3, 2, 0, 2, 4, 0, 3, 2, 2, 2, 0, 0, 2, 4, 0, 2, 0, 4, 4, 2, 3, 2, 4, 4, 3, 3, 0, 4, 4, 0, 4, 3, 2, 4, 0, 4, 2, 3, 2, 3, 2, 0, 3, 0, 2, 0, 3, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.70      0.85      0.77       100\n",
      "           3       0.79      0.84      0.81       100\n",
      "           4       0.57      0.86      0.69       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.55      0.68      0.61       500\n",
      "weighted avg       0.55      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.222543478012085, Val acc: 0.68\n",
      "Epoch 3/30\n",
      "Iteration 3800 - Batch 12/1894 - Train loss: 1.0795746308106642, Train acc: 0.8269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3900 - Batch 112/1894 - Train loss: 1.0971734180914616, Train acc: 0.808075221238938\n",
      "Iteration 4000 - Batch 212/1894 - Train loss: 1.0896535546566959, Train acc: 0.8141138497652582\n",
      "Iteration 4100 - Batch 312/1894 - Train loss: 1.0843767855114068, Train acc: 0.8201876996805112\n",
      "Iteration 4200 - Batch 412/1894 - Train loss: 1.0838106270275163, Train acc: 0.8205205811138014\n",
      "Iteration 4300 - Batch 512/1894 - Train loss: 1.0812485471338789, Train acc: 0.8233430799220273\n",
      "Iteration 4400 - Batch 612/1894 - Train loss: 1.080342870260335, Train acc: 0.8238682707993474\n",
      "Iteration 4500 - Batch 712/1894 - Train loss: 1.0785022367100228, Train acc: 0.8254733520336606\n",
      "Iteration 4600 - Batch 812/1894 - Train loss: 1.0779423129367947, Train acc: 0.8259148216482165\n",
      "Iteration 4700 - Batch 912/1894 - Train loss: 1.0781522005437367, Train acc: 0.8257461664841182\n",
      "Iteration 4800 - Batch 1012/1894 - Train loss: 1.0776553327568898, Train acc: 0.8262894866732478\n",
      "Iteration 4900 - Batch 1112/1894 - Train loss: 1.0763329705566516, Train acc: 0.8277459568733153\n",
      "Iteration 5000 - Batch 1212/1894 - Train loss: 1.0757183640925037, Train acc: 0.8282409315746084\n",
      "Iteration 5100 - Batch 1312/1894 - Train loss: 1.0761576885043984, Train acc: 0.8278274942878904\n",
      "Iteration 5200 - Batch 1412/1894 - Train loss: 1.076368381221161, Train acc: 0.8277158527954707\n",
      "Iteration 5300 - Batch 1512/1894 - Train loss: 1.0762282432662047, Train acc: 0.8278255122273629\n",
      "Iteration 5400 - Batch 1612/1894 - Train loss: 1.0762294149517053, Train acc: 0.8277859578425294\n",
      "Iteration 5500 - Batch 1712/1894 - Train loss: 1.0756378899661685, Train acc: 0.8284624927028604\n",
      "Iteration 5600 - Batch 1812/1894 - Train loss: 1.0758062234190506, Train acc: 0.8282887479316051\n",
      "[1, 0, 0, 1, 2, 2, 3, 2, 0, 4, 4, 4, 4, 4, 4, 3, 3, 0, 3, 1, 2, 0, 4, 3, 0, 3, 4, 4, 1, 0, 0, 2, 1, 4, 2, 0, 1, 3, 3, 3, 1, 3, 4, 1, 4, 3, 4, 4, 2, 1, 3, 4, 4, 4, 4, 3, 4, 3, 2, 3, 2, 0, 2, 1, 1, 1, 1, 4, 4, 1, 4, 1, 0, 3, 2, 1, 3, 1, 3, 0, 0, 2, 1, 3, 1, 1, 1, 3, 1, 3, 0, 4, 1, 1, 2, 0, 2, 3, 2, 2, 0, 3, 3, 0, 1, 3, 3, 1, 4, 1, 0, 0, 2, 0, 3, 3, 0, 4, 2, 0, 1, 3, 2, 1, 3, 4, 1, 0, 2, 2, 0, 4, 3, 3, 0, 3, 2, 1, 3, 0, 4, 4, 4, 0, 0, 3, 2, 0, 1, 4, 2, 1, 4, 3, 1, 3, 1, 0, 4, 0, 2, 0, 0, 1, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 0, 0, 4, 2, 0, 3, 0, 1, 2, 1, 0, 3, 3, 2, 4, 3, 1, 4, 1, 4, 0, 4, 1, 4, 1, 3, 4, 1, 3, 0, 1, 1, 0, 1, 3, 0, 1, 4, 0, 4, 4, 4, 0, 1, 1, 4, 2, 3, 3, 2, 4, 0, 3, 3, 4, 2, 3, 1, 3, 0, 1, 2, 3, 1, 4, 1, 0, 4, 2, 1, 2, 3, 2, 2, 0, 4, 4, 0, 2, 3, 2, 0, 2, 0, 2, 4, 0, 1, 2, 3, 0, 4, 3, 2, 4, 4, 3, 0, 3, 2, 1, 2, 3, 4, 0, 0, 0, 2, 0, 2, 3, 0, 2, 0, 4, 2, 0, 1, 3, 4, 1, 2, 1, 1, 3, 4, 3, 4, 0, 2, 1, 3, 0, 1, 3, 2, 4, 3, 3, 2, 2, 0, 0, 1, 0, 1, 1, 2, 2, 0, 4, 2, 1, 4, 4, 1, 0, 0, 3, 3, 2, 2, 0, 4, 2, 0, 0, 2, 1, 2, 2, 2, 1, 4, 1, 2, 0, 3, 1, 3, 3, 1, 0, 2, 1, 2, 1, 4, 4, 4, 1, 4, 0, 2, 1, 2, 0, 2, 4, 4, 4, 4, 0, 2, 4, 4, 2, 4, 3, 0, 1, 1, 4, 4, 2, 0, 3, 1, 2, 2, 2, 1, 2, 2, 2, 4, 2, 2, 1, 3, 4, 3, 1, 4, 3, 1, 2, 4, 3, 4, 0, 0, 3, 2, 0, 4, 4, 2, 3, 0, 0, 1, 0, 2, 2, 1, 0, 4, 0, 2, 3, 1, 4, 1, 3, 0, 1, 4, 4, 4, 4, 3, 3, 2, 4, 1, 0, 2, 1, 2, 2, 4, 2, 0, 2, 1, 3, 3, 2, 2, 1, 4, 0, 0, 1, 2, 1, 0, 4, 0, 4, 3, 1, 1, 3, 3, 3, 4, 4, 0, 4, 3, 1, 0, 0, 3, 3, 1, 0, 2, 1, 0, 0, 2, 1, 2]\n",
      "[2, 0, 0, 4, 2, 3, 3, 2, 0, 4, 4, 4, 4, 4, 4, 3, 3, 2, 3, 0, 2, 0, 3, 3, 0, 3, 4, 4, 3, 0, 2, 2, 4, 4, 2, 0, 4, 3, 0, 3, 4, 4, 4, 0, 4, 3, 4, 4, 2, 0, 3, 4, 4, 4, 4, 3, 4, 4, 2, 3, 2, 0, 2, 4, 2, 2, 3, 4, 4, 0, 4, 0, 0, 3, 2, 4, 3, 2, 3, 0, 4, 2, 3, 3, 4, 3, 4, 3, 0, 3, 0, 4, 4, 0, 0, 0, 2, 3, 2, 2, 0, 3, 3, 2, 3, 2, 4, 3, 4, 0, 0, 0, 2, 0, 4, 3, 0, 4, 2, 2, 3, 4, 2, 4, 3, 4, 4, 2, 3, 2, 0, 4, 3, 4, 4, 3, 2, 4, 0, 0, 2, 4, 4, 2, 0, 4, 2, 0, 4, 4, 2, 3, 4, 3, 0, 3, 4, 0, 4, 0, 0, 0, 0, 4, 3, 3, 3, 3, 0, 2, 3, 3, 3, 3, 0, 0, 4, 2, 0, 3, 0, 4, 2, 4, 0, 4, 4, 2, 4, 3, 0, 4, 4, 2, 2, 4, 4, 4, 4, 3, 4, 4, 3, 2, 3, 3, 0, 4, 3, 0, 4, 4, 2, 2, 4, 4, 0, 0, 4, 2, 2, 3, 2, 2, 4, 0, 3, 3, 0, 2, 3, 2, 4, 0, 3, 2, 3, 2, 4, 0, 0, 4, 2, 3, 2, 3, 2, 2, 0, 4, 4, 0, 2, 3, 0, 0, 2, 0, 2, 4, 0, 3, 2, 3, 0, 4, 3, 2, 4, 4, 3, 2, 3, 2, 2, 2, 3, 4, 0, 0, 0, 2, 0, 2, 3, 0, 2, 0, 4, 2, 0, 3, 3, 4, 0, 2, 2, 4, 3, 4, 3, 4, 0, 2, 2, 3, 0, 3, 3, 2, 4, 3, 3, 2, 2, 2, 0, 4, 0, 4, 4, 2, 2, 4, 4, 2, 0, 4, 4, 4, 0, 0, 4, 4, 2, 2, 2, 2, 2, 0, 0, 2, 4, 0, 2, 2, 2, 4, 3, 2, 4, 3, 4, 3, 3, 4, 0, 2, 0, 2, 0, 4, 4, 4, 3, 4, 0, 2, 2, 2, 0, 2, 4, 0, 4, 4, 0, 2, 4, 4, 2, 4, 3, 0, 4, 0, 4, 4, 2, 0, 3, 4, 0, 0, 2, 4, 2, 2, 0, 3, 2, 2, 4, 4, 4, 3, 0, 4, 3, 0, 2, 4, 3, 4, 0, 0, 3, 2, 4, 0, 4, 2, 3, 0, 0, 4, 0, 2, 2, 3, 0, 4, 0, 4, 3, 3, 4, 4, 3, 0, 4, 4, 4, 4, 4, 4, 3, 2, 4, 4, 0, 2, 4, 2, 2, 4, 2, 0, 4, 0, 4, 3, 0, 2, 4, 4, 0, 2, 4, 2, 4, 0, 4, 0, 4, 3, 0, 3, 3, 3, 3, 4, 4, 0, 4, 3, 0, 0, 2, 3, 3, 3, 2, 2, 0, 0, 2, 2, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.72      0.87      0.79       100\n",
      "           3       0.76      0.81      0.79       100\n",
      "           4       0.57      0.90      0.70       100\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.55      0.67      0.60       500\n",
      "weighted avg       0.55      0.67      0.60       500\n",
      "\n",
      "Val loss: 1.2255858704447746, Val acc: 0.674\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5700 - Batch 18/1894 - Train loss: 1.0534342119568272, Train acc: 0.850328947368421\n",
      "Iteration 5800 - Batch 118/1894 - Train loss: 1.0645569317481096, Train acc: 0.8400735294117647\n",
      "Iteration 5900 - Batch 218/1894 - Train loss: 1.0675475904930671, Train acc: 0.836615296803653\n",
      "Iteration 6000 - Batch 318/1894 - Train loss: 1.0677580848382933, Train acc: 0.8363048589341693\n",
      "Iteration 6100 - Batch 418/1894 - Train loss: 1.064311306914737, Train acc: 0.8399463007159904\n",
      "Iteration 6200 - Batch 518/1894 - Train loss: 1.0649602328192063, Train acc: 0.8391738921001927\n",
      "Iteration 6300 - Batch 618/1894 - Train loss: 1.0644095874179353, Train acc: 0.8397112277867528\n",
      "Iteration 6400 - Batch 718/1894 - Train loss: 1.0628501699100117, Train acc: 0.8411856745479833\n",
      "Iteration 6500 - Batch 818/1894 - Train loss: 1.0621611130979909, Train acc: 0.8418421855921856\n",
      "Iteration 6600 - Batch 918/1894 - Train loss: 1.0627494100906902, Train acc: 0.841063656147987\n",
      "Iteration 6700 - Batch 1018/1894 - Train loss: 1.0624925668503984, Train acc: 0.8410819430814525\n",
      "Iteration 6800 - Batch 1118/1894 - Train loss: 1.063220978156065, Train acc: 0.8403987935656837\n",
      "Iteration 6900 - Batch 1218/1894 - Train loss: 1.0641898232664213, Train acc: 0.8393406480721903\n",
      "Iteration 7000 - Batch 1318/1894 - Train loss: 1.0641114642170002, Train acc: 0.8394143290371494\n",
      "Iteration 7100 - Batch 1418/1894 - Train loss: 1.0638761858943484, Train acc: 0.8398079633544749\n",
      "Iteration 7200 - Batch 1518/1894 - Train loss: 1.0651302374923912, Train acc: 0.8384833772218565\n",
      "Iteration 7300 - Batch 1618/1894 - Train loss: 1.0656027457020472, Train acc: 0.8380172946263126\n",
      "Iteration 7400 - Batch 1718/1894 - Train loss: 1.065585193140275, Train acc: 0.8380780977312391\n",
      "Iteration 7500 - Batch 1818/1894 - Train loss: 1.0650922031177146, Train acc: 0.8385788894997251\n",
      "[1, 2, 4, 3, 3, 4, 1, 0, 4, 0, 2, 3, 2, 1, 2, 0, 3, 4, 2, 3, 1, 1, 4, 4, 0, 0, 2, 1, 0, 1, 1, 1, 4, 2, 4, 4, 1, 2, 4, 4, 3, 2, 3, 1, 3, 1, 3, 3, 1, 3, 1, 4, 4, 3, 4, 0, 3, 3, 1, 0, 2, 3, 4, 1, 3, 0, 3, 3, 4, 0, 0, 1, 1, 2, 0, 2, 4, 4, 4, 3, 0, 2, 2, 3, 4, 4, 4, 4, 4, 2, 3, 1, 4, 3, 2, 0, 0, 0, 1, 4, 2, 0, 3, 0, 2, 1, 1, 2, 1, 4, 2, 0, 1, 1, 1, 0, 0, 3, 1, 0, 1, 2, 1, 0, 4, 2, 1, 4, 0, 2, 2, 0, 3, 1, 0, 3, 1, 3, 0, 1, 4, 1, 1, 0, 3, 3, 4, 3, 0, 1, 2, 1, 3, 2, 4, 0, 2, 0, 2, 2, 2, 1, 3, 3, 3, 4, 0, 1, 2, 3, 1, 2, 0, 1, 3, 4, 0, 4, 2, 1, 2, 4, 0, 1, 0, 2, 0, 1, 2, 3, 3, 3, 3, 4, 1, 0, 3, 3, 3, 4, 3, 4, 4, 1, 4, 0, 3, 4, 0, 4, 3, 0, 3, 1, 1, 0, 2, 0, 3, 4, 2, 4, 0, 0, 0, 0, 4, 0, 4, 1, 4, 4, 0, 1, 2, 0, 3, 0, 1, 4, 1, 3, 2, 1, 1, 0, 4, 4, 1, 2, 0, 2, 0, 4, 1, 4, 4, 1, 4, 1, 4, 4, 0, 0, 1, 3, 4, 3, 3, 2, 1, 0, 2, 3, 1, 1, 3, 1, 4, 4, 3, 0, 4, 3, 1, 0, 2, 3, 2, 2, 2, 3, 3, 0, 3, 2, 3, 0, 4, 2, 1, 4, 2, 2, 2, 1, 3, 1, 0, 3, 0, 2, 2, 4, 3, 4, 2, 3, 1, 3, 2, 0, 4, 0, 1, 3, 3, 2, 1, 0, 3, 4, 4, 3, 0, 2, 3, 0, 1, 2, 3, 2, 4, 2, 3, 1, 1, 4, 1, 1, 2, 1, 2, 2, 4, 0, 3, 0, 2, 3, 4, 4, 4, 2, 4, 3, 0, 2, 4, 4, 0, 0, 0, 1, 3, 2, 1, 2, 2, 3, 4, 4, 4, 0, 0, 2, 3, 2, 2, 1, 1, 3, 0, 3, 1, 1, 3, 1, 4, 3, 0, 0, 2, 4, 1, 0, 1, 4, 1, 1, 1, 0, 0, 3, 2, 4, 4, 3, 2, 0, 0, 3, 1, 0, 0, 2, 0, 4, 3, 2, 4, 3, 2, 1, 1, 4, 2, 1, 0, 2, 4, 3, 2, 1, 3, 3, 2, 4, 0, 2, 4, 1, 0, 2, 2, 4, 2, 0, 4, 4, 2, 0, 4, 4, 3, 1, 1, 2, 0, 4, 2, 3, 0, 3, 2, 3, 2, 2, 2, 3, 3, 0, 1, 2, 3, 0, 0, 4, 2, 2, 3, 2, 1, 0, 0, 4, 1, 0, 1, 2]\n",
      "[4, 2, 4, 3, 4, 4, 4, 2, 4, 0, 2, 3, 2, 3, 3, 0, 3, 4, 2, 3, 4, 3, 4, 4, 0, 0, 2, 0, 0, 0, 3, 3, 4, 2, 4, 4, 0, 0, 4, 4, 4, 2, 3, 2, 3, 2, 3, 0, 0, 3, 0, 4, 4, 3, 4, 0, 3, 3, 2, 0, 2, 3, 4, 0, 2, 0, 3, 3, 4, 0, 0, 3, 0, 2, 0, 2, 4, 4, 4, 3, 0, 0, 2, 3, 4, 4, 2, 4, 4, 2, 3, 3, 4, 3, 2, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 2, 4, 0, 4, 4, 2, 0, 0, 4, 4, 0, 0, 3, 4, 0, 4, 2, 3, 0, 4, 2, 0, 4, 0, 2, 2, 0, 3, 0, 0, 3, 4, 3, 2, 4, 4, 0, 4, 0, 3, 3, 4, 3, 2, 0, 2, 2, 3, 2, 4, 0, 0, 0, 2, 2, 2, 0, 3, 3, 3, 4, 0, 4, 2, 3, 0, 4, 0, 0, 3, 3, 0, 4, 2, 4, 2, 4, 0, 3, 0, 2, 0, 4, 2, 3, 4, 3, 3, 4, 3, 0, 4, 3, 3, 4, 3, 4, 4, 0, 4, 2, 4, 4, 4, 4, 3, 2, 3, 4, 2, 0, 2, 2, 3, 4, 2, 4, 0, 0, 0, 4, 4, 2, 4, 3, 4, 4, 0, 0, 2, 0, 3, 0, 4, 4, 4, 3, 2, 0, 4, 0, 4, 4, 4, 0, 2, 2, 0, 4, 0, 4, 4, 4, 4, 0, 4, 4, 0, 2, 0, 4, 4, 3, 3, 2, 3, 0, 2, 3, 3, 4, 3, 4, 4, 4, 3, 0, 4, 3, 3, 0, 2, 3, 2, 2, 2, 3, 3, 0, 3, 2, 3, 0, 4, 2, 3, 4, 3, 2, 0, 3, 3, 3, 2, 3, 0, 2, 2, 4, 3, 4, 2, 3, 0, 3, 0, 0, 4, 0, 4, 3, 3, 2, 3, 0, 3, 4, 4, 3, 0, 2, 3, 0, 4, 2, 3, 0, 4, 2, 3, 4, 3, 4, 0, 4, 2, 0, 2, 2, 4, 0, 3, 0, 2, 3, 4, 4, 4, 0, 4, 3, 0, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 3, 4, 4, 4, 0, 0, 2, 3, 2, 2, 4, 4, 3, 0, 3, 0, 0, 3, 4, 4, 3, 0, 4, 2, 4, 2, 0, 3, 4, 3, 0, 0, 0, 2, 3, 2, 4, 4, 3, 2, 0, 0, 3, 0, 0, 0, 2, 0, 4, 3, 2, 3, 3, 3, 4, 4, 4, 2, 4, 4, 2, 4, 3, 2, 4, 3, 3, 2, 4, 0, 2, 4, 3, 0, 2, 2, 4, 2, 0, 3, 4, 2, 0, 4, 4, 3, 4, 4, 2, 4, 3, 2, 3, 0, 3, 2, 3, 2, 2, 2, 3, 3, 0, 4, 2, 3, 0, 0, 4, 2, 2, 3, 2, 4, 0, 0, 4, 4, 0, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.86      0.82       100\n",
      "           3       0.76      0.91      0.83       100\n",
      "           4       0.63      0.94      0.76       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.197211503982544, Val acc: 0.704\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7600 - Batch 24/1894 - Train loss: 1.0480672097206116, Train acc: 0.8575\n",
      "Iteration 7700 - Batch 124/1894 - Train loss: 1.0578782653808594, Train acc: 0.84625\n",
      "Iteration 7800 - Batch 224/1894 - Train loss: 1.0573205235269334, Train acc: 0.8469444444444445\n",
      "Iteration 7900 - Batch 324/1894 - Train loss: 1.055788818689493, Train acc: 0.8484615384615385\n",
      "Iteration 8000 - Batch 424/1894 - Train loss: 1.0553593241467196, Train acc: 0.8486029411764706\n",
      "Iteration 8100 - Batch 524/1894 - Train loss: 1.056163728237152, Train acc: 0.8475595238095238\n",
      "Iteration 8200 - Batch 624/1894 - Train loss: 1.0572671102523803, Train acc: 0.84645\n",
      "Iteration 8300 - Batch 724/1894 - Train loss: 1.0593655659412515, Train acc: 0.8444396551724138\n",
      "Iteration 8400 - Batch 824/1894 - Train loss: 1.0598049708568689, Train acc: 0.8439015151515151\n",
      "Iteration 8500 - Batch 924/1894 - Train loss: 1.0589714938885457, Train acc: 0.8449662162162163\n",
      "Iteration 8600 - Batch 1024/1894 - Train loss: 1.0591801746880136, Train acc: 0.8444817073170732\n",
      "Iteration 8700 - Batch 1124/1894 - Train loss: 1.059681236108144, Train acc: 0.8441111111111111\n",
      "Iteration 8800 - Batch 1224/1894 - Train loss: 1.0594870532775411, Train acc: 0.8443112244897959\n",
      "Iteration 8900 - Batch 1324/1894 - Train loss: 1.059334612657439, Train acc: 0.8444575471698114\n",
      "Iteration 9000 - Batch 1424/1894 - Train loss: 1.0596166155631082, Train acc: 0.8441666666666666\n",
      "Iteration 9100 - Batch 1524/1894 - Train loss: 1.0595632402232436, Train acc: 0.8443237704918033\n",
      "Iteration 9200 - Batch 1624/1894 - Train loss: 1.0587457304000853, Train acc: 0.8451538461538461\n",
      "Iteration 9300 - Batch 1724/1894 - Train loss: 1.0588716949932817, Train acc: 0.845018115942029\n",
      "Iteration 9400 - Batch 1824/1894 - Train loss: 1.0581759069390493, Train acc: 0.8457705479452055\n",
      "[0, 0, 1, 4, 3, 1, 0, 0, 1, 3, 1, 2, 4, 2, 3, 1, 0, 4, 4, 1, 2, 4, 4, 4, 4, 2, 0, 1, 4, 2, 1, 3, 3, 2, 3, 1, 1, 4, 0, 1, 2, 4, 2, 3, 1, 0, 3, 0, 4, 3, 0, 2, 1, 1, 4, 0, 1, 4, 3, 4, 2, 1, 4, 0, 1, 0, 1, 3, 0, 0, 3, 2, 1, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 3, 1, 2, 1, 3, 1, 2, 0, 1, 3, 2, 4, 0, 4, 4, 4, 1, 1, 1, 4, 4, 2, 1, 4, 3, 4, 4, 2, 0, 0, 0, 2, 0, 0, 1, 4, 2, 4, 1, 2, 3, 2, 2, 2, 2, 4, 1, 1, 4, 1, 3, 3, 1, 2, 2, 0, 0, 2, 3, 0, 3, 2, 2, 4, 3, 3, 0, 1, 0, 3, 2, 1, 3, 0, 0, 4, 2, 3, 2, 4, 3, 3, 3, 1, 2, 1, 2, 4, 3, 1, 0, 4, 3, 4, 1, 1, 1, 1, 4, 3, 2, 2, 3, 2, 2, 0, 0, 1, 0, 0, 1, 4, 3, 2, 3, 2, 0, 2, 0, 3, 2, 2, 3, 4, 0, 4, 0, 3, 0, 4, 4, 3, 1, 2, 0, 0, 3, 4, 1, 2, 4, 1, 3, 3, 4, 2, 1, 0, 2, 3, 0, 2, 0, 0, 3, 4, 1, 2, 4, 4, 0, 3, 4, 3, 1, 3, 4, 0, 2, 2, 4, 0, 4, 3, 1, 3, 3, 2, 3, 2, 3, 0, 4, 1, 3, 0, 0, 2, 0, 1, 4, 2, 0, 1, 3, 3, 1, 4, 0, 4, 0, 0, 1, 1, 4, 4, 0, 3, 3, 3, 3, 4, 0, 4, 1, 4, 2, 0, 4, 1, 0, 4, 3, 0, 1, 1, 3, 4, 2, 4, 1, 0, 4, 2, 1, 0, 4, 1, 1, 4, 4, 0, 1, 3, 3, 0, 0, 4, 2, 2, 0, 2, 2, 1, 2, 4, 0, 3, 4, 3, 3, 3, 4, 0, 1, 3, 0, 0, 3, 3, 2, 1, 4, 4, 1, 1, 4, 2, 0, 2, 0, 1, 1, 1, 4, 2, 0, 3, 1, 3, 0, 1, 4, 4, 4, 2, 4, 4, 2, 0, 4, 3, 0, 4, 2, 0, 1, 3, 4, 3, 2, 2, 3, 2, 1, 3, 2, 2, 2, 4, 4, 4, 3, 3, 2, 0, 1, 1, 2, 2, 1, 2, 0, 0, 3, 1, 2, 3, 0, 1, 1, 3, 2, 3, 0, 3, 4, 2, 4, 0, 0, 2, 2, 3, 3, 2, 0, 4, 4, 3, 1, 4, 0, 2, 4, 4, 3, 0, 4, 2, 1, 3, 1, 0, 2, 2, 2, 0, 4, 1, 1, 4, 1, 3, 3, 1, 0, 2, 3, 1, 3, 0, 3, 1, 2, 3, 4, 0, 3, 2, 3, 2, 0, 2, 4, 2, 3, 0, 4, 1, 2, 3, 1, 2, 2, 3, 1]\n",
      "[0, 4, 4, 4, 3, 4, 0, 4, 3, 3, 3, 2, 4, 3, 3, 4, 0, 3, 4, 4, 0, 4, 4, 4, 4, 2, 0, 0, 3, 2, 3, 3, 3, 2, 3, 3, 3, 4, 0, 4, 2, 3, 2, 4, 0, 0, 3, 0, 4, 3, 0, 2, 3, 2, 4, 0, 4, 4, 3, 3, 2, 4, 3, 0, 4, 0, 4, 3, 0, 0, 3, 2, 3, 0, 0, 0, 3, 0, 2, 4, 0, 0, 0, 3, 4, 2, 4, 3, 0, 2, 0, 4, 2, 0, 4, 0, 4, 4, 4, 4, 2, 2, 3, 4, 3, 3, 4, 3, 3, 4, 2, 0, 0, 0, 2, 0, 4, 4, 4, 2, 0, 3, 2, 3, 2, 0, 2, 2, 3, 4, 4, 4, 4, 3, 3, 4, 0, 2, 0, 0, 2, 3, 0, 3, 3, 0, 4, 3, 3, 0, 4, 0, 3, 2, 2, 3, 0, 0, 4, 2, 3, 2, 4, 3, 3, 3, 4, 0, 4, 2, 4, 3, 3, 0, 4, 3, 2, 4, 4, 3, 3, 4, 3, 2, 2, 3, 2, 0, 0, 0, 4, 0, 0, 3, 4, 3, 2, 3, 2, 0, 2, 0, 3, 2, 2, 3, 4, 0, 4, 0, 3, 0, 4, 4, 3, 4, 2, 0, 0, 3, 4, 0, 2, 4, 3, 3, 3, 4, 0, 0, 0, 2, 3, 0, 0, 0, 0, 3, 4, 4, 0, 4, 0, 0, 4, 4, 3, 0, 3, 4, 0, 0, 2, 4, 0, 4, 3, 0, 3, 3, 2, 3, 0, 3, 0, 4, 4, 3, 0, 0, 2, 0, 3, 4, 2, 0, 4, 3, 4, 0, 4, 0, 4, 0, 0, 4, 4, 3, 4, 0, 3, 3, 0, 3, 4, 0, 4, 4, 3, 2, 0, 4, 3, 0, 4, 3, 0, 4, 3, 3, 4, 2, 4, 4, 0, 4, 2, 3, 0, 4, 3, 4, 4, 4, 0, 4, 3, 3, 0, 0, 4, 2, 0, 0, 2, 2, 0, 2, 4, 0, 3, 4, 3, 3, 3, 4, 4, 4, 3, 0, 0, 3, 3, 2, 4, 4, 4, 4, 3, 4, 2, 0, 2, 0, 4, 4, 4, 4, 2, 0, 3, 4, 3, 0, 0, 4, 4, 4, 2, 4, 4, 2, 0, 4, 3, 0, 4, 2, 0, 4, 3, 4, 3, 2, 2, 3, 2, 0, 3, 2, 0, 0, 4, 4, 4, 4, 3, 0, 0, 0, 0, 0, 2, 4, 2, 4, 0, 3, 4, 2, 3, 0, 4, 4, 3, 2, 3, 0, 3, 4, 2, 3, 4, 0, 2, 2, 3, 3, 2, 0, 4, 4, 3, 4, 4, 0, 2, 4, 4, 3, 0, 4, 2, 4, 3, 0, 0, 2, 2, 2, 0, 4, 4, 3, 4, 0, 3, 3, 3, 0, 2, 3, 3, 3, 0, 3, 4, 2, 3, 4, 2, 3, 2, 3, 2, 0, 3, 4, 2, 3, 0, 4, 4, 0, 3, 4, 2, 2, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.92      0.78      0.84       100\n",
      "           3       0.71      0.94      0.81       100\n",
      "           4       0.57      0.86      0.69       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2028330117464066, Val acc: 0.702\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9500 - Batch 30/1894 - Train loss: 1.0433465453886217, Train acc: 0.8639112903225806\n",
      "Iteration 9600 - Batch 130/1894 - Train loss: 1.051479348244558, Train acc: 0.8523377862595419\n",
      "Iteration 9700 - Batch 230/1894 - Train loss: 1.0541600685615045, Train acc: 0.8499729437229437\n",
      "Iteration 9800 - Batch 330/1894 - Train loss: 1.0545332089651747, Train acc: 0.849320241691843\n",
      "Iteration 9900 - Batch 430/1894 - Train loss: 1.0531606057403813, Train acc: 0.8505655452436195\n",
      "Iteration 10000 - Batch 530/1894 - Train loss: 1.0548942857991954, Train acc: 0.8489289077212806\n",
      "Iteration 10100 - Batch 630/1894 - Train loss: 1.0540298522935616, Train acc: 0.8499405705229794\n",
      "Iteration 10200 - Batch 730/1894 - Train loss: 1.0538823205045083, Train acc: 0.8499914500683995\n",
      "Iteration 10300 - Batch 830/1894 - Train loss: 1.053821411158634, Train acc: 0.8501052948255114\n",
      "Iteration 10400 - Batch 930/1894 - Train loss: 1.054625519364272, Train acc: 0.8494562298603652\n",
      "Iteration 10500 - Batch 1030/1894 - Train loss: 1.0548867258946948, Train acc: 0.8492664888457808\n",
      "Iteration 10600 - Batch 1130/1894 - Train loss: 1.0534689713641672, Train acc: 0.8506852343059239\n",
      "Iteration 10700 - Batch 1230/1894 - Train loss: 1.0539718510463507, Train acc: 0.8501218521527214\n",
      "Iteration 10800 - Batch 1330/1894 - Train loss: 1.0540340524880534, Train acc: 0.8499718256949662\n",
      "Iteration 10900 - Batch 1430/1894 - Train loss: 1.0545405159456425, Train acc: 0.8494060097833682\n",
      "Iteration 11000 - Batch 1530/1894 - Train loss: 1.0544799774554257, Train acc: 0.8493835728282169\n",
      "Iteration 11100 - Batch 1630/1894 - Train loss: 1.0537949097003037, Train acc: 0.8501302881667688\n",
      "Iteration 11200 - Batch 1730/1894 - Train loss: 1.0536992397010843, Train acc: 0.8501408145580589\n",
      "Iteration 11300 - Batch 1830/1894 - Train loss: 1.053861556516717, Train acc: 0.8499795193883124\n",
      "[3, 0, 3, 0, 1, 3, 0, 4, 2, 3, 4, 3, 2, 0, 4, 2, 2, 3, 1, 3, 4, 4, 4, 1, 2, 0, 3, 1, 4, 1, 1, 3, 4, 2, 3, 2, 0, 2, 4, 2, 4, 2, 3, 0, 1, 3, 3, 0, 4, 2, 4, 4, 3, 4, 2, 3, 3, 0, 3, 4, 0, 4, 2, 2, 3, 0, 0, 1, 2, 1, 4, 4, 2, 1, 0, 3, 3, 3, 2, 3, 3, 4, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 3, 4, 2, 3, 0, 1, 0, 4, 0, 4, 0, 4, 2, 0, 2, 4, 4, 1, 1, 4, 4, 4, 0, 0, 1, 2, 4, 4, 4, 1, 1, 1, 3, 2, 4, 1, 1, 2, 2, 2, 0, 3, 1, 3, 1, 4, 1, 2, 2, 2, 3, 0, 0, 4, 4, 2, 1, 2, 1, 1, 4, 2, 0, 0, 1, 0, 4, 2, 3, 1, 4, 3, 2, 4, 0, 1, 2, 3, 3, 3, 0, 1, 0, 4, 3, 0, 4, 0, 1, 0, 3, 1, 3, 2, 0, 2, 2, 0, 4, 1, 4, 2, 0, 2, 3, 0, 1, 3, 0, 0, 3, 1, 0, 1, 3, 2, 2, 3, 1, 3, 0, 1, 4, 2, 4, 0, 0, 4, 0, 2, 1, 3, 3, 0, 3, 4, 2, 2, 0, 4, 0, 4, 0, 3, 3, 4, 2, 4, 1, 0, 0, 4, 3, 3, 1, 4, 4, 1, 2, 1, 1, 1, 4, 2, 3, 2, 2, 2, 4, 4, 2, 0, 4, 3, 3, 3, 2, 2, 4, 1, 1, 0, 1, 2, 4, 3, 2, 2, 3, 4, 4, 3, 4, 2, 4, 1, 1, 2, 3, 1, 4, 2, 0, 3, 2, 0, 1, 0, 3, 0, 0, 2, 1, 2, 0, 2, 1, 3, 0, 1, 1, 1, 1, 3, 1, 1, 0, 4, 0, 1, 3, 3, 2, 4, 2, 4, 4, 0, 3, 3, 0, 1, 1, 2, 2, 2, 3, 0, 4, 2, 4, 3, 0, 3, 0, 1, 3, 2, 1, 0, 1, 2, 2, 1, 1, 4, 0, 4, 4, 3, 3, 1, 1, 1, 0, 3, 1, 3, 1, 3, 3, 0, 2, 1, 0, 0, 0, 4, 2, 2, 4, 1, 4, 0, 0, 2, 1, 2, 1, 4, 0, 2, 4, 3, 4, 4, 4, 2, 1, 3, 1, 4, 4, 3, 2, 0, 0, 3, 3, 3, 3, 3, 0, 3, 1, 4, 4, 0, 4, 2, 4, 3, 0, 0, 1, 2, 1, 2, 1, 3, 0, 2, 4, 0, 1, 2, 3, 3, 4, 1, 0, 3, 1, 1, 2, 1, 0, 3, 4, 4, 2, 3, 1, 1, 3, 0, 2, 4, 1, 4, 1, 2, 3, 0, 3, 3, 0, 1, 0, 2, 3, 4, 3, 2, 1, 4, 1, 2, 0, 2, 1, 4, 2, 0, 4, 1, 3, 0, 3, 4, 4, 1]\n",
      "[3, 0, 3, 0, 0, 3, 0, 2, 2, 3, 4, 3, 2, 0, 3, 0, 2, 3, 3, 3, 4, 4, 4, 0, 2, 0, 3, 2, 0, 2, 2, 3, 4, 2, 3, 3, 0, 0, 2, 0, 4, 2, 3, 0, 4, 3, 4, 4, 4, 2, 4, 4, 3, 4, 2, 3, 3, 0, 3, 4, 0, 4, 2, 2, 3, 0, 3, 0, 0, 4, 4, 4, 2, 3, 0, 3, 3, 3, 2, 3, 3, 4, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 3, 0, 2, 2, 3, 0, 2, 4, 0, 4, 0, 4, 0, 4, 0, 4, 2, 0, 2, 4, 4, 4, 4, 4, 4, 4, 0, 0, 3, 2, 4, 2, 4, 0, 4, 3, 3, 2, 4, 3, 0, 2, 2, 2, 0, 3, 3, 3, 4, 4, 0, 2, 2, 2, 3, 0, 0, 0, 4, 2, 4, 2, 0, 4, 4, 0, 0, 0, 4, 0, 4, 2, 3, 4, 4, 3, 0, 3, 0, 0, 2, 3, 3, 3, 0, 0, 0, 4, 3, 0, 4, 0, 3, 2, 3, 4, 3, 2, 0, 2, 2, 2, 4, 3, 4, 2, 0, 2, 4, 0, 4, 3, 0, 2, 3, 3, 0, 3, 3, 2, 2, 3, 4, 3, 0, 4, 4, 2, 2, 0, 0, 4, 0, 2, 0, 3, 3, 0, 3, 4, 2, 0, 0, 4, 0, 4, 0, 3, 3, 4, 2, 4, 0, 0, 4, 4, 3, 3, 4, 3, 4, 3, 2, 3, 2, 0, 4, 2, 3, 2, 2, 0, 4, 4, 2, 0, 4, 3, 3, 3, 2, 2, 4, 0, 3, 0, 0, 0, 4, 3, 3, 2, 3, 4, 4, 3, 3, 2, 4, 2, 4, 2, 4, 4, 4, 0, 0, 3, 2, 0, 4, 0, 3, 0, 0, 2, 0, 2, 0, 2, 0, 3, 0, 4, 4, 0, 4, 3, 4, 3, 0, 4, 0, 4, 3, 3, 2, 4, 2, 4, 2, 0, 3, 3, 2, 4, 4, 2, 2, 2, 3, 0, 4, 2, 3, 3, 0, 3, 0, 0, 3, 0, 3, 0, 3, 2, 2, 3, 0, 4, 0, 4, 4, 3, 3, 3, 4, 0, 0, 3, 4, 3, 4, 3, 3, 0, 2, 3, 0, 0, 0, 4, 3, 2, 4, 4, 4, 0, 0, 2, 4, 2, 0, 4, 0, 2, 4, 3, 4, 4, 4, 2, 3, 3, 4, 4, 4, 3, 2, 0, 0, 3, 3, 3, 3, 3, 0, 3, 3, 4, 4, 0, 4, 2, 4, 3, 0, 4, 0, 2, 4, 2, 2, 3, 0, 0, 4, 0, 0, 0, 3, 3, 4, 4, 4, 3, 4, 0, 3, 3, 4, 3, 4, 4, 2, 3, 2, 3, 0, 0, 2, 4, 3, 4, 4, 2, 3, 0, 2, 3, 0, 0, 2, 2, 3, 4, 4, 2, 4, 4, 0, 0, 2, 0, 4, 2, 2, 0, 4, 0, 3, 0, 3, 4, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.88      0.75       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.79      0.81      0.80       100\n",
      "           3       0.73      0.93      0.82       100\n",
      "           4       0.63      0.85      0.73       100\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.56      0.69      0.62       500\n",
      "weighted avg       0.56      0.69      0.62       500\n",
      "\n",
      "Val loss: 1.2097147703170776, Val acc: 0.694\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11400 - Batch 36/1894 - Train loss: 1.083208618937312, Train acc: 0.8184121621621622\n",
      "Iteration 11500 - Batch 136/1894 - Train loss: 1.0557120585963673, Train acc: 0.8492244525547445\n",
      "Iteration 11600 - Batch 236/1894 - Train loss: 1.0548534984327067, Train acc: 0.8502109704641351\n",
      "Iteration 11700 - Batch 336/1894 - Train loss: 1.0515848285012854, Train acc: 0.8535793768545994\n",
      "Iteration 11800 - Batch 436/1894 - Train loss: 1.0500415099840141, Train acc: 0.8546195652173914\n",
      "Iteration 11900 - Batch 536/1894 - Train loss: 1.050563648093346, Train acc: 0.8535265363128491\n",
      "Iteration 12000 - Batch 636/1894 - Train loss: 1.049827020153333, Train acc: 0.8544446624803768\n",
      "Iteration 12100 - Batch 736/1894 - Train loss: 1.0494405979055563, Train acc: 0.8546896200814111\n",
      "Iteration 12200 - Batch 836/1894 - Train loss: 1.0484704876601199, Train acc: 0.8556227598566308\n",
      "Iteration 12300 - Batch 936/1894 - Train loss: 1.048003300785891, Train acc: 0.8560565635005336\n",
      "Iteration 12400 - Batch 1036/1894 - Train loss: 1.0477126630430855, Train acc: 0.8561656219864995\n",
      "Iteration 12500 - Batch 1136/1894 - Train loss: 1.048132950104216, Train acc: 0.8556783201407212\n",
      "Iteration 12600 - Batch 1236/1894 - Train loss: 1.0482925372250926, Train acc: 0.8555224333063864\n",
      "Iteration 12700 - Batch 1336/1894 - Train loss: 1.0484305843097912, Train acc: 0.8554833582647718\n",
      "Iteration 12800 - Batch 1436/1894 - Train loss: 1.0482980004183187, Train acc: 0.8556236951983298\n",
      "Iteration 12900 - Batch 1536/1894 - Train loss: 1.048288244315379, Train acc: 0.8556237800910865\n",
      "Iteration 13000 - Batch 1636/1894 - Train loss: 1.0488574727687008, Train acc: 0.8549748014660965\n",
      "Iteration 13100 - Batch 1736/1894 - Train loss: 1.0484526174193356, Train acc: 0.8554080310880829\n",
      "Iteration 13200 - Batch 1836/1894 - Train loss: 1.048414188587737, Train acc: 0.8555048992923244\n",
      "[0, 3, 4, 3, 4, 2, 0, 2, 4, 4, 3, 0, 2, 1, 2, 0, 0, 1, 2, 2, 4, 0, 2, 2, 1, 0, 3, 2, 2, 1, 4, 4, 3, 4, 1, 4, 4, 0, 3, 4, 0, 2, 3, 4, 4, 3, 3, 4, 2, 3, 3, 4, 4, 1, 4, 0, 0, 2, 2, 0, 0, 1, 3, 3, 1, 3, 3, 4, 3, 4, 1, 2, 0, 2, 2, 3, 3, 0, 3, 0, 1, 0, 1, 3, 4, 3, 4, 0, 3, 0, 4, 0, 0, 0, 0, 1, 4, 1, 0, 1, 1, 3, 1, 0, 3, 3, 2, 1, 0, 3, 2, 0, 0, 2, 1, 2, 2, 4, 1, 4, 4, 3, 3, 1, 3, 4, 4, 3, 0, 1, 4, 4, 1, 2, 4, 3, 1, 3, 2, 3, 4, 4, 0, 4, 3, 1, 4, 0, 3, 1, 2, 0, 2, 2, 2, 4, 1, 1, 4, 2, 1, 4, 2, 1, 2, 4, 0, 4, 4, 4, 3, 1, 2, 2, 2, 4, 4, 1, 4, 1, 2, 4, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1, 3, 1, 3, 0, 4, 3, 3, 4, 2, 0, 2, 1, 0, 0, 1, 3, 1, 4, 0, 0, 1, 1, 1, 3, 1, 1, 0, 3, 0, 3, 4, 1, 1, 2, 2, 3, 1, 3, 2, 4, 0, 2, 3, 4, 3, 2, 2, 1, 4, 0, 1, 2, 0, 4, 0, 3, 2, 2, 1, 2, 2, 3, 4, 1, 1, 1, 0, 1, 4, 2, 3, 2, 1, 2, 4, 3, 0, 4, 0, 2, 1, 4, 2, 4, 3, 0, 4, 4, 4, 4, 2, 3, 4, 4, 0, 2, 2, 3, 3, 1, 3, 3, 3, 3, 4, 4, 3, 2, 4, 2, 0, 0, 2, 2, 3, 3, 1, 1, 2, 0, 0, 3, 3, 3, 0, 3, 2, 3, 4, 4, 4, 1, 4, 3, 4, 4, 2, 3, 1, 4, 3, 4, 1, 0, 0, 0, 0, 1, 1, 4, 4, 0, 1, 1, 0, 1, 0, 1, 2, 4, 0, 0, 3, 2, 1, 1, 2, 3, 2, 3, 2, 4, 1, 3, 4, 1, 1, 2, 2, 1, 0, 2, 2, 0, 3, 2, 3, 2, 2, 0, 2, 1, 4, 1, 0, 0, 0, 2, 0, 2, 4, 4, 2, 0, 4, 3, 2, 4, 3, 3, 3, 4, 3, 3, 1, 1, 2, 2, 2, 0, 1, 2, 3, 0, 0, 2, 3, 2, 2, 0, 3, 1, 1, 3, 4, 0, 1, 1, 2, 1, 4, 1, 0, 1, 0, 3, 4, 4, 3, 2, 3, 3, 3, 1, 1, 0, 2, 2, 0, 3, 1, 3, 1, 4, 2, 0, 0, 0, 4, 2, 0, 4, 3, 1, 3, 4, 0, 4, 2, 0, 3, 0, 1, 3, 4, 0, 1, 1, 2, 3, 1, 1, 1, 2, 0, 0, 4, 2, 4, 0, 1, 0, 2, 0, 1, 2, 1, 3]\n",
      "[0, 3, 4, 3, 4, 2, 0, 2, 4, 4, 4, 0, 2, 4, 3, 0, 0, 4, 2, 2, 4, 0, 2, 2, 4, 0, 3, 0, 2, 4, 4, 4, 3, 4, 4, 0, 4, 0, 3, 4, 0, 2, 3, 4, 4, 3, 3, 4, 2, 3, 4, 4, 4, 0, 4, 0, 0, 2, 2, 4, 0, 0, 3, 3, 2, 4, 3, 4, 3, 4, 4, 2, 0, 0, 0, 3, 3, 0, 3, 0, 4, 0, 4, 3, 4, 3, 4, 0, 3, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4, 3, 4, 4, 4, 3, 2, 0, 0, 3, 2, 2, 0, 2, 4, 3, 2, 4, 4, 4, 4, 3, 3, 0, 3, 3, 4, 0, 0, 0, 4, 4, 4, 0, 4, 3, 4, 3, 2, 3, 2, 4, 2, 2, 3, 4, 4, 0, 3, 4, 0, 0, 2, 2, 2, 4, 4, 4, 4, 2, 0, 4, 2, 4, 2, 4, 0, 4, 4, 4, 3, 0, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 4, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 4, 0, 4, 3, 3, 4, 2, 0, 2, 3, 2, 0, 3, 3, 4, 4, 0, 0, 0, 3, 4, 3, 0, 3, 4, 3, 0, 3, 2, 4, 4, 2, 2, 3, 0, 3, 2, 4, 0, 2, 3, 3, 3, 2, 2, 4, 0, 0, 2, 2, 0, 4, 0, 3, 2, 2, 4, 2, 2, 4, 4, 4, 3, 3, 0, 4, 4, 2, 3, 2, 4, 2, 4, 4, 0, 4, 0, 2, 3, 4, 0, 4, 3, 0, 4, 4, 4, 4, 2, 3, 4, 4, 0, 0, 2, 3, 3, 2, 3, 3, 3, 3, 4, 4, 3, 0, 4, 2, 0, 0, 0, 2, 3, 3, 0, 2, 2, 0, 0, 3, 3, 3, 0, 3, 2, 3, 4, 4, 2, 4, 4, 3, 2, 4, 2, 3, 0, 4, 3, 4, 3, 0, 0, 0, 0, 0, 4, 4, 4, 0, 3, 4, 0, 3, 0, 4, 2, 4, 0, 0, 3, 0, 2, 4, 3, 4, 2, 3, 2, 4, 0, 3, 4, 3, 0, 2, 2, 4, 0, 2, 0, 0, 3, 2, 3, 2, 2, 0, 2, 4, 4, 4, 0, 4, 0, 0, 2, 2, 4, 4, 2, 0, 4, 3, 2, 4, 3, 4, 3, 4, 2, 3, 0, 3, 2, 2, 2, 0, 4, 0, 3, 0, 0, 2, 4, 2, 2, 0, 3, 4, 4, 4, 4, 0, 4, 2, 2, 4, 4, 4, 0, 4, 0, 3, 4, 4, 3, 2, 3, 3, 4, 4, 4, 0, 2, 2, 0, 3, 4, 3, 4, 4, 2, 0, 0, 0, 4, 2, 0, 4, 3, 3, 3, 4, 0, 4, 0, 0, 3, 0, 4, 3, 4, 0, 0, 3, 2, 3, 2, 0, 3, 2, 0, 0, 3, 2, 4, 0, 4, 0, 2, 0, 0, 2, 0, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.82      0.82      0.82       100\n",
      "           3       0.79      0.86      0.82       100\n",
      "           4       0.57      0.90      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.63       500\n",
      "weighted avg       0.57      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.201527200639248, Val acc: 0.7\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13300 - Batch 42/1894 - Train loss: 1.0452279531678488, Train acc: 0.8604651162790697\n",
      "Iteration 13400 - Batch 142/1894 - Train loss: 1.0504279974457267, Train acc: 0.854458041958042\n",
      "Iteration 13500 - Batch 242/1894 - Train loss: 1.047096168308101, Train acc: 0.8582818930041153\n",
      "Iteration 13600 - Batch 342/1894 - Train loss: 1.0468876003871506, Train acc: 0.857871720116618\n",
      "Iteration 13700 - Batch 442/1894 - Train loss: 1.0442869450653112, Train acc: 0.860186230248307\n",
      "Iteration 13800 - Batch 542/1894 - Train loss: 1.0445582508821294, Train acc: 0.8598641804788214\n",
      "Iteration 13900 - Batch 642/1894 - Train loss: 1.0430780154179267, Train acc: 0.8615377138413686\n",
      "Iteration 14000 - Batch 742/1894 - Train loss: 1.0446527846568687, Train acc: 0.859942799461642\n",
      "Iteration 14100 - Batch 842/1894 - Train loss: 1.0437408969919877, Train acc: 0.8607280545670225\n",
      "Iteration 14200 - Batch 942/1894 - Train loss: 1.0441903992776274, Train acc: 0.8603194591728526\n",
      "Iteration 14300 - Batch 1042/1894 - Train loss: 1.0439117295401437, Train acc: 0.860558485139022\n",
      "Iteration 14400 - Batch 1142/1894 - Train loss: 1.0434869106986078, Train acc: 0.8609470691163604\n",
      "Iteration 14500 - Batch 1242/1894 - Train loss: 1.0433826714106749, Train acc: 0.8609462992759453\n",
      "Iteration 14600 - Batch 1342/1894 - Train loss: 1.0433940007805558, Train acc: 0.8608060312732688\n",
      "Iteration 14700 - Batch 1442/1894 - Train loss: 1.044196924482545, Train acc: 0.8600355162855163\n",
      "Iteration 14800 - Batch 1542/1894 - Train loss: 1.0444180936451786, Train acc: 0.8598104342190538\n",
      "Iteration 14900 - Batch 1642/1894 - Train loss: 1.0447387425041896, Train acc: 0.859441570298235\n",
      "Iteration 15000 - Batch 1742/1894 - Train loss: 1.0447771020545675, Train acc: 0.8594198221457258\n",
      "Iteration 15100 - Batch 1842/1894 - Train loss: 1.0443374434050436, Train acc: 0.8599260716223549\n",
      "[0, 1, 1, 4, 4, 3, 1, 3, 2, 0, 2, 2, 2, 1, 0, 2, 4, 0, 0, 0, 0, 1, 2, 4, 4, 1, 0, 3, 0, 2, 2, 3, 3, 0, 0, 3, 4, 2, 2, 1, 2, 4, 2, 1, 2, 1, 0, 2, 3, 1, 1, 2, 0, 4, 1, 0, 4, 0, 2, 2, 1, 3, 1, 0, 1, 3, 2, 3, 3, 3, 1, 1, 2, 3, 0, 2, 2, 3, 1, 1, 3, 3, 4, 4, 4, 1, 2, 0, 2, 2, 2, 0, 3, 2, 2, 2, 1, 2, 3, 4, 0, 1, 1, 1, 1, 0, 4, 0, 1, 3, 2, 4, 2, 2, 3, 4, 0, 3, 4, 2, 0, 0, 1, 2, 0, 0, 3, 4, 2, 1, 3, 4, 0, 0, 4, 0, 1, 0, 0, 0, 1, 3, 1, 4, 0, 3, 1, 2, 4, 4, 1, 2, 4, 2, 0, 4, 4, 4, 1, 0, 0, 3, 2, 1, 2, 2, 3, 1, 4, 0, 1, 0, 3, 1, 4, 1, 4, 1, 4, 2, 1, 2, 4, 1, 1, 3, 0, 4, 0, 1, 2, 0, 3, 2, 4, 3, 2, 3, 3, 1, 0, 0, 1, 3, 2, 4, 3, 1, 4, 4, 3, 1, 4, 0, 1, 1, 2, 3, 4, 1, 4, 4, 1, 2, 0, 4, 3, 4, 3, 2, 2, 1, 1, 1, 1, 0, 4, 3, 3, 1, 3, 3, 2, 0, 2, 4, 2, 1, 0, 2, 3, 2, 1, 3, 2, 0, 2, 1, 1, 1, 2, 2, 1, 0, 3, 0, 0, 0, 3, 2, 0, 3, 0, 1, 1, 1, 3, 3, 2, 2, 3, 1, 0, 1, 3, 3, 0, 0, 0, 4, 0, 2, 3, 4, 1, 3, 1, 3, 3, 4, 0, 4, 1, 3, 4, 0, 4, 3, 1, 3, 4, 4, 2, 3, 3, 4, 1, 4, 0, 4, 1, 4, 3, 2, 4, 2, 3, 3, 2, 4, 3, 1, 3, 1, 0, 2, 3, 0, 3, 2, 3, 2, 0, 2, 3, 1, 1, 4, 4, 3, 4, 4, 4, 3, 2, 0, 2, 1, 0, 4, 4, 0, 3, 4, 0, 2, 3, 2, 4, 3, 3, 4, 3, 3, 2, 3, 4, 3, 4, 2, 3, 2, 2, 2, 4, 1, 1, 3, 3, 0, 0, 4, 3, 0, 4, 3, 2, 2, 1, 2, 1, 1, 4, 4, 3, 1, 0, 2, 3, 0, 4, 1, 0, 2, 3, 3, 1, 0, 3, 1, 4, 1, 4, 0, 4, 4, 4, 4, 2, 4, 1, 1, 2, 2, 1, 0, 0, 0, 0, 1, 4, 0, 4, 1, 0, 0, 3, 0, 4, 2, 3, 4, 0, 4, 4, 4, 4, 2, 0, 0, 0, 0, 0, 3, 4, 4, 4, 3, 3, 4, 0, 2, 0, 3, 2, 2, 1, 0, 4, 2, 0, 3, 1, 4, 1, 2, 3, 4, 0, 1, 0, 0, 4, 1, 2, 2, 2, 1, 2, 3]\n",
      "[0, 4, 4, 2, 4, 3, 4, 4, 2, 4, 2, 0, 2, 0, 0, 2, 4, 0, 0, 0, 0, 4, 0, 4, 4, 3, 0, 3, 0, 0, 2, 3, 3, 0, 0, 3, 4, 2, 2, 4, 2, 4, 2, 4, 0, 4, 0, 2, 3, 4, 0, 2, 0, 4, 0, 0, 4, 0, 2, 2, 4, 3, 3, 0, 4, 3, 2, 3, 3, 4, 0, 0, 2, 3, 0, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 4, 2, 0, 2, 0, 2, 0, 4, 2, 2, 2, 4, 2, 4, 4, 0, 4, 4, 0, 2, 0, 4, 0, 0, 3, 2, 4, 2, 0, 3, 4, 0, 3, 4, 2, 0, 0, 4, 2, 0, 0, 3, 4, 2, 0, 0, 4, 0, 0, 4, 4, 4, 0, 0, 0, 2, 3, 4, 4, 0, 4, 4, 4, 4, 4, 3, 2, 4, 2, 0, 4, 4, 4, 3, 0, 0, 4, 2, 4, 2, 3, 3, 4, 4, 0, 4, 0, 3, 4, 4, 4, 4, 0, 4, 2, 0, 2, 4, 0, 4, 3, 0, 4, 0, 2, 2, 2, 3, 2, 3, 3, 0, 3, 4, 4, 0, 0, 4, 3, 3, 4, 3, 4, 4, 4, 3, 4, 4, 0, 2, 2, 2, 3, 4, 4, 4, 4, 4, 0, 0, 4, 3, 2, 4, 0, 3, 3, 3, 4, 4, 0, 4, 3, 3, 3, 3, 3, 0, 2, 0, 4, 2, 0, 0, 2, 3, 2, 4, 4, 2, 0, 2, 3, 4, 0, 2, 2, 4, 0, 3, 0, 4, 0, 3, 2, 0, 3, 2, 4, 4, 4, 4, 3, 2, 0, 3, 4, 0, 3, 3, 3, 0, 0, 2, 4, 0, 2, 3, 4, 4, 3, 4, 3, 3, 4, 0, 0, 4, 3, 3, 0, 4, 3, 3, 3, 4, 4, 2, 3, 3, 4, 3, 3, 0, 4, 0, 3, 3, 2, 4, 2, 3, 3, 2, 4, 3, 4, 3, 4, 0, 2, 3, 0, 3, 2, 3, 0, 0, 0, 3, 4, 3, 4, 4, 3, 4, 2, 4, 3, 2, 0, 2, 4, 0, 4, 4, 0, 3, 4, 4, 0, 3, 2, 4, 3, 2, 3, 3, 3, 2, 3, 4, 3, 4, 2, 3, 2, 0, 2, 4, 0, 0, 3, 3, 0, 0, 4, 3, 0, 4, 3, 2, 2, 4, 2, 0, 0, 4, 4, 3, 4, 0, 2, 3, 0, 3, 3, 0, 2, 3, 3, 4, 0, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, 2, 4, 0, 4, 2, 2, 0, 0, 4, 0, 0, 4, 2, 0, 4, 3, 0, 0, 3, 0, 4, 0, 3, 0, 0, 4, 4, 4, 4, 2, 0, 0, 0, 0, 0, 4, 4, 4, 4, 3, 3, 4, 0, 0, 0, 3, 2, 2, 4, 0, 4, 2, 0, 3, 3, 4, 0, 2, 3, 4, 0, 0, 0, 0, 4, 3, 2, 2, 2, 4, 2, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.90      0.77       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.78      0.81       100\n",
      "           3       0.75      0.86      0.80       100\n",
      "           4       0.55      0.88      0.67       100\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.57      0.68      0.61       500\n",
      "weighted avg       0.57      0.68      0.61       500\n",
      "\n",
      "Val loss: 1.2130211889743805, Val acc: 0.684\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15200 - Batch 48/1894 - Train loss: 1.0340717982272714, Train acc: 0.8698979591836735\n",
      "Iteration 15300 - Batch 148/1894 - Train loss: 1.041613875619517, Train acc: 0.8617869127516778\n",
      "Iteration 15400 - Batch 248/1894 - Train loss: 1.0377569540916198, Train acc: 0.8653363453815262\n",
      "Iteration 15500 - Batch 348/1894 - Train loss: 1.0408119513175549, Train acc: 0.8626432664756447\n",
      "Iteration 15600 - Batch 448/1894 - Train loss: 1.0448839238332481, Train acc: 0.8583658129175946\n",
      "Iteration 15700 - Batch 548/1894 - Train loss: 1.0444263645425738, Train acc: 0.8591188524590164\n",
      "Iteration 15800 - Batch 648/1894 - Train loss: 1.045145123048997, Train acc: 0.8582434514637904\n",
      "Iteration 15900 - Batch 748/1894 - Train loss: 1.0436984213872331, Train acc: 0.8598548064085447\n",
      "Iteration 16000 - Batch 848/1894 - Train loss: 1.0421811475630223, Train acc: 0.8614914605418139\n",
      "Iteration 16100 - Batch 948/1894 - Train loss: 1.0421012391908402, Train acc: 0.8615648050579557\n",
      "Iteration 16200 - Batch 1048/1894 - Train loss: 1.042884263001361, Train acc: 0.8607304575786463\n",
      "Iteration 16300 - Batch 1148/1894 - Train loss: 1.0424583888344396, Train acc: 0.8612380330722367\n",
      "Iteration 16400 - Batch 1248/1894 - Train loss: 1.042105309432559, Train acc: 0.8614391513210569\n",
      "Iteration 16500 - Batch 1348/1894 - Train loss: 1.0411964812218657, Train acc: 0.8623980726464048\n",
      "Iteration 16600 - Batch 1448/1894 - Train loss: 1.0411448190342236, Train acc: 0.8625345065562456\n",
      "Iteration 16700 - Batch 1548/1894 - Train loss: 1.0417712510517139, Train acc: 0.8618867010974822\n",
      "Iteration 16800 - Batch 1648/1894 - Train loss: 1.0422669563819742, Train acc: 0.8613553668890237\n",
      "Iteration 16900 - Batch 1748/1894 - Train loss: 1.0430394992479397, Train acc: 0.8605989136649514\n",
      "Iteration 17000 - Batch 1848/1894 - Train loss: 1.043516537123206, Train acc: 0.8601608977825852\n",
      "[0, 0, 3, 2, 0, 4, 3, 3, 3, 4, 4, 3, 0, 0, 1, 0, 4, 1, 4, 2, 0, 0, 3, 3, 2, 1, 4, 3, 4, 4, 0, 0, 0, 3, 1, 2, 0, 4, 1, 2, 1, 3, 1, 1, 1, 2, 3, 3, 1, 3, 4, 0, 2, 2, 2, 4, 1, 1, 0, 3, 1, 3, 2, 3, 2, 0, 0, 3, 3, 0, 2, 2, 3, 2, 3, 1, 2, 4, 3, 3, 4, 2, 0, 1, 3, 0, 1, 1, 0, 4, 4, 0, 0, 2, 1, 4, 4, 0, 1, 1, 0, 4, 1, 0, 3, 3, 2, 2, 1, 2, 1, 2, 3, 2, 1, 0, 4, 1, 1, 1, 1, 0, 4, 1, 1, 0, 3, 3, 2, 1, 3, 2, 2, 3, 1, 4, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 1, 4, 0, 0, 0, 0, 4, 1, 2, 1, 0, 4, 0, 1, 2, 2, 2, 4, 0, 4, 0, 0, 3, 3, 2, 3, 0, 0, 3, 1, 0, 4, 3, 4, 0, 1, 0, 1, 3, 0, 1, 3, 0, 1, 3, 1, 4, 4, 4, 2, 4, 2, 0, 2, 3, 0, 2, 3, 3, 3, 1, 2, 3, 2, 0, 1, 0, 3, 4, 4, 2, 2, 3, 4, 4, 4, 0, 2, 4, 2, 1, 4, 4, 4, 4, 4, 2, 1, 0, 0, 1, 3, 4, 0, 1, 2, 1, 2, 2, 3, 4, 1, 3, 3, 2, 3, 4, 4, 4, 1, 0, 0, 2, 4, 0, 1, 4, 1, 2, 2, 4, 4, 1, 0, 2, 2, 3, 4, 2, 3, 4, 2, 1, 2, 0, 0, 3, 4, 4, 0, 2, 0, 3, 2, 2, 4, 1, 0, 3, 1, 0, 1, 0, 4, 0, 3, 3, 2, 2, 4, 1, 4, 0, 4, 4, 1, 1, 3, 1, 4, 1, 2, 3, 1, 3, 1, 2, 2, 1, 2, 0, 3, 3, 4, 1, 4, 1, 4, 2, 4, 2, 0, 3, 1, 1, 2, 2, 2, 4, 2, 4, 3, 0, 2, 4, 4, 0, 1, 0, 3, 3, 3, 3, 4, 2, 2, 1, 2, 0, 4, 0, 2, 3, 3, 2, 0, 4, 0, 3, 1, 0, 2, 3, 3, 0, 1, 3, 3, 4, 1, 2, 4, 0, 3, 2, 1, 2, 2, 2, 2, 0, 1, 3, 3, 4, 1, 0, 0, 1, 0, 0, 1, 1, 1, 2, 4, 3, 4, 4, 0, 0, 4, 1, 0, 3, 1, 1, 3, 2, 1, 1, 1, 2, 3, 0, 4, 3, 2, 4, 2, 4, 3, 4, 2, 1, 1, 4, 4, 0, 4, 4, 4, 0, 1, 4, 0, 4, 1, 4, 2, 0, 3, 2, 3, 4, 3, 0, 2, 4, 0, 2, 0, 3, 3, 4, 2, 3, 3, 1, 4, 0, 2, 2, 3, 3, 1, 4, 3, 2, 0, 1, 3, 0, 4, 2, 1, 0, 0, 4, 3, 2, 0, 3, 3]\n",
      "[0, 0, 3, 2, 0, 4, 2, 3, 4, 4, 3, 3, 0, 0, 4, 0, 4, 3, 4, 2, 0, 4, 3, 3, 0, 2, 4, 3, 4, 4, 0, 0, 0, 3, 0, 2, 0, 4, 4, 2, 4, 3, 3, 4, 3, 2, 3, 3, 3, 3, 4, 0, 0, 3, 2, 4, 4, 4, 0, 3, 3, 3, 2, 3, 4, 4, 0, 3, 3, 0, 0, 2, 3, 2, 3, 0, 2, 4, 3, 3, 4, 2, 0, 0, 3, 0, 4, 4, 4, 4, 4, 0, 0, 0, 3, 4, 4, 0, 4, 4, 0, 4, 3, 0, 3, 3, 2, 2, 4, 2, 3, 2, 3, 0, 4, 0, 3, 0, 3, 0, 4, 0, 4, 3, 4, 4, 3, 3, 2, 4, 3, 0, 2, 3, 4, 4, 4, 3, 0, 2, 0, 3, 4, 4, 2, 2, 3, 3, 0, 0, 0, 0, 4, 4, 3, 3, 2, 4, 0, 3, 2, 0, 2, 4, 0, 4, 0, 0, 3, 3, 2, 3, 0, 0, 3, 3, 0, 4, 3, 4, 0, 3, 0, 4, 3, 0, 2, 3, 0, 4, 3, 4, 4, 4, 4, 0, 4, 0, 0, 2, 3, 4, 2, 3, 3, 3, 3, 2, 3, 2, 0, 3, 0, 3, 4, 4, 0, 2, 3, 4, 4, 4, 0, 2, 3, 2, 4, 4, 0, 4, 4, 4, 2, 4, 0, 0, 0, 3, 3, 0, 3, 0, 4, 2, 2, 3, 4, 2, 3, 3, 2, 3, 3, 4, 4, 0, 0, 0, 2, 2, 0, 3, 4, 4, 2, 2, 4, 0, 4, 0, 2, 2, 3, 4, 0, 3, 4, 2, 3, 2, 0, 0, 3, 4, 4, 0, 2, 0, 3, 2, 2, 4, 0, 0, 3, 4, 0, 4, 0, 4, 0, 3, 3, 2, 0, 4, 4, 4, 0, 0, 4, 4, 4, 3, 3, 4, 4, 2, 3, 4, 3, 4, 0, 2, 3, 2, 0, 3, 3, 4, 4, 4, 4, 4, 2, 3, 2, 0, 1, 3, 0, 2, 2, 2, 4, 2, 4, 3, 0, 2, 4, 4, 0, 4, 0, 3, 3, 3, 4, 3, 3, 2, 3, 2, 0, 3, 0, 2, 3, 3, 2, 0, 4, 0, 0, 4, 0, 2, 3, 3, 0, 4, 3, 3, 4, 4, 2, 3, 0, 3, 2, 3, 0, 2, 3, 2, 0, 3, 3, 3, 4, 0, 0, 0, 3, 0, 0, 3, 3, 0, 2, 4, 3, 4, 4, 0, 0, 4, 3, 0, 3, 4, 2, 3, 2, 4, 4, 4, 2, 3, 0, 4, 3, 2, 4, 2, 4, 3, 2, 2, 3, 0, 4, 4, 0, 4, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 3, 2, 4, 4, 3, 0, 2, 4, 0, 2, 0, 3, 3, 4, 2, 3, 3, 3, 4, 0, 2, 2, 3, 3, 4, 4, 3, 2, 0, 4, 3, 0, 4, 2, 3, 0, 0, 4, 3, 0, 0, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.94      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.78      0.84       100\n",
      "           3       0.67      0.94      0.78       100\n",
      "           4       0.59      0.85      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2001908197999, Val acc: 0.702\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17100 - Batch 54/1894 - Train loss: 1.0543626221743496, Train acc: 0.8471590909090909\n",
      "Iteration 17200 - Batch 154/1894 - Train loss: 1.0439599060243177, Train acc: 0.8582661290322581\n",
      "Iteration 17300 - Batch 254/1894 - Train loss: 1.037359790241017, Train acc: 0.865686274509804\n",
      "Iteration 17400 - Batch 354/1894 - Train loss: 1.0386207212864513, Train acc: 0.8650528169014085\n",
      "Iteration 17500 - Batch 454/1894 - Train loss: 1.039834199501918, Train acc: 0.864217032967033\n",
      "Iteration 17600 - Batch 554/1894 - Train loss: 1.0394334622331567, Train acc: 0.8648085585585585\n",
      "Iteration 17700 - Batch 654/1894 - Train loss: 1.0395332463825022, Train acc: 0.8646469465648855\n",
      "Iteration 17800 - Batch 754/1894 - Train loss: 1.0403620213862286, Train acc: 0.8639072847682119\n",
      "Iteration 17900 - Batch 854/1894 - Train loss: 1.0405420132547791, Train acc: 0.8635233918128655\n",
      "Iteration 18000 - Batch 954/1894 - Train loss: 1.040071294445018, Train acc: 0.8639397905759162\n",
      "Iteration 18100 - Batch 1054/1894 - Train loss: 1.040471638435436, Train acc: 0.8635367298578199\n",
      "Iteration 18200 - Batch 1154/1894 - Train loss: 1.0410655841166838, Train acc: 0.8628787878787879\n",
      "Iteration 18300 - Batch 1254/1894 - Train loss: 1.04072509082665, Train acc: 0.8631723107569721\n",
      "Iteration 18400 - Batch 1354/1894 - Train loss: 1.0411651437133, Train acc: 0.8627767527675276\n",
      "Iteration 18500 - Batch 1454/1894 - Train loss: 1.0415791102701037, Train acc: 0.8624570446735396\n",
      "Iteration 18600 - Batch 1554/1894 - Train loss: 1.0410355112176999, Train acc: 0.8629019292604502\n",
      "Iteration 18700 - Batch 1654/1894 - Train loss: 1.0410646295259367, Train acc: 0.8628965256797583\n",
      "Iteration 18800 - Batch 1754/1894 - Train loss: 1.040450815257863, Train acc: 0.8634793447293447\n",
      "Iteration 18900 - Batch 1854/1894 - Train loss: 1.040801300706889, Train acc: 0.8631064690026954\n",
      "[4, 0, 4, 0, 2, 4, 2, 0, 2, 1, 4, 0, 1, 2, 4, 1, 1, 1, 3, 1, 3, 2, 4, 3, 3, 3, 3, 3, 3, 3, 4, 1, 2, 1, 1, 1, 3, 2, 2, 0, 2, 4, 1, 4, 2, 4, 2, 4, 2, 1, 1, 0, 3, 3, 0, 4, 4, 2, 3, 4, 0, 4, 0, 2, 3, 2, 4, 2, 4, 1, 2, 0, 0, 2, 2, 1, 0, 3, 4, 0, 4, 4, 0, 2, 2, 2, 2, 4, 2, 0, 0, 0, 0, 0, 4, 1, 1, 4, 2, 2, 0, 2, 0, 1, 1, 4, 3, 0, 1, 2, 0, 3, 4, 1, 0, 1, 2, 1, 4, 2, 1, 0, 1, 3, 4, 3, 1, 3, 3, 4, 4, 4, 4, 1, 4, 2, 1, 3, 4, 3, 4, 0, 0, 4, 1, 4, 4, 1, 2, 1, 2, 1, 0, 4, 3, 0, 4, 3, 3, 3, 1, 3, 0, 4, 1, 3, 4, 1, 0, 3, 4, 0, 0, 0, 3, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 1, 1, 2, 0, 3, 0, 2, 3, 1, 1, 4, 1, 3, 3, 1, 1, 0, 1, 2, 0, 4, 4, 3, 0, 4, 4, 1, 2, 0, 0, 0, 4, 2, 1, 3, 0, 3, 2, 1, 0, 4, 2, 1, 1, 2, 3, 4, 4, 4, 3, 2, 1, 3, 3, 3, 4, 3, 3, 4, 4, 1, 0, 4, 3, 4, 3, 4, 2, 3, 0, 0, 0, 3, 4, 4, 2, 2, 3, 0, 4, 2, 1, 0, 0, 1, 1, 0, 3, 4, 0, 4, 0, 2, 4, 0, 0, 2, 2, 0, 4, 2, 2, 1, 2, 0, 4, 0, 0, 1, 3, 2, 0, 0, 0, 1, 3, 4, 3, 0, 0, 2, 0, 3, 1, 2, 2, 1, 2, 2, 3, 3, 0, 4, 2, 2, 1, 3, 2, 4, 1, 4, 1, 1, 2, 3, 3, 0, 4, 4, 0, 2, 4, 4, 3, 2, 1, 1, 3, 3, 3, 1, 1, 2, 3, 2, 0, 1, 3, 4, 0, 2, 3, 3, 3, 4, 3, 2, 0, 2, 0, 1, 3, 0, 1, 1, 1, 1, 3, 0, 2, 3, 2, 3, 0, 3, 1, 2, 0, 1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 1, 4, 1, 0, 1, 3, 1, 2, 0, 3, 4, 4, 2, 1, 4, 3, 3, 3, 2, 4, 3, 3, 4, 2, 0, 3, 3, 4, 4, 1, 0, 1, 2, 4, 3, 4, 1, 4, 1, 1, 0, 1, 3, 4, 2, 3, 2, 4, 1, 2, 4, 1, 3, 3, 2, 2, 4, 4, 4, 3, 4, 1, 0, 2, 4, 1, 1, 2, 0, 1, 2, 3, 0, 2, 3, 0, 4, 2, 0, 2, 3, 4, 2, 0, 2, 0, 2, 3, 3, 2, 0, 4, 0, 0, 2, 2, 0, 3, 3, 4, 1, 0, 1, 3, 4]\n",
      "[4, 4, 4, 0, 2, 4, 2, 0, 2, 3, 4, 0, 4, 2, 3, 3, 0, 3, 3, 4, 3, 2, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 0, 3, 3, 0, 3, 2, 2, 0, 2, 4, 0, 4, 2, 4, 3, 4, 2, 3, 4, 0, 3, 3, 0, 4, 4, 2, 3, 4, 0, 4, 0, 2, 4, 2, 4, 2, 4, 3, 2, 0, 0, 2, 2, 0, 0, 3, 4, 0, 4, 4, 0, 2, 0, 2, 0, 4, 2, 2, 0, 0, 0, 0, 4, 4, 4, 4, 2, 3, 0, 2, 0, 2, 4, 4, 3, 2, 3, 2, 0, 3, 4, 4, 0, 0, 3, 4, 0, 2, 4, 0, 4, 3, 4, 3, 0, 4, 3, 4, 4, 4, 3, 3, 4, 2, 4, 3, 4, 3, 4, 0, 0, 4, 3, 4, 4, 3, 2, 3, 2, 4, 0, 4, 3, 0, 3, 3, 3, 3, 4, 0, 0, 4, 3, 3, 4, 3, 0, 3, 4, 2, 0, 0, 3, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 4, 4, 0, 0, 3, 0, 2, 3, 4, 4, 4, 4, 3, 3, 3, 4, 0, 4, 0, 0, 4, 4, 3, 0, 4, 4, 4, 0, 0, 0, 0, 4, 2, 3, 3, 4, 3, 2, 4, 0, 4, 2, 2, 4, 0, 3, 4, 4, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3, 0, 4, 3, 3, 3, 3, 2, 3, 0, 4, 0, 3, 4, 4, 2, 2, 3, 0, 2, 2, 4, 4, 0, 2, 3, 2, 3, 4, 0, 0, 0, 2, 4, 0, 0, 2, 2, 0, 4, 2, 2, 4, 2, 0, 4, 0, 0, 3, 4, 2, 0, 0, 0, 0, 3, 4, 3, 0, 0, 2, 0, 3, 4, 2, 0, 4, 0, 0, 3, 3, 0, 4, 2, 2, 0, 3, 2, 4, 3, 3, 4, 3, 2, 3, 3, 0, 4, 4, 4, 2, 4, 0, 3, 2, 0, 2, 3, 3, 4, 4, 4, 2, 3, 2, 0, 0, 3, 4, 0, 2, 3, 3, 3, 4, 3, 2, 0, 2, 2, 4, 3, 0, 4, 0, 4, 4, 3, 0, 2, 3, 2, 3, 0, 3, 4, 2, 0, 4, 3, 3, 2, 3, 3, 3, 4, 0, 3, 4, 4, 4, 0, 0, 3, 4, 0, 0, 3, 4, 4, 2, 3, 4, 3, 3, 3, 2, 4, 3, 3, 4, 0, 0, 3, 3, 4, 4, 4, 0, 4, 2, 4, 3, 4, 4, 4, 4, 4, 0, 0, 3, 4, 2, 3, 0, 4, 4, 2, 4, 0, 3, 3, 2, 0, 3, 4, 3, 3, 4, 2, 0, 2, 4, 0, 4, 2, 0, 4, 2, 3, 0, 2, 3, 0, 4, 2, 0, 2, 3, 4, 2, 0, 2, 0, 2, 3, 3, 2, 0, 4, 4, 0, 2, 2, 0, 3, 3, 4, 3, 0, 0, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.82      0.85       100\n",
      "           3       0.71      0.95      0.81       100\n",
      "           4       0.59      0.88      0.71       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.192448876798153, Val acc: 0.708\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19000 - Batch 60/1894 - Train loss: 1.0398740875916404, Train acc: 0.8642418032786885\n",
      "Iteration 19100 - Batch 160/1894 - Train loss: 1.0433659120376066, Train acc: 0.8604425465838509\n",
      "Iteration 19200 - Batch 260/1894 - Train loss: 1.0422437474188677, Train acc: 0.8609913793103449\n",
      "Iteration 19300 - Batch 360/1894 - Train loss: 1.037429027775318, Train acc: 0.8661703601108033\n",
      "Iteration 19400 - Batch 460/1894 - Train loss: 1.0371162509969931, Train acc: 0.8667977223427332\n",
      "Iteration 19500 - Batch 560/1894 - Train loss: 1.03777083717353, Train acc: 0.8664772727272727\n",
      "Iteration 19600 - Batch 660/1894 - Train loss: 1.0374090257643211, Train acc: 0.866821104387292\n",
      "Iteration 19700 - Batch 760/1894 - Train loss: 1.0364989088493326, Train acc: 0.8675673455978975\n",
      "Iteration 19800 - Batch 860/1894 - Train loss: 1.0361334191382139, Train acc: 0.8678861788617886\n",
      "Iteration 19900 - Batch 960/1894 - Train loss: 1.0379558735285788, Train acc: 0.8659274193548387\n",
      "Iteration 20000 - Batch 1060/1894 - Train loss: 1.0388346476222299, Train acc: 0.8652803958529689\n",
      "Iteration 20100 - Batch 1160/1894 - Train loss: 1.040230818497118, Train acc: 0.8638835055986219\n",
      "Iteration 20200 - Batch 1260/1894 - Train loss: 1.0402936775659777, Train acc: 0.8639472640761301\n",
      "Iteration 20300 - Batch 1360/1894 - Train loss: 1.0397693394388372, Train acc: 0.8645756796473182\n",
      "Iteration 20400 - Batch 1460/1894 - Train loss: 1.0393550971613446, Train acc: 0.8649469541409993\n",
      "Iteration 20500 - Batch 1560/1894 - Train loss: 1.039234072981852, Train acc: 0.8650904868673926\n",
      "Iteration 20600 - Batch 1660/1894 - Train loss: 1.0389887270333178, Train acc: 0.8653484346779049\n",
      "Iteration 20700 - Batch 1760/1894 - Train loss: 1.0390968506881826, Train acc: 0.8652044293015332\n",
      "Iteration 20800 - Batch 1860/1894 - Train loss: 1.0390616676168118, Train acc: 0.8651598602901666\n",
      "[1, 1, 0, 0, 1, 3, 2, 0, 4, 0, 3, 1, 2, 2, 3, 2, 4, 1, 2, 4, 4, 0, 2, 2, 1, 0, 4, 4, 0, 0, 3, 3, 4, 0, 2, 4, 2, 0, 4, 0, 4, 3, 4, 4, 2, 2, 3, 0, 0, 3, 4, 1, 0, 4, 1, 1, 1, 1, 4, 4, 0, 1, 1, 4, 1, 2, 1, 1, 1, 4, 1, 4, 4, 2, 0, 1, 2, 2, 1, 1, 1, 3, 3, 2, 4, 1, 0, 2, 0, 2, 3, 0, 0, 0, 3, 4, 3, 2, 1, 4, 0, 2, 3, 2, 1, 2, 1, 1, 3, 3, 0, 4, 0, 1, 0, 4, 1, 1, 3, 0, 2, 1, 3, 2, 2, 0, 4, 4, 3, 0, 4, 2, 4, 3, 3, 3, 0, 4, 0, 4, 3, 1, 4, 0, 2, 3, 1, 2, 0, 3, 2, 3, 1, 3, 0, 0, 2, 1, 2, 0, 1, 3, 1, 1, 4, 4, 4, 4, 4, 4, 1, 4, 2, 3, 3, 3, 2, 2, 4, 2, 2, 3, 2, 1, 4, 1, 4, 4, 4, 2, 0, 3, 2, 2, 2, 0, 1, 4, 1, 2, 0, 4, 3, 2, 4, 4, 3, 4, 0, 3, 4, 3, 0, 0, 3, 4, 1, 2, 3, 3, 3, 4, 2, 3, 2, 0, 3, 3, 4, 3, 4, 3, 0, 0, 1, 0, 0, 3, 0, 0, 4, 4, 1, 4, 3, 4, 1, 2, 3, 0, 0, 2, 2, 2, 0, 2, 3, 4, 4, 3, 2, 2, 2, 0, 4, 1, 2, 3, 0, 2, 3, 3, 3, 0, 0, 4, 1, 1, 0, 1, 1, 2, 3, 0, 1, 1, 0, 0, 3, 3, 3, 0, 1, 3, 3, 1, 1, 3, 1, 2, 2, 1, 0, 0, 3, 4, 1, 1, 3, 2, 3, 1, 2, 2, 1, 0, 1, 4, 3, 3, 2, 4, 2, 3, 0, 1, 3, 3, 0, 0, 2, 1, 4, 4, 1, 2, 1, 4, 0, 0, 4, 0, 0, 1, 3, 4, 4, 1, 4, 3, 0, 3, 2, 4, 2, 3, 1, 2, 2, 2, 0, 2, 2, 0, 4, 1, 3, 2, 4, 0, 0, 3, 2, 4, 1, 2, 4, 4, 3, 4, 1, 0, 2, 3, 1, 2, 2, 4, 0, 4, 1, 0, 0, 0, 3, 2, 2, 1, 1, 2, 0, 2, 1, 2, 1, 4, 4, 3, 4, 1, 1, 3, 3, 1, 0, 0, 4, 1, 2, 3, 2, 0, 2, 1, 1, 4, 4, 1, 3, 3, 3, 2, 4, 0, 3, 4, 4, 2, 0, 0, 2, 3, 1, 0, 1, 1, 4, 3, 1, 1, 0, 3, 1, 3, 0, 3, 0, 0, 1, 0, 1, 2, 0, 0, 1, 2, 2, 2, 1, 0, 0, 3, 3, 2, 4, 2, 4, 2, 4, 3, 4, 4, 4, 3, 2, 4, 0, 0, 3, 3, 1, 1, 0, 1, 3, 2, 4, 2, 3, 4]\n",
      "[4, 4, 0, 0, 3, 3, 2, 0, 4, 0, 3, 4, 2, 0, 3, 2, 4, 0, 2, 4, 4, 0, 2, 2, 3, 0, 4, 4, 0, 0, 3, 3, 4, 0, 2, 4, 2, 0, 4, 0, 4, 3, 4, 0, 2, 2, 3, 0, 4, 3, 4, 4, 0, 4, 3, 4, 0, 4, 4, 4, 0, 3, 4, 4, 4, 2, 4, 4, 4, 4, 4, 3, 2, 2, 0, 3, 2, 0, 0, 4, 3, 3, 3, 2, 4, 0, 0, 2, 0, 2, 3, 0, 0, 0, 3, 4, 3, 2, 0, 4, 0, 2, 3, 2, 4, 2, 4, 3, 3, 2, 0, 4, 0, 4, 2, 4, 4, 4, 3, 0, 2, 4, 3, 2, 3, 0, 4, 4, 3, 0, 4, 0, 4, 3, 3, 3, 0, 4, 0, 3, 3, 4, 4, 0, 0, 3, 4, 2, 0, 3, 0, 3, 4, 3, 0, 0, 2, 2, 2, 0, 3, 3, 3, 0, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 3, 3, 2, 2, 4, 2, 2, 3, 2, 4, 4, 4, 4, 4, 4, 2, 0, 3, 2, 2, 2, 0, 4, 4, 4, 2, 0, 4, 3, 2, 4, 4, 3, 2, 2, 3, 4, 4, 4, 2, 3, 4, 3, 2, 3, 3, 3, 4, 0, 3, 3, 0, 3, 3, 4, 0, 4, 3, 2, 0, 4, 0, 3, 3, 0, 0, 4, 4, 3, 4, 3, 4, 3, 2, 3, 0, 0, 2, 2, 0, 0, 2, 3, 4, 4, 3, 2, 2, 2, 0, 4, 4, 2, 3, 0, 2, 3, 3, 3, 0, 0, 4, 4, 4, 0, 2, 3, 2, 3, 0, 4, 0, 0, 0, 3, 3, 3, 4, 0, 3, 4, 3, 2, 3, 0, 2, 2, 3, 0, 0, 3, 4, 3, 0, 3, 2, 3, 3, 2, 2, 0, 0, 0, 4, 3, 3, 0, 4, 0, 3, 0, 0, 3, 3, 0, 0, 2, 4, 0, 4, 4, 2, 0, 4, 0, 0, 4, 0, 4, 4, 3, 4, 4, 3, 4, 3, 0, 3, 2, 4, 2, 3, 0, 2, 2, 2, 0, 2, 2, 0, 4, 2, 3, 2, 4, 0, 0, 3, 2, 4, 2, 3, 4, 4, 3, 4, 3, 0, 0, 3, 2, 2, 2, 0, 0, 2, 4, 0, 0, 0, 4, 2, 2, 3, 4, 3, 0, 2, 0, 2, 4, 4, 4, 3, 4, 3, 2, 3, 3, 4, 0, 0, 4, 0, 0, 3, 2, 0, 2, 3, 0, 4, 4, 0, 3, 3, 3, 2, 4, 0, 3, 4, 4, 2, 0, 2, 0, 3, 4, 0, 3, 4, 4, 3, 4, 4, 0, 4, 3, 3, 0, 3, 0, 0, 4, 0, 4, 2, 0, 0, 3, 2, 2, 2, 0, 0, 0, 3, 3, 2, 3, 0, 4, 2, 3, 3, 4, 4, 4, 3, 2, 3, 0, 0, 3, 3, 2, 3, 0, 4, 3, 0, 4, 2, 3, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.82      0.82      0.82       100\n",
      "           3       0.72      0.94      0.82       100\n",
      "           4       0.62      0.88      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.57      0.71      0.63       500\n",
      "weighted avg       0.57      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1972525492310524, Val acc: 0.708\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20900 - Batch 66/1894 - Train loss: 1.039435955125894, Train acc: 0.8647388059701493\n",
      "Iteration 21000 - Batch 166/1894 - Train loss: 1.0444106634505494, Train acc: 0.8600299401197605\n",
      "Iteration 21100 - Batch 266/1894 - Train loss: 1.0430886350320967, Train acc: 0.8607209737827716\n",
      "Iteration 21200 - Batch 366/1894 - Train loss: 1.0394287945788954, Train acc: 0.864441416893733\n",
      "Iteration 21300 - Batch 466/1894 - Train loss: 1.040131247145716, Train acc: 0.8636241970021413\n",
      "Iteration 21400 - Batch 566/1894 - Train loss: 1.0384555328670213, Train acc: 0.8655202821869489\n",
      "Iteration 21500 - Batch 666/1894 - Train loss: 1.038033183368071, Train acc: 0.8661450524737632\n",
      "Iteration 21600 - Batch 766/1894 - Train loss: 1.0382125045050232, Train acc: 0.8659957627118644\n",
      "Iteration 21700 - Batch 866/1894 - Train loss: 1.0380643797993248, Train acc: 0.866169261822376\n",
      "Iteration 21800 - Batch 966/1894 - Train loss: 1.0378708554645606, Train acc: 0.8663715098241985\n",
      "Iteration 21900 - Batch 1066/1894 - Train loss: 1.0372560358315623, Train acc: 0.8671508903467666\n",
      "Iteration 22000 - Batch 1166/1894 - Train loss: 1.037616582333582, Train acc: 0.8666720222793488\n",
      "Iteration 22100 - Batch 1266/1894 - Train loss: 1.037628682466972, Train acc: 0.8666633780584057\n",
      "Iteration 22200 - Batch 1366/1894 - Train loss: 1.0377680272539775, Train acc: 0.8664731163130943\n",
      "Iteration 22300 - Batch 1466/1894 - Train loss: 1.0378807962306438, Train acc: 0.8663087934560327\n",
      "Iteration 22400 - Batch 1566/1894 - Train loss: 1.0378592156572712, Train acc: 0.8663050414805361\n",
      "Iteration 22500 - Batch 1666/1894 - Train loss: 1.0384023469511305, Train acc: 0.8657580983803239\n",
      "Iteration 22600 - Batch 1766/1894 - Train loss: 1.0382998257150202, Train acc: 0.8658213073005093\n",
      "Iteration 22700 - Batch 1866/1894 - Train loss: 1.037929984804265, Train acc: 0.8662292447777182\n",
      "[1, 3, 4, 2, 1, 1, 3, 1, 0, 3, 3, 4, 0, 4, 4, 2, 4, 1, 4, 3, 1, 1, 2, 0, 4, 3, 1, 2, 1, 0, 2, 2, 0, 3, 0, 4, 1, 0, 4, 4, 0, 1, 0, 2, 1, 1, 2, 0, 4, 2, 0, 1, 4, 4, 1, 3, 4, 3, 1, 0, 0, 0, 3, 3, 4, 1, 0, 4, 3, 4, 4, 4, 2, 1, 0, 3, 1, 3, 4, 0, 2, 2, 1, 0, 3, 4, 1, 2, 1, 4, 2, 0, 2, 1, 4, 1, 3, 4, 2, 4, 0, 3, 1, 2, 3, 0, 3, 0, 4, 0, 0, 3, 2, 2, 0, 2, 0, 1, 1, 2, 4, 0, 0, 0, 2, 2, 0, 0, 1, 3, 4, 3, 4, 4, 0, 4, 1, 1, 2, 0, 2, 2, 0, 0, 1, 1, 2, 2, 0, 3, 1, 4, 1, 1, 1, 2, 0, 2, 3, 1, 4, 1, 3, 4, 2, 3, 2, 0, 2, 1, 1, 3, 2, 0, 3, 3, 4, 2, 1, 3, 4, 4, 4, 3, 4, 1, 2, 0, 1, 2, 2, 1, 1, 4, 2, 1, 2, 2, 3, 0, 2, 3, 4, 0, 4, 4, 1, 3, 1, 1, 1, 3, 2, 2, 1, 2, 2, 0, 3, 0, 0, 4, 0, 4, 4, 2, 3, 0, 0, 3, 3, 1, 3, 4, 2, 0, 2, 1, 0, 4, 2, 2, 0, 2, 1, 4, 1, 3, 3, 2, 3, 0, 0, 0, 0, 2, 1, 4, 1, 3, 2, 0, 4, 3, 1, 4, 3, 2, 3, 1, 4, 3, 4, 3, 3, 4, 4, 2, 2, 3, 0, 3, 4, 0, 4, 2, 3, 4, 2, 2, 2, 4, 1, 3, 2, 0, 2, 4, 0, 1, 2, 1, 1, 0, 1, 1, 3, 4, 0, 2, 4, 1, 1, 4, 3, 2, 3, 3, 2, 4, 4, 1, 4, 0, 0, 4, 4, 1, 3, 4, 0, 1, 4, 1, 4, 1, 1, 0, 3, 3, 2, 0, 1, 2, 0, 4, 1, 3, 1, 1, 1, 0, 0, 3, 4, 2, 4, 3, 3, 3, 2, 2, 2, 2, 0, 4, 0, 4, 2, 3, 4, 3, 1, 4, 3, 0, 3, 3, 4, 3, 4, 2, 3, 1, 0, 4, 0, 1, 0, 4, 0, 0, 2, 2, 3, 0, 1, 0, 1, 4, 3, 1, 4, 4, 3, 4, 2, 3, 2, 3, 0, 4, 1, 2, 4, 1, 0, 0, 0, 0, 2, 0, 4, 2, 3, 3, 2, 2, 0, 3, 3, 4, 3, 2, 3, 2, 0, 1, 3, 1, 0, 1, 1, 2, 1, 3, 2, 4, 0, 3, 1, 4, 3, 3, 2, 2, 4, 0, 3, 0, 0, 0, 3, 3, 0, 3, 1, 3, 0, 2, 2, 4, 0, 4, 2, 2, 1, 1, 3, 2, 1, 1, 0, 2, 2, 1, 1, 4, 4, 1, 3, 3, 3, 3, 4, 2, 3, 4, 0, 0]\n",
      "[3, 3, 4, 0, 3, 0, 3, 0, 0, 3, 3, 4, 0, 4, 4, 2, 4, 3, 4, 4, 4, 4, 2, 0, 4, 3, 0, 2, 4, 0, 2, 2, 0, 3, 0, 0, 2, 0, 4, 4, 4, 2, 4, 2, 0, 4, 2, 0, 4, 2, 0, 4, 3, 3, 4, 3, 4, 3, 4, 0, 0, 0, 3, 3, 4, 4, 0, 4, 3, 4, 4, 0, 2, 3, 0, 3, 0, 3, 4, 0, 2, 2, 2, 4, 3, 4, 4, 2, 4, 4, 2, 0, 2, 3, 4, 3, 3, 4, 2, 4, 0, 4, 0, 2, 3, 0, 3, 0, 4, 0, 0, 3, 2, 2, 0, 2, 0, 4, 3, 2, 4, 0, 0, 0, 2, 2, 0, 0, 0, 3, 4, 3, 4, 4, 0, 4, 0, 4, 0, 0, 3, 2, 0, 0, 0, 4, 2, 0, 0, 3, 0, 4, 3, 3, 3, 0, 0, 2, 3, 3, 4, 4, 3, 4, 2, 3, 2, 0, 2, 3, 0, 4, 0, 0, 3, 3, 4, 2, 0, 3, 4, 4, 4, 3, 4, 4, 2, 0, 4, 2, 2, 3, 4, 4, 2, 0, 2, 2, 3, 0, 0, 3, 4, 0, 4, 4, 3, 3, 3, 3, 4, 3, 0, 2, 4, 3, 2, 0, 4, 0, 0, 4, 0, 4, 4, 2, 3, 0, 0, 3, 3, 4, 3, 4, 0, 0, 2, 0, 0, 4, 2, 2, 0, 2, 3, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 4, 3, 4, 3, 2, 0, 4, 3, 4, 0, 3, 2, 3, 4, 4, 3, 4, 3, 3, 4, 2, 0, 0, 3, 0, 3, 4, 0, 4, 2, 3, 4, 2, 2, 2, 4, 3, 3, 0, 2, 0, 4, 0, 4, 2, 4, 3, 0, 4, 4, 3, 4, 4, 0, 4, 4, 4, 4, 3, 2, 3, 3, 2, 4, 4, 4, 4, 0, 0, 4, 4, 2, 3, 4, 2, 4, 4, 3, 4, 0, 0, 0, 3, 3, 2, 0, 4, 3, 0, 4, 3, 3, 4, 0, 0, 0, 0, 3, 4, 2, 4, 3, 3, 3, 2, 0, 2, 2, 0, 4, 0, 4, 2, 0, 4, 4, 4, 4, 3, 4, 3, 3, 4, 3, 4, 0, 3, 4, 0, 4, 0, 4, 0, 4, 0, 0, 2, 2, 3, 0, 4, 0, 4, 4, 3, 3, 4, 4, 3, 4, 2, 3, 2, 3, 0, 4, 0, 2, 4, 4, 0, 0, 0, 0, 2, 0, 4, 2, 3, 3, 2, 2, 0, 3, 3, 4, 3, 2, 3, 2, 0, 4, 4, 3, 4, 0, 3, 2, 4, 3, 3, 4, 0, 3, 4, 4, 3, 4, 2, 0, 4, 0, 4, 0, 0, 0, 3, 3, 0, 3, 3, 2, 0, 2, 2, 4, 0, 4, 2, 2, 4, 4, 3, 2, 4, 4, 0, 2, 0, 4, 3, 4, 4, 4, 3, 3, 3, 3, 4, 2, 3, 4, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.77      0.83       100\n",
      "           3       0.72      0.90      0.80       100\n",
      "           4       0.59      0.92      0.72       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.1988995000720024, Val acc: 0.702\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22800 - Batch 72/1894 - Train loss: 1.0237250956770492, Train acc: 0.879708904109589\n",
      "Iteration 22900 - Batch 172/1894 - Train loss: 1.0289576267231406, Train acc: 0.875\n",
      "Iteration 23000 - Batch 272/1894 - Train loss: 1.030176260532477, Train acc: 0.8738553113553114\n",
      "Iteration 23100 - Batch 372/1894 - Train loss: 1.0348081419359263, Train acc: 0.8693867292225201\n",
      "Iteration 23200 - Batch 472/1894 - Train loss: 1.0337776873126847, Train acc: 0.8701109936575053\n",
      "Iteration 23300 - Batch 572/1894 - Train loss: 1.0351998009190717, Train acc: 0.868564572425829\n",
      "Iteration 23400 - Batch 672/1894 - Train loss: 1.0358041923432257, Train acc: 0.8678491827637445\n",
      "Iteration 23500 - Batch 772/1894 - Train loss: 1.0369288727814598, Train acc: 0.8668337645536869\n",
      "Iteration 23600 - Batch 872/1894 - Train loss: 1.0356985488981179, Train acc: 0.8680197594501718\n",
      "Iteration 23700 - Batch 972/1894 - Train loss: 1.035365416665484, Train acc: 0.8683517471736896\n",
      "Iteration 23800 - Batch 1072/1894 - Train loss: 1.0342864602498663, Train acc: 0.8695829450139795\n",
      "Iteration 23900 - Batch 1172/1894 - Train loss: 1.0343553933544436, Train acc: 0.8694852941176471\n",
      "Iteration 24000 - Batch 1272/1894 - Train loss: 1.034358869597187, Train acc: 0.8694275333857031\n",
      "Iteration 24100 - Batch 1372/1894 - Train loss: 1.033817206519586, Train acc: 0.8700154770575382\n",
      "Iteration 24200 - Batch 1472/1894 - Train loss: 1.033905035649848, Train acc: 0.8700356415478615\n",
      "Iteration 24300 - Batch 1572/1894 - Train loss: 1.0338653437816938, Train acc: 0.8701327082008901\n",
      "Iteration 24400 - Batch 1672/1894 - Train loss: 1.0340155327811758, Train acc: 0.8699753436939629\n",
      "Iteration 24500 - Batch 1772/1894 - Train loss: 1.0340866095523544, Train acc: 0.8699414833615341\n",
      "Iteration 24600 - Batch 1872/1894 - Train loss: 1.0339880379775088, Train acc: 0.8699779765082755\n",
      "[3, 3, 2, 2, 2, 1, 0, 2, 1, 2, 3, 1, 1, 1, 2, 0, 4, 2, 2, 1, 3, 0, 0, 1, 0, 1, 2, 2, 4, 4, 4, 0, 0, 4, 3, 3, 2, 0, 3, 2, 4, 0, 2, 0, 0, 1, 4, 2, 2, 0, 3, 0, 4, 1, 4, 2, 0, 1, 1, 1, 0, 4, 4, 1, 0, 0, 0, 2, 0, 0, 2, 1, 3, 4, 0, 0, 3, 4, 1, 3, 1, 1, 1, 4, 4, 0, 2, 3, 1, 1, 2, 2, 1, 4, 1, 3, 3, 2, 2, 2, 1, 4, 4, 1, 0, 3, 4, 0, 1, 3, 1, 0, 3, 4, 1, 2, 1, 1, 4, 1, 2, 4, 0, 2, 3, 4, 0, 3, 1, 4, 0, 2, 0, 3, 4, 1, 3, 3, 1, 1, 4, 3, 2, 0, 2, 2, 2, 1, 4, 1, 3, 2, 1, 4, 1, 1, 0, 1, 3, 3, 0, 2, 4, 4, 0, 3, 2, 3, 4, 4, 4, 3, 0, 3, 0, 2, 1, 4, 2, 3, 1, 3, 3, 2, 4, 4, 2, 3, 1, 2, 4, 1, 2, 1, 3, 1, 2, 4, 4, 4, 4, 0, 3, 2, 1, 3, 1, 2, 3, 1, 3, 3, 0, 4, 3, 4, 4, 1, 3, 4, 4, 4, 1, 0, 3, 3, 0, 0, 1, 4, 0, 2, 0, 2, 4, 0, 0, 3, 3, 0, 4, 1, 2, 2, 4, 3, 3, 2, 3, 1, 1, 0, 0, 2, 1, 4, 4, 2, 0, 3, 3, 1, 2, 1, 4, 0, 0, 2, 2, 2, 3, 4, 1, 1, 3, 0, 1, 4, 0, 3, 3, 0, 0, 2, 1, 2, 2, 3, 1, 4, 4, 1, 0, 1, 3, 4, 1, 3, 1, 3, 2, 1, 4, 3, 3, 0, 3, 4, 4, 4, 0, 2, 1, 1, 4, 1, 2, 4, 0, 4, 3, 3, 1, 3, 2, 0, 0, 0, 1, 2, 2, 4, 1, 1, 2, 2, 0, 0, 2, 3, 4, 2, 1, 0, 4, 3, 3, 1, 3, 3, 4, 2, 1, 1, 4, 2, 2, 4, 3, 1, 3, 1, 3, 1, 1, 0, 4, 0, 2, 1, 4, 2, 0, 1, 4, 3, 4, 4, 4, 1, 3, 3, 4, 0, 0, 4, 2, 2, 3, 1, 3, 2, 3, 4, 2, 1, 0, 0, 2, 3, 1, 2, 2, 3, 2, 2, 3, 3, 2, 2, 3, 0, 0, 2, 0, 3, 1, 0, 0, 3, 2, 4, 1, 3, 3, 4, 0, 4, 3, 0, 3, 2, 2, 0, 3, 0, 4, 0, 4, 0, 3, 2, 0, 2, 4, 0, 3, 0, 4, 2, 0, 2, 0, 4, 2, 4, 0, 1, 0, 3, 0, 4, 4, 1, 4, 2, 3, 3, 3, 0, 2, 1, 2, 0, 0, 0, 4, 0, 2, 0, 0, 0, 0, 4, 4, 2, 4, 1, 3, 3, 1, 2, 3, 1, 4, 2, 1, 1, 4, 4]\n",
      "[3, 3, 3, 2, 0, 4, 0, 2, 0, 2, 3, 3, 0, 4, 2, 0, 4, 2, 2, 4, 3, 0, 0, 2, 0, 2, 2, 0, 4, 4, 3, 0, 0, 4, 3, 3, 0, 0, 3, 2, 0, 0, 0, 0, 0, 4, 4, 0, 2, 0, 4, 0, 4, 0, 4, 2, 0, 3, 0, 0, 0, 4, 4, 3, 0, 0, 0, 2, 0, 0, 3, 0, 3, 4, 0, 0, 3, 4, 4, 3, 0, 3, 0, 4, 4, 0, 2, 3, 4, 0, 2, 2, 0, 4, 4, 4, 3, 2, 2, 2, 4, 4, 2, 3, 0, 4, 4, 0, 3, 3, 2, 0, 3, 3, 0, 2, 3, 3, 4, 0, 3, 3, 4, 2, 4, 2, 0, 3, 4, 4, 0, 0, 0, 3, 4, 4, 3, 3, 4, 3, 4, 0, 2, 0, 2, 2, 2, 3, 4, 4, 3, 2, 0, 3, 2, 4, 0, 0, 3, 3, 0, 2, 4, 4, 0, 3, 2, 3, 4, 3, 4, 3, 0, 4, 0, 2, 3, 4, 2, 3, 3, 3, 3, 2, 4, 4, 2, 3, 4, 2, 4, 4, 0, 3, 3, 4, 2, 4, 4, 4, 4, 0, 3, 0, 0, 3, 3, 0, 3, 3, 3, 3, 0, 4, 3, 4, 4, 4, 3, 4, 4, 0, 4, 0, 3, 3, 0, 0, 3, 4, 0, 2, 0, 2, 4, 0, 0, 3, 3, 0, 4, 0, 2, 2, 4, 3, 3, 2, 3, 0, 4, 0, 0, 2, 4, 4, 4, 2, 0, 3, 3, 3, 2, 4, 4, 0, 0, 0, 2, 2, 3, 2, 4, 3, 3, 0, 4, 4, 4, 3, 3, 0, 0, 2, 4, 2, 2, 3, 3, 3, 4, 4, 0, 4, 3, 4, 4, 3, 0, 3, 2, 0, 4, 3, 3, 0, 4, 4, 4, 3, 0, 2, 0, 4, 4, 0, 0, 4, 0, 3, 3, 3, 0, 3, 0, 0, 0, 0, 4, 2, 2, 4, 4, 0, 2, 2, 0, 0, 2, 3, 4, 2, 3, 0, 4, 3, 3, 3, 3, 3, 4, 2, 0, 4, 4, 2, 2, 4, 3, 4, 3, 3, 3, 4, 0, 4, 4, 0, 2, 4, 4, 2, 0, 0, 4, 3, 4, 0, 4, 4, 3, 3, 4, 0, 0, 4, 2, 0, 3, 3, 3, 2, 3, 4, 2, 4, 0, 0, 2, 3, 4, 2, 2, 4, 2, 2, 3, 4, 0, 2, 3, 0, 0, 0, 0, 3, 4, 0, 0, 3, 2, 4, 4, 3, 3, 4, 0, 4, 3, 0, 3, 0, 2, 2, 3, 0, 4, 0, 4, 0, 3, 0, 0, 0, 4, 0, 3, 0, 4, 2, 0, 2, 0, 4, 2, 4, 0, 3, 0, 3, 0, 4, 4, 0, 3, 2, 3, 3, 3, 0, 2, 4, 2, 0, 0, 0, 4, 0, 2, 0, 0, 0, 0, 4, 4, 2, 4, 2, 4, 3, 3, 2, 3, 4, 4, 2, 3, 4, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.79      0.84       100\n",
      "           3       0.70      0.90      0.79       100\n",
      "           4       0.61      0.85      0.71       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.2039224803447723, Val acc: 0.7\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24700 - Batch 78/1894 - Train loss: 1.038760244846344, Train acc: 0.8647151898734177\n",
      "Iteration 24800 - Batch 178/1894 - Train loss: 1.0340271731994672, Train acc: 0.8695879888268156\n",
      "Iteration 24900 - Batch 278/1894 - Train loss: 1.0331297540322855, Train acc: 0.8701836917562724\n",
      "Iteration 25000 - Batch 378/1894 - Train loss: 1.0330900880151814, Train acc: 0.8702176781002638\n",
      "Iteration 25100 - Batch 478/1894 - Train loss: 1.0327056439783977, Train acc: 0.8708898747390397\n",
      "Iteration 25200 - Batch 578/1894 - Train loss: 1.0318510935920095, Train acc: 0.8717076856649395\n",
      "Iteration 25300 - Batch 678/1894 - Train loss: 1.0313529882234396, Train acc: 0.8722385861561119\n",
      "Iteration 25400 - Batch 778/1894 - Train loss: 1.0317286032614261, Train acc: 0.8717506418485238\n",
      "Iteration 25500 - Batch 878/1894 - Train loss: 1.0327167661523655, Train acc: 0.8709115472127418\n",
      "Iteration 25600 - Batch 978/1894 - Train loss: 1.0326090279711644, Train acc: 0.871105720122574\n",
      "Iteration 25700 - Batch 1078/1894 - Train loss: 1.0328430780887161, Train acc: 0.8708005097312326\n",
      "Iteration 25800 - Batch 1178/1894 - Train loss: 1.03328691735118, Train acc: 0.870414546225615\n",
      "Iteration 25900 - Batch 1278/1894 - Train loss: 1.0335964124308983, Train acc: 0.8701866692728695\n",
      "Iteration 26000 - Batch 1378/1894 - Train loss: 1.033497862879827, Train acc: 0.8704677302393038\n",
      "Iteration 26100 - Batch 1478/1894 - Train loss: 1.0331044953122503, Train acc: 0.870816430020284\n",
      "Iteration 26200 - Batch 1578/1894 - Train loss: 1.03344315909524, Train acc: 0.8705470234325523\n",
      "Iteration 26300 - Batch 1678/1894 - Train loss: 1.0337971930989487, Train acc: 0.8702538713519953\n",
      "Iteration 26400 - Batch 1778/1894 - Train loss: 1.03362782833079, Train acc: 0.8704679595278246\n",
      "Iteration 26500 - Batch 1878/1894 - Train loss: 1.0333582578725546, Train acc: 0.8707756785524216\n",
      "[0, 2, 2, 4, 4, 2, 0, 2, 3, 2, 0, 2, 2, 1, 1, 4, 3, 4, 3, 3, 1, 2, 0, 2, 0, 2, 3, 0, 1, 2, 4, 4, 3, 2, 0, 0, 0, 1, 2, 2, 4, 3, 4, 0, 1, 1, 0, 0, 3, 3, 4, 1, 2, 1, 1, 4, 3, 4, 0, 2, 1, 1, 3, 4, 0, 4, 4, 0, 3, 4, 3, 1, 2, 4, 3, 3, 0, 2, 3, 2, 4, 0, 0, 0, 1, 3, 4, 3, 3, 1, 4, 2, 1, 2, 4, 0, 3, 3, 2, 2, 0, 0, 1, 2, 3, 2, 1, 0, 4, 2, 3, 4, 3, 1, 3, 1, 0, 2, 0, 2, 0, 1, 1, 1, 0, 3, 3, 1, 1, 2, 2, 4, 2, 4, 2, 4, 3, 3, 0, 2, 2, 3, 2, 3, 4, 1, 2, 4, 4, 1, 4, 4, 3, 3, 2, 4, 3, 4, 1, 0, 0, 1, 0, 4, 0, 1, 1, 4, 4, 1, 2, 1, 4, 1, 0, 0, 0, 2, 2, 3, 1, 0, 3, 2, 1, 3, 1, 3, 3, 1, 4, 3, 3, 4, 1, 1, 3, 1, 2, 1, 3, 4, 0, 1, 3, 0, 1, 3, 4, 0, 4, 4, 1, 3, 3, 1, 3, 1, 0, 0, 4, 0, 4, 1, 4, 0, 0, 2, 0, 4, 0, 2, 0, 4, 3, 4, 1, 2, 0, 0, 4, 0, 3, 3, 1, 4, 4, 4, 1, 2, 2, 1, 1, 4, 3, 4, 2, 3, 3, 0, 0, 2, 2, 2, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 3, 3, 2, 3, 3, 2, 1, 1, 2, 0, 4, 3, 3, 2, 0, 3, 1, 3, 0, 0, 0, 0, 2, 4, 4, 2, 4, 3, 1, 4, 3, 3, 1, 3, 2, 1, 3, 4, 1, 3, 2, 3, 1, 3, 1, 2, 3, 0, 0, 3, 3, 0, 3, 4, 4, 2, 2, 4, 2, 0, 1, 0, 2, 0, 4, 3, 2, 1, 1, 2, 3, 3, 2, 0, 2, 1, 2, 3, 4, 1, 3, 3, 2, 0, 3, 3, 4, 0, 4, 2, 2, 3, 0, 3, 2, 0, 1, 1, 1, 4, 0, 4, 4, 2, 4, 2, 1, 1, 0, 4, 4, 0, 1, 3, 1, 3, 1, 2, 1, 4, 3, 4, 0, 4, 0, 4, 0, 4, 0, 4, 4, 4, 1, 4, 1, 4, 2, 3, 2, 2, 2, 0, 1, 3, 1, 2, 0, 4, 2, 0, 3, 2, 4, 4, 4, 0, 2, 2, 2, 0, 3, 3, 2, 4, 1, 4, 1, 1, 0, 0, 3, 2, 1, 4, 2, 3, 0, 2, 4, 0, 1, 4, 0, 4, 0, 2, 3, 4, 2, 4, 1, 1, 0, 4, 2, 2, 0, 4, 1, 0, 2, 4, 4, 3, 3, 0, 1, 1, 1, 1, 0, 3, 0, 0, 2, 2, 2, 4, 0, 3, 1, 2, 1, 2, 3, 1]\n",
      "[0, 2, 2, 4, 4, 2, 0, 2, 3, 2, 0, 0, 2, 4, 4, 4, 2, 4, 3, 3, 0, 2, 0, 0, 0, 2, 3, 0, 3, 2, 3, 0, 3, 2, 2, 0, 0, 4, 0, 2, 4, 3, 4, 0, 2, 4, 0, 0, 3, 3, 4, 4, 2, 4, 4, 4, 3, 3, 0, 2, 3, 3, 4, 4, 0, 4, 4, 0, 3, 4, 3, 4, 2, 4, 3, 3, 0, 0, 3, 2, 4, 0, 4, 0, 4, 3, 4, 3, 3, 0, 4, 2, 4, 2, 0, 0, 3, 3, 2, 2, 0, 0, 4, 2, 3, 0, 4, 4, 4, 2, 3, 4, 3, 3, 3, 4, 0, 2, 0, 2, 0, 0, 4, 4, 0, 3, 3, 2, 3, 2, 0, 4, 2, 4, 2, 4, 3, 3, 0, 2, 2, 3, 0, 3, 4, 4, 2, 4, 4, 4, 4, 4, 3, 3, 0, 4, 3, 4, 4, 0, 0, 0, 0, 4, 0, 4, 0, 4, 4, 4, 2, 4, 4, 0, 0, 0, 0, 2, 2, 3, 4, 2, 3, 2, 4, 3, 0, 3, 3, 4, 4, 3, 3, 4, 4, 3, 3, 3, 2, 4, 3, 4, 0, 4, 3, 0, 0, 3, 4, 0, 4, 4, 0, 3, 3, 3, 3, 4, 4, 0, 2, 0, 4, 0, 4, 0, 2, 2, 0, 4, 0, 3, 0, 4, 3, 4, 4, 0, 0, 0, 4, 0, 3, 3, 4, 0, 4, 4, 4, 2, 2, 3, 4, 4, 3, 4, 2, 3, 4, 4, 0, 2, 2, 2, 3, 0, 3, 3, 0, 0, 4, 4, 0, 4, 3, 3, 2, 3, 3, 2, 3, 3, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3, 0, 0, 4, 0, 2, 4, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 2, 0, 3, 4, 4, 3, 0, 3, 4, 4, 3, 2, 3, 0, 0, 3, 3, 4, 3, 4, 4, 2, 0, 4, 2, 0, 0, 0, 2, 0, 4, 3, 2, 3, 4, 2, 3, 3, 2, 0, 2, 2, 2, 3, 4, 4, 3, 3, 2, 0, 3, 3, 4, 0, 4, 2, 2, 3, 0, 3, 2, 0, 0, 3, 4, 4, 0, 4, 4, 2, 3, 2, 3, 4, 0, 4, 4, 0, 4, 3, 3, 3, 4, 2, 4, 4, 3, 4, 0, 4, 0, 4, 0, 4, 0, 3, 4, 4, 3, 4, 4, 4, 2, 3, 2, 2, 2, 0, 2, 3, 3, 2, 0, 4, 0, 0, 3, 2, 4, 4, 0, 0, 2, 2, 2, 0, 3, 3, 0, 4, 3, 4, 4, 4, 0, 0, 3, 2, 4, 4, 2, 0, 0, 2, 4, 0, 4, 4, 0, 4, 2, 2, 3, 4, 2, 4, 0, 0, 0, 4, 2, 2, 0, 4, 2, 0, 2, 4, 4, 4, 4, 2, 3, 3, 3, 4, 0, 3, 0, 0, 2, 3, 2, 4, 0, 3, 4, 2, 4, 2, 3, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.82      0.84       100\n",
      "           3       0.73      0.93      0.82       100\n",
      "           4       0.58      0.89      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2007641941308975, Val acc: 0.704\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26600 - Batch 84/1894 - Train loss: 1.0344736057169297, Train acc: 0.8716911764705882\n",
      "Iteration 26700 - Batch 184/1894 - Train loss: 1.0288269812996322, Train acc: 0.8761824324324324\n",
      "Iteration 26800 - Batch 284/1894 - Train loss: 1.0315063457739981, Train acc: 0.8726973684210526\n",
      "Iteration 26900 - Batch 384/1894 - Train loss: 1.0303706704796134, Train acc: 0.8739448051948052\n",
      "Iteration 27000 - Batch 484/1894 - Train loss: 1.032883275046791, Train acc: 0.8711340206185567\n",
      "Iteration 27100 - Batch 584/1894 - Train loss: 1.03206626716842, Train acc: 0.8719017094017094\n",
      "Iteration 27200 - Batch 684/1894 - Train loss: 1.0324000678793357, Train acc: 0.8717153284671533\n",
      "Iteration 27300 - Batch 784/1894 - Train loss: 1.032948100111287, Train acc: 0.8711783439490446\n",
      "Iteration 27400 - Batch 884/1894 - Train loss: 1.0311584337956488, Train acc: 0.8730225988700565\n",
      "Iteration 27500 - Batch 984/1894 - Train loss: 1.030941524239361, Train acc: 0.8731598984771574\n",
      "Iteration 27600 - Batch 1084/1894 - Train loss: 1.0308227727490087, Train acc: 0.8732718894009217\n",
      "Iteration 27700 - Batch 1184/1894 - Train loss: 1.031272563451453, Train acc: 0.872837552742616\n",
      "Iteration 27800 - Batch 1284/1894 - Train loss: 1.0317950767765713, Train acc: 0.872227626459144\n",
      "Iteration 27900 - Batch 1384/1894 - Train loss: 1.0318823551012721, Train acc: 0.872134476534296\n",
      "Iteration 28000 - Batch 1484/1894 - Train loss: 1.031874738598512, Train acc: 0.8722011784511785\n",
      "Iteration 28100 - Batch 1584/1894 - Train loss: 1.032665423865574, Train acc: 0.8713130914826498\n",
      "Iteration 28200 - Batch 1684/1894 - Train loss: 1.0318930326300488, Train acc: 0.872106824925816\n",
      "Iteration 28300 - Batch 1784/1894 - Train loss: 1.0317365883111287, Train acc: 0.8722689075630252\n",
      "Iteration 28400 - Batch 1884/1894 - Train loss: 1.0316687297757805, Train acc: 0.8723474801061007\n",
      "[4, 3, 2, 4, 0, 3, 3, 3, 1, 0, 1, 1, 1, 0, 3, 2, 4, 4, 4, 3, 3, 4, 4, 4, 4, 3, 1, 0, 2, 1, 0, 1, 1, 3, 2, 1, 0, 3, 2, 3, 0, 1, 2, 3, 0, 4, 1, 4, 0, 2, 3, 3, 3, 0, 4, 1, 3, 0, 0, 4, 4, 2, 4, 0, 1, 0, 4, 1, 0, 4, 0, 2, 3, 0, 3, 3, 3, 2, 2, 1, 3, 0, 1, 2, 0, 1, 3, 0, 0, 4, 0, 2, 1, 0, 4, 0, 0, 1, 3, 0, 0, 4, 3, 0, 3, 0, 1, 2, 4, 3, 3, 2, 2, 2, 4, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 2, 4, 2, 1, 3, 4, 1, 0, 4, 1, 3, 1, 4, 4, 1, 0, 0, 1, 3, 4, 0, 1, 3, 4, 2, 2, 3, 3, 0, 4, 3, 3, 0, 0, 3, 2, 2, 2, 3, 4, 2, 3, 1, 3, 3, 3, 1, 4, 0, 2, 4, 4, 1, 0, 1, 2, 3, 4, 1, 2, 2, 4, 0, 3, 4, 3, 0, 2, 0, 3, 4, 3, 2, 2, 1, 3, 4, 0, 0, 4, 4, 4, 2, 1, 1, 0, 3, 3, 3, 3, 2, 0, 3, 3, 3, 0, 4, 0, 1, 2, 3, 3, 2, 2, 2, 4, 1, 2, 0, 3, 0, 1, 2, 3, 3, 1, 1, 2, 2, 2, 1, 1, 4, 3, 2, 4, 1, 4, 4, 4, 0, 0, 1, 4, 1, 2, 1, 1, 2, 4, 3, 4, 0, 2, 1, 2, 4, 2, 1, 2, 3, 2, 4, 4, 1, 1, 2, 1, 2, 1, 4, 3, 4, 1, 1, 2, 3, 1, 0, 3, 2, 4, 0, 4, 0, 3, 1, 0, 4, 1, 4, 2, 1, 1, 4, 0, 0, 1, 4, 4, 2, 2, 3, 4, 4, 4, 2, 4, 4, 1, 1, 3, 2, 1, 3, 1, 0, 2, 0, 4, 3, 3, 3, 1, 1, 2, 3, 4, 0, 0, 4, 0, 2, 2, 4, 3, 4, 4, 1, 4, 1, 0, 0, 4, 1, 2, 1, 3, 2, 2, 1, 1, 3, 1, 1, 0, 4, 0, 3, 4, 3, 2, 2, 3, 0, 2, 2, 0, 2, 4, 1, 1, 2, 0, 2, 1, 3, 0, 3, 2, 4, 2, 3, 0, 3, 1, 2, 2, 1, 0, 0, 4, 1, 4, 4, 0, 2, 3, 3, 2, 0, 3, 0, 4, 0, 1, 4, 3, 3, 2, 2, 4, 3, 2, 3, 1, 4, 2, 1, 1, 3, 4, 2, 4, 1, 0, 4, 3, 0, 3, 2, 0, 1, 4, 2, 2, 0, 3, 1, 0, 2, 3, 1, 2, 4, 0, 0, 1, 2, 2, 4, 1, 2, 0, 0, 1, 0, 3, 2, 1, 1, 0, 4, 2, 4, 4, 1, 3, 3, 1, 0, 4, 3, 0, 3, 2, 1, 1, 0, 0, 4, 4, 2, 0]\n",
      "[4, 3, 2, 4, 0, 4, 3, 3, 4, 0, 4, 0, 3, 0, 3, 2, 2, 4, 4, 3, 3, 4, 3, 4, 4, 3, 4, 0, 2, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 3, 0, 3, 2, 3, 0, 4, 4, 4, 0, 2, 3, 3, 4, 2, 4, 4, 3, 0, 4, 4, 4, 0, 4, 0, 3, 0, 4, 4, 0, 4, 0, 3, 3, 0, 3, 3, 3, 2, 2, 3, 3, 0, 4, 0, 0, 0, 3, 0, 0, 4, 0, 2, 4, 0, 4, 0, 0, 2, 3, 0, 0, 3, 3, 0, 3, 0, 4, 2, 4, 3, 3, 0, 2, 2, 4, 4, 4, 0, 2, 0, 0, 0, 4, 2, 0, 2, 2, 4, 2, 0, 3, 4, 4, 0, 4, 4, 3, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 4, 4, 4, 2, 2, 3, 3, 0, 4, 3, 3, 0, 0, 3, 2, 2, 0, 3, 4, 2, 3, 4, 3, 2, 2, 0, 4, 0, 2, 4, 4, 4, 0, 0, 2, 3, 4, 0, 2, 0, 4, 0, 3, 4, 3, 0, 0, 0, 3, 4, 3, 0, 2, 4, 3, 4, 0, 0, 4, 4, 3, 2, 4, 0, 0, 3, 3, 3, 3, 2, 0, 3, 3, 3, 0, 4, 0, 2, 2, 3, 3, 2, 2, 2, 4, 4, 2, 0, 3, 0, 4, 2, 3, 3, 0, 0, 2, 2, 0, 0, 3, 4, 3, 0, 4, 3, 4, 4, 4, 0, 0, 0, 4, 3, 2, 3, 4, 2, 4, 3, 4, 0, 0, 0, 0, 4, 0, 3, 2, 3, 2, 4, 4, 0, 4, 2, 4, 2, 4, 4, 3, 4, 4, 0, 2, 3, 0, 0, 3, 2, 4, 0, 4, 0, 3, 0, 0, 4, 4, 4, 0, 0, 4, 4, 0, 0, 3, 4, 4, 2, 2, 3, 4, 0, 4, 4, 4, 4, 4, 3, 3, 2, 3, 3, 3, 0, 2, 0, 4, 3, 3, 3, 4, 3, 2, 3, 4, 0, 0, 4, 0, 2, 2, 4, 3, 4, 2, 2, 4, 4, 0, 0, 4, 3, 2, 2, 3, 2, 2, 4, 3, 3, 4, 4, 0, 3, 0, 3, 4, 3, 2, 2, 3, 0, 2, 2, 0, 2, 4, 2, 3, 2, 0, 2, 2, 3, 0, 4, 2, 4, 0, 3, 2, 3, 4, 2, 2, 4, 4, 0, 0, 3, 4, 4, 0, 2, 0, 3, 2, 0, 3, 0, 4, 0, 0, 4, 3, 3, 2, 2, 4, 3, 2, 3, 4, 0, 2, 0, 3, 3, 4, 2, 4, 4, 4, 4, 3, 0, 3, 2, 0, 3, 2, 0, 0, 0, 3, 3, 0, 2, 3, 4, 2, 3, 0, 0, 0, 2, 2, 4, 3, 2, 0, 0, 4, 0, 3, 0, 4, 4, 0, 4, 2, 4, 4, 4, 3, 3, 4, 0, 4, 3, 0, 3, 2, 0, 4, 0, 0, 4, 4, 0, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.94      0.78       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.79      0.82       100\n",
      "           3       0.76      0.93      0.83       100\n",
      "           4       0.62      0.89      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.186949945986271, Val acc: 0.71\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28500 - Batch 90/1894 - Train loss: 1.038676537655212, Train acc: 0.8636675824175825\n",
      "Iteration 28600 - Batch 190/1894 - Train loss: 1.031694971142015, Train acc: 0.8705824607329843\n",
      "Iteration 28700 - Batch 290/1894 - Train loss: 1.029667937673654, Train acc: 0.872852233676976\n",
      "Iteration 28800 - Batch 390/1894 - Train loss: 1.0273943435200645, Train acc: 0.8754795396419437\n",
      "Iteration 28900 - Batch 490/1894 - Train loss: 1.028471043299269, Train acc: 0.8742998981670062\n",
      "Iteration 29000 - Batch 590/1894 - Train loss: 1.0269405375882454, Train acc: 0.8763219120135364\n",
      "Iteration 29100 - Batch 690/1894 - Train loss: 1.028186578999035, Train acc: 0.8750904486251809\n",
      "Iteration 29200 - Batch 790/1894 - Train loss: 1.0280810337603168, Train acc: 0.8751580278128951\n",
      "Iteration 29300 - Batch 890/1894 - Train loss: 1.0274359060056282, Train acc: 0.8758066778900112\n",
      "Iteration 29400 - Batch 990/1894 - Train loss: 1.027421202597055, Train acc: 0.875882946518668\n",
      "Iteration 29500 - Batch 1090/1894 - Train loss: 1.027635575160316, Train acc: 0.8758020164986251\n",
      "Iteration 29600 - Batch 1190/1894 - Train loss: 1.0275389859398105, Train acc: 0.8760232997481109\n",
      "Iteration 29700 - Batch 1290/1894 - Train loss: 1.0278802386648798, Train acc: 0.8756777691711851\n",
      "Iteration 29800 - Batch 1390/1894 - Train loss: 1.0286860633119244, Train acc: 0.8749775341480949\n",
      "Iteration 29900 - Batch 1490/1894 - Train loss: 1.0297238094785883, Train acc: 0.8739310865191147\n",
      "Iteration 30000 - Batch 1590/1894 - Train loss: 1.0295564786658056, Train acc: 0.8741161219358894\n",
      "Iteration 30100 - Batch 1690/1894 - Train loss: 1.0295803318497416, Train acc: 0.8740759905381431\n",
      "Iteration 30200 - Batch 1790/1894 - Train loss: 1.0298990910776096, Train acc: 0.8737960636515912\n",
      "Iteration 30300 - Batch 1890/1894 - Train loss: 1.0299724045725236, Train acc: 0.8736283712321523\n",
      "[2, 2, 1, 4, 0, 3, 3, 2, 3, 3, 0, 1, 3, 1, 0, 2, 3, 2, 0, 0, 3, 1, 3, 1, 2, 2, 3, 0, 3, 3, 0, 0, 1, 4, 2, 3, 0, 4, 1, 3, 3, 1, 2, 2, 1, 0, 3, 2, 3, 0, 3, 2, 1, 4, 0, 2, 3, 1, 1, 0, 4, 3, 2, 2, 0, 1, 3, 1, 1, 1, 1, 3, 4, 3, 0, 0, 1, 3, 2, 0, 4, 1, 1, 4, 3, 2, 1, 2, 1, 0, 2, 0, 2, 4, 2, 4, 1, 4, 0, 0, 2, 3, 4, 1, 0, 1, 1, 4, 1, 3, 3, 2, 3, 1, 1, 1, 1, 0, 2, 3, 4, 2, 2, 0, 4, 3, 1, 2, 4, 0, 2, 0, 1, 4, 1, 1, 3, 1, 4, 4, 3, 2, 3, 2, 0, 1, 4, 1, 4, 2, 2, 2, 3, 0, 0, 2, 0, 0, 1, 1, 0, 0, 3, 3, 4, 3, 0, 3, 4, 1, 0, 0, 0, 0, 0, 2, 4, 4, 3, 0, 0, 3, 3, 0, 2, 3, 0, 0, 0, 2, 1, 3, 2, 2, 3, 4, 0, 2, 2, 4, 4, 2, 2, 4, 2, 4, 0, 3, 0, 2, 2, 1, 0, 3, 0, 1, 4, 2, 1, 2, 2, 2, 1, 0, 2, 2, 3, 2, 0, 1, 1, 4, 2, 3, 4, 1, 4, 1, 3, 4, 1, 3, 2, 0, 4, 0, 4, 1, 4, 3, 2, 2, 3, 0, 3, 3, 1, 0, 2, 3, 4, 0, 0, 4, 0, 4, 1, 1, 2, 0, 4, 1, 3, 3, 3, 1, 1, 3, 0, 2, 4, 2, 2, 0, 2, 0, 4, 0, 1, 2, 0, 3, 0, 1, 3, 1, 1, 0, 1, 2, 0, 2, 4, 4, 3, 3, 2, 3, 4, 0, 2, 1, 0, 0, 4, 1, 4, 2, 3, 3, 2, 4, 3, 0, 1, 2, 4, 4, 0, 2, 4, 0, 1, 2, 1, 1, 1, 2, 3, 3, 4, 4, 3, 2, 3, 0, 0, 2, 3, 2, 0, 0, 1, 4, 4, 0, 4, 2, 2, 3, 1, 3, 3, 4, 3, 0, 2, 4, 2, 0, 1, 3, 3, 1, 2, 4, 4, 4, 4, 2, 3, 3, 4, 1, 0, 1, 0, 0, 3, 3, 4, 3, 1, 3, 0, 4, 2, 4, 1, 1, 4, 1, 3, 0, 2, 0, 3, 0, 4, 2, 1, 1, 1, 0, 4, 2, 4, 2, 1, 4, 4, 2, 2, 0, 3, 2, 4, 1, 1, 1, 1, 4, 1, 0, 2, 2, 3, 4, 3, 1, 1, 4, 1, 3, 0, 1, 1, 2, 4, 3, 4, 4, 4, 4, 0, 0, 4, 1, 4, 1, 4, 0, 2, 0, 1, 3, 4, 2, 4, 1, 2, 3, 2, 3, 4, 3, 4, 1, 4, 0, 4, 4, 0, 1, 2, 4, 4, 3, 2, 0, 3, 3, 4, 3, 4, 4, 4, 3, 4, 0]\n",
      "[2, 0, 3, 2, 0, 4, 3, 2, 3, 3, 0, 4, 3, 4, 0, 2, 3, 2, 4, 4, 3, 0, 3, 0, 2, 2, 3, 0, 3, 3, 0, 0, 4, 3, 0, 3, 0, 4, 3, 3, 3, 4, 2, 2, 4, 0, 3, 2, 3, 0, 3, 2, 4, 4, 0, 2, 3, 3, 4, 0, 4, 3, 2, 2, 0, 3, 4, 4, 4, 0, 3, 3, 4, 3, 0, 0, 3, 3, 2, 0, 4, 4, 0, 4, 3, 3, 0, 2, 4, 0, 0, 0, 2, 4, 2, 4, 4, 4, 0, 0, 2, 3, 4, 3, 0, 4, 3, 4, 3, 3, 4, 3, 3, 0, 4, 0, 4, 0, 0, 3, 4, 2, 2, 0, 4, 3, 4, 2, 4, 0, 2, 0, 4, 4, 4, 4, 3, 2, 4, 3, 3, 2, 3, 2, 4, 4, 4, 4, 4, 0, 0, 2, 3, 0, 0, 2, 0, 0, 0, 4, 0, 0, 3, 3, 4, 3, 0, 3, 4, 4, 0, 0, 0, 0, 0, 2, 4, 4, 3, 0, 0, 3, 3, 0, 2, 3, 0, 0, 0, 2, 0, 3, 0, 2, 0, 4, 0, 2, 2, 4, 4, 2, 2, 4, 2, 4, 0, 3, 4, 2, 2, 3, 0, 3, 0, 4, 4, 2, 3, 2, 0, 2, 0, 0, 2, 2, 3, 0, 0, 0, 4, 4, 2, 3, 4, 4, 4, 4, 3, 4, 3, 3, 2, 0, 3, 0, 4, 4, 4, 4, 2, 2, 3, 0, 3, 3, 4, 0, 2, 3, 4, 0, 0, 4, 0, 4, 0, 2, 2, 0, 4, 4, 3, 3, 3, 0, 4, 3, 0, 2, 4, 2, 2, 0, 2, 0, 4, 0, 3, 0, 0, 3, 0, 3, 3, 4, 4, 0, 2, 2, 0, 2, 4, 4, 3, 3, 2, 3, 4, 0, 2, 4, 0, 0, 4, 4, 4, 2, 3, 3, 2, 4, 3, 0, 4, 2, 3, 4, 0, 2, 4, 0, 4, 0, 3, 4, 2, 2, 3, 3, 4, 4, 3, 2, 3, 2, 0, 2, 3, 2, 0, 0, 3, 4, 4, 0, 2, 2, 2, 3, 3, 3, 3, 0, 3, 0, 2, 4, 2, 0, 4, 4, 3, 0, 2, 4, 4, 4, 4, 0, 3, 3, 4, 3, 0, 2, 0, 0, 3, 3, 4, 3, 4, 3, 0, 0, 0, 4, 3, 4, 4, 4, 3, 0, 2, 0, 3, 4, 4, 0, 3, 3, 0, 0, 4, 0, 4, 2, 3, 4, 4, 0, 4, 0, 3, 0, 4, 4, 4, 3, 2, 4, 0, 0, 2, 2, 3, 4, 3, 0, 4, 4, 4, 3, 0, 3, 0, 2, 4, 2, 4, 4, 4, 4, 0, 4, 4, 3, 4, 4, 4, 0, 2, 0, 4, 3, 4, 2, 4, 4, 2, 3, 2, 3, 4, 3, 4, 3, 4, 0, 4, 4, 0, 4, 0, 4, 4, 3, 2, 0, 3, 3, 4, 3, 4, 4, 4, 3, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.79      0.84       100\n",
      "           3       0.74      0.93      0.83       100\n",
      "           4       0.60      0.92      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.183611422777176, Val acc: 0.714\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30400 - Batch 96/1894 - Train loss: 1.0338970097069888, Train acc: 0.8701675257731959\n",
      "Iteration 30500 - Batch 196/1894 - Train loss: 1.0357146880348322, Train acc: 0.8681789340101523\n",
      "Iteration 30600 - Batch 296/1894 - Train loss: 1.0325266076659514, Train acc: 0.8717382154882155\n",
      "Iteration 30700 - Batch 396/1894 - Train loss: 1.031542073118897, Train acc: 0.8730321158690176\n",
      "Iteration 30800 - Batch 496/1894 - Train loss: 1.0313006590309757, Train acc: 0.8731765593561368\n",
      "Iteration 30900 - Batch 596/1894 - Train loss: 1.0307617955271722, Train acc: 0.8737960636515912\n",
      "Iteration 31000 - Batch 696/1894 - Train loss: 1.0309159963510641, Train acc: 0.8738342898134863\n",
      "Iteration 31100 - Batch 796/1894 - Train loss: 1.030158494167974, Train acc: 0.8744902760351317\n",
      "Iteration 31200 - Batch 896/1894 - Train loss: 1.0309704425874495, Train acc: 0.8737109810479375\n",
      "Iteration 31300 - Batch 996/1894 - Train loss: 1.030566786033818, Train acc: 0.8739969909729187\n",
      "Iteration 31400 - Batch 1096/1894 - Train loss: 1.030208676211271, Train acc: 0.874373290793072\n",
      "Iteration 31500 - Batch 1196/1894 - Train loss: 1.0299366198187583, Train acc: 0.8745561821219716\n",
      "Iteration 31600 - Batch 1296/1894 - Train loss: 1.0300206899091475, Train acc: 0.8745181187355435\n",
      "Iteration 31700 - Batch 1396/1894 - Train loss: 1.0295055331975627, Train acc: 0.8750671080887616\n",
      "Iteration 31800 - Batch 1496/1894 - Train loss: 1.028921176133828, Train acc: 0.87562625250501\n",
      "Iteration 31900 - Batch 1596/1894 - Train loss: 1.0291943350059207, Train acc: 0.8753130870381967\n",
      "Iteration 32000 - Batch 1696/1894 - Train loss: 1.0294224063859803, Train acc: 0.8750552445492045\n",
      "Iteration 32100 - Batch 1796/1894 - Train loss: 1.0301672973829172, Train acc: 0.8742174457429048\n",
      "[1, 2, 1, 4, 3, 4, 3, 2, 3, 1, 1, 1, 3, 4, 1, 0, 0, 2, 2, 0, 2, 4, 2, 2, 2, 4, 4, 1, 3, 4, 1, 0, 0, 3, 2, 4, 4, 0, 0, 3, 3, 1, 3, 4, 3, 0, 1, 0, 0, 1, 2, 1, 2, 0, 2, 2, 1, 4, 4, 2, 1, 2, 1, 3, 3, 1, 4, 1, 0, 2, 4, 0, 1, 3, 4, 3, 4, 0, 4, 0, 4, 2, 3, 3, 3, 3, 1, 0, 4, 0, 1, 1, 2, 4, 3, 0, 3, 3, 0, 0, 3, 4, 3, 1, 4, 4, 2, 4, 3, 1, 2, 3, 2, 4, 1, 4, 4, 1, 0, 2, 3, 4, 3, 1, 4, 0, 2, 2, 2, 3, 2, 0, 3, 1, 2, 3, 2, 1, 0, 3, 1, 2, 4, 1, 4, 0, 1, 2, 1, 2, 3, 4, 1, 1, 2, 2, 0, 1, 0, 1, 4, 1, 3, 2, 4, 1, 4, 4, 2, 2, 2, 4, 4, 4, 2, 0, 2, 2, 0, 4, 1, 1, 3, 3, 1, 2, 2, 3, 3, 4, 1, 0, 0, 2, 3, 4, 4, 4, 3, 1, 2, 1, 0, 1, 3, 4, 0, 4, 3, 2, 0, 2, 0, 3, 2, 0, 1, 1, 3, 3, 0, 1, 4, 3, 2, 1, 1, 1, 2, 1, 0, 3, 4, 0, 4, 4, 4, 3, 2, 2, 4, 1, 4, 3, 0, 3, 4, 1, 0, 0, 3, 4, 0, 4, 4, 4, 1, 1, 3, 3, 4, 2, 3, 0, 0, 1, 2, 2, 0, 1, 4, 3, 4, 3, 4, 4, 3, 4, 2, 3, 1, 1, 0, 1, 4, 1, 2, 2, 3, 0, 1, 4, 2, 0, 1, 4, 0, 1, 1, 4, 3, 0, 0, 0, 4, 4, 3, 4, 3, 3, 3, 2, 2, 3, 0, 0, 3, 4, 0, 0, 3, 2, 0, 1, 2, 0, 2, 3, 4, 2, 1, 2, 0, 2, 2, 1, 3, 1, 0, 0, 4, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 2, 1, 3, 0, 1, 0, 3, 3, 4, 4, 2, 0, 0, 3, 3, 3, 0, 3, 2, 2, 3, 3, 0, 4, 1, 3, 0, 0, 4, 3, 1, 0, 0, 1, 4, 3, 2, 3, 4, 4, 2, 3, 1, 4, 0, 4, 0, 0, 1, 3, 4, 1, 4, 2, 1, 2, 4, 1, 1, 3, 2, 2, 3, 2, 4, 4, 0, 0, 0, 0, 2, 0, 0, 4, 1, 1, 2, 0, 4, 2, 4, 2, 0, 0, 0, 3, 2, 2, 1, 4, 0, 1, 3, 1, 4, 2, 2, 3, 0, 2, 3, 1, 0, 3, 4, 4, 3, 4, 2, 0, 2, 2, 3, 2, 1, 2, 0, 0, 1, 3, 1, 4, 4, 3, 3, 3, 1, 1, 0, 1, 3, 3, 4, 0, 4, 1, 1, 0, 0, 1, 0, 0, 3, 2, 3, 2, 2, 0, 1]\n",
      "[0, 2, 3, 4, 3, 4, 3, 2, 3, 0, 4, 3, 3, 4, 4, 0, 0, 2, 2, 0, 2, 4, 2, 3, 2, 4, 4, 3, 3, 0, 4, 0, 0, 3, 2, 4, 4, 0, 0, 3, 3, 3, 3, 4, 3, 0, 2, 4, 0, 4, 0, 0, 2, 0, 2, 2, 4, 4, 4, 2, 0, 2, 4, 3, 3, 4, 4, 4, 0, 2, 4, 0, 3, 3, 4, 3, 4, 0, 4, 0, 2, 2, 3, 3, 4, 3, 4, 0, 4, 0, 4, 3, 2, 4, 3, 0, 3, 3, 0, 4, 3, 4, 3, 3, 4, 4, 2, 4, 3, 3, 0, 3, 2, 4, 3, 4, 4, 3, 4, 2, 3, 4, 3, 0, 4, 0, 2, 0, 0, 3, 2, 0, 3, 0, 2, 3, 2, 4, 0, 3, 3, 2, 4, 4, 4, 0, 3, 2, 0, 2, 3, 4, 0, 4, 2, 2, 0, 2, 0, 0, 4, 3, 3, 0, 4, 4, 4, 4, 3, 2, 2, 4, 4, 4, 0, 0, 2, 0, 0, 3, 4, 0, 3, 3, 4, 2, 2, 3, 3, 4, 4, 0, 0, 2, 3, 4, 4, 4, 3, 4, 2, 4, 0, 4, 4, 4, 0, 4, 3, 2, 0, 2, 0, 3, 2, 2, 4, 0, 3, 3, 0, 0, 4, 3, 2, 4, 4, 3, 2, 4, 0, 2, 4, 0, 4, 3, 4, 3, 2, 2, 4, 4, 4, 3, 2, 3, 4, 4, 0, 0, 3, 4, 0, 4, 4, 4, 4, 4, 3, 3, 4, 2, 3, 0, 4, 2, 0, 2, 0, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 0, 4, 3, 4, 0, 2, 4, 0, 3, 4, 2, 0, 0, 4, 0, 3, 4, 4, 3, 0, 0, 0, 4, 4, 3, 4, 3, 3, 3, 2, 0, 3, 0, 0, 3, 3, 0, 0, 3, 2, 0, 2, 2, 0, 2, 3, 4, 2, 4, 2, 0, 2, 2, 4, 3, 4, 0, 0, 4, 0, 0, 0, 0, 2, 3, 2, 0, 2, 0, 2, 3, 3, 0, 4, 0, 3, 3, 4, 4, 2, 0, 0, 3, 0, 3, 0, 3, 0, 2, 3, 3, 0, 4, 2, 3, 0, 0, 0, 4, 4, 0, 0, 4, 4, 3, 2, 3, 4, 4, 2, 3, 4, 4, 0, 4, 0, 0, 4, 3, 4, 0, 4, 2, 4, 0, 4, 4, 3, 3, 0, 2, 3, 2, 4, 4, 0, 0, 0, 0, 2, 0, 0, 4, 3, 4, 2, 0, 4, 2, 4, 2, 0, 0, 0, 3, 2, 4, 3, 4, 0, 4, 3, 4, 4, 2, 2, 3, 0, 2, 3, 3, 0, 3, 4, 4, 3, 4, 2, 0, 2, 0, 3, 2, 3, 0, 0, 0, 4, 3, 3, 4, 2, 3, 3, 4, 4, 4, 0, 4, 3, 3, 4, 0, 4, 4, 4, 0, 0, 0, 0, 0, 3, 2, 3, 2, 2, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.79      0.84       100\n",
      "           3       0.74      0.91      0.82       100\n",
      "           4       0.59      0.92      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.59      0.71      0.64       500\n",
      "weighted avg       0.59      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1908914223313332, Val acc: 0.712\n",
      "Epoch 18/30\n",
      "Iteration 32200 - Batch 2/1894 - Train loss: 1.0148125886917114, Train acc: 0.8854166666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32300 - Batch 102/1894 - Train loss: 1.0293432786626724, Train acc: 0.875\n",
      "Iteration 32400 - Batch 202/1894 - Train loss: 1.030750264968778, Train acc: 0.8729987684729064\n",
      "Iteration 32500 - Batch 302/1894 - Train loss: 1.03259413962317, Train acc: 0.8706683168316832\n",
      "Iteration 32600 - Batch 402/1894 - Train loss: 1.031531906897022, Train acc: 0.8719758064516129\n",
      "Iteration 32700 - Batch 502/1894 - Train loss: 1.0317320314126746, Train acc: 0.8718936381709742\n",
      "Iteration 32800 - Batch 602/1894 - Train loss: 1.0312025722974965, Train acc: 0.8726679104477612\n",
      "Iteration 32900 - Batch 702/1894 - Train loss: 1.0304756697007635, Train acc: 0.8734886201991465\n",
      "Iteration 33000 - Batch 802/1894 - Train loss: 1.029544666353822, Train acc: 0.8744551681195517\n",
      "Iteration 33100 - Batch 902/1894 - Train loss: 1.0296207546923777, Train acc: 0.8744462901439646\n",
      "Iteration 33200 - Batch 1002/1894 - Train loss: 1.0300001303552988, Train acc: 0.8739718344965105\n",
      "Iteration 33300 - Batch 1102/1894 - Train loss: 1.0295828896442112, Train acc: 0.8744616953762466\n",
      "Iteration 33400 - Batch 1202/1894 - Train loss: 1.0294437474839804, Train acc: 0.8746882793017456\n",
      "Iteration 33500 - Batch 1302/1894 - Train loss: 1.0292369636863539, Train acc: 0.8748321181887951\n",
      "Iteration 33600 - Batch 1402/1894 - Train loss: 1.028443256192605, Train acc: 0.8755345687811832\n",
      "Iteration 33700 - Batch 1502/1894 - Train loss: 1.02831526870975, Train acc: 0.8756029607451763\n",
      "Iteration 33800 - Batch 1602/1894 - Train loss: 1.0278857376005823, Train acc: 0.876052713661884\n",
      "Iteration 33900 - Batch 1702/1894 - Train loss: 1.0279426056010124, Train acc: 0.8759725484439225\n",
      "Iteration 34000 - Batch 1802/1894 - Train loss: 1.0285495455834974, Train acc: 0.8753639767054908\n",
      "[4, 4, 1, 3, 4, 4, 4, 2, 4, 2, 0, 0, 2, 3, 4, 1, 2, 4, 0, 4, 2, 0, 1, 4, 3, 0, 1, 0, 1, 3, 4, 1, 4, 1, 2, 2, 4, 0, 3, 0, 4, 4, 0, 3, 4, 4, 1, 0, 2, 4, 3, 3, 2, 3, 0, 3, 0, 0, 0, 0, 1, 2, 1, 1, 1, 1, 2, 0, 0, 1, 0, 0, 4, 2, 3, 4, 4, 2, 4, 4, 2, 0, 1, 3, 4, 1, 2, 2, 2, 3, 3, 1, 4, 0, 0, 0, 4, 1, 0, 0, 4, 3, 0, 3, 2, 1, 2, 1, 3, 4, 0, 1, 1, 0, 2, 1, 3, 2, 0, 2, 2, 0, 2, 1, 3, 3, 3, 4, 2, 3, 0, 3, 3, 2, 3, 0, 0, 4, 1, 2, 2, 0, 1, 1, 3, 4, 1, 2, 3, 2, 4, 0, 3, 1, 1, 3, 0, 2, 2, 1, 4, 3, 1, 1, 4, 3, 1, 2, 0, 3, 0, 0, 2, 2, 4, 4, 1, 3, 3, 3, 1, 1, 2, 2, 2, 2, 0, 2, 2, 3, 2, 1, 3, 0, 2, 0, 3, 0, 3, 3, 2, 2, 4, 1, 2, 0, 0, 0, 3, 0, 1, 4, 4, 4, 4, 4, 0, 0, 0, 2, 3, 3, 0, 3, 1, 0, 3, 4, 3, 1, 3, 2, 0, 1, 3, 2, 0, 1, 4, 3, 3, 4, 3, 1, 4, 2, 3, 0, 3, 3, 0, 1, 2, 2, 3, 4, 2, 3, 0, 4, 3, 3, 4, 1, 3, 1, 4, 4, 0, 1, 1, 2, 4, 0, 2, 4, 3, 0, 1, 2, 3, 0, 1, 1, 4, 2, 4, 2, 1, 2, 1, 4, 3, 1, 3, 0, 4, 0, 1, 3, 1, 0, 4, 4, 1, 2, 4, 3, 4, 0, 2, 3, 1, 4, 3, 4, 3, 2, 3, 1, 1, 3, 0, 4, 3, 0, 2, 3, 3, 4, 4, 2, 1, 2, 4, 3, 1, 4, 0, 1, 0, 2, 4, 1, 2, 3, 0, 2, 0, 4, 3, 0, 1, 4, 1, 0, 1, 1, 2, 1, 4, 0, 3, 3, 4, 3, 2, 3, 4, 2, 3, 1, 3, 3, 1, 4, 4, 3, 1, 2, 3, 0, 4, 3, 2, 4, 1, 0, 1, 0, 4, 3, 2, 1, 2, 4, 0, 0, 0, 0, 2, 0, 4, 3, 2, 3, 2, 2, 2, 2, 2, 2, 0, 1, 1, 4, 2, 1, 2, 0, 1, 4, 3, 1, 1, 4, 2, 4, 3, 3, 4, 0, 2, 4, 4, 0, 2, 1, 1, 3, 3, 3, 1, 2, 4, 4, 4, 4, 1, 3, 4, 2, 1, 2, 4, 4, 2, 3, 0, 0, 1, 2, 1, 1, 0, 4, 1, 1, 1, 1, 2, 0, 1, 2, 2, 0, 1, 2, 1, 0, 0, 1, 3, 2, 0, 0, 0, 2, 0, 4, 4, 1, 4, 3, 0, 3, 2, 0, 4, 0]\n",
      "[4, 4, 4, 3, 4, 4, 4, 2, 4, 2, 0, 0, 0, 3, 4, 4, 2, 4, 0, 4, 2, 0, 4, 4, 3, 0, 4, 0, 3, 3, 4, 4, 4, 4, 2, 2, 3, 0, 3, 0, 3, 4, 0, 3, 4, 4, 0, 0, 2, 4, 3, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 2, 4, 0, 0, 4, 3, 0, 0, 3, 0, 0, 4, 2, 3, 4, 4, 2, 4, 3, 2, 0, 0, 3, 4, 2, 2, 2, 2, 3, 4, 0, 4, 0, 0, 0, 2, 4, 0, 0, 4, 3, 0, 3, 2, 3, 2, 3, 3, 4, 0, 0, 3, 0, 2, 0, 3, 2, 0, 0, 2, 0, 0, 4, 3, 3, 3, 4, 2, 3, 2, 3, 3, 0, 3, 0, 0, 4, 3, 2, 2, 0, 4, 4, 3, 4, 4, 2, 3, 0, 4, 0, 4, 4, 0, 3, 0, 2, 3, 3, 4, 3, 3, 4, 4, 3, 4, 2, 0, 3, 4, 0, 2, 2, 4, 4, 4, 3, 3, 3, 3, 4, 2, 2, 3, 0, 0, 2, 2, 3, 0, 4, 3, 4, 2, 0, 3, 0, 3, 3, 2, 2, 4, 0, 2, 0, 4, 0, 3, 0, 3, 4, 0, 4, 4, 4, 0, 0, 0, 2, 3, 3, 4, 3, 4, 0, 3, 4, 3, 4, 3, 2, 2, 4, 3, 2, 0, 3, 4, 0, 3, 4, 3, 4, 4, 2, 4, 0, 3, 3, 0, 4, 2, 2, 3, 4, 2, 3, 4, 4, 3, 3, 4, 4, 3, 0, 4, 4, 0, 0, 4, 2, 4, 0, 2, 4, 3, 0, 0, 0, 3, 0, 0, 0, 4, 2, 2, 0, 3, 2, 4, 4, 3, 3, 3, 0, 2, 0, 4, 4, 4, 4, 4, 4, 4, 2, 4, 3, 4, 0, 2, 3, 4, 4, 3, 4, 3, 2, 3, 3, 3, 3, 0, 4, 3, 0, 2, 3, 3, 4, 4, 0, 4, 2, 4, 3, 0, 4, 0, 4, 0, 2, 4, 4, 2, 3, 0, 2, 4, 4, 3, 0, 4, 4, 0, 0, 4, 4, 2, 0, 4, 0, 3, 3, 3, 3, 0, 3, 4, 2, 3, 4, 3, 3, 0, 4, 3, 3, 2, 2, 3, 0, 4, 3, 2, 4, 3, 0, 4, 0, 4, 3, 3, 4, 2, 4, 0, 0, 0, 0, 2, 0, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 0, 4, 4, 3, 2, 4, 0, 0, 0, 4, 3, 4, 4, 4, 2, 4, 3, 3, 4, 0, 2, 4, 4, 0, 2, 2, 4, 3, 3, 3, 4, 2, 4, 4, 4, 4, 4, 3, 4, 2, 3, 2, 4, 4, 0, 3, 0, 0, 3, 2, 3, 4, 0, 4, 3, 3, 4, 4, 0, 0, 4, 2, 2, 0, 3, 2, 0, 0, 0, 3, 3, 2, 0, 0, 0, 2, 0, 4, 4, 3, 0, 3, 0, 3, 2, 0, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.81      0.86       100\n",
      "           3       0.73      0.95      0.82       100\n",
      "           4       0.58      0.88      0.70       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.64       500\n",
      "weighted avg       0.58      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.189662218093872, Val acc: 0.71\n",
      "Epoch 19/30\n",
      "Iteration 34100 - Batch 8/1894 - Train loss: 1.0106557541423373, Train acc: 0.8923611111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34200 - Batch 108/1894 - Train loss: 1.0246824058917685, Train acc: 0.8798738532110092\n",
      "Iteration 34300 - Batch 208/1894 - Train loss: 1.031848686448695, Train acc: 0.8733552631578947\n",
      "Iteration 34400 - Batch 308/1894 - Train loss: 1.0316967971888176, Train acc: 0.8731796116504854\n",
      "Iteration 34500 - Batch 408/1894 - Train loss: 1.030196398278029, Train acc: 0.8743887530562348\n",
      "Iteration 34600 - Batch 508/1894 - Train loss: 1.0323124361647136, Train acc: 0.8721144400785854\n",
      "Iteration 34700 - Batch 608/1894 - Train loss: 1.0301673677558774, Train acc: 0.8739737274220033\n",
      "Iteration 34800 - Batch 708/1894 - Train loss: 1.0295898299795616, Train acc: 0.8744710860366713\n",
      "Iteration 34900 - Batch 808/1894 - Train loss: 1.0297567100990541, Train acc: 0.8742660692212608\n",
      "Iteration 35000 - Batch 908/1894 - Train loss: 1.0294210417698189, Train acc: 0.8746562156215621\n",
      "Iteration 35100 - Batch 1008/1894 - Train loss: 1.030011949087867, Train acc: 0.8740089197224975\n",
      "Iteration 35200 - Batch 1108/1894 - Train loss: 1.0293168612597114, Train acc: 0.8747182146077548\n",
      "Iteration 35300 - Batch 1208/1894 - Train loss: 1.0298211967481672, Train acc: 0.8742504135649297\n",
      "Iteration 35400 - Batch 1308/1894 - Train loss: 1.029231057857356, Train acc: 0.8748090145148969\n",
      "Iteration 35500 - Batch 1408/1894 - Train loss: 1.0291634135588084, Train acc: 0.8749334634492548\n",
      "Iteration 35600 - Batch 1508/1894 - Train loss: 1.028797535567666, Train acc: 0.8752899271040424\n",
      "Iteration 35700 - Batch 1608/1894 - Train loss: 1.0286943954736865, Train acc: 0.8753884400248602\n",
      "Iteration 35800 - Batch 1708/1894 - Train loss: 1.0288236266412953, Train acc: 0.8753108543007607\n",
      "Iteration 35900 - Batch 1808/1894 - Train loss: 1.028402766283867, Train acc: 0.8757428137092316\n",
      "[1, 3, 0, 0, 4, 3, 4, 1, 2, 1, 2, 1, 2, 4, 1, 2, 4, 4, 4, 2, 2, 0, 3, 4, 1, 1, 0, 1, 0, 3, 2, 1, 1, 4, 4, 0, 3, 4, 0, 2, 1, 1, 1, 2, 0, 2, 0, 4, 0, 0, 4, 1, 0, 0, 1, 2, 4, 2, 0, 2, 4, 0, 1, 2, 1, 0, 2, 1, 4, 2, 0, 2, 1, 1, 3, 1, 3, 4, 3, 4, 1, 4, 4, 0, 4, 1, 2, 4, 3, 3, 0, 4, 2, 1, 2, 1, 3, 3, 3, 1, 3, 1, 1, 3, 4, 2, 3, 4, 2, 3, 4, 4, 1, 3, 4, 2, 2, 4, 2, 0, 3, 2, 0, 2, 4, 1, 2, 3, 4, 3, 0, 1, 3, 0, 0, 2, 4, 1, 3, 4, 0, 2, 3, 2, 4, 3, 1, 0, 1, 3, 4, 4, 1, 4, 1, 2, 0, 1, 2, 0, 0, 4, 3, 0, 4, 2, 2, 4, 1, 3, 0, 3, 4, 4, 2, 1, 0, 4, 2, 4, 3, 2, 3, 3, 4, 2, 2, 0, 0, 1, 4, 0, 3, 0, 2, 2, 0, 4, 0, 2, 1, 3, 1, 1, 3, 4, 3, 4, 2, 3, 1, 3, 0, 2, 0, 1, 0, 0, 3, 2, 0, 4, 3, 3, 1, 3, 2, 1, 1, 4, 3, 2, 4, 0, 1, 0, 1, 3, 2, 0, 4, 3, 1, 0, 2, 1, 3, 0, 2, 0, 0, 2, 1, 1, 1, 1, 4, 3, 2, 3, 2, 1, 1, 4, 4, 2, 4, 3, 0, 0, 2, 2, 0, 1, 3, 4, 2, 3, 1, 3, 4, 1, 3, 4, 1, 3, 2, 1, 0, 2, 3, 2, 3, 2, 2, 1, 4, 4, 2, 0, 1, 2, 0, 4, 1, 0, 2, 2, 1, 3, 0, 3, 0, 1, 1, 1, 3, 3, 3, 0, 1, 3, 2, 4, 2, 0, 3, 2, 1, 2, 3, 4, 3, 1, 4, 4, 0, 3, 2, 2, 3, 1, 0, 3, 1, 2, 0, 0, 2, 0, 1, 2, 1, 0, 4, 1, 0, 1, 1, 2, 2, 3, 0, 4, 3, 4, 0, 1, 4, 2, 0, 2, 3, 0, 3, 2, 4, 2, 1, 4, 1, 1, 4, 4, 2, 4, 1, 3, 0, 0, 2, 4, 2, 4, 2, 3, 1, 1, 4, 2, 2, 1, 0, 1, 3, 4, 1, 4, 3, 3, 3, 3, 0, 3, 0, 1, 4, 4, 0, 2, 0, 3, 0, 2, 1, 3, 4, 3, 3, 3, 4, 0, 1, 0, 2, 4, 0, 3, 4, 4, 3, 4, 3, 0, 4, 3, 0, 4, 2, 1, 3, 2, 3, 4, 4, 0, 0, 0, 4, 1, 2, 3, 2, 4, 3, 3, 2, 0, 1, 1, 4, 0, 2, 0, 1, 3, 0, 4, 4, 2, 3, 0, 0, 1, 3, 4, 3, 0, 2, 0, 0, 0, 1, 4, 2, 0, 0, 3, 3, 4]\n",
      "[3, 3, 0, 0, 4, 3, 4, 4, 2, 4, 2, 0, 0, 3, 0, 2, 4, 4, 4, 2, 0, 0, 3, 3, 4, 0, 0, 4, 0, 3, 0, 4, 4, 3, 4, 0, 3, 4, 0, 2, 4, 3, 4, 0, 0, 2, 0, 4, 0, 0, 4, 4, 0, 0, 3, 2, 4, 2, 0, 2, 4, 0, 4, 2, 0, 0, 2, 4, 4, 2, 0, 2, 4, 4, 3, 4, 3, 2, 3, 4, 4, 4, 4, 0, 4, 2, 2, 4, 3, 3, 0, 4, 2, 0, 2, 4, 3, 3, 3, 4, 3, 0, 4, 3, 4, 2, 3, 4, 2, 3, 4, 4, 3, 3, 4, 2, 2, 4, 0, 0, 3, 0, 0, 2, 4, 2, 2, 3, 4, 3, 0, 3, 3, 0, 0, 2, 4, 4, 3, 4, 0, 2, 3, 2, 4, 4, 3, 0, 4, 4, 3, 4, 2, 4, 4, 3, 0, 4, 0, 0, 0, 4, 4, 0, 4, 2, 0, 4, 4, 3, 0, 3, 4, 4, 2, 4, 0, 4, 2, 4, 3, 2, 3, 3, 4, 2, 2, 0, 0, 0, 4, 0, 3, 0, 0, 2, 0, 4, 0, 2, 4, 3, 0, 4, 3, 4, 4, 4, 2, 3, 4, 3, 0, 2, 0, 0, 4, 0, 3, 2, 0, 0, 3, 3, 4, 3, 2, 3, 4, 4, 3, 2, 4, 4, 4, 0, 0, 3, 2, 0, 4, 3, 3, 0, 0, 4, 3, 0, 2, 0, 0, 2, 3, 3, 3, 4, 4, 3, 2, 3, 2, 3, 3, 4, 4, 0, 4, 3, 0, 0, 2, 2, 0, 2, 0, 4, 2, 3, 3, 3, 4, 4, 3, 4, 3, 3, 2, 4, 0, 2, 3, 2, 2, 2, 2, 4, 4, 4, 2, 0, 4, 2, 0, 4, 4, 0, 2, 2, 3, 3, 0, 3, 0, 4, 3, 4, 4, 4, 3, 0, 4, 3, 3, 4, 0, 0, 3, 0, 3, 0, 3, 4, 3, 3, 4, 4, 0, 3, 0, 2, 4, 3, 0, 4, 3, 3, 0, 0, 2, 0, 0, 2, 3, 0, 4, 4, 0, 0, 3, 2, 2, 3, 0, 4, 3, 4, 0, 3, 4, 2, 0, 2, 3, 0, 3, 2, 4, 2, 3, 4, 2, 2, 4, 3, 2, 4, 0, 3, 0, 0, 2, 4, 2, 4, 2, 3, 3, 3, 0, 0, 4, 0, 0, 4, 3, 4, 4, 4, 3, 3, 3, 3, 2, 3, 0, 4, 4, 4, 4, 2, 0, 3, 0, 2, 4, 3, 4, 3, 3, 3, 3, 0, 0, 0, 2, 4, 0, 3, 4, 4, 3, 4, 3, 0, 4, 3, 0, 4, 2, 3, 3, 0, 3, 4, 4, 0, 0, 0, 4, 4, 2, 3, 0, 4, 3, 3, 2, 0, 4, 4, 4, 0, 2, 4, 0, 4, 0, 4, 4, 2, 3, 0, 0, 4, 3, 4, 3, 0, 2, 0, 0, 0, 4, 4, 2, 0, 0, 3, 3, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.90      0.78      0.83       100\n",
      "           3       0.71      0.89      0.79       100\n",
      "           4       0.59      0.91      0.71       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1909855976700783, Val acc: 0.706\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36000 - Batch 14/1894 - Train loss: 1.0330930590629577, Train acc: 0.8729166666666667\n",
      "Iteration 36100 - Batch 114/1894 - Train loss: 1.031553241999253, Train acc: 0.8730978260869565\n",
      "Iteration 36200 - Batch 214/1894 - Train loss: 1.0309737510459367, Train acc: 0.8732558139534884\n",
      "Iteration 36300 - Batch 314/1894 - Train loss: 1.0273350687254044, Train acc: 0.8768849206349206\n",
      "Iteration 36400 - Batch 414/1894 - Train loss: 1.0260923230504415, Train acc: 0.8780873493975904\n",
      "Iteration 36500 - Batch 514/1894 - Train loss: 1.0270299408042316, Train acc: 0.877002427184466\n",
      "Iteration 36600 - Batch 614/1894 - Train loss: 1.0273609296093142, Train acc: 0.8766768292682927\n",
      "Iteration 36700 - Batch 714/1894 - Train loss: 1.026732400163904, Train acc: 0.8772727272727273\n",
      "Iteration 36800 - Batch 814/1894 - Train loss: 1.0263696075217124, Train acc: 0.877569018404908\n",
      "Iteration 36900 - Batch 914/1894 - Train loss: 1.02633708682868, Train acc: 0.8777322404371585\n",
      "Iteration 37000 - Batch 1014/1894 - Train loss: 1.0273477946596192, Train acc: 0.8766625615763547\n",
      "Iteration 37100 - Batch 1114/1894 - Train loss: 1.0273633750030278, Train acc: 0.8767656950672645\n",
      "Iteration 37200 - Batch 1214/1894 - Train loss: 1.0266766347021723, Train acc: 0.8775205761316872\n",
      "Iteration 37300 - Batch 1314/1894 - Train loss: 1.0275977698569063, Train acc: 0.8766397338403041\n",
      "Iteration 37400 - Batch 1414/1894 - Train loss: 1.0271950627384254, Train acc: 0.8771422261484099\n",
      "Iteration 37500 - Batch 1514/1894 - Train loss: 1.0276456928095803, Train acc: 0.876608910891089\n",
      "Iteration 37600 - Batch 1614/1894 - Train loss: 1.0277934249340566, Train acc: 0.8764125386996904\n",
      "Iteration 37700 - Batch 1714/1894 - Train loss: 1.0262460430579006, Train acc: 0.8779883381924198\n",
      "Iteration 37800 - Batch 1814/1894 - Train loss: 1.0270432886670116, Train acc: 0.8771694214876034\n",
      "[3, 2, 4, 1, 3, 2, 4, 1, 0, 0, 2, 4, 3, 1, 0, 2, 0, 1, 2, 2, 1, 2, 4, 0, 1, 4, 4, 3, 4, 4, 1, 1, 3, 3, 2, 4, 4, 2, 2, 0, 3, 1, 2, 1, 3, 4, 0, 4, 3, 4, 2, 0, 4, 4, 3, 0, 2, 2, 1, 2, 0, 0, 0, 3, 0, 1, 2, 3, 0, 1, 3, 4, 1, 4, 2, 2, 1, 3, 4, 1, 2, 1, 4, 3, 2, 2, 4, 2, 4, 2, 3, 2, 1, 3, 2, 4, 3, 2, 1, 0, 2, 2, 3, 0, 2, 3, 4, 4, 1, 0, 1, 1, 4, 4, 2, 2, 3, 2, 0, 0, 1, 2, 1, 0, 3, 2, 1, 4, 2, 2, 1, 1, 3, 4, 1, 4, 3, 4, 1, 3, 3, 0, 4, 1, 0, 2, 2, 3, 2, 3, 4, 0, 1, 1, 3, 2, 3, 4, 3, 3, 2, 1, 0, 0, 1, 3, 0, 2, 0, 4, 4, 0, 2, 0, 3, 1, 3, 1, 0, 3, 4, 4, 1, 3, 1, 3, 3, 3, 2, 0, 1, 0, 2, 0, 2, 3, 0, 1, 2, 1, 0, 0, 0, 4, 0, 3, 0, 4, 1, 3, 4, 0, 2, 4, 1, 1, 2, 0, 4, 4, 4, 1, 4, 4, 3, 3, 2, 1, 4, 0, 0, 4, 3, 1, 0, 0, 3, 4, 2, 3, 2, 2, 4, 0, 1, 0, 2, 4, 4, 0, 0, 0, 2, 2, 2, 3, 4, 2, 0, 2, 4, 4, 3, 1, 0, 0, 1, 4, 1, 2, 2, 2, 2, 4, 3, 4, 2, 0, 1, 1, 3, 3, 3, 2, 0, 0, 1, 4, 3, 0, 0, 3, 2, 3, 1, 3, 0, 0, 1, 4, 4, 0, 1, 3, 2, 4, 3, 3, 1, 0, 2, 3, 4, 1, 0, 3, 4, 4, 3, 1, 4, 3, 1, 2, 2, 1, 4, 0, 3, 4, 2, 1, 1, 3, 4, 1, 3, 3, 4, 1, 0, 0, 3, 1, 1, 3, 4, 4, 2, 1, 1, 4, 3, 4, 4, 3, 3, 0, 3, 4, 0, 3, 0, 2, 3, 0, 2, 3, 3, 4, 0, 4, 2, 4, 0, 0, 1, 2, 0, 1, 0, 4, 3, 4, 3, 2, 2, 2, 1, 2, 0, 1, 3, 0, 2, 2, 0, 1, 1, 4, 1, 4, 3, 2, 1, 4, 0, 1, 4, 2, 1, 2, 0, 2, 0, 2, 0, 2, 1, 3, 0, 2, 1, 3, 2, 1, 0, 0, 2, 0, 1, 3, 2, 1, 3, 0, 1, 0, 4, 0, 4, 0, 1, 4, 2, 4, 1, 3, 4, 2, 2, 3, 4, 3, 0, 2, 1, 3, 4, 0, 3, 1, 0, 1, 0, 1, 1, 4, 1, 0, 4, 2, 1, 4, 2, 0, 0, 3, 4, 3, 4, 4, 1, 2, 0, 1, 1, 4, 3, 3, 0, 0, 3, 1, 2, 3, 3, 3, 4, 1]\n",
      "[3, 2, 4, 4, 3, 2, 3, 3, 0, 0, 2, 4, 3, 0, 0, 2, 0, 4, 0, 2, 4, 2, 4, 0, 2, 4, 4, 3, 4, 4, 3, 4, 3, 3, 2, 4, 4, 2, 2, 0, 3, 4, 2, 3, 3, 4, 0, 3, 3, 4, 2, 0, 4, 4, 3, 4, 2, 2, 3, 4, 0, 0, 0, 3, 0, 0, 2, 3, 0, 3, 3, 4, 0, 4, 2, 2, 4, 3, 4, 4, 2, 3, 4, 3, 2, 2, 4, 2, 4, 2, 3, 0, 4, 3, 2, 4, 0, 2, 4, 0, 2, 2, 3, 0, 2, 3, 4, 4, 0, 0, 4, 4, 4, 4, 0, 2, 3, 2, 0, 0, 4, 2, 0, 0, 3, 2, 3, 4, 2, 2, 2, 0, 3, 4, 3, 4, 3, 4, 3, 3, 3, 0, 4, 3, 0, 2, 0, 3, 2, 3, 3, 2, 4, 4, 3, 2, 3, 4, 3, 3, 2, 4, 0, 0, 3, 3, 0, 2, 0, 4, 4, 0, 2, 0, 3, 4, 3, 4, 0, 3, 4, 4, 2, 3, 2, 3, 3, 3, 2, 2, 4, 0, 0, 0, 0, 3, 0, 3, 0, 4, 0, 0, 0, 4, 0, 3, 0, 4, 3, 3, 4, 0, 2, 4, 3, 4, 2, 0, 4, 4, 3, 4, 4, 4, 3, 3, 2, 4, 4, 0, 0, 4, 3, 3, 2, 0, 3, 4, 2, 3, 3, 0, 4, 0, 4, 0, 0, 4, 4, 0, 0, 0, 2, 2, 2, 3, 4, 0, 0, 2, 4, 4, 3, 4, 0, 0, 4, 4, 4, 2, 2, 2, 0, 4, 3, 4, 2, 4, 0, 4, 3, 3, 4, 2, 0, 0, 4, 4, 3, 0, 0, 3, 2, 3, 4, 3, 0, 2, 4, 4, 4, 0, 3, 3, 2, 4, 3, 3, 0, 0, 2, 3, 4, 4, 0, 3, 4, 4, 3, 3, 3, 3, 3, 2, 2, 4, 4, 0, 3, 4, 0, 2, 3, 3, 4, 3, 3, 3, 2, 0, 0, 0, 3, 4, 3, 3, 4, 3, 2, 3, 4, 4, 3, 4, 4, 3, 3, 4, 3, 4, 0, 3, 0, 0, 3, 0, 2, 3, 3, 4, 0, 4, 2, 4, 0, 0, 0, 2, 4, 4, 0, 4, 3, 4, 3, 2, 0, 2, 0, 2, 0, 3, 3, 4, 2, 2, 2, 4, 0, 4, 0, 4, 3, 2, 3, 4, 0, 4, 4, 2, 3, 2, 0, 3, 0, 2, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 0, 0, 0, 4, 3, 2, 3, 3, 0, 4, 0, 4, 0, 4, 0, 4, 4, 2, 4, 4, 4, 4, 2, 2, 3, 4, 3, 0, 2, 3, 3, 4, 0, 3, 3, 0, 4, 0, 3, 3, 0, 4, 0, 4, 2, 4, 4, 4, 0, 2, 3, 0, 3, 4, 4, 0, 2, 0, 4, 4, 4, 3, 3, 0, 0, 3, 0, 2, 3, 4, 3, 2, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.80      0.83       100\n",
      "           3       0.71      0.96      0.81       100\n",
      "           4       0.61      0.90      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1933056116104126, Val acc: 0.71\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37900 - Batch 20/1894 - Train loss: 1.0436855753262837, Train acc: 0.8616071428571429\n",
      "Iteration 38000 - Batch 120/1894 - Train loss: 1.0233188946385028, Train acc: 0.881198347107438\n",
      "Iteration 38100 - Batch 220/1894 - Train loss: 1.0221646468563856, Train acc: 0.8815045248868778\n",
      "Iteration 38200 - Batch 320/1894 - Train loss: 1.023121343409161, Train acc: 0.8811331775700935\n",
      "Iteration 38300 - Batch 420/1894 - Train loss: 1.024307543902952, Train acc: 0.8799732779097387\n",
      "Iteration 38400 - Batch 520/1894 - Train loss: 1.0237927028405231, Train acc: 0.880338291746641\n",
      "Iteration 38500 - Batch 620/1894 - Train loss: 1.0247758899525936, Train acc: 0.8794786634460547\n",
      "Iteration 38600 - Batch 720/1894 - Train loss: 1.0250019780805801, Train acc: 0.8791175450762829\n",
      "Iteration 38700 - Batch 820/1894 - Train loss: 1.0258766087486741, Train acc: 0.8782353836784409\n",
      "Iteration 38800 - Batch 920/1894 - Train loss: 1.0252636464618057, Train acc: 0.8790377307274702\n",
      "Iteration 38900 - Batch 1020/1894 - Train loss: 1.0264578256737824, Train acc: 0.8778158667972575\n",
      "Iteration 39000 - Batch 1120/1894 - Train loss: 1.026307328219503, Train acc: 0.8780664585191793\n",
      "Iteration 39100 - Batch 1220/1894 - Train loss: 1.0251178383143782, Train acc: 0.8791973791973792\n",
      "Iteration 39200 - Batch 1320/1894 - Train loss: 1.0251969248394819, Train acc: 0.8790688872066617\n",
      "Iteration 39300 - Batch 1420/1894 - Train loss: 1.0247850486881542, Train acc: 0.8793983110485574\n",
      "Iteration 39400 - Batch 1520/1894 - Train loss: 1.0252812616061726, Train acc: 0.8788831360946746\n",
      "Iteration 39500 - Batch 1620/1894 - Train loss: 1.0253781538403821, Train acc: 0.8788170882171499\n",
      "Iteration 39600 - Batch 1720/1894 - Train loss: 1.0254333650283105, Train acc: 0.8787950319581639\n",
      "Iteration 39700 - Batch 1820/1894 - Train loss: 1.0256789649403535, Train acc: 0.878500823723229\n",
      "[4, 4, 1, 1, 2, 0, 2, 0, 3, 0, 1, 0, 4, 2, 3, 2, 1, 2, 2, 3, 4, 0, 3, 2, 0, 2, 0, 4, 3, 3, 1, 4, 2, 3, 0, 0, 1, 3, 2, 2, 4, 2, 1, 4, 2, 3, 2, 0, 2, 0, 4, 2, 0, 1, 2, 4, 0, 3, 1, 2, 3, 4, 2, 2, 1, 3, 1, 0, 2, 4, 4, 3, 3, 0, 2, 0, 3, 2, 1, 1, 0, 0, 1, 3, 3, 3, 1, 3, 3, 1, 4, 0, 0, 2, 3, 2, 3, 4, 2, 0, 1, 0, 3, 0, 1, 3, 1, 0, 3, 1, 1, 1, 4, 1, 2, 2, 3, 4, 2, 3, 3, 4, 0, 1, 1, 1, 2, 0, 3, 0, 3, 1, 1, 0, 4, 3, 3, 3, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 2, 4, 2, 0, 1, 1, 3, 2, 3, 4, 1, 3, 4, 4, 0, 4, 4, 1, 4, 0, 0, 4, 4, 1, 0, 3, 3, 1, 3, 0, 3, 3, 1, 3, 4, 1, 1, 3, 4, 0, 4, 1, 1, 0, 2, 0, 4, 2, 3, 2, 3, 3, 3, 3, 4, 4, 0, 2, 3, 1, 2, 0, 0, 3, 2, 0, 1, 3, 4, 4, 3, 3, 1, 3, 4, 0, 2, 4, 0, 1, 4, 1, 4, 4, 4, 2, 0, 2, 4, 4, 3, 3, 4, 2, 1, 2, 1, 0, 3, 0, 2, 1, 0, 3, 3, 2, 3, 2, 2, 4, 2, 0, 1, 0, 2, 0, 2, 0, 3, 3, 2, 4, 2, 4, 0, 4, 0, 2, 2, 3, 0, 0, 3, 3, 2, 2, 4, 4, 3, 3, 1, 4, 0, 1, 0, 4, 0, 0, 3, 4, 4, 1, 1, 4, 2, 1, 2, 4, 1, 4, 2, 0, 4, 2, 1, 0, 1, 4, 0, 4, 0, 4, 1, 4, 1, 0, 1, 0, 2, 2, 2, 2, 1, 2, 2, 1, 2, 3, 2, 4, 4, 4, 3, 1, 4, 3, 0, 0, 3, 4, 4, 1, 3, 3, 3, 1, 1, 1, 4, 2, 1, 4, 1, 1, 3, 4, 2, 4, 1, 0, 1, 2, 0, 4, 0, 1, 4, 0, 0, 2, 1, 4, 4, 4, 4, 1, 0, 3, 0, 1, 1, 0, 1, 0, 1, 1, 2, 3, 2, 1, 0, 2, 4, 2, 0, 4, 1, 4, 2, 4, 3, 2, 1, 1, 1, 2, 4, 3, 4, 4, 2, 3, 3, 1, 2, 0, 1, 4, 4, 2, 1, 3, 4, 3, 0, 1, 2, 3, 3, 2, 1, 2, 3, 0, 3, 4, 1, 1, 3, 1, 2, 1, 3, 2, 0, 0, 2, 4, 3, 4, 2, 4, 0, 4, 4, 0, 3, 0, 2, 0, 4, 3, 0, 0, 1, 0, 1, 2, 3, 4, 4, 3, 3, 1, 2, 4, 2, 0, 3, 2, 2, 0, 4, 2, 3, 2, 0, 0, 1, 3, 3]\n",
      "[4, 4, 4, 0, 0, 0, 0, 0, 3, 3, 4, 0, 4, 2, 3, 2, 3, 2, 2, 3, 4, 0, 3, 2, 0, 2, 0, 4, 3, 3, 0, 4, 0, 3, 0, 0, 4, 3, 2, 2, 3, 2, 4, 4, 2, 3, 2, 0, 0, 0, 4, 2, 0, 4, 0, 4, 0, 3, 4, 2, 3, 4, 0, 2, 4, 3, 0, 0, 2, 4, 4, 3, 3, 0, 2, 0, 3, 2, 3, 4, 0, 0, 4, 3, 3, 3, 3, 3, 3, 4, 4, 0, 0, 2, 3, 2, 3, 4, 2, 0, 3, 0, 2, 0, 3, 3, 3, 0, 3, 3, 4, 4, 4, 3, 3, 0, 3, 4, 2, 3, 3, 4, 0, 4, 0, 4, 2, 0, 3, 0, 3, 3, 4, 0, 4, 3, 3, 3, 0, 0, 0, 3, 0, 4, 4, 2, 0, 0, 2, 2, 0, 2, 0, 0, 4, 3, 2, 3, 4, 3, 3, 4, 4, 0, 4, 4, 0, 4, 0, 0, 3, 4, 4, 0, 3, 3, 4, 3, 0, 3, 3, 3, 3, 3, 4, 0, 3, 4, 0, 4, 4, 3, 4, 2, 0, 4, 3, 3, 0, 3, 3, 3, 3, 4, 4, 0, 2, 4, 4, 0, 0, 0, 3, 3, 0, 2, 3, 4, 4, 3, 4, 3, 3, 4, 0, 2, 0, 0, 3, 4, 4, 3, 4, 4, 2, 4, 2, 0, 4, 3, 3, 4, 2, 4, 2, 0, 0, 3, 0, 2, 4, 0, 3, 3, 0, 3, 2, 2, 4, 2, 0, 4, 0, 2, 0, 2, 0, 3, 4, 0, 4, 2, 4, 0, 4, 0, 2, 0, 3, 0, 0, 3, 0, 2, 2, 2, 4, 3, 3, 3, 4, 0, 4, 0, 2, 0, 2, 3, 4, 2, 3, 3, 4, 2, 3, 2, 3, 0, 4, 2, 0, 4, 2, 4, 0, 4, 4, 0, 4, 0, 4, 4, 4, 0, 0, 3, 0, 4, 2, 2, 2, 4, 2, 0, 0, 2, 3, 0, 4, 4, 4, 3, 3, 4, 3, 0, 0, 3, 4, 4, 0, 3, 3, 3, 4, 3, 3, 4, 2, 3, 4, 4, 4, 3, 4, 2, 4, 4, 0, 4, 2, 0, 4, 2, 0, 3, 3, 0, 2, 0, 4, 4, 4, 4, 0, 0, 3, 4, 2, 4, 0, 3, 0, 4, 4, 2, 3, 2, 0, 0, 0, 4, 2, 0, 4, 2, 4, 2, 3, 3, 2, 0, 4, 2, 2, 4, 3, 4, 4, 0, 3, 3, 4, 2, 0, 4, 4, 4, 0, 2, 3, 4, 3, 0, 4, 0, 3, 3, 2, 3, 2, 3, 0, 3, 4, 4, 4, 3, 4, 2, 0, 3, 2, 0, 0, 2, 4, 4, 3, 2, 3, 0, 4, 4, 0, 3, 0, 2, 0, 4, 3, 2, 0, 3, 0, 3, 2, 3, 4, 4, 3, 3, 4, 2, 4, 2, 0, 3, 2, 2, 0, 4, 2, 3, 2, 0, 0, 4, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.87      0.78      0.82       100\n",
      "           3       0.69      0.94      0.80       100\n",
      "           4       0.60      0.85      0.70       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.57      0.70      0.62       500\n",
      "weighted avg       0.57      0.70      0.62       500\n",
      "\n",
      "Val loss: 1.1988657861948013, Val acc: 0.698\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39800 - Batch 26/1894 - Train loss: 1.0225500928031073, Train acc: 0.8819444444444444\n",
      "Iteration 39900 - Batch 126/1894 - Train loss: 1.0220615474257881, Train acc: 0.8811515748031497\n",
      "Iteration 40000 - Batch 226/1894 - Train loss: 1.020915027757048, Train acc: 0.8827092511013216\n",
      "Iteration 40100 - Batch 326/1894 - Train loss: 1.0184232692835162, Train acc: 0.886085626911315\n",
      "Iteration 40200 - Batch 426/1894 - Train loss: 1.019648632204784, Train acc: 0.8848067915690867\n",
      "Iteration 40300 - Batch 526/1894 - Train loss: 1.021729332559249, Train acc: 0.8827680265654649\n",
      "Iteration 40400 - Batch 626/1894 - Train loss: 1.0221037084215947, Train acc: 0.8822268740031898\n",
      "Iteration 40500 - Batch 726/1894 - Train loss: 1.0218555363205144, Train acc: 0.8824363823933975\n",
      "Iteration 40600 - Batch 826/1894 - Train loss: 1.0221038812449361, Train acc: 0.8821039903264812\n",
      "Iteration 40700 - Batch 926/1894 - Train loss: 1.022195127853941, Train acc: 0.8819444444444444\n",
      "Iteration 40800 - Batch 1026/1894 - Train loss: 1.02277762754054, Train acc: 0.8813595423563778\n",
      "Iteration 40900 - Batch 1126/1894 - Train loss: 1.0229760486146677, Train acc: 0.8811002661934338\n",
      "Iteration 41000 - Batch 1226/1894 - Train loss: 1.0229469195749086, Train acc: 0.8811634066829666\n",
      "Iteration 41100 - Batch 1326/1894 - Train loss: 1.0237147511623816, Train acc: 0.8802986058779201\n",
      "Iteration 41200 - Batch 1426/1894 - Train loss: 1.0237770636514425, Train acc: 0.8802119831814996\n",
      "Iteration 41300 - Batch 1526/1894 - Train loss: 1.0242279588434535, Train acc: 0.8797274066797642\n",
      "Iteration 41400 - Batch 1626/1894 - Train loss: 1.0245198150976493, Train acc: 0.8794368469575906\n",
      "Iteration 41500 - Batch 1726/1894 - Train loss: 1.02417482709222, Train acc: 0.8798675448755067\n",
      "Iteration 41600 - Batch 1826/1894 - Train loss: 1.0239320213702054, Train acc: 0.8800629447181171\n",
      "[1, 3, 0, 2, 0, 3, 0, 2, 1, 4, 3, 2, 2, 2, 2, 3, 3, 4, 1, 3, 1, 1, 2, 2, 2, 4, 3, 1, 1, 4, 0, 2, 4, 4, 0, 1, 3, 1, 3, 4, 0, 1, 0, 4, 3, 1, 1, 2, 2, 3, 3, 0, 4, 0, 4, 1, 4, 3, 1, 2, 4, 1, 2, 0, 1, 4, 4, 4, 0, 1, 4, 1, 3, 3, 0, 3, 3, 4, 2, 3, 1, 2, 0, 4, 3, 3, 0, 2, 1, 4, 1, 1, 0, 1, 2, 4, 3, 3, 3, 1, 3, 1, 4, 1, 1, 4, 4, 1, 3, 4, 1, 0, 3, 0, 3, 2, 1, 0, 0, 0, 3, 0, 3, 4, 1, 4, 0, 0, 3, 0, 1, 4, 0, 1, 4, 3, 0, 1, 4, 1, 2, 1, 4, 4, 0, 2, 4, 0, 2, 4, 3, 0, 2, 4, 1, 4, 2, 2, 2, 3, 1, 2, 0, 1, 0, 2, 4, 2, 4, 3, 4, 0, 2, 0, 0, 0, 4, 2, 3, 1, 1, 1, 4, 1, 1, 4, 4, 4, 2, 4, 1, 0, 0, 1, 1, 1, 0, 2, 2, 4, 1, 1, 3, 4, 0, 4, 0, 0, 0, 0, 4, 3, 2, 3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 2, 1, 3, 2, 3, 1, 0, 4, 0, 3, 4, 3, 0, 4, 0, 1, 2, 4, 3, 0, 0, 1, 0, 0, 3, 1, 3, 2, 0, 1, 4, 2, 3, 1, 3, 0, 4, 0, 0, 0, 3, 2, 1, 1, 4, 3, 2, 4, 2, 0, 2, 4, 3, 0, 0, 4, 2, 4, 0, 2, 1, 1, 3, 3, 2, 4, 2, 1, 2, 1, 4, 0, 0, 0, 3, 3, 4, 4, 2, 0, 1, 1, 2, 2, 1, 3, 1, 0, 3, 2, 2, 4, 2, 0, 3, 3, 2, 3, 4, 4, 4, 3, 0, 2, 4, 4, 2, 2, 1, 2, 1, 0, 1, 3, 0, 2, 4, 1, 4, 2, 3, 1, 3, 3, 0, 3, 4, 0, 4, 1, 0, 3, 2, 3, 4, 2, 2, 4, 0, 4, 4, 2, 1, 0, 3, 3, 1, 1, 4, 2, 0, 1, 1, 3, 3, 1, 1, 2, 0, 3, 1, 3, 1, 3, 1, 3, 2, 4, 2, 1, 4, 3, 3, 2, 3, 2, 2, 0, 4, 4, 2, 4, 2, 3, 4, 3, 0, 3, 4, 0, 1, 3, 4, 2, 3, 0, 2, 2, 4, 3, 2, 1, 2, 1, 0, 0, 1, 3, 0, 4, 2, 4, 2, 2, 3, 1, 3, 2, 1, 2, 2, 2, 4, 4, 3, 1, 4, 2, 4, 1, 1, 1, 1, 4, 4, 0, 2, 3, 0, 0, 2, 2, 0, 0, 0, 2, 2, 3, 0, 1, 0, 1, 3, 3, 0, 1, 2, 1, 2, 2, 3, 2, 0, 2, 2, 0, 0, 1, 3, 4, 2, 4, 4, 4, 0, 4]\n",
      "[4, 3, 0, 2, 0, 3, 0, 2, 0, 4, 3, 2, 2, 2, 2, 3, 3, 4, 4, 3, 0, 3, 2, 2, 3, 0, 0, 3, 4, 4, 0, 2, 4, 4, 0, 3, 3, 4, 3, 4, 0, 4, 0, 4, 3, 0, 4, 2, 2, 3, 3, 0, 4, 0, 4, 4, 4, 4, 0, 2, 4, 2, 2, 0, 4, 0, 4, 4, 0, 3, 4, 3, 3, 3, 0, 3, 3, 4, 2, 3, 0, 2, 0, 4, 3, 3, 0, 2, 4, 3, 3, 4, 0, 2, 0, 4, 3, 3, 3, 0, 3, 3, 4, 0, 0, 4, 4, 4, 3, 4, 4, 0, 4, 0, 3, 2, 4, 0, 0, 0, 3, 0, 3, 4, 4, 4, 0, 0, 3, 0, 4, 4, 0, 3, 4, 4, 0, 4, 4, 4, 2, 2, 4, 4, 0, 2, 4, 0, 0, 4, 3, 0, 2, 4, 4, 2, 2, 0, 2, 3, 0, 2, 0, 2, 0, 2, 4, 2, 4, 3, 4, 0, 2, 0, 0, 0, 4, 2, 3, 4, 4, 0, 4, 4, 4, 4, 4, 4, 2, 4, 4, 0, 0, 4, 3, 4, 0, 2, 2, 4, 3, 3, 3, 4, 0, 4, 0, 0, 0, 0, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 2, 0, 3, 2, 3, 4, 0, 4, 0, 3, 4, 4, 0, 4, 0, 3, 0, 4, 3, 0, 0, 4, 4, 0, 3, 4, 3, 2, 0, 4, 4, 3, 3, 4, 3, 0, 4, 0, 0, 0, 3, 0, 3, 3, 4, 3, 0, 4, 2, 0, 2, 4, 3, 0, 0, 4, 2, 4, 0, 2, 4, 4, 3, 3, 2, 4, 2, 4, 2, 4, 4, 4, 0, 0, 3, 3, 4, 4, 2, 2, 4, 3, 2, 3, 3, 3, 2, 0, 3, 2, 2, 4, 2, 0, 3, 3, 0, 3, 4, 4, 4, 3, 0, 3, 4, 4, 2, 2, 4, 2, 0, 0, 0, 3, 0, 2, 4, 0, 4, 2, 3, 4, 3, 3, 0, 3, 4, 0, 3, 3, 0, 3, 0, 3, 4, 2, 2, 4, 0, 4, 4, 0, 3, 0, 3, 3, 0, 3, 4, 2, 0, 4, 0, 3, 3, 4, 4, 2, 0, 4, 3, 3, 2, 3, 3, 3, 2, 4, 2, 3, 4, 3, 3, 2, 3, 2, 2, 0, 4, 4, 2, 4, 0, 3, 4, 3, 4, 3, 4, 0, 3, 3, 4, 2, 3, 0, 0, 2, 4, 3, 0, 4, 2, 4, 0, 0, 3, 3, 0, 4, 2, 4, 0, 2, 3, 3, 3, 2, 4, 2, 2, 2, 4, 3, 3, 4, 4, 2, 4, 4, 0, 0, 3, 3, 4, 0, 2, 3, 0, 0, 0, 2, 0, 0, 0, 2, 2, 3, 0, 3, 0, 4, 3, 3, 0, 4, 2, 3, 2, 2, 3, 0, 4, 2, 2, 0, 0, 3, 3, 4, 0, 4, 4, 4, 0, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.91      0.79      0.84       100\n",
      "           3       0.71      0.94      0.81       100\n",
      "           4       0.62      0.92      0.74       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.182163305580616, Val acc: 0.72\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41700 - Batch 32/1894 - Train loss: 0.9975883635607633, Train acc: 0.9081439393939394\n",
      "Iteration 41800 - Batch 132/1894 - Train loss: 1.0206615400493593, Train acc: 0.8834586466165414\n",
      "Iteration 41900 - Batch 232/1894 - Train loss: 1.0216643462365278, Train acc: 0.8829130901287554\n",
      "Iteration 42000 - Batch 332/1894 - Train loss: 1.0224235371068433, Train acc: 0.8823198198198198\n",
      "Iteration 42100 - Batch 432/1894 - Train loss: 1.0236925471737532, Train acc: 0.8807736720554272\n",
      "Iteration 42200 - Batch 532/1894 - Train loss: 1.0237445125660352, Train acc: 0.880452626641651\n",
      "Iteration 42300 - Batch 632/1894 - Train loss: 1.021835111987911, Train acc: 0.8826026856240127\n",
      "Iteration 42400 - Batch 732/1894 - Train loss: 1.0225847075613264, Train acc: 0.8818212824010914\n",
      "Iteration 42500 - Batch 832/1894 - Train loss: 1.021207461122419, Train acc: 0.883140756302521\n",
      "Iteration 42600 - Batch 932/1894 - Train loss: 1.0217383025415714, Train acc: 0.882569667738478\n",
      "Iteration 42700 - Batch 1032/1894 - Train loss: 1.0222660891661224, Train acc: 0.882169651500484\n",
      "Iteration 42800 - Batch 1132/1894 - Train loss: 1.0228851467555113, Train acc: 0.881371359223301\n",
      "Iteration 42900 - Batch 1232/1894 - Train loss: 1.022100740637319, Train acc: 0.8821218572587186\n",
      "Iteration 43000 - Batch 1332/1894 - Train loss: 1.0220850757969473, Train acc: 0.8821971117779445\n",
      "Iteration 43100 - Batch 1432/1894 - Train loss: 1.021670682980976, Train acc: 0.8826543963712491\n",
      "Iteration 43200 - Batch 1532/1894 - Train loss: 1.0212597359027726, Train acc: 0.883011252446184\n",
      "Iteration 43300 - Batch 1632/1894 - Train loss: 1.0212925388560439, Train acc: 0.8829416717697489\n",
      "Iteration 43400 - Batch 1732/1894 - Train loss: 1.0212609419503518, Train acc: 0.8829522504327756\n",
      "Iteration 43500 - Batch 1832/1894 - Train loss: 1.0210958535529457, Train acc: 0.8831151118385161\n",
      "[4, 1, 1, 3, 4, 0, 1, 1, 1, 2, 2, 4, 3, 1, 2, 3, 0, 4, 3, 2, 3, 0, 3, 4, 0, 0, 0, 4, 1, 2, 3, 4, 1, 4, 3, 4, 3, 2, 2, 1, 2, 3, 4, 0, 4, 3, 0, 0, 1, 4, 3, 1, 1, 0, 0, 1, 0, 2, 1, 4, 1, 0, 3, 0, 0, 3, 2, 4, 0, 3, 3, 4, 2, 1, 4, 1, 2, 1, 2, 3, 2, 1, 2, 1, 2, 4, 2, 3, 0, 0, 2, 1, 0, 1, 0, 4, 3, 1, 3, 3, 4, 0, 0, 2, 2, 1, 1, 4, 2, 1, 3, 1, 1, 0, 1, 0, 0, 3, 3, 4, 3, 2, 2, 0, 0, 4, 3, 0, 4, 1, 1, 2, 2, 3, 4, 0, 3, 1, 0, 3, 2, 0, 1, 4, 2, 4, 3, 1, 1, 0, 3, 0, 2, 0, 4, 0, 4, 4, 1, 0, 0, 3, 3, 1, 0, 0, 1, 2, 0, 0, 2, 1, 1, 3, 0, 2, 3, 4, 2, 4, 2, 1, 0, 3, 1, 0, 0, 0, 3, 0, 4, 3, 0, 1, 2, 0, 2, 1, 2, 3, 1, 4, 0, 2, 1, 1, 3, 2, 2, 1, 0, 1, 3, 1, 1, 2, 4, 3, 0, 2, 3, 2, 0, 4, 2, 2, 4, 4, 3, 1, 2, 4, 4, 1, 2, 0, 1, 2, 4, 2, 1, 4, 1, 3, 4, 1, 1, 4, 0, 4, 3, 1, 3, 1, 1, 0, 0, 3, 1, 3, 4, 2, 3, 2, 4, 0, 2, 4, 1, 4, 2, 0, 1, 0, 2, 4, 2, 3, 3, 1, 0, 2, 0, 0, 3, 2, 4, 4, 4, 1, 3, 1, 2, 2, 4, 3, 0, 1, 3, 2, 0, 0, 2, 4, 2, 3, 3, 1, 4, 4, 4, 0, 1, 2, 1, 3, 4, 4, 2, 2, 0, 1, 1, 0, 2, 4, 2, 4, 3, 0, 4, 1, 1, 0, 3, 2, 3, 3, 1, 0, 4, 2, 2, 3, 1, 1, 4, 4, 2, 3, 4, 3, 2, 2, 1, 3, 0, 2, 1, 1, 0, 2, 3, 0, 2, 3, 3, 1, 1, 2, 3, 2, 4, 3, 4, 2, 0, 4, 4, 4, 3, 0, 3, 0, 0, 4, 4, 2, 2, 3, 1, 2, 3, 1, 3, 4, 0, 2, 0, 1, 1, 0, 0, 2, 4, 3, 4, 2, 2, 2, 3, 0, 2, 0, 0, 2, 1, 2, 3, 4, 3, 0, 4, 4, 0, 2, 3, 3, 1, 0, 2, 4, 2, 4, 4, 4, 3, 3, 4, 3, 3, 2, 4, 4, 0, 1, 2, 2, 4, 1, 0, 3, 4, 0, 3, 3, 0, 4, 4, 2, 2, 4, 4, 4, 1, 3, 3, 3, 1, 1, 4, 4, 4, 0, 3, 2, 3, 0, 1, 3, 0, 0, 3, 1, 3, 1, 0, 0, 2, 0, 1, 1, 4, 3, 3, 1, 2, 4, 4, 4]\n",
      "[4, 4, 4, 3, 4, 0, 4, 4, 3, 2, 2, 4, 3, 4, 2, 3, 0, 4, 3, 2, 3, 0, 3, 3, 0, 0, 0, 4, 3, 2, 3, 4, 4, 4, 3, 4, 3, 0, 2, 3, 2, 3, 4, 4, 4, 3, 0, 0, 0, 2, 3, 4, 0, 0, 0, 4, 0, 2, 4, 4, 4, 0, 3, 0, 0, 3, 0, 4, 0, 3, 3, 4, 2, 2, 4, 4, 2, 0, 2, 3, 2, 4, 4, 4, 2, 4, 2, 3, 0, 4, 2, 3, 0, 4, 0, 3, 3, 4, 3, 3, 4, 0, 0, 2, 2, 3, 4, 4, 2, 3, 3, 3, 0, 0, 4, 0, 0, 3, 3, 4, 3, 2, 2, 0, 0, 4, 3, 0, 4, 2, 2, 2, 2, 3, 4, 0, 3, 0, 0, 4, 2, 0, 4, 4, 2, 4, 3, 0, 2, 0, 3, 0, 2, 0, 4, 0, 4, 4, 0, 4, 0, 3, 3, 4, 0, 0, 4, 2, 0, 2, 2, 4, 0, 3, 0, 2, 3, 4, 2, 4, 0, 4, 0, 3, 3, 2, 0, 0, 3, 0, 4, 3, 0, 4, 4, 0, 2, 0, 0, 3, 4, 4, 0, 2, 0, 3, 3, 0, 2, 3, 0, 4, 0, 4, 3, 2, 4, 3, 0, 0, 3, 2, 0, 4, 2, 2, 4, 4, 4, 0, 2, 4, 4, 4, 0, 0, 3, 2, 2, 2, 4, 4, 3, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 0, 4, 0, 0, 3, 0, 3, 4, 2, 3, 2, 4, 0, 2, 4, 4, 4, 0, 0, 4, 0, 0, 4, 2, 3, 3, 3, 0, 0, 4, 0, 3, 2, 4, 4, 4, 4, 3, 4, 2, 2, 4, 3, 2, 4, 3, 2, 0, 0, 2, 4, 2, 3, 3, 4, 4, 4, 4, 0, 4, 2, 4, 3, 4, 3, 2, 2, 0, 4, 4, 0, 0, 4, 2, 4, 3, 0, 4, 2, 0, 0, 3, 2, 3, 3, 4, 0, 4, 2, 2, 3, 0, 4, 4, 4, 2, 3, 4, 4, 2, 3, 3, 3, 0, 0, 4, 4, 0, 0, 3, 0, 2, 3, 3, 4, 4, 2, 3, 2, 4, 3, 4, 2, 0, 4, 4, 4, 4, 2, 3, 0, 0, 4, 4, 2, 2, 3, 4, 2, 4, 4, 3, 4, 0, 0, 0, 4, 4, 0, 0, 2, 4, 3, 4, 0, 2, 3, 3, 2, 2, 4, 0, 2, 3, 2, 3, 4, 3, 0, 4, 4, 0, 2, 3, 3, 4, 0, 2, 4, 0, 4, 4, 4, 3, 3, 4, 3, 3, 2, 4, 4, 0, 0, 2, 2, 4, 3, 0, 3, 4, 0, 3, 3, 0, 4, 4, 2, 2, 4, 3, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 0, 3, 2, 3, 0, 3, 2, 0, 0, 3, 3, 3, 4, 0, 0, 2, 4, 3, 0, 4, 3, 3, 4, 2, 4, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.86      0.80      0.83       100\n",
      "           3       0.76      0.92      0.83       100\n",
      "           4       0.57      0.94      0.71       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1955064460635185, Val acc: 0.708\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43600 - Batch 38/1894 - Train loss: 1.0300199343607976, Train acc: 0.8725961538461539\n",
      "Iteration 43700 - Batch 138/1894 - Train loss: 1.0253555731807682, Train acc: 0.8788219424460432\n",
      "Iteration 43800 - Batch 238/1894 - Train loss: 1.0255181831794802, Train acc: 0.8787918410041841\n",
      "Iteration 43900 - Batch 338/1894 - Train loss: 1.0268857252281325, Train acc: 0.8775811209439528\n",
      "Iteration 44000 - Batch 438/1894 - Train loss: 1.0244979706331918, Train acc: 0.8800541002277904\n",
      "Iteration 44100 - Batch 538/1894 - Train loss: 1.023645269074555, Train acc: 0.8807397959183674\n",
      "Iteration 44200 - Batch 638/1894 - Train loss: 1.0223743520059123, Train acc: 0.8819933489827856\n",
      "Iteration 44300 - Batch 738/1894 - Train loss: 1.0219310197036546, Train acc: 0.8824424898511503\n",
      "Iteration 44400 - Batch 838/1894 - Train loss: 1.0218639390119069, Train acc: 0.8824493444576877\n",
      "Iteration 44500 - Batch 938/1894 - Train loss: 1.0212701386410081, Train acc: 0.8831203407880724\n",
      "Iteration 44600 - Batch 1038/1894 - Train loss: 1.0218434036064883, Train acc: 0.8824891722810395\n",
      "Iteration 44700 - Batch 1138/1894 - Train loss: 1.021402278995179, Train acc: 0.882929104477612\n",
      "Iteration 44800 - Batch 1238/1894 - Train loss: 1.020719373534051, Train acc: 0.8835754640839386\n",
      "Iteration 44900 - Batch 1338/1894 - Train loss: 1.021620052843685, Train acc: 0.8827483196415236\n",
      "Iteration 45000 - Batch 1438/1894 - Train loss: 1.0218514462491552, Train acc: 0.8824487491313412\n",
      "Iteration 45100 - Batch 1538/1894 - Train loss: 1.0214862827359275, Train acc: 0.8828175763482781\n",
      "Iteration 45200 - Batch 1638/1894 - Train loss: 1.0217061775206355, Train acc: 0.8826075350823673\n",
      "Iteration 45300 - Batch 1738/1894 - Train loss: 1.0218297971467165, Train acc: 0.8824575905692927\n",
      "Iteration 45400 - Batch 1838/1894 - Train loss: 1.0219718739998087, Train acc: 0.8823749320282762\n",
      "[1, 2, 2, 2, 3, 2, 1, 2, 2, 3, 4, 0, 4, 0, 3, 4, 4, 0, 3, 0, 2, 1, 2, 0, 1, 4, 0, 2, 0, 3, 1, 1, 4, 3, 2, 2, 0, 0, 2, 0, 0, 3, 3, 4, 2, 3, 4, 1, 0, 1, 2, 2, 0, 2, 4, 4, 0, 2, 2, 2, 3, 3, 3, 2, 1, 2, 3, 3, 2, 0, 4, 1, 4, 2, 2, 4, 2, 4, 1, 3, 3, 1, 1, 3, 3, 1, 0, 1, 2, 4, 4, 2, 2, 2, 4, 3, 4, 4, 2, 2, 4, 1, 3, 1, 1, 0, 0, 2, 3, 2, 4, 3, 1, 0, 4, 0, 1, 0, 1, 3, 4, 4, 2, 0, 3, 1, 3, 1, 3, 3, 3, 2, 1, 3, 2, 4, 0, 0, 1, 1, 3, 2, 4, 1, 2, 1, 4, 4, 0, 4, 1, 0, 1, 2, 1, 3, 0, 0, 0, 1, 3, 2, 1, 0, 4, 3, 4, 0, 0, 0, 4, 1, 0, 0, 0, 0, 2, 0, 1, 3, 3, 2, 0, 0, 2, 0, 3, 1, 0, 3, 4, 0, 1, 0, 3, 1, 2, 0, 1, 0, 4, 2, 2, 4, 0, 4, 4, 4, 2, 0, 4, 3, 2, 4, 0, 4, 3, 4, 3, 3, 0, 0, 4, 3, 1, 2, 2, 2, 2, 4, 3, 1, 1, 1, 2, 0, 0, 3, 0, 2, 0, 3, 1, 2, 2, 3, 3, 4, 1, 1, 1, 2, 2, 3, 1, 3, 1, 3, 2, 3, 0, 1, 2, 3, 1, 0, 4, 2, 4, 3, 3, 0, 4, 4, 4, 1, 4, 4, 1, 0, 4, 3, 2, 3, 3, 4, 1, 4, 0, 3, 4, 1, 0, 2, 1, 1, 4, 3, 1, 1, 1, 1, 1, 0, 2, 3, 3, 1, 2, 2, 2, 0, 2, 1, 1, 0, 1, 2, 3, 3, 4, 0, 3, 2, 0, 1, 0, 4, 4, 1, 3, 4, 2, 2, 0, 0, 4, 1, 3, 4, 4, 0, 4, 4, 4, 0, 0, 3, 3, 2, 3, 1, 0, 1, 2, 3, 1, 3, 1, 4, 0, 3, 3, 4, 1, 2, 1, 1, 0, 3, 1, 1, 4, 4, 4, 1, 2, 3, 4, 4, 0, 4, 2, 0, 0, 2, 4, 4, 1, 1, 2, 0, 1, 4, 4, 2, 2, 0, 1, 2, 4, 1, 0, 2, 3, 3, 2, 0, 3, 0, 1, 2, 4, 1, 4, 4, 2, 2, 3, 4, 1, 3, 2, 0, 0, 2, 1, 3, 2, 2, 0, 1, 2, 3, 1, 0, 3, 4, 1, 3, 1, 4, 2, 2, 0, 0, 1, 3, 3, 4, 0, 4, 1, 3, 0, 1, 2, 1, 3, 1, 2, 0, 4, 3, 2, 3, 4, 1, 3, 0, 4, 4, 0, 4, 1, 2, 3, 4, 0, 4, 4, 1, 0, 0, 4, 0, 4, 4, 4, 2, 3, 3, 0, 2, 3, 0, 3, 3, 3, 3]\n",
      "[3, 2, 2, 2, 3, 2, 0, 0, 2, 3, 4, 0, 4, 0, 3, 4, 3, 0, 2, 4, 0, 3, 0, 0, 4, 4, 0, 2, 0, 3, 3, 4, 4, 3, 2, 2, 0, 2, 2, 0, 0, 3, 3, 3, 2, 3, 4, 0, 0, 4, 2, 2, 0, 2, 4, 4, 0, 2, 2, 2, 3, 3, 3, 2, 3, 2, 3, 3, 2, 0, 2, 4, 4, 2, 2, 4, 2, 4, 4, 3, 3, 4, 0, 3, 3, 2, 0, 4, 2, 4, 4, 2, 2, 2, 3, 3, 4, 4, 3, 2, 4, 3, 3, 3, 3, 0, 4, 3, 3, 2, 4, 3, 3, 0, 4, 2, 2, 4, 4, 3, 0, 4, 2, 0, 3, 4, 3, 0, 3, 3, 3, 0, 4, 3, 2, 4, 0, 0, 4, 3, 3, 2, 3, 4, 2, 4, 4, 4, 2, 4, 4, 0, 4, 2, 3, 3, 0, 0, 0, 3, 3, 2, 4, 0, 4, 4, 4, 0, 0, 0, 4, 3, 0, 0, 0, 0, 2, 0, 0, 3, 3, 2, 0, 0, 2, 0, 3, 0, 0, 3, 4, 2, 2, 2, 3, 3, 0, 0, 4, 0, 4, 2, 0, 4, 0, 3, 4, 4, 2, 0, 4, 3, 2, 4, 0, 4, 3, 4, 3, 3, 0, 0, 4, 3, 3, 2, 2, 2, 2, 4, 4, 4, 2, 3, 2, 0, 0, 3, 0, 3, 0, 3, 3, 2, 2, 3, 3, 3, 4, 4, 4, 2, 2, 3, 3, 3, 0, 3, 2, 3, 0, 3, 2, 3, 4, 0, 4, 2, 4, 3, 3, 0, 3, 3, 4, 2, 4, 4, 3, 0, 4, 3, 2, 0, 3, 4, 3, 4, 0, 3, 4, 2, 0, 2, 0, 4, 4, 3, 3, 2, 3, 3, 4, 0, 2, 4, 3, 4, 0, 0, 2, 0, 2, 4, 4, 0, 3, 2, 3, 3, 4, 0, 3, 3, 2, 3, 2, 4, 4, 4, 3, 4, 2, 2, 0, 0, 4, 3, 3, 4, 4, 4, 4, 4, 4, 0, 0, 3, 3, 2, 3, 4, 0, 4, 2, 3, 4, 3, 4, 4, 0, 3, 3, 4, 4, 2, 3, 4, 0, 3, 3, 4, 4, 4, 4, 3, 2, 3, 4, 4, 0, 4, 2, 0, 0, 2, 4, 4, 2, 0, 2, 0, 4, 4, 4, 2, 2, 4, 4, 0, 4, 4, 0, 2, 3, 3, 2, 0, 3, 0, 4, 2, 4, 4, 4, 4, 2, 2, 3, 4, 0, 3, 2, 0, 0, 2, 0, 3, 2, 2, 0, 3, 2, 3, 0, 0, 3, 4, 4, 3, 2, 3, 0, 2, 0, 0, 4, 3, 3, 4, 0, 4, 4, 3, 0, 4, 2, 4, 3, 4, 2, 2, 4, 3, 0, 3, 4, 3, 3, 0, 4, 4, 0, 4, 4, 2, 3, 4, 0, 4, 4, 4, 0, 0, 4, 0, 4, 4, 4, 2, 3, 3, 0, 2, 3, 0, 3, 3, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.82      0.85      0.83       100\n",
      "           3       0.68      0.95      0.79       100\n",
      "           4       0.61      0.89      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.64       500\n",
      "weighted avg       0.58      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1862430423498154, Val acc: 0.712\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45500 - Batch 44/1894 - Train loss: 1.0278408580356173, Train acc: 0.875\n",
      "Iteration 45600 - Batch 144/1894 - Train loss: 1.0255337682263606, Train acc: 0.877801724137931\n",
      "Iteration 45700 - Batch 244/1894 - Train loss: 1.0238343861638284, Train acc: 0.8801020408163265\n",
      "Iteration 45800 - Batch 344/1894 - Train loss: 1.021585710843404, Train acc: 0.8821557971014493\n",
      "Iteration 45900 - Batch 444/1894 - Train loss: 1.021006453305148, Train acc: 0.8827949438202247\n",
      "Iteration 46000 - Batch 544/1894 - Train loss: 1.0209381511452, Train acc: 0.8833142201834863\n",
      "Iteration 46100 - Batch 644/1894 - Train loss: 1.022495155741078, Train acc: 0.8816375968992248\n",
      "Iteration 46200 - Batch 744/1894 - Train loss: 1.0227222977868662, Train acc: 0.8814597315436241\n",
      "Iteration 46300 - Batch 844/1894 - Train loss: 1.0234964817233339, Train acc: 0.8807322485207101\n",
      "Iteration 46400 - Batch 944/1894 - Train loss: 1.023077903285859, Train acc: 0.8811507936507936\n",
      "Iteration 46500 - Batch 1044/1894 - Train loss: 1.0223566750019932, Train acc: 0.8818480861244019\n",
      "Iteration 46600 - Batch 1144/1894 - Train loss: 1.0218416769952232, Train acc: 0.8823144104803493\n",
      "Iteration 46700 - Batch 1244/1894 - Train loss: 1.021043713552406, Train acc: 0.8831074297188755\n",
      "Iteration 46800 - Batch 1344/1894 - Train loss: 1.0213731088159697, Train acc: 0.8827834572490706\n",
      "Iteration 46900 - Batch 1444/1894 - Train loss: 1.0219388993553638, Train acc: 0.8821799307958478\n",
      "Iteration 47000 - Batch 1544/1894 - Train loss: 1.0221150844614098, Train acc: 0.8819377022653722\n",
      "Iteration 47100 - Batch 1644/1894 - Train loss: 1.0224379453615577, Train acc: 0.8816109422492401\n",
      "Iteration 47200 - Batch 1744/1894 - Train loss: 1.0221623989435868, Train acc: 0.8818409742120343\n",
      "Iteration 47300 - Batch 1844/1894 - Train loss: 1.0218085856941657, Train acc: 0.8821815718157181\n",
      "[1, 1, 4, 1, 2, 2, 3, 0, 1, 0, 4, 2, 4, 2, 2, 2, 3, 2, 1, 2, 4, 0, 4, 1, 4, 3, 1, 2, 1, 1, 1, 3, 1, 3, 4, 0, 1, 2, 0, 4, 4, 0, 2, 0, 2, 3, 2, 3, 4, 3, 2, 4, 1, 4, 1, 1, 0, 1, 0, 4, 4, 0, 3, 3, 0, 4, 4, 1, 2, 1, 4, 1, 1, 2, 1, 2, 3, 4, 3, 3, 2, 0, 0, 0, 3, 0, 3, 1, 0, 3, 1, 3, 0, 0, 4, 4, 4, 1, 3, 2, 1, 4, 3, 4, 3, 0, 4, 3, 1, 1, 3, 2, 4, 2, 0, 2, 0, 3, 3, 2, 0, 3, 3, 2, 4, 4, 0, 2, 2, 0, 3, 2, 3, 2, 0, 4, 4, 1, 4, 4, 0, 2, 3, 3, 4, 1, 3, 0, 0, 0, 4, 1, 1, 4, 1, 0, 2, 2, 3, 2, 0, 4, 3, 3, 1, 1, 0, 0, 0, 3, 4, 0, 2, 2, 0, 1, 4, 0, 0, 4, 3, 2, 3, 4, 3, 2, 4, 0, 1, 2, 3, 3, 0, 1, 4, 0, 4, 4, 0, 3, 0, 0, 4, 4, 1, 2, 2, 3, 0, 4, 2, 0, 1, 3, 3, 4, 4, 0, 4, 3, 1, 1, 2, 1, 1, 2, 3, 0, 0, 0, 2, 1, 4, 0, 3, 0, 2, 3, 1, 2, 2, 1, 3, 2, 3, 3, 4, 1, 0, 4, 2, 0, 3, 0, 4, 3, 4, 1, 4, 1, 1, 3, 1, 2, 0, 1, 4, 3, 1, 2, 3, 3, 0, 0, 0, 4, 4, 0, 1, 1, 0, 4, 3, 2, 1, 3, 4, 4, 0, 3, 2, 1, 3, 4, 4, 1, 4, 3, 4, 2, 1, 2, 1, 2, 1, 2, 3, 4, 2, 2, 1, 1, 3, 3, 3, 4, 3, 4, 3, 1, 2, 4, 3, 4, 0, 0, 4, 0, 3, 2, 2, 4, 0, 3, 3, 3, 0, 4, 3, 1, 1, 2, 4, 2, 2, 2, 3, 3, 0, 0, 0, 3, 1, 3, 2, 2, 2, 0, 1, 2, 3, 4, 0, 1, 2, 4, 0, 3, 1, 0, 1, 1, 1, 1, 4, 3, 4, 0, 3, 0, 4, 0, 4, 0, 2, 2, 1, 3, 0, 4, 2, 1, 3, 4, 3, 0, 0, 4, 4, 1, 1, 2, 3, 3, 4, 0, 0, 0, 0, 4, 2, 2, 0, 2, 0, 4, 3, 2, 1, 1, 4, 1, 2, 2, 1, 2, 0, 1, 1, 0, 4, 3, 3, 3, 1, 1, 0, 1, 1, 2, 2, 4, 4, 1, 3, 4, 4, 2, 4, 3, 1, 1, 4, 1, 1, 2, 0, 1, 1, 4, 2, 0, 2, 0, 3, 2, 2, 1, 4, 3, 2, 1, 0, 4, 2, 3, 1, 0, 2, 1, 3, 2, 2, 3, 2, 0, 2, 4, 3, 0, 3, 1, 0, 0, 2, 2, 0, 2, 4, 2]\n",
      "[4, 4, 4, 4, 2, 2, 3, 0, 0, 0, 4, 2, 4, 2, 2, 0, 4, 2, 3, 2, 4, 2, 4, 2, 4, 3, 4, 0, 3, 3, 4, 3, 0, 2, 4, 4, 0, 2, 0, 0, 4, 0, 3, 0, 2, 3, 0, 3, 4, 3, 2, 4, 4, 4, 0, 3, 0, 0, 0, 4, 4, 0, 3, 2, 0, 4, 4, 0, 2, 4, 4, 0, 3, 2, 4, 2, 3, 4, 3, 3, 2, 0, 0, 4, 3, 4, 3, 4, 0, 4, 0, 3, 4, 0, 4, 4, 4, 4, 3, 2, 3, 4, 3, 4, 3, 0, 4, 3, 3, 0, 3, 2, 3, 0, 0, 0, 0, 3, 3, 2, 0, 3, 3, 2, 4, 4, 0, 2, 2, 0, 3, 2, 3, 0, 0, 4, 4, 4, 4, 4, 0, 2, 3, 3, 4, 4, 3, 0, 0, 0, 4, 4, 0, 4, 4, 0, 0, 0, 3, 2, 0, 4, 3, 3, 4, 4, 0, 0, 0, 3, 4, 0, 2, 0, 0, 0, 4, 0, 0, 4, 4, 2, 3, 4, 3, 2, 2, 0, 4, 2, 3, 3, 0, 4, 4, 0, 4, 4, 0, 3, 2, 0, 4, 4, 4, 0, 2, 3, 2, 4, 0, 0, 0, 3, 3, 4, 4, 0, 4, 3, 4, 4, 2, 4, 4, 2, 3, 0, 0, 0, 2, 3, 4, 0, 3, 0, 2, 3, 4, 2, 2, 4, 3, 0, 3, 3, 4, 4, 0, 4, 2, 0, 3, 0, 4, 3, 4, 2, 4, 4, 0, 2, 3, 2, 0, 4, 4, 3, 4, 2, 3, 3, 0, 0, 0, 4, 3, 0, 4, 0, 0, 4, 3, 2, 3, 3, 4, 4, 0, 4, 2, 4, 3, 4, 4, 3, 4, 3, 4, 2, 4, 2, 0, 2, 4, 2, 3, 4, 2, 0, 4, 0, 3, 3, 3, 4, 4, 4, 3, 4, 2, 4, 3, 4, 0, 0, 4, 0, 3, 2, 2, 4, 0, 3, 3, 3, 0, 4, 3, 4, 0, 2, 4, 2, 2, 2, 3, 3, 0, 0, 0, 3, 4, 3, 2, 2, 2, 0, 0, 2, 3, 4, 0, 4, 2, 4, 2, 3, 0, 0, 0, 2, 3, 3, 4, 3, 4, 0, 3, 0, 4, 0, 4, 0, 2, 0, 3, 4, 0, 4, 2, 3, 3, 4, 3, 0, 0, 4, 4, 4, 3, 2, 3, 3, 4, 0, 0, 0, 0, 4, 2, 2, 0, 2, 0, 3, 3, 2, 4, 2, 4, 3, 2, 2, 2, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 2, 0, 4, 0, 2, 2, 4, 4, 4, 3, 4, 4, 2, 4, 3, 4, 4, 4, 4, 3, 3, 0, 4, 3, 4, 2, 0, 2, 0, 3, 0, 2, 3, 4, 3, 2, 3, 0, 4, 2, 3, 4, 0, 2, 3, 3, 2, 2, 4, 2, 0, 2, 3, 3, 0, 3, 4, 0, 0, 2, 2, 0, 2, 4, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.85      0.83      0.84       100\n",
      "           3       0.76      0.90      0.82       100\n",
      "           4       0.61      0.94      0.74       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.58      0.72      0.64       500\n",
      "weighted avg       0.58      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1863084807991982, Val acc: 0.716\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47400 - Batch 50/1894 - Train loss: 1.0117597241027683, Train acc: 0.8927696078431373\n",
      "Iteration 47500 - Batch 150/1894 - Train loss: 1.010227913888085, Train acc: 0.8942466887417219\n",
      "Iteration 47600 - Batch 250/1894 - Train loss: 1.0122864141882177, Train acc: 0.8921812749003984\n",
      "Iteration 47700 - Batch 350/1894 - Train loss: 1.015948657126848, Train acc: 0.8882656695156695\n",
      "Iteration 47800 - Batch 450/1894 - Train loss: 1.018616017507608, Train acc: 0.8855321507760532\n",
      "Iteration 47900 - Batch 550/1894 - Train loss: 1.0177832019740138, Train acc: 0.8863430127041743\n",
      "Iteration 48000 - Batch 650/1894 - Train loss: 1.019040288372157, Train acc: 0.8848406298003072\n",
      "Iteration 48100 - Batch 750/1894 - Train loss: 1.0169070466221888, Train acc: 0.8869840213049268\n",
      "Iteration 48200 - Batch 850/1894 - Train loss: 1.016622637259554, Train acc: 0.887448589894242\n",
      "Iteration 48300 - Batch 950/1894 - Train loss: 1.016628182962239, Train acc: 0.887519716088328\n",
      "Iteration 48400 - Batch 1050/1894 - Train loss: 1.0169946787246174, Train acc: 0.8871015699333967\n",
      "Iteration 48500 - Batch 1150/1894 - Train loss: 1.018015799886967, Train acc: 0.8860230234578628\n",
      "Iteration 48600 - Batch 1250/1894 - Train loss: 1.0180061935520859, Train acc: 0.8860911270983214\n",
      "Iteration 48700 - Batch 1350/1894 - Train loss: 1.0183865880189693, Train acc: 0.8856865284974094\n",
      "Iteration 48800 - Batch 1450/1894 - Train loss: 1.0185386051727443, Train acc: 0.885553066850448\n",
      "Iteration 48900 - Batch 1550/1894 - Train loss: 1.0194660583517, Train acc: 0.8846308833010961\n",
      "Iteration 49000 - Batch 1650/1894 - Train loss: 1.019839609846211, Train acc: 0.8842746820109025\n",
      "Iteration 49100 - Batch 1750/1894 - Train loss: 1.019787191595778, Train acc: 0.8842982581382067\n",
      "Iteration 49200 - Batch 1850/1894 - Train loss: 1.0199953202683496, Train acc: 0.8840829281469476\n",
      "[4, 3, 0, 0, 2, 3, 0, 4, 2, 4, 4, 2, 2, 0, 1, 0, 1, 1, 2, 4, 3, 3, 4, 1, 2, 2, 1, 2, 4, 0, 0, 1, 1, 2, 4, 2, 0, 2, 0, 4, 4, 2, 4, 1, 4, 1, 3, 4, 4, 1, 3, 2, 0, 1, 3, 2, 1, 3, 0, 3, 3, 0, 3, 3, 4, 2, 3, 1, 0, 0, 4, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 4, 3, 1, 2, 4, 3, 0, 2, 2, 0, 4, 3, 4, 1, 4, 2, 0, 2, 1, 3, 4, 2, 2, 3, 0, 4, 3, 4, 2, 0, 3, 1, 4, 4, 2, 1, 3, 1, 4, 4, 2, 2, 2, 2, 1, 0, 0, 1, 2, 3, 4, 3, 0, 3, 3, 0, 2, 3, 1, 1, 0, 0, 0, 1, 0, 2, 1, 1, 4, 2, 3, 4, 2, 1, 3, 4, 0, 2, 1, 2, 1, 4, 2, 4, 0, 4, 2, 1, 4, 1, 2, 4, 2, 1, 2, 2, 2, 3, 2, 0, 1, 2, 0, 2, 1, 2, 1, 4, 0, 4, 4, 4, 4, 2, 3, 1, 4, 1, 4, 0, 3, 4, 4, 1, 3, 0, 0, 2, 2, 3, 2, 2, 3, 2, 2, 1, 0, 4, 4, 3, 2, 0, 2, 3, 0, 4, 4, 3, 2, 0, 2, 4, 1, 4, 3, 3, 0, 1, 2, 1, 4, 3, 4, 4, 3, 1, 1, 2, 3, 0, 0, 3, 4, 3, 3, 4, 3, 3, 4, 4, 2, 2, 0, 2, 4, 4, 3, 3, 3, 3, 3, 0, 4, 4, 2, 3, 0, 3, 1, 0, 1, 4, 4, 3, 0, 2, 3, 2, 1, 3, 1, 4, 1, 0, 1, 2, 3, 3, 4, 0, 1, 3, 1, 3, 1, 3, 2, 2, 0, 0, 3, 3, 3, 0, 4, 3, 3, 1, 3, 2, 0, 0, 1, 1, 0, 3, 1, 2, 2, 1, 2, 0, 4, 4, 2, 3, 3, 3, 2, 3, 4, 0, 2, 0, 0, 1, 4, 3, 0, 0, 2, 3, 3, 2, 1, 3, 1, 3, 0, 4, 1, 4, 4, 3, 4, 0, 1, 4, 1, 0, 1, 2, 4, 3, 1, 2, 2, 4, 3, 4, 0, 3, 3, 1, 1, 3, 1, 1, 2, 0, 1, 4, 0, 4, 1, 1, 2, 0, 3, 1, 2, 2, 0, 1, 3, 1, 0, 2, 4, 3, 3, 2, 2, 0, 2, 1, 2, 1, 0, 4, 1, 0, 4, 4, 3, 2, 4, 1, 0, 1, 4, 3, 4, 0, 1, 1, 0, 0, 3, 3, 0, 4, 3, 0, 2, 1, 3, 4, 1, 2, 1, 0, 0, 3, 3, 4, 4, 0, 2, 0, 0, 2, 3, 4, 1, 0, 0, 0, 2, 2, 4, 1, 2, 1, 1, 0, 0, 4, 2, 1, 1, 1, 1, 0, 0, 3, 4, 4, 0, 3, 4, 4, 2, 0, 3, 1]\n",
      "[4, 3, 0, 4, 2, 3, 2, 4, 2, 4, 4, 2, 0, 0, 3, 0, 4, 3, 2, 4, 3, 3, 4, 4, 2, 3, 0, 2, 4, 0, 0, 4, 0, 2, 4, 2, 0, 2, 0, 4, 4, 2, 4, 4, 4, 4, 3, 4, 4, 3, 3, 2, 0, 2, 3, 2, 2, 3, 0, 3, 3, 0, 3, 3, 0, 2, 3, 4, 0, 0, 4, 4, 0, 0, 0, 0, 2, 4, 0, 0, 2, 3, 0, 0, 4, 3, 3, 2, 4, 3, 0, 2, 2, 4, 4, 3, 4, 3, 4, 2, 0, 2, 4, 3, 3, 2, 2, 3, 0, 4, 3, 4, 2, 0, 3, 3, 4, 4, 2, 4, 3, 4, 4, 4, 3, 2, 2, 0, 4, 0, 0, 4, 2, 3, 4, 3, 2, 3, 3, 0, 2, 3, 4, 0, 2, 0, 2, 3, 2, 2, 4, 4, 4, 2, 3, 4, 2, 3, 3, 4, 2, 2, 4, 2, 4, 4, 2, 4, 0, 4, 0, 0, 4, 4, 2, 4, 2, 0, 2, 2, 2, 3, 3, 0, 4, 2, 0, 2, 3, 2, 4, 4, 4, 4, 4, 4, 4, 0, 3, 3, 4, 3, 2, 0, 3, 4, 4, 4, 3, 0, 0, 2, 2, 3, 2, 2, 4, 2, 2, 4, 0, 4, 4, 3, 2, 0, 2, 3, 0, 4, 4, 3, 2, 0, 0, 4, 4, 4, 3, 3, 0, 4, 2, 3, 3, 4, 4, 4, 3, 2, 3, 2, 3, 0, 0, 3, 4, 3, 3, 4, 3, 3, 4, 4, 2, 2, 0, 2, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 2, 3, 0, 3, 3, 0, 4, 4, 4, 3, 0, 2, 3, 2, 4, 3, 4, 4, 3, 0, 3, 2, 3, 3, 3, 0, 4, 3, 0, 3, 4, 3, 2, 2, 0, 0, 3, 3, 3, 4, 4, 3, 3, 0, 3, 2, 0, 0, 3, 0, 0, 3, 4, 2, 2, 3, 2, 0, 4, 4, 0, 3, 4, 4, 2, 2, 4, 0, 0, 0, 0, 4, 4, 3, 0, 0, 3, 3, 3, 2, 3, 3, 2, 3, 0, 4, 3, 4, 4, 3, 4, 0, 4, 4, 3, 0, 4, 2, 4, 3, 3, 2, 2, 4, 3, 4, 0, 3, 3, 4, 3, 3, 4, 4, 0, 0, 3, 4, 0, 4, 4, 3, 2, 0, 3, 3, 2, 2, 0, 4, 3, 4, 4, 2, 4, 3, 3, 0, 2, 0, 2, 0, 2, 4, 0, 4, 3, 2, 4, 2, 4, 2, 4, 3, 4, 3, 4, 3, 4, 0, 0, 4, 0, 0, 3, 3, 0, 4, 3, 0, 0, 4, 3, 3, 4, 2, 4, 0, 2, 3, 3, 4, 4, 0, 2, 0, 0, 2, 3, 4, 4, 0, 0, 0, 0, 2, 4, 4, 2, 2, 4, 2, 0, 4, 2, 4, 4, 4, 4, 0, 0, 3, 4, 4, 0, 3, 4, 4, 2, 0, 3, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.83      0.85      0.84       100\n",
      "           3       0.71      0.94      0.81       100\n",
      "           4       0.59      0.93      0.72       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.64       500\n",
      "weighted avg       0.58      0.71      0.64       500\n",
      "\n",
      "Val loss: 1.1890240088105202, Val acc: 0.712\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49300 - Batch 56/1894 - Train loss: 1.0161836471473962, Train acc: 0.8881578947368421\n",
      "Iteration 49400 - Batch 156/1894 - Train loss: 1.0206113681671725, Train acc: 0.8837579617834395\n",
      "Iteration 49500 - Batch 256/1894 - Train loss: 1.0203468741609893, Train acc: 0.8844844357976653\n",
      "Iteration 49600 - Batch 356/1894 - Train loss: 1.0215454919665468, Train acc: 0.883140756302521\n",
      "Iteration 49700 - Batch 456/1894 - Train loss: 1.0215954811880834, Train acc: 0.8830005470459519\n",
      "Iteration 49800 - Batch 556/1894 - Train loss: 1.0228981178795629, Train acc: 0.881508078994614\n",
      "Iteration 49900 - Batch 656/1894 - Train loss: 1.0224368554997842, Train acc: 0.8822298325722984\n",
      "Iteration 50000 - Batch 756/1894 - Train loss: 1.0221709754696926, Train acc: 0.8824719286657859\n",
      "Iteration 50100 - Batch 856/1894 - Train loss: 1.0207430166708547, Train acc: 0.883933780630105\n",
      "Iteration 50200 - Batch 956/1894 - Train loss: 1.0217689917877302, Train acc: 0.8829022988505747\n",
      "Iteration 50300 - Batch 1056/1894 - Train loss: 1.0216524497224344, Train acc: 0.8829529328287606\n",
      "Iteration 50400 - Batch 1156/1894 - Train loss: 1.0210293033768003, Train acc: 0.883480985306828\n",
      "Iteration 50500 - Batch 1256/1894 - Train loss: 1.0204218529289264, Train acc: 0.8840990453460621\n",
      "Iteration 50600 - Batch 1356/1894 - Train loss: 1.0203803432014116, Train acc: 0.884096352247605\n",
      "Iteration 50700 - Batch 1456/1894 - Train loss: 1.0205040117936668, Train acc: 0.8840296842827728\n",
      "Iteration 50800 - Batch 1556/1894 - Train loss: 1.0203963858850047, Train acc: 0.8840719332048812\n",
      "Iteration 50900 - Batch 1656/1894 - Train loss: 1.0205295883753103, Train acc: 0.8839393482196741\n",
      "Iteration 51000 - Batch 1756/1894 - Train loss: 1.0208234705908705, Train acc: 0.8836262094479226\n",
      "Iteration 51100 - Batch 1856/1894 - Train loss: 1.0205581753434965, Train acc: 0.8839189553042541\n",
      "[2, 2, 2, 3, 0, 3, 0, 3, 3, 0, 0, 1, 0, 0, 2, 0, 2, 1, 3, 2, 3, 3, 2, 4, 2, 3, 3, 1, 3, 2, 2, 4, 2, 1, 3, 4, 3, 0, 0, 2, 0, 1, 3, 4, 3, 3, 3, 0, 3, 3, 0, 3, 4, 4, 1, 2, 3, 1, 3, 4, 1, 3, 3, 1, 1, 2, 3, 3, 4, 3, 3, 4, 3, 4, 0, 3, 3, 3, 1, 4, 4, 0, 4, 1, 1, 3, 1, 4, 0, 4, 2, 2, 4, 2, 2, 4, 4, 0, 2, 2, 4, 4, 0, 4, 0, 4, 0, 0, 2, 1, 4, 1, 3, 1, 1, 0, 0, 4, 0, 2, 4, 0, 1, 3, 0, 0, 1, 4, 0, 2, 2, 1, 4, 4, 0, 2, 0, 1, 3, 4, 2, 4, 4, 0, 2, 2, 2, 1, 4, 1, 1, 4, 2, 0, 3, 0, 0, 4, 2, 3, 0, 2, 2, 3, 1, 1, 1, 1, 1, 4, 1, 3, 1, 3, 3, 0, 3, 0, 3, 2, 0, 1, 0, 4, 4, 1, 4, 0, 4, 3, 4, 3, 2, 3, 2, 4, 4, 2, 4, 4, 3, 2, 2, 2, 1, 2, 1, 2, 2, 4, 0, 0, 3, 0, 3, 0, 3, 3, 1, 1, 1, 0, 3, 3, 3, 2, 0, 3, 0, 4, 0, 3, 1, 2, 3, 4, 4, 2, 2, 0, 1, 0, 0, 4, 3, 1, 0, 4, 4, 4, 1, 3, 0, 0, 0, 4, 1, 1, 1, 1, 2, 4, 3, 1, 1, 1, 3, 2, 3, 3, 4, 0, 3, 1, 1, 4, 3, 3, 1, 3, 2, 2, 1, 4, 1, 2, 3, 2, 1, 2, 3, 2, 3, 4, 0, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 3, 0, 3, 4, 2, 3, 0, 0, 0, 4, 1, 1, 3, 1, 2, 1, 0, 3, 2, 0, 2, 3, 4, 3, 2, 0, 0, 0, 4, 0, 4, 2, 3, 2, 3, 2, 4, 4, 4, 0, 4, 1, 3, 0, 1, 3, 1, 2, 0, 0, 1, 1, 3, 1, 4, 1, 4, 3, 3, 0, 4, 4, 2, 1, 2, 1, 4, 1, 2, 2, 2, 3, 0, 4, 1, 0, 0, 3, 4, 1, 4, 0, 1, 2, 3, 0, 4, 2, 1, 2, 2, 1, 2, 3, 3, 4, 1, 2, 1, 0, 0, 2, 0, 4, 2, 1, 1, 4, 2, 0, 2, 0, 3, 1, 3, 4, 4, 1, 0, 2, 4, 2, 2, 3, 4, 1, 4, 0, 3, 1, 4, 4, 1, 2, 1, 4, 2, 2, 1, 1, 1, 0, 4, 1, 2, 0, 1, 4, 0, 0, 4, 3, 1, 3, 1, 0, 0, 4, 0, 3, 1, 2, 3, 2, 1, 0, 2, 0, 0, 3, 2, 2, 4, 1, 0, 4, 2, 4, 4, 3, 0, 2, 4, 1, 4, 0, 4, 2, 3, 2, 0, 4, 0, 4, 1]\n",
      "[2, 2, 2, 3, 0, 3, 0, 3, 3, 0, 0, 4, 0, 0, 2, 0, 2, 4, 3, 2, 3, 3, 2, 4, 2, 0, 3, 0, 3, 2, 0, 3, 2, 4, 3, 4, 3, 0, 0, 0, 0, 4, 3, 4, 3, 3, 3, 0, 3, 2, 0, 3, 4, 4, 3, 2, 3, 4, 3, 4, 2, 3, 3, 3, 3, 2, 3, 3, 4, 3, 3, 4, 3, 4, 0, 3, 3, 3, 3, 4, 4, 0, 4, 4, 3, 3, 4, 4, 0, 4, 2, 2, 4, 0, 2, 4, 4, 0, 2, 0, 4, 0, 0, 4, 0, 4, 0, 0, 2, 4, 4, 3, 3, 3, 0, 0, 0, 4, 0, 2, 4, 0, 4, 3, 0, 0, 0, 4, 0, 2, 0, 4, 4, 3, 0, 2, 0, 4, 3, 4, 2, 4, 4, 0, 2, 0, 4, 2, 4, 3, 4, 4, 0, 0, 3, 0, 0, 4, 2, 3, 0, 2, 2, 3, 3, 3, 4, 0, 3, 4, 4, 3, 3, 3, 3, 4, 3, 4, 3, 2, 0, 4, 0, 2, 4, 4, 4, 0, 4, 3, 4, 4, 0, 3, 0, 4, 4, 2, 4, 4, 3, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 0, 3, 0, 3, 0, 3, 3, 4, 3, 3, 0, 3, 3, 3, 2, 0, 3, 0, 4, 0, 3, 4, 2, 3, 4, 4, 3, 2, 0, 4, 0, 0, 4, 3, 0, 0, 4, 4, 4, 3, 3, 0, 0, 0, 4, 3, 3, 4, 3, 2, 4, 3, 3, 3, 4, 3, 2, 3, 3, 4, 0, 3, 4, 4, 4, 3, 3, 0, 3, 2, 2, 3, 4, 2, 2, 3, 2, 4, 2, 3, 2, 3, 4, 0, 2, 2, 0, 3, 0, 3, 4, 0, 0, 2, 3, 0, 3, 4, 2, 3, 0, 0, 0, 4, 3, 4, 3, 4, 3, 4, 0, 3, 2, 0, 2, 3, 4, 3, 2, 0, 0, 0, 4, 0, 4, 2, 4, 3, 3, 2, 4, 4, 4, 0, 4, 0, 3, 0, 4, 3, 4, 2, 0, 0, 2, 3, 3, 4, 4, 4, 4, 3, 3, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 0, 4, 0, 0, 0, 3, 3, 3, 4, 0, 3, 2, 3, 0, 4, 0, 0, 2, 2, 4, 0, 4, 3, 4, 4, 2, 4, 0, 4, 2, 0, 4, 2, 4, 0, 4, 2, 0, 2, 0, 3, 3, 3, 4, 4, 2, 0, 2, 4, 2, 2, 3, 4, 0, 4, 0, 3, 3, 4, 4, 3, 2, 0, 4, 2, 2, 0, 4, 3, 0, 4, 4, 2, 4, 4, 4, 0, 0, 4, 3, 0, 3, 4, 0, 0, 4, 3, 3, 0, 0, 3, 2, 4, 0, 2, 0, 0, 3, 2, 2, 4, 4, 0, 4, 2, 4, 4, 3, 0, 0, 4, 4, 4, 0, 4, 2, 3, 0, 0, 3, 0, 4, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.93      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.80      0.84       100\n",
      "           3       0.70      0.94      0.80       100\n",
      "           4       0.62      0.93      0.74       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1826189309358597, Val acc: 0.72\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 51200 - Batch 62/1894 - Train loss: 1.0284969598527938, Train acc: 0.8745039682539683\n",
      "Iteration 51300 - Batch 162/1894 - Train loss: 1.0246671101798308, Train acc: 0.8778757668711656\n",
      "Iteration 51400 - Batch 262/1894 - Train loss: 1.020367789857741, Train acc: 0.8828422053231939\n",
      "Iteration 51500 - Batch 362/1894 - Train loss: 1.0199738112034549, Train acc: 0.8836949035812672\n",
      "Iteration 51600 - Batch 462/1894 - Train loss: 1.0197744507254072, Train acc: 0.8841117710583153\n",
      "Iteration 51700 - Batch 562/1894 - Train loss: 1.0193333293362579, Train acc: 0.8846025754884547\n",
      "Iteration 51800 - Batch 662/1894 - Train loss: 1.0175391053542113, Train acc: 0.8862179487179487\n",
      "Iteration 51900 - Batch 762/1894 - Train loss: 1.0166874867747995, Train acc: 0.8871641546526867\n",
      "Iteration 52000 - Batch 862/1894 - Train loss: 1.0169418454170227, Train acc: 0.8869858053302433\n",
      "Iteration 52100 - Batch 962/1894 - Train loss: 1.0176556034251536, Train acc: 0.8862603842159917\n",
      "Iteration 52200 - Batch 1062/1894 - Train loss: 1.0178284804886057, Train acc: 0.8861418156161807\n",
      "Iteration 52300 - Batch 1162/1894 - Train loss: 1.0170304553322205, Train acc: 0.8869572226999141\n",
      "Iteration 52400 - Batch 1262/1894 - Train loss: 1.017754955085987, Train acc: 0.8862331749802058\n",
      "Iteration 52500 - Batch 1362/1894 - Train loss: 1.0172753426754029, Train acc: 0.8867617388114454\n",
      "Iteration 52600 - Batch 1462/1894 - Train loss: 1.0172952216778075, Train acc: 0.8868122009569378\n",
      "Iteration 52700 - Batch 1562/1894 - Train loss: 1.017223339925877, Train acc: 0.8868162188099808\n",
      "Iteration 52800 - Batch 1662/1894 - Train loss: 1.0174349228875579, Train acc: 0.8866130487071557\n",
      "Iteration 52900 - Batch 1762/1894 - Train loss: 1.0175537805765513, Train acc: 0.886468377765173\n",
      "Iteration 53000 - Batch 1862/1894 - Train loss: 1.0175818525778626, Train acc: 0.8864398819108964\n",
      "[2, 4, 2, 1, 3, 2, 0, 1, 0, 2, 0, 2, 2, 3, 4, 2, 3, 0, 4, 4, 2, 1, 0, 1, 0, 4, 1, 3, 4, 4, 1, 4, 1, 1, 1, 0, 3, 0, 0, 4, 3, 4, 3, 0, 0, 0, 1, 2, 0, 4, 3, 3, 1, 2, 4, 2, 2, 2, 2, 0, 3, 4, 3, 1, 2, 4, 3, 1, 3, 0, 0, 1, 0, 4, 0, 2, 1, 4, 4, 1, 4, 1, 1, 0, 3, 2, 1, 3, 0, 2, 3, 4, 2, 3, 0, 3, 0, 4, 1, 2, 3, 3, 3, 3, 1, 4, 4, 0, 0, 0, 4, 4, 0, 3, 1, 4, 0, 2, 3, 3, 3, 1, 3, 4, 1, 4, 2, 2, 0, 2, 2, 3, 3, 1, 1, 0, 2, 0, 4, 4, 3, 4, 4, 1, 2, 4, 3, 3, 3, 0, 3, 2, 2, 0, 0, 2, 4, 3, 0, 3, 4, 3, 4, 2, 0, 4, 2, 1, 1, 2, 1, 3, 1, 4, 4, 2, 4, 4, 4, 2, 0, 3, 4, 2, 4, 3, 0, 3, 1, 2, 2, 3, 1, 3, 4, 1, 2, 0, 3, 0, 1, 1, 3, 2, 0, 1, 3, 1, 0, 0, 4, 1, 0, 3, 3, 0, 2, 0, 4, 1, 2, 4, 0, 0, 2, 0, 3, 4, 2, 0, 3, 1, 0, 4, 3, 2, 3, 2, 3, 4, 3, 2, 0, 0, 2, 3, 3, 1, 2, 2, 4, 0, 3, 2, 1, 4, 3, 1, 4, 0, 1, 2, 3, 1, 4, 2, 0, 3, 2, 2, 3, 1, 1, 1, 2, 1, 1, 2, 3, 0, 2, 3, 0, 1, 2, 2, 1, 0, 1, 0, 2, 1, 4, 1, 4, 1, 2, 1, 3, 0, 0, 3, 2, 1, 2, 3, 1, 4, 2, 1, 3, 2, 1, 1, 0, 0, 1, 0, 2, 2, 2, 3, 3, 3, 3, 2, 0, 1, 2, 3, 2, 0, 2, 3, 0, 0, 1, 0, 2, 4, 4, 3, 2, 2, 4, 4, 3, 1, 4, 0, 1, 4, 2, 3, 2, 3, 4, 1, 3, 4, 3, 4, 2, 2, 4, 0, 1, 4, 0, 1, 0, 2, 0, 0, 2, 3, 3, 1, 4, 4, 0, 4, 0, 2, 0, 2, 1, 0, 2, 4, 1, 1, 3, 4, 4, 1, 1, 2, 4, 4, 2, 1, 3, 1, 0, 0, 3, 1, 4, 1, 3, 0, 2, 3, 0, 4, 2, 4, 3, 1, 3, 3, 4, 2, 4, 1, 1, 4, 1, 4, 0, 1, 2, 0, 4, 2, 1, 1, 3, 4, 4, 0, 2, 1, 3, 4, 0, 0, 3, 4, 3, 0, 1, 0, 2, 0, 1, 3, 0, 4, 1, 0, 2, 0, 2, 0, 4, 4, 0, 1, 4, 1, 3, 0, 3, 2, 4, 4, 0, 4, 1, 1, 3, 2, 0, 4, 2, 4, 2, 4, 1, 4, 0, 3, 3, 1, 1, 3, 1, 4]\n",
      "[2, 4, 2, 4, 3, 2, 0, 2, 0, 2, 0, 2, 2, 3, 4, 2, 3, 0, 4, 4, 2, 3, 0, 3, 0, 4, 0, 3, 4, 4, 4, 4, 4, 4, 3, 0, 3, 0, 0, 4, 3, 4, 3, 0, 0, 0, 0, 2, 0, 4, 3, 3, 0, 2, 4, 2, 2, 2, 0, 0, 3, 4, 3, 4, 2, 4, 3, 2, 3, 4, 0, 0, 0, 4, 0, 2, 4, 4, 4, 4, 3, 3, 4, 0, 4, 2, 2, 3, 0, 2, 3, 4, 2, 3, 0, 3, 0, 4, 3, 2, 4, 3, 3, 3, 3, 4, 4, 0, 0, 0, 4, 4, 4, 3, 4, 4, 0, 2, 3, 3, 3, 0, 3, 4, 3, 4, 2, 0, 0, 2, 2, 3, 4, 0, 4, 0, 2, 0, 4, 4, 3, 4, 4, 0, 2, 4, 3, 3, 3, 2, 4, 0, 2, 0, 0, 2, 4, 3, 0, 3, 4, 3, 4, 2, 0, 4, 2, 3, 4, 2, 4, 3, 3, 4, 4, 0, 3, 4, 4, 2, 0, 3, 4, 2, 4, 3, 0, 3, 4, 0, 2, 3, 3, 3, 3, 0, 2, 0, 3, 0, 2, 4, 3, 2, 0, 3, 3, 0, 0, 0, 3, 4, 0, 3, 3, 0, 2, 0, 4, 3, 0, 2, 0, 0, 0, 0, 3, 4, 0, 0, 3, 4, 0, 4, 3, 2, 3, 2, 3, 4, 3, 2, 0, 0, 2, 3, 3, 2, 2, 2, 4, 0, 3, 2, 3, 4, 3, 3, 4, 0, 3, 2, 3, 4, 4, 0, 0, 3, 2, 2, 3, 4, 4, 4, 2, 0, 3, 2, 3, 0, 2, 3, 0, 3, 2, 2, 4, 0, 3, 0, 2, 0, 4, 3, 4, 3, 2, 4, 3, 0, 0, 3, 2, 3, 2, 3, 4, 3, 2, 4, 3, 2, 4, 0, 0, 0, 4, 0, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 2, 3, 2, 0, 3, 3, 0, 0, 4, 0, 2, 4, 4, 3, 0, 2, 3, 4, 3, 0, 4, 0, 4, 0, 3, 3, 0, 3, 4, 3, 3, 4, 3, 4, 2, 2, 4, 0, 4, 4, 0, 4, 0, 0, 0, 0, 2, 3, 3, 4, 4, 4, 0, 4, 0, 2, 0, 2, 4, 0, 3, 4, 3, 4, 4, 4, 4, 4, 3, 2, 3, 4, 0, 4, 3, 4, 0, 0, 3, 3, 0, 3, 3, 0, 2, 3, 4, 4, 3, 4, 3, 4, 3, 3, 3, 2, 4, 4, 3, 3, 3, 4, 0, 4, 0, 0, 4, 2, 4, 0, 3, 4, 4, 0, 2, 4, 3, 2, 0, 0, 3, 4, 3, 4, 4, 0, 2, 0, 4, 3, 0, 2, 0, 0, 2, 0, 0, 0, 4, 0, 0, 2, 4, 4, 0, 0, 3, 2, 4, 4, 0, 3, 4, 4, 3, 2, 0, 3, 0, 4, 2, 4, 4, 4, 0, 3, 3, 0, 4, 3, 4, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.95      0.82       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.79      0.84       100\n",
      "           3       0.69      0.94      0.79       100\n",
      "           4       0.59      0.83      0.69       100\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.58      0.70      0.63       500\n",
      "weighted avg       0.58      0.70      0.63       500\n",
      "\n",
      "Val loss: 1.2037918418645859, Val acc: 0.702\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53100 - Batch 68/1894 - Train loss: 1.0102140151936074, Train acc: 0.8935688405797102\n",
      "Iteration 53200 - Batch 168/1894 - Train loss: 1.0110929146320862, Train acc: 0.8923816568047337\n",
      "Iteration 53300 - Batch 268/1894 - Train loss: 1.0140076988691733, Train acc: 0.8903345724907064\n",
      "Iteration 53400 - Batch 368/1894 - Train loss: 1.0152187725392783, Train acc: 0.8888888888888888\n",
      "Iteration 53500 - Batch 468/1894 - Train loss: 1.0150852418149203, Train acc: 0.8890591684434968\n",
      "Iteration 53600 - Batch 568/1894 - Train loss: 1.0178227104076392, Train acc: 0.8860391036906854\n",
      "Iteration 53700 - Batch 668/1894 - Train loss: 1.0181787720531983, Train acc: 0.8856969357249627\n",
      "Iteration 53800 - Batch 768/1894 - Train loss: 1.017946817319942, Train acc: 0.885890767230169\n",
      "Iteration 53900 - Batch 868/1894 - Train loss: 1.0188991888345866, Train acc: 0.8849611622554661\n",
      "Iteration 54000 - Batch 968/1894 - Train loss: 1.0190198835450675, Train acc: 0.8849974200206399\n",
      "Iteration 54100 - Batch 1068/1894 - Train loss: 1.0183077067610702, Train acc: 0.885757717492984\n",
      "Iteration 54200 - Batch 1168/1894 - Train loss: 1.0195356951094368, Train acc: 0.8844632164242943\n",
      "Iteration 54300 - Batch 1268/1894 - Train loss: 1.0192170738234494, Train acc: 0.884801024428684\n",
      "Iteration 54400 - Batch 1368/1894 - Train loss: 1.019946489915785, Train acc: 0.8840622717311907\n",
      "Iteration 54500 - Batch 1468/1894 - Train loss: 1.0201395384059462, Train acc: 0.8838495575221239\n",
      "Iteration 54600 - Batch 1568/1894 - Train loss: 1.0202949975538285, Train acc: 0.8836838750796686\n",
      "Iteration 54700 - Batch 1668/1894 - Train loss: 1.0201984549297267, Train acc: 0.8838189035350509\n",
      "Iteration 54800 - Batch 1768/1894 - Train loss: 1.0198786443340502, Train acc: 0.8841859807801018\n",
      "Iteration 54900 - Batch 1868/1894 - Train loss: 1.0196456129439952, Train acc: 0.8844803370786517\n",
      "[1, 4, 4, 1, 0, 1, 2, 1, 3, 3, 4, 0, 3, 4, 4, 1, 4, 2, 2, 0, 2, 4, 0, 3, 0, 0, 0, 0, 2, 1, 0, 4, 2, 0, 0, 1, 0, 1, 1, 2, 4, 1, 3, 2, 3, 0, 1, 4, 3, 3, 2, 2, 4, 0, 4, 3, 3, 2, 2, 4, 1, 3, 3, 3, 2, 3, 0, 4, 1, 2, 0, 2, 2, 1, 0, 4, 1, 1, 4, 4, 4, 0, 4, 2, 4, 2, 4, 0, 2, 1, 4, 1, 2, 3, 1, 0, 0, 3, 0, 0, 4, 1, 1, 0, 0, 4, 1, 2, 3, 0, 0, 4, 3, 4, 1, 0, 0, 3, 2, 4, 3, 1, 3, 0, 0, 3, 0, 0, 4, 3, 3, 2, 1, 3, 0, 1, 0, 4, 2, 3, 3, 2, 1, 2, 2, 4, 2, 1, 3, 2, 4, 0, 0, 2, 4, 2, 1, 1, 1, 4, 0, 2, 0, 2, 0, 2, 1, 1, 2, 3, 1, 4, 0, 3, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 1, 1, 2, 2, 4, 2, 4, 2, 0, 4, 2, 4, 3, 1, 1, 4, 4, 1, 2, 1, 4, 3, 0, 1, 4, 3, 1, 4, 3, 4, 3, 1, 0, 3, 1, 3, 3, 0, 1, 3, 4, 1, 3, 1, 1, 4, 0, 1, 4, 1, 2, 1, 3, 3, 4, 4, 1, 1, 2, 2, 4, 0, 3, 4, 0, 3, 4, 4, 3, 3, 0, 3, 1, 4, 4, 1, 0, 0, 3, 3, 2, 3, 0, 1, 3, 3, 0, 3, 0, 2, 2, 3, 3, 2, 0, 3, 1, 0, 2, 3, 3, 0, 3, 3, 4, 0, 3, 2, 4, 3, 3, 2, 0, 4, 4, 4, 3, 1, 4, 4, 3, 2, 0, 1, 1, 2, 0, 1, 2, 2, 1, 2, 1, 3, 2, 0, 3, 2, 4, 1, 2, 3, 3, 0, 0, 2, 3, 0, 1, 1, 3, 4, 0, 2, 0, 1, 2, 2, 1, 1, 4, 4, 2, 3, 0, 2, 2, 1, 1, 0, 2, 3, 1, 4, 4, 4, 4, 1, 4, 3, 2, 3, 3, 0, 2, 0, 4, 0, 0, 3, 0, 0, 4, 3, 2, 1, 3, 3, 0, 3, 3, 2, 2, 2, 1, 4, 0, 3, 1, 4, 4, 1, 0, 3, 1, 1, 3, 1, 1, 0, 0, 3, 2, 0, 3, 0, 0, 3, 0, 2, 1, 2, 0, 2, 0, 1, 4, 3, 3, 2, 1, 2, 3, 1, 0, 0, 2, 0, 0, 2, 4, 1, 1, 1, 1, 1, 2, 0, 3, 3, 0, 4, 4, 2, 2, 4, 2, 1, 3, 4, 3, 4, 0, 1, 0, 4, 1, 4, 2, 4, 1, 4, 1, 3, 4, 3, 4, 4, 2, 2, 1, 4, 4, 4, 3, 3, 0, 2, 2, 0, 2, 4, 4, 3, 0, 2, 1, 4, 1, 0, 1, 0, 1, 4, 0, 2]\n",
      "[3, 4, 4, 0, 0, 0, 2, 0, 3, 3, 4, 0, 3, 4, 4, 4, 4, 0, 2, 0, 2, 4, 0, 3, 0, 0, 0, 0, 2, 4, 0, 4, 2, 0, 0, 4, 0, 3, 4, 2, 4, 4, 3, 2, 3, 0, 2, 4, 3, 3, 2, 2, 4, 0, 4, 3, 3, 2, 2, 4, 3, 3, 3, 3, 2, 3, 0, 4, 4, 0, 0, 2, 0, 4, 4, 4, 3, 4, 4, 4, 4, 0, 4, 0, 4, 2, 4, 0, 2, 4, 4, 3, 2, 3, 4, 0, 0, 3, 0, 0, 4, 4, 0, 0, 0, 4, 4, 2, 4, 0, 0, 4, 3, 4, 4, 0, 0, 3, 2, 4, 3, 4, 3, 0, 0, 3, 0, 0, 4, 3, 3, 2, 3, 3, 0, 4, 0, 4, 2, 3, 3, 2, 3, 2, 2, 4, 2, 4, 3, 3, 2, 0, 0, 2, 4, 2, 3, 0, 0, 4, 0, 2, 0, 2, 0, 2, 0, 4, 0, 4, 4, 4, 0, 3, 2, 2, 4, 2, 2, 0, 4, 2, 4, 2, 4, 3, 2, 2, 4, 0, 4, 2, 0, 4, 2, 4, 3, 4, 4, 4, 4, 0, 2, 3, 4, 3, 0, 0, 4, 3, 3, 4, 4, 4, 3, 4, 0, 3, 4, 3, 3, 0, 2, 3, 4, 4, 3, 3, 0, 4, 0, 4, 4, 4, 2, 4, 3, 3, 4, 4, 0, 4, 2, 2, 3, 0, 3, 4, 0, 0, 4, 3, 3, 3, 0, 3, 4, 4, 4, 4, 2, 0, 3, 3, 0, 3, 0, 4, 3, 3, 0, 3, 0, 2, 2, 3, 3, 2, 0, 3, 4, 0, 0, 3, 3, 0, 3, 3, 2, 0, 4, 0, 4, 3, 3, 2, 0, 4, 4, 4, 3, 0, 4, 4, 3, 2, 0, 3, 0, 2, 0, 3, 0, 2, 3, 2, 4, 3, 2, 0, 3, 2, 3, 0, 2, 2, 3, 0, 0, 2, 3, 0, 3, 0, 3, 4, 0, 2, 0, 3, 2, 0, 3, 0, 4, 4, 2, 3, 0, 2, 2, 4, 4, 0, 2, 3, 3, 4, 4, 4, 4, 3, 4, 3, 2, 3, 3, 0, 2, 0, 4, 0, 0, 3, 0, 0, 4, 3, 2, 3, 3, 3, 0, 3, 3, 0, 0, 2, 0, 3, 4, 3, 4, 4, 4, 3, 0, 3, 2, 2, 3, 4, 4, 0, 0, 4, 4, 0, 3, 0, 0, 4, 0, 2, 0, 2, 0, 2, 0, 0, 4, 3, 3, 2, 3, 2, 3, 3, 0, 4, 2, 0, 0, 0, 4, 4, 0, 3, 4, 4, 2, 0, 3, 3, 0, 4, 4, 2, 2, 4, 0, 2, 3, 4, 3, 4, 0, 3, 0, 0, 4, 4, 2, 4, 4, 4, 0, 3, 4, 3, 4, 4, 2, 2, 3, 4, 4, 4, 4, 3, 0, 2, 2, 2, 0, 4, 4, 3, 0, 2, 4, 4, 4, 0, 4, 0, 4, 4, 0, 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.89      0.81      0.85       100\n",
      "           3       0.74      0.91      0.82       100\n",
      "           4       0.62      0.93      0.74       100\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.59      0.72      0.64       500\n",
      "weighted avg       0.59      0.72      0.64       500\n",
      "\n",
      "Val loss: 1.1811149194836617, Val acc: 0.72\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 55000 - Batch 74/1894 - Train loss: 1.017685091495514, Train acc: 0.8866666666666667\n",
      "Iteration 55100 - Batch 174/1894 - Train loss: 1.0152654361724853, Train acc: 0.88875\n",
      "Iteration 55200 - Batch 274/1894 - Train loss: 1.0148640019243413, Train acc: 0.889090909090909\n",
      "Iteration 55300 - Batch 374/1894 - Train loss: 1.014762440363566, Train acc: 0.8891666666666667\n",
      "Iteration 55400 - Batch 474/1894 - Train loss: 1.014410157078191, Train acc: 0.8893421052631579\n",
      "Iteration 55500 - Batch 574/1894 - Train loss: 1.013947332734647, Train acc: 0.8898369565217391\n",
      "Iteration 55600 - Batch 674/1894 - Train loss: 1.013669489313055, Train acc: 0.8901851851851852\n",
      "Iteration 55700 - Batch 774/1894 - Train loss: 1.0141075457296065, Train acc: 0.8897177419354839\n",
      "Iteration 55800 - Batch 874/1894 - Train loss: 1.0150536831447057, Train acc: 0.8888571428571429\n",
      "Iteration 55900 - Batch 974/1894 - Train loss: 1.0156726932525635, Train acc: 0.8880769230769231\n",
      "Iteration 56000 - Batch 1074/1894 - Train loss: 1.0163030247910079, Train acc: 0.8875872093023256\n",
      "Iteration 56100 - Batch 1174/1894 - Train loss: 1.0167931243206592, Train acc: 0.8870212765957447\n",
      "Iteration 56200 - Batch 1274/1894 - Train loss: 1.0175695984036315, Train acc: 0.88625\n",
      "Iteration 56300 - Batch 1374/1894 - Train loss: 1.0173404633782126, Train acc: 0.8865\n",
      "Iteration 56400 - Batch 1474/1894 - Train loss: 1.0172136152800868, Train acc: 0.8866101694915254\n",
      "Iteration 56500 - Batch 1574/1894 - Train loss: 1.0178273895430185, Train acc: 0.8860119047619047\n",
      "Iteration 56600 - Batch 1674/1894 - Train loss: 1.0185812608519598, Train acc: 0.885223880597015\n",
      "Iteration 56700 - Batch 1774/1894 - Train loss: 1.0184722466871772, Train acc: 0.8853521126760563\n",
      "Iteration 56800 - Batch 1874/1894 - Train loss: 1.0182404855728149, Train acc: 0.8855666666666666\n",
      "[0, 0, 2, 1, 3, 3, 0, 2, 0, 3, 0, 1, 3, 2, 2, 1, 2, 3, 1, 4, 0, 1, 1, 0, 1, 4, 0, 4, 4, 0, 2, 2, 4, 4, 1, 1, 0, 3, 4, 2, 1, 3, 3, 1, 0, 0, 1, 1, 0, 0, 4, 1, 0, 1, 1, 4, 0, 2, 2, 0, 4, 1, 4, 1, 1, 2, 0, 4, 3, 1, 4, 1, 3, 3, 4, 4, 0, 0, 0, 2, 0, 1, 0, 0, 4, 2, 4, 0, 4, 2, 4, 2, 3, 3, 4, 2, 3, 0, 1, 4, 2, 2, 2, 0, 1, 4, 2, 1, 2, 1, 0, 3, 1, 3, 1, 4, 0, 4, 4, 1, 3, 4, 3, 2, 2, 0, 0, 4, 2, 2, 2, 4, 3, 0, 2, 3, 4, 1, 4, 1, 0, 4, 4, 3, 3, 0, 2, 4, 3, 2, 1, 4, 3, 2, 3, 0, 4, 3, 0, 1, 4, 3, 1, 2, 2, 1, 2, 3, 0, 2, 2, 1, 0, 3, 0, 3, 4, 1, 1, 0, 2, 4, 0, 2, 2, 3, 0, 0, 0, 2, 4, 3, 3, 3, 2, 3, 3, 0, 3, 0, 3, 3, 3, 1, 1, 2, 2, 1, 0, 3, 3, 2, 1, 3, 4, 3, 0, 3, 2, 3, 4, 4, 4, 1, 3, 1, 2, 0, 2, 1, 2, 4, 0, 1, 3, 2, 3, 3, 2, 3, 2, 1, 1, 3, 4, 4, 0, 2, 2, 2, 2, 3, 2, 1, 4, 4, 2, 0, 2, 4, 1, 2, 2, 3, 1, 1, 3, 4, 3, 0, 0, 1, 4, 2, 1, 0, 1, 4, 0, 1, 2, 3, 0, 3, 1, 3, 2, 3, 1, 4, 1, 4, 2, 0, 0, 3, 2, 4, 2, 2, 1, 4, 4, 3, 4, 1, 0, 0, 1, 2, 1, 0, 2, 0, 4, 2, 2, 2, 4, 4, 4, 0, 0, 3, 1, 1, 3, 1, 0, 1, 3, 4, 3, 1, 3, 4, 2, 4, 4, 4, 0, 4, 4, 0, 2, 4, 4, 4, 4, 0, 3, 3, 4, 0, 0, 2, 0, 0, 4, 3, 3, 4, 0, 2, 1, 3, 1, 0, 2, 0, 4, 0, 4, 1, 1, 3, 4, 3, 4, 4, 0, 4, 1, 0, 2, 1, 3, 1, 0, 3, 1, 2, 0, 2, 1, 2, 3, 1, 3, 4, 0, 3, 4, 4, 1, 0, 3, 2, 0, 3, 2, 3, 2, 0, 4, 0, 2, 0, 1, 0, 2, 3, 3, 2, 1, 0, 4, 1, 4, 1, 3, 3, 1, 1, 3, 4, 0, 0, 4, 2, 2, 0, 3, 1, 4, 2, 1, 0, 4, 0, 1, 3, 0, 4, 2, 2, 2, 4, 1, 4, 3, 2, 2, 1, 0, 0, 1, 1, 3, 2, 3, 2, 3, 0, 4, 3, 3, 3, 4, 2, 3, 3, 3, 2, 2, 3, 2, 4, 1, 1, 1, 4, 1, 0, 1, 1, 1, 1, 4, 0]\n",
      "[0, 0, 2, 0, 3, 3, 0, 0, 0, 3, 0, 4, 3, 2, 2, 4, 2, 3, 0, 0, 0, 4, 2, 0, 4, 4, 2, 3, 4, 0, 2, 2, 4, 4, 0, 0, 0, 3, 4, 2, 2, 3, 3, 4, 0, 0, 3, 4, 4, 0, 4, 4, 0, 3, 0, 4, 0, 2, 2, 0, 4, 0, 4, 4, 2, 2, 0, 4, 3, 0, 4, 4, 3, 3, 4, 4, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 4, 4, 4, 3, 4, 0, 3, 3, 4, 2, 3, 0, 0, 4, 2, 2, 2, 0, 4, 4, 2, 4, 2, 4, 0, 3, 3, 3, 4, 4, 0, 4, 3, 4, 3, 3, 3, 2, 2, 0, 2, 4, 2, 2, 2, 4, 3, 0, 2, 3, 4, 0, 4, 0, 0, 4, 4, 3, 3, 0, 2, 4, 3, 2, 4, 4, 4, 2, 3, 0, 4, 4, 0, 3, 4, 3, 4, 0, 2, 3, 2, 3, 0, 2, 2, 3, 0, 3, 0, 3, 4, 4, 0, 0, 0, 4, 0, 0, 2, 3, 0, 0, 0, 2, 3, 3, 3, 3, 2, 3, 3, 0, 3, 0, 3, 3, 3, 4, 4, 2, 2, 4, 0, 3, 3, 2, 4, 3, 4, 3, 0, 3, 2, 3, 4, 4, 4, 4, 3, 4, 0, 0, 2, 4, 2, 2, 0, 4, 3, 2, 3, 3, 0, 3, 2, 3, 4, 3, 4, 4, 0, 2, 2, 2, 2, 3, 2, 3, 4, 4, 2, 0, 2, 4, 3, 0, 2, 3, 3, 4, 3, 4, 3, 0, 0, 3, 4, 2, 0, 0, 3, 4, 0, 4, 2, 3, 0, 3, 0, 4, 2, 3, 0, 4, 4, 4, 2, 0, 0, 3, 2, 4, 0, 0, 4, 4, 4, 3, 3, 4, 0, 0, 4, 2, 2, 0, 2, 0, 4, 2, 2, 0, 4, 4, 4, 0, 0, 3, 3, 0, 4, 4, 0, 4, 3, 4, 3, 0, 3, 4, 2, 2, 4, 4, 0, 4, 4, 0, 2, 4, 4, 4, 4, 0, 4, 3, 4, 0, 0, 2, 0, 0, 4, 3, 3, 0, 0, 2, 4, 4, 4, 0, 0, 0, 4, 4, 4, 3, 4, 3, 4, 3, 4, 3, 0, 4, 4, 0, 2, 3, 3, 0, 0, 3, 3, 2, 2, 2, 3, 2, 3, 0, 3, 4, 0, 2, 4, 4, 0, 0, 3, 2, 0, 3, 3, 3, 2, 0, 4, 0, 0, 0, 0, 0, 2, 3, 3, 2, 3, 0, 4, 0, 4, 0, 3, 3, 3, 3, 3, 4, 0, 0, 4, 2, 2, 0, 3, 0, 4, 0, 4, 0, 4, 0, 3, 3, 0, 4, 2, 2, 2, 4, 4, 4, 3, 3, 0, 0, 0, 0, 3, 3, 0, 2, 3, 2, 3, 0, 4, 3, 3, 3, 4, 2, 3, 3, 3, 2, 2, 2, 0, 4, 4, 3, 4, 4, 4, 0, 4, 4, 4, 4, 4, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79       100\n",
      "           1       0.00      0.00      0.00       100\n",
      "           2       0.88      0.81      0.84       100\n",
      "           3       0.73      0.91      0.81       100\n",
      "           4       0.61      0.89      0.73       100\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.58      0.71      0.63       500\n",
      "weighted avg       0.58      0.71      0.63       500\n",
      "\n",
      "Val loss: 1.1974427476525307, Val acc: 0.71\n",
      "Tiempo total de entrenamiento: 759.8896 [s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nfierroflo/anaconda3/envs/gans/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader,val_loader=get_training_loaders(synthetic_SN=fake_wgangp.detach().cpu(),batch_size=32,file_name=\"stamp_dataset_only_images_63.pkl\",label_as_strings=True)\n",
    "print(torch.bincount(train_loader.dataset.labels.to(torch.int)))\n",
    "curves=trainer(train_loader,val_loader,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
